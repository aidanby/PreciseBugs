{"buggy_code": ["#!/usr/bin/python3 -OO\n# Copyright 2007-2023 The SABnzbd-Team <team@sabnzbd.org>\n#\n# This program is free software; you can redistribute it and/or\n# modify it under the terms of the GNU General Public License\n# as published by the Free Software Foundation; either version 2\n# of the License, or (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n\n\"\"\"\nsabnzbd.newsunpack\n\"\"\"\n\nimport os\nimport sys\nimport re\nimport subprocess\nimport logging\nimport time\nimport io\nimport shutil\nimport functools\nfrom typing import Tuple, List, BinaryIO, Optional, Dict, Any, Union\n\nimport sabnzbd\nfrom sabnzbd.encoding import correct_unknown_encoding, ubtou\nimport sabnzbd.utils.rarfile as rarfile\nfrom sabnzbd.misc import (\n    format_time_string,\n    find_on_path,\n    int_conv,\n    get_all_passwords,\n    calc_age,\n    cmp,\n    run_command,\n    build_and_run_command,\n    format_time_left,\n)\nfrom sabnzbd.filesystem import (\n    make_script_path,\n    real_path,\n    globber,\n    globber_full,\n    renamer,\n    clip_path,\n    long_path,\n    remove_file,\n    listdir_full,\n    setname_from_path,\n    get_ext,\n    TS_RE,\n    build_filelists,\n    get_filename,\n    SEVENMULTI_RE,\n    is_size,\n)\nfrom sabnzbd.nzbstuff import NzbObject\nimport sabnzbd.cfg as cfg\nfrom sabnzbd.constants import Status, JOB_ADMIN\nfrom sabnzbd.sorting import Sorter\n\n# Regex globals\nRAR_V3_RE = re.compile(r\"\\.(?P<ext>part\\d*)$\", re.I)\nRAR_EXTRACTFROM_RE = re.compile(r\"^Extracting\\sfrom\\s(.+)\")\nRAR_EXTRACTED_RE = re.compile(r\"^(Extracting|Creating|...)\\s+(.*?)\\s+OK\\s*$\")\nSEVENZIP_PATH_RE = re.compile(\"^Path = (.+)\")\nPAR2_TARGET_RE = re.compile(r'^(?:File|Target): \"(.+)\" -')\nPAR2_BLOCK_FOUND_RE = re.compile(r'File: \"([^\"]+)\" - found \\d+ of \\d+ data blocks from \"([^\"]+)\"')\nPAR2_IS_MATCH_FOR_RE = re.compile(r'File: \"([^\"]+)\" - is a match for \"([^\"]+)\"')\nPAR2_FILENAME_RE = re.compile(r'\"([^\"]+)\"')\n\n# Constants\nSEVENZIP_ID = b\"7z\\xbc\\xaf'\\x1c\"\nPAR2_COMMAND = None\nMULTIPAR_COMMAND = None\nRAR_COMMAND = None\nNICE_COMMAND = None\nZIP_COMMAND = None\nSEVENZIP_COMMAND = None\nIONICE_COMMAND = None\nRAR_PROBLEM = False\nPAR2_MT = True\nRAR_VERSION = 0\nSEVENZIP_VERSION = \"\"\n\n\ndef find_programs(curdir: str):\n    \"\"\"Find external programs\"\"\"\n\n    def check(path: str, program: str) -> Optional[str]:\n        p = os.path.abspath(os.path.join(path, program))\n        if os.access(p, os.X_OK):\n            return p\n        else:\n            return None\n\n    if sabnzbd.MACOS:\n        if sabnzbd.MACOSARM64:\n            # M1 (ARM64) versions\n            sabnzbd.newsunpack.PAR2_COMMAND = check(curdir, \"osx/par2/arm64/par2\")\n            sabnzbd.newsunpack.RAR_COMMAND = check(curdir, \"osx/unrar/arm64/unrar\")\n        else:\n            # Regular x64 versions\n            sabnzbd.newsunpack.PAR2_COMMAND = check(curdir, \"osx/par2/par2-sl64\")\n            sabnzbd.newsunpack.RAR_COMMAND = check(curdir, \"osx/unrar/unrar\")\n        # The 7zip binary is universal2\n        sabnzbd.newsunpack.SEVENZIP_COMMAND = check(curdir, \"osx/7zip/7zz\")\n\n    if sabnzbd.WIN32:\n        if sabnzbd.WIN64:\n            # 64 bit versions\n            sabnzbd.newsunpack.MULTIPAR_COMMAND = check(curdir, \"win/multipar/par2j64.exe\")\n            sabnzbd.newsunpack.RAR_COMMAND = check(curdir, \"win/unrar/x64/UnRAR.exe\")\n        else:\n            # 32 bit versions\n            sabnzbd.newsunpack.MULTIPAR_COMMAND = check(curdir, \"win/multipar/par2j.exe\")\n            sabnzbd.newsunpack.RAR_COMMAND = check(curdir, \"win/unrar/UnRAR.exe\")\n        # We just use the 32 bit version\n        sabnzbd.newsunpack.SEVENZIP_COMMAND = check(curdir, \"win/7zip/7za.exe\")\n    else:\n        if not sabnzbd.newsunpack.PAR2_COMMAND:\n            sabnzbd.newsunpack.PAR2_COMMAND = find_on_path(\"par2\")\n        if not sabnzbd.newsunpack.RAR_COMMAND:\n            sabnzbd.newsunpack.RAR_COMMAND = find_on_path(\n                (\n                    \"unrar\",\n                    \"rar\",\n                    \"unrar3\",\n                    \"rar3\",\n                )\n            )\n        sabnzbd.newsunpack.NICE_COMMAND = find_on_path(\"nice\")\n        sabnzbd.newsunpack.IONICE_COMMAND = find_on_path(\"ionice\")\n        if not sabnzbd.newsunpack.ZIP_COMMAND:\n            sabnzbd.newsunpack.ZIP_COMMAND = find_on_path(\"unzip\")\n        if not sabnzbd.newsunpack.SEVENZIP_COMMAND:\n            sabnzbd.newsunpack.SEVENZIP_COMMAND = find_on_path(\"7za\")  # 7za = 7z stand-alone executable\n        if not sabnzbd.newsunpack.SEVENZIP_COMMAND:\n            sabnzbd.newsunpack.SEVENZIP_COMMAND = find_on_path(\"7z\")\n\n    if not (sabnzbd.WIN32 or sabnzbd.MACOS):\n        # Run check on rar version\n        version, original = unrar_check(sabnzbd.newsunpack.RAR_COMMAND)\n        sabnzbd.newsunpack.RAR_PROBLEM = not original or version < sabnzbd.constants.REC_RAR_VERSION\n        sabnzbd.newsunpack.RAR_VERSION = version\n\n        # Run check on 7zip\n        sabnzbd.newsunpack.SEVENZIP_VERSION = sevenzip_check(sabnzbd.newsunpack.SEVENZIP_COMMAND)\n\n        # Run check on par2-multicore\n        sabnzbd.newsunpack.PAR2_MT = par2_mt_check(sabnzbd.newsunpack.PAR2_COMMAND)\n\n    # Set the path for rarfile\n    rarfile.UNRAR_TOOL = sabnzbd.newsunpack.RAR_COMMAND\n\n\nENV_NZO_FIELDS = [\n    \"bytes\",\n    \"bytes_downloaded\",\n    \"bytes_tried\",\n    \"cat\",\n    \"correct_password\",\n    \"duplicate\",\n    \"encrypted\",\n    \"fail_msg\",\n    \"filename\",\n    \"final_name\",\n    \"group\",\n    \"nzo_id\",\n    \"oversized\",\n    \"password\",\n    \"pp\",\n    \"priority\",\n    \"repair\",\n    \"script\",\n    \"status\",\n    \"unpack\",\n    \"unwanted_ext\",\n    \"url\",\n]\n\n\ndef external_processing(\n    extern_proc: str, nzo: NzbObject, complete_dir: str, nicename: str, status: int\n) -> Tuple[str, int]:\n    \"\"\"Run a user postproc script, return console output and exit value\"\"\"\n    failure_url = nzo.nzo_info.get(\"failure\", \"\")\n    # Items can be bool or null, causing POpen to fail\n    command = [\n        str(extern_proc),\n        str(complete_dir),\n        str(nzo.filename),\n        str(nicename),\n        \"\",\n        str(nzo.cat),\n        str(nzo.group),\n        str(status),\n        str(failure_url),\n    ]\n\n    # Add path to original NZB\n    nzb_paths = globber_full(nzo.admin_path, \"*.gz\")\n\n    # Fields not in the NZO directly\n    extra_env_fields = {\n        \"failure_url\": failure_url,\n        \"complete_dir\": complete_dir,\n        \"pp_status\": status,\n        \"download_time\": nzo.nzo_info.get(\"download_time\", \"\"),\n        \"avg_bps\": int(nzo.avg_bps_total / nzo.avg_bps_freq) if nzo.avg_bps_freq else 0,\n        \"age\": calc_age(nzo.avg_date),\n        \"orig_nzb_gz\": clip_path(nzb_paths[0]) if nzb_paths else \"\",\n    }\n\n    # Make sure that if we run a Python script it's output is unbuffered, so we can show it to the user\n    if extern_proc.endswith(\".py\"):\n        extra_env_fields[\"pythonunbuffered\"] = True\n\n    try:\n        p = build_and_run_command(command, env=create_env(nzo, extra_env_fields))\n        sabnzbd.PostProcessor.external_process = p\n\n        # Follow the output, so we can abort it\n        lines = []\n        while 1:\n            line = p.stdout.readline()\n            if not line:\n                break\n            line = line.strip()\n            lines.append(line)\n\n            # Show current line in history\n            nzo.set_action_line(T(\"Running script\"), line)\n    except:\n        logging.debug(\"Failed script %s, Traceback: \", extern_proc, exc_info=True)\n        return \"Cannot run script %s\\r\\n\" % extern_proc, -1\n\n    output = \"\\n\".join(lines)\n    ret = p.wait()\n    return output, ret\n\n\ndef unpacker(\n    nzo: NzbObject,\n    workdir_complete: str,\n    one_folder: bool,\n    joinables: List[str] = [],\n    zips: List[str] = [],\n    rars: List[str] = [],\n    sevens: List[str] = [],\n    ts: List[str] = [],\n    depth: int = 0,\n) -> Tuple[Union[int, bool], List[str]]:\n    \"\"\"Do a recursive unpack from all archives in 'download_path' to 'workdir_complete'\"\"\"\n    if depth > 5:\n        logging.warning(T(\"Unpack nesting too deep [%s]\"), nzo.final_name)\n        return False, []\n    depth += 1\n\n    if depth == 1:\n        # First time, ignore anything in workdir_complete\n        xjoinables, xzips, xrars, xsevens, xts = build_filelists(nzo.download_path)\n    else:\n        xjoinables, xzips, xrars, xsevens, xts = build_filelists(\n            nzo.download_path, workdir_complete, check_both=nzo.delete\n        )\n\n    force_rerun = False\n    newfiles = []\n    error = None\n    new_joins = new_ts = None\n\n    if cfg.enable_filejoin():\n        new_joins = [jn for jn in xjoinables if jn not in joinables]\n        if new_joins:\n            logging.info(\"Filejoin starting on %s\", nzo.download_path)\n            error, newf = file_join(nzo, workdir_complete, new_joins)\n            if newf:\n                newfiles.extend(newf)\n            logging.info(\"Filejoin finished on %s\", nzo.download_path)\n\n    if cfg.enable_unrar():\n        new_rars = [rar for rar in xrars if rar not in rars]\n        if new_rars:\n            logging.info(\"Unrar starting on %s\", nzo.download_path)\n            error, newf = rar_unpack(nzo, workdir_complete, one_folder, new_rars)\n            if newf:\n                newfiles.extend(newf)\n            logging.info(\"Unrar finished on %s\", nzo.download_path)\n\n    if cfg.enable_7zip():\n        new_sevens = [seven for seven in xsevens if seven not in sevens]\n        if new_sevens:\n            logging.info(\"7za starting on %s\", nzo.download_path)\n            error, newf = unseven(nzo, workdir_complete, one_folder, new_sevens)\n            if newf:\n                newfiles.extend(newf)\n            logging.info(\"7za finished on %s\", nzo.download_path)\n\n    if cfg.enable_unzip():\n        new_zips = [zipfile for zipfile in xzips if zipfile not in zips]\n        if new_zips:\n            logging.info(\"Unzip starting on %s\", nzo.download_path)\n            if SEVENZIP_COMMAND:\n                error, newf = unseven(nzo, workdir_complete, one_folder, new_zips)\n            else:\n                error, newf = unzip(nzo, workdir_complete, one_folder, new_zips)\n            if newf:\n                newfiles.extend(newf)\n            logging.info(\"Unzip finished on %s\", nzo.download_path)\n\n    if cfg.enable_tsjoin():\n        new_ts = [_ts for _ts in xts if _ts not in ts]\n        if new_ts:\n            logging.info(\"TS Joining starting on %s\", nzo.download_path)\n            error, newf = file_join(nzo, workdir_complete, new_ts)\n            if newf:\n                newfiles.extend(newf)\n            logging.info(\"TS Joining finished on %s\", nzo.download_path)\n\n    # Refresh history and set output\n    nzo.set_action_line()\n\n    # Only re-run if something was unpacked and it was success\n    rerun = error in (False, 0)\n\n    # During a Retry we might miss files in the complete folder\n    # that failed during recursive unpack in the first run\n    if nzo.reuse and depth == 1 and any(build_filelists(workdir=None, workdir_complete=workdir_complete)):\n        rerun = True\n\n    # We can't recursive unpack on long paths on Windows\n    # See: https://github.com/sabnzbd/sabnzbd/pull/771\n    if sabnzbd.WIN32 and len(workdir_complete) > 256:\n        rerun = False\n\n    # Double-check that we didn't miss any files in workdir\n    # But only if dele=True, otherwise of course there will be files left\n    if rerun and nzo.delete and depth == 1 and any(build_filelists(nzo.download_path)):\n        force_rerun = True\n        # Clear lists to force re-scan of files\n        xjoinables, xzips, xrars, xsevens, xts = ([], [], [], [], [])\n\n    if rerun and (cfg.enable_recursive() or new_ts or new_joins or force_rerun):\n        z, y = unpacker(nzo, workdir_complete, one_folder, xjoinables, xzips, xrars, xsevens, xts, depth)\n        if z:\n            error = z\n        if y:\n            newfiles.extend(y)\n\n    return error, newfiles\n\n\n##############################################################################\n# Filejoin Functions\n##############################################################################\ndef match_ts(file: str) -> Tuple[str, int]:\n    \"\"\"Return True if file is a joinable TS file\"\"\"\n    match = TS_RE.search(file)\n    if not match:\n        return \"\", 0\n\n    num = int(match.group(1))\n    try:\n        setname = file[: match.start()]\n        setname += \".ts\"\n    except:\n        setname = \"\"\n    return setname, num\n\n\ndef clean_up_joinables(names: List[str]):\n    \"\"\"Remove joinable files and their .1 backups\"\"\"\n    for name in names:\n        if os.path.exists(name):\n            try:\n                remove_file(name)\n            except:\n                pass\n        name1 = name + \".1\"\n        if os.path.exists(name1):\n            try:\n                remove_file(name1)\n            except:\n                pass\n\n\ndef get_seq_number(name: str) -> int:\n    \"\"\"Return sequence number if name as an int\"\"\"\n    head, tail = os.path.splitext(name)\n    if tail == \".ts\":\n        _, num = match_ts(name)\n    else:\n        num = tail[1:]\n    if num.isdigit():\n        return int(num)\n    else:\n        return 0\n\n\ndef file_join(nzo: NzbObject, workdir_complete: str, joinables: List[str]) -> Tuple[bool, List[str]]:\n    \"\"\"Join and joinable files in 'workdir' to 'workdir_complete' and\n    when successful, delete originals\n    \"\"\"\n    newfiles = []\n    bufsize = 24 * 1024 * 1024\n\n    # Create matching sets from the list of files\n    joinable_sets = {}\n    joinable_set = None\n    for joinable in joinables:\n        head, tail = os.path.splitext(joinable)\n        if tail == \".ts\":\n            head, _ = match_ts(joinable)\n        if head not in joinable_sets:\n            joinable_sets[head] = []\n        joinable_sets[head].append(joinable)\n    logging.debug(\"joinable_sets: %s\", joinable_sets)\n\n    try:\n        # Handle each set\n        for joinable_set in joinable_sets:\n            current = joinable_sets[joinable_set]\n            joinable_sets[joinable_set].sort()\n\n            # If par2 already did the work, just remove the files\n            if os.path.exists(joinable_set):\n                logging.debug(\"file_join(): Skipping %s, (probably) joined by par2\", joinable_set)\n                if nzo.delete:\n                    clean_up_joinables(current)\n                # done, go to next set\n                continue\n\n            # Only join when there is more than one file\n            size = len(current)\n            if size < 2:\n                continue\n\n            # Prepare joined file\n            filename = joinable_set\n            if workdir_complete:\n                filename = filename.replace(nzo.download_path, workdir_complete)\n            logging.debug(\"file_join(): Assembling %s\", filename)\n\n            # Join the segments\n            with open(filename, \"ab\") as joined_file:\n                n = get_seq_number(current[0])\n                seq_error = n > 1\n                for joinable in current:\n                    if get_seq_number(joinable) != n:\n                        seq_error = True\n                    perc = (100.0 / size) * n\n                    logging.debug(\"Processing %s\", joinable)\n                    nzo.set_action_line(T(\"Joining\"), \"%.0f%%\" % perc)\n                    with open(joinable, \"rb\") as f:\n                        shutil.copyfileobj(f, joined_file, bufsize)\n                    if nzo.delete:\n                        remove_file(joinable)\n                    n += 1\n\n            # Remove any remaining .1 files\n            clean_up_joinables(current)\n\n            # Finish up\n            newfiles.append(filename)\n\n            setname = setname_from_path(joinable_set)\n            if seq_error:\n                msg = T(\"Incomplete sequence of joinable files\")\n                nzo.fail_msg = T(\"File join of %s failed\") % setname\n                nzo.set_unpack_info(\"Filejoin\", T('[%s] Error \"%s\" while joining files') % (setname, msg))\n                logging.error(T('Error \"%s\" while running file_join on %s'), msg, nzo.final_name)\n                return True, []\n            else:\n                msg = T(\"[%s] Joined %s files\") % (joinable_set, size)\n                nzo.set_unpack_info(\"Filejoin\", msg, setname)\n    except:\n        msg = sys.exc_info()[1]\n        nzo.fail_msg = T(\"File join of %s failed\") % msg\n        nzo.set_unpack_info(\n            \"Filejoin\", T('[%s] Error \"%s\" while joining files') % (setname_from_path(joinable_set), msg)\n        )\n        logging.error(T('Error \"%s\" while running file_join on %s'), msg, nzo.final_name)\n        return True, []\n\n    return False, newfiles\n\n\n##############################################################################\n# (Un)Rar Functions\n##############################################################################\ndef rar_unpack(nzo: NzbObject, workdir_complete: str, one_folder: bool, rars: List[str]) -> Tuple[int, List[str]]:\n    \"\"\"Unpack multiple sets 'rars' of RAR files from 'download_path' to 'workdir_complete.\n    When 'delete' is set, originals will be deleted.\n    When 'one_folder' is set, all files will be in a single folder\n    \"\"\"\n    fail = 0\n    newfiles = extracted_files = []\n    rar_sets = {}\n    for rar in rars:\n        rar_set = setname_from_path(rar)\n        if RAR_V3_RE.search(rar_set):\n            # Remove the \".partXX\" part\n            rar_set = os.path.splitext(rar_set)[0]\n        if rar_set not in rar_sets:\n            rar_sets[rar_set] = []\n        rar_sets[rar_set].append(rar)\n\n    logging.debug(\"Rar_sets: %s\", rar_sets)\n\n    for rar_set in rar_sets:\n        # Run the RAR extractor\n        rar_sets[rar_set].sort(key=functools.cmp_to_key(rar_sort))\n\n        rarpath = rar_sets[rar_set][0]\n\n        if workdir_complete and rarpath.startswith(nzo.download_path):\n            extraction_path = workdir_complete\n        else:\n            extraction_path = os.path.split(rarpath)[0]\n\n        # Is the direct-unpacker still running? We wait for it\n        if nzo.direct_unpacker:\n            wait_count = 0\n            last_stats = nzo.direct_unpacker.get_formatted_stats()\n            while nzo.direct_unpacker.is_alive():\n                logging.debug(\"DirectUnpacker still alive for %s: %s\", nzo.final_name, last_stats)\n\n                # Bump the file-lock in case it's stuck\n                with nzo.direct_unpacker.next_file_lock:\n                    nzo.direct_unpacker.next_file_lock.notify()\n                time.sleep(2)\n\n                # Did something change? Might be stuck\n                if last_stats == nzo.direct_unpacker.get_formatted_stats():\n                    wait_count += 1\n                    if wait_count > 60:\n                        # We abort after 2 minutes of no changes\n                        nzo.direct_unpacker.abort()\n                else:\n                    wait_count = 0\n                last_stats = nzo.direct_unpacker.get_formatted_stats()\n\n        # Did we already direct-unpack it? Not when recursive-unpacking\n        if nzo.direct_unpacker and rar_set in nzo.direct_unpacker.success_sets:\n            logging.info(\"Set %s completed by DirectUnpack\", rar_set)\n            fail = 0\n            success = True\n            rars, newfiles = nzo.direct_unpacker.success_sets.pop(rar_set)\n        else:\n            logging.info(\"Extracting rarfile %s (belonging to %s) to %s\", rarpath, rar_set, extraction_path)\n            try:\n                fail, newfiles, rars = rar_extract(\n                    rarpath, len(rar_sets[rar_set]), one_folder, nzo, rar_set, extraction_path\n                )\n                success = not fail\n            except:\n                success = False\n                fail = 1\n                msg = sys.exc_info()[1]\n                nzo.fail_msg = T(\"Unpacking failed, %s\") % msg\n                setname = nzo.final_name\n                nzo.set_unpack_info(\"Unpack\", T('[%s] Error \"%s\" while unpacking RAR files') % (setname, msg))\n\n                logging.error(T('Error \"%s\" while running rar_unpack on %s'), msg, setname)\n                logging.debug(\"Traceback: \", exc_info=True)\n\n        if success:\n            logging.debug(\"rar_unpack(): Rars: %s\", rars)\n            logging.debug(\"rar_unpack(): Newfiles: %s\", newfiles)\n            extracted_files.extend(newfiles)\n\n        # Do not fail if this was a recursive unpack\n        if fail and rarpath.startswith(workdir_complete):\n            # Do not delete the files, leave it to user!\n            logging.info(\"Ignoring failure to do recursive unpack of %s\", rarpath)\n            fail = 0\n            success = True\n            newfiles = []\n\n        # Do not fail if this was maybe just some duplicate fileset\n        # Multipar and par2tbb will detect and log them, par2cmdline will not\n        if fail and rar_set.endswith((\".1\", \".2\")):\n            # Just in case, we leave the raw files\n            logging.info(\"Ignoring failure of unpack for possible duplicate file %s\", rarpath)\n            fail = 0\n            success = True\n            newfiles = []\n\n        # Delete the old files if we have to\n        if success and nzo.delete and newfiles:\n            for rar in rars:\n                try:\n                    remove_file(rar)\n                except OSError:\n                    if os.path.exists(rar):\n                        logging.warning(T(\"Deleting %s failed!\"), rar)\n\n                brokenrar = \"%s.1\" % rar\n\n                if os.path.exists(brokenrar):\n                    logging.info(\"Deleting %s\", brokenrar)\n                    try:\n                        remove_file(brokenrar)\n                    except OSError:\n                        if os.path.exists(brokenrar):\n                            logging.warning(T(\"Deleting %s failed!\"), brokenrar)\n\n    return fail, extracted_files\n\n\ndef rar_extract(\n    rarfile_path: str, numrars: int, one_folder: bool, nzo: NzbObject, setname: str, extraction_path: str\n) -> Tuple[int, List[str], List[str]]:\n    \"\"\"Unpack single rar set 'rarfile' to 'extraction_path',\n    with password tries\n    Return fail==0(ok)/fail==1(error)/fail==2(wrong password)/fail==3(crc-error), new_files, rars\n    \"\"\"\n    fail = 0\n    new_files = []\n    rars = []\n    passwords = get_all_passwords(nzo)\n\n    for password in passwords:\n        if password:\n            logging.debug('Trying unrar with password \"%s\"', password)\n            msg = T('Trying unrar with password \"%s\"') % password\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n        fail, new_files, rars = rar_extract_core(\n            rarfile_path, numrars, one_folder, nzo, setname, extraction_path, password\n        )\n        if fail != 2:\n            break\n\n    return fail, new_files, rars\n\n\ndef rar_extract_core(\n    rarfile_path: str, numrars: int, one_folder: bool, nzo: NzbObject, setname: str, extraction_path: str, password: str\n) -> Tuple[int, List[str], List[str]]:\n    \"\"\"Unpack single rar set 'rarfile_path' to 'extraction_path'\n    Return fail==0(ok)/fail==1(error)/fail==2(wrong password)/fail==3(crc-error), new_files, rars\n    \"\"\"\n    start = time.time()\n\n    logging.debug(\"rar_extract(): Extractionpath: %s\", extraction_path)\n\n    if password:\n        password_command = \"-p%s\" % password\n    else:\n        password_command = \"-p-\"\n\n    ############################################################################\n\n    if one_folder or cfg.flat_unpack():\n        action = \"e\"\n    else:\n        action = \"x\"\n    if cfg.overwrite_files():\n        overwrite = \"-o+\"  # Enable overwrite\n        rename = \"-o+\"  # Dummy\n    else:\n        overwrite = \"-o-\"  # Disable overwrite\n        rename = \"-or\"  # Auto renaming\n\n    if sabnzbd.WIN32:\n        # On Windows, UnRar uses a custom argument parser\n        # See: https://github.com/sabnzbd/sabnzbd/issues/1043\n        # The -scf forces the output to be UTF8\n        command = [\n            RAR_COMMAND,\n            action,\n            \"-idp\",\n            \"-scf\",\n            overwrite,\n            rename,\n            \"-ai\",\n            password_command,\n            rarfile_path,\n            \"%s\\\\\" % long_path(extraction_path),\n        ]\n\n    elif RAR_PROBLEM:\n        # Use only oldest options, specifically no \"-or\" or \"-scf\"\n        command = [\n            RAR_COMMAND,\n            action,\n            \"-idp\",\n            overwrite,\n            password_command,\n            rarfile_path,\n            \"%s/\" % extraction_path,\n        ]\n    else:\n        # The -scf forces the output to be UTF8\n        command = [\n            RAR_COMMAND,\n            action,\n            \"-idp\",\n            \"-scf\",\n            overwrite,\n            rename,\n            \"-ai\",\n            password_command,\n            rarfile_path,\n            \"%s/\" % extraction_path,\n        ]\n\n    if cfg.ignore_unrar_dates():\n        command.insert(3, \"-tsm-\")\n\n    # Get list of all the volumes part of this set\n    logging.debug(\"Analyzing rar file ... %s found\", rarfile.is_rarfile(rarfile_path))\n    p = build_and_run_command(command, windows_unrar_command=True)\n    sabnzbd.PostProcessor.external_process = p\n\n    nzo.set_action_line(T(\"Unpacking\"), \"00/%02d\" % numrars)\n\n    # Loop over the output from rar!\n    curr = 0\n    extracted = []\n    rarfiles = []\n    fail = 0\n    inrecovery = False\n    lines = []\n\n    while 1:\n        line = p.stdout.readline()\n        if not line:\n            break\n\n        line = line.strip()\n        lines.append(line)\n\n        if line.startswith(\"Extracting from\"):\n            filename = re.search(RAR_EXTRACTFROM_RE, line).group(1)\n            if filename not in rarfiles:\n                rarfiles.append(filename)\n            curr += 1\n            perc = (curr / numrars) * 100\n            nzo.set_action_line(T(\"Unpacking\"), \"%02d/%02d %s\" % (curr, numrars, add_time_left(perc, start)))\n\n        elif line.find(\"recovery volumes found\") > -1:\n            inrecovery = True  # and thus start ignoring \"Cannot find volume\" for a while\n            logging.debug(\"unrar recovery start: %s\" % line)\n        elif line.startswith(\"Reconstruct\"):\n            # end of reconstruction: 'Reconstructing... 100%' or 'Reconstructing... ' (both success), or 'Reconstruction impossible'\n            inrecovery = False\n            logging.debug(\"unrar recovery result: %s\" % line)\n\n        elif line.startswith(\"Cannot find volume\") and not inrecovery:\n            filename = os.path.basename(line[19:])\n            msg = T(\"Unpacking failed, unable to find %s\") % filename\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 1\n\n        elif line.endswith(\"- CRC failed\"):\n            msg = T(\"Unpacking failed, CRC error\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 2  # Older unrar versions report a wrong password as a CRC error\n\n        elif line.startswith(\"File too large\"):\n            msg = T(\"Unpacking failed, file too large for filesystem (FAT?)\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 1\n\n        elif line.startswith(\"Write error\"):\n            msg = \"%s %s\" % (T(\"Unpacking failed, write error or disk is full?\"), line[11:])\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 1\n\n        elif line.startswith(\"Cannot create\"):\n            line2 = p.stdout.readline()\n            if \"must not exceed 260\" in line2:\n                msg = \"%s: %s\" % (T(\"Unpacking failed, path is too long\"), line[13:])\n            else:\n                msg = \"%s %s\" % (T(\"Unpacking failed, write error or disk is full?\"), line[13:])\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 1\n            # Kill the process (can stay in endless loop on Windows Server)\n            p.kill()\n\n        elif line.startswith(\"ERROR: \"):\n            nzo.fail_msg = line\n            nzo.set_unpack_info(\"Unpack\", line, setname)\n            fail = 1\n\n        elif (\n            \"The specified password is incorrect\" in line\n            or \"Incorrect password\" in line\n            or (\"ncrypted file\" in line and ((\"CRC failed\" in line) or (\"Checksum error\" in line)))\n        ):\n            # unrar 3.x: \"Encrypted file: CRC failed in oLKQfrcNVivzdzSG22a2xo7t001.part1.rar (password incorrect ?)\"\n            # unrar 4.x: \"CRC failed in the encrypted file oLKQfrcNVivzdzSG22a2xo7t001.part1.rar. Corrupt file or wrong password.\"\n            # unrar 5.x: \"Checksum error in the encrypted file oLKQfrcNVivzdzSG22a2xo7t001.part1.rar. Corrupt file or wrong password.\"\n            # unrar 5.01: \"The specified password is incorrect.\"\n            # unrar 5.80: \"Incorrect password for oLKQfrcNVivzdzSG22a2xo7t001.part1.rar\"\n            msg = T(\"Unpacking failed, archive requires a password\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 2\n\n        elif \"is not RAR archive\" in line:\n            # Unrecognizable RAR file\n            msg = T(\"Unusable RAR file\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 3\n\n        elif \"checksum error\" in line or \"Unexpected end of archive\" in line:\n            # Corrupt archive or passworded, we can't know\n            # packed data checksum error in volume FILE\n            msg = T(\"Corrupt RAR file\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 3\n\n        else:\n            m = re.search(RAR_EXTRACTED_RE, line)\n            if m:\n                # In case of flat-unpack, UnRar still prints the whole path (?!)\n                unpacked_file = m.group(2)\n                if cfg.flat_unpack():\n                    unpacked_file = os.path.basename(unpacked_file)\n                extracted.append(real_path(extraction_path, unpacked_file))\n\n        if fail:\n            if p.stdout:\n                p.stdout.close()\n            p.wait()\n            logging.debug(\"UNRAR output %s\", \"\\n\".join(lines))\n            return fail, [], []\n\n    if p.stdout:\n        p.stdout.close()\n    p.wait()\n\n    # Which files did we use to extract this?\n    rarfiles = rar_volumelist(rarfile_path, password, rarfiles)\n\n    logging.debug(\"UNRAR output %s\", \"\\n\".join(lines))\n    msg = T(\"Unpacked %s files/folders in %s\") % (len(extracted), format_time_string(time.time() - start))\n    nzo.set_unpack_info(\"Unpack\", msg, setname)\n    logging.info(msg)\n\n    return 0, extracted, rarfiles\n\n\n##############################################################################\n# (Un)Zip Functions\n##############################################################################\ndef unzip(nzo: NzbObject, workdir_complete: str, one_folder: bool, zips: List[str]):\n    \"\"\"Unpack multiple sets 'zips' of ZIP files from 'download_path' to 'workdir_complete.\n    When 'delete' is ste, originals will be deleted.\n    \"\"\"\n\n    try:\n        i = 0\n        unzip_failed = False\n        tms = time.time()\n\n        # For file-bookkeeping\n        orig_dir_content = listdir_full(workdir_complete)\n\n        for _zip in zips:\n            logging.info(\"Starting extract on zipfile: %s \", _zip)\n            nzo.set_action_line(T(\"Unpacking\"), \"%s\" % setname_from_path(_zip))\n\n            if workdir_complete and _zip.startswith(nzo.download_path):\n                extraction_path = workdir_complete\n            else:\n                extraction_path = os.path.split(_zip)[0]\n\n            if unzip_core(_zip, extraction_path, one_folder):\n                unzip_failed = True\n            else:\n                i += 1\n\n        msg = T(\"%s files in %s\") % (str(i), format_time_string(time.time() - tms))\n        nzo.set_unpack_info(\"Unpack\", msg)\n\n        # What's new? Use symmetric difference\n        new_files = list(set(orig_dir_content) ^ set(listdir_full(workdir_complete)))\n\n        # Delete the old files if we have to\n        if nzo.delete and not unzip_failed:\n            i = 0\n\n            for _zip in zips:\n                try:\n                    remove_file(_zip)\n                    i += 1\n                except OSError:\n                    logging.warning(T(\"Deleting %s failed!\"), _zip)\n\n                brokenzip = \"%s.1\" % _zip\n\n                if os.path.exists(brokenzip):\n                    try:\n                        remove_file(brokenzip)\n                        i += 1\n                    except OSError:\n                        logging.warning(T(\"Deleting %s failed!\"), brokenzip)\n\n        return unzip_failed, new_files\n    except:\n        msg = sys.exc_info()[1]\n        nzo.fail_msg = T(\"Unpacking failed, %s\") % msg\n        logging.error(T('Error \"%s\" while running unzip() on %s'), msg, nzo.final_name)\n        return True, []\n\n\ndef unzip_core(zipfile, extraction_path, one_folder):\n    \"\"\"Unzip single zip set 'zipfile' to 'extraction_path'\"\"\"\n    command = [\"%s\" % ZIP_COMMAND, \"-o\", \"-Pnone\", \"%s\" % clip_path(zipfile), \"-d%s\" % extraction_path]\n\n    if one_folder or cfg.flat_unpack():\n        command.insert(3, \"-j\")  # Unpack without folders\n\n    p = build_and_run_command(command)\n    logging.debug(\"unzip output: \\n%s\", p.stdout.read())\n    return p.wait()\n\n\n##############################################################################\n# 7Zip Functions\n##############################################################################\ndef unseven(nzo: NzbObject, workdir_complete: str, one_folder: bool, sevens: List[str]):\n    \"\"\"Unpack multiple sets '7z' of 7Zip files from 'download_path' to 'workdir_complete.\n    When 'delete' is set, originals will be deleted.\n    \"\"\"\n    # Before we start, make sure the 7z binary SEVENZIP_COMMAND is defined\n    if not SEVENZIP_COMMAND:\n        msg = T('No 7za binary found, cannot unpack \"%s\"') % nzo.final_name\n        logging.error(msg)\n        nzo.fail_msg = msg\n        nzo.status = Status.FAILED\n        nzo.set_unpack_info(\"Unpack\", msg)\n        return 1, []\n\n    unseven_failed = False\n    new_files = []\n\n    # Find multi-volume sets, because 7zip will not provide actual set members\n    seven_sets = {}\n    for seven in sevens:\n        setname = setname_from_path(seven)\n        if SEVENMULTI_RE.search(setname):\n            # Remove the \".001\" part\n            setname = os.path.splitext(setname)[0]\n        if setname not in seven_sets:\n            seven_sets[setname] = []\n        seven_sets[setname].append(seven)\n\n    # Unpack each set\n    for seven_set in seven_sets:\n        logging.info(\"Starting extract on 7zip set/file: %s \", seven_set)\n        nzo.set_action_line(T(\"Unpacking\"), setname_from_path(seven_set))\n\n        # Sort, so that x.001 is the first one\n        seven_sets[seven_set].sort()\n        seven_path = seven_sets[seven_set][0]\n\n        if workdir_complete and seven_path.startswith(nzo.download_path):\n            extraction_path = workdir_complete\n        else:\n            extraction_path = os.path.split(seven_path)[0]\n\n        res, new_files_set = seven_extract(nzo, seven_path, seven_set, extraction_path, one_folder)\n        if res:\n            unseven_failed = True\n        elif nzo.delete:\n            for seven in seven_sets[seven_set]:\n                try:\n                    remove_file(seven)\n                except:\n                    logging.warning(T(\"Deleting %s failed!\"), seven)\n        new_files.extend(new_files_set)\n\n    return unseven_failed, new_files\n\n\ndef seven_extract(\n    nzo: NzbObject, seven_path: str, seven_set: str, extraction_path: str, one_folder: bool\n) -> Tuple[int, List[str]]:\n    \"\"\"Unpack single set 'sevenset' to 'extraction_path', with password tries\n    Return fail==0(ok)/fail==1(error)/fail==2(wrong password), new_files, sevens\n    \"\"\"\n    fail = 0\n    new_files = []\n\n    passwords = get_all_passwords(nzo)\n\n    for password in passwords:\n        if password:\n            msg = T('Trying 7zip with password \"%s\"') % password\n            logging.debug(msg)\n            nzo.set_unpack_info(\"Unpack\", msg, seven_set)\n        fail, new_files = seven_extract_core(nzo, seven_path, extraction_path, seven_set, one_folder, password)\n        if fail != 2:\n            # anything else than a password problem (so: OK, or disk problem):\n            break\n\n    return fail, new_files\n\n\ndef seven_extract_core(\n    nzo: NzbObject, seven_path: str, extraction_path: str, seven_set: str, one_folder: bool, password: str\n) -> Tuple[int, List[str]]:\n    \"\"\"Unpack single 7Z set 'sevenset' to 'extraction_path'\n    Return fail==0(ok)/fail==1(error)/fail==2(wrong password), new_files, message\n    \"\"\"\n    start = time.time()\n    if one_folder:\n        method = \"e\"  # Unpack without folders\n    else:\n        method = \"x\"  # Unpack with folders\n    if sabnzbd.WIN32 or sabnzbd.MACOS:\n        case = \"-ssc-\"  # Case insensitive\n    else:\n        case = \"-ssc\"  # Case sensitive\n    if cfg.overwrite_files():\n        overwrite = \"-aoa\"\n    else:\n        overwrite = \"-aou\"\n    if password:\n        password = \"-p%s\" % password\n    else:\n        password = \"-p\"\n\n    # For file-bookkeeping\n    orig_dir_content = listdir_full(extraction_path)\n\n    command = [SEVENZIP_COMMAND, method, \"-y\", overwrite, case, password, \"-o%s\" % extraction_path, seven_path]\n    p = build_and_run_command(command)\n    sabnzbd.PostProcessor.external_process = p\n    output = p.stdout.read()\n    logging.debug(\"7za output: %s\", output)\n\n    # ret contains the 7z/7za exit code: 0 = Normal, 1 = Warning, 2 = Fatal error, etc\n    ret = p.wait()\n\n    # What's new? Use symmetric difference\n    new_files = list(set(orig_dir_content) ^ set(listdir_full(extraction_path)))\n\n    # Anything else than 0 as RC: 7z unpack had a problem\n    if ret > 0:\n        # Let's try to find the cause:\n        if \"Data Error in encrypted file. Wrong password?\" in output:\n            msg = T(\"Unpacking failed, archive requires a password\")\n        elif \"Disk full.\" in output or \"No space left on device\" in output:\n            # note: the above does not work with 7z version 16.02, and does work with 7z 19.00 and higher\n            ret = 1\n            msg = T(\"Unpacking failed, write error or disk is full?\")\n        elif \"ERROR: CRC Failed\" in output:\n            ret = 1\n            msg = T(\"Unpacking failed, CRC error\")\n        else:\n            # Default message\n            msg = T(\"Unpacking failed, %s\") % T(\"see logfile\")\n            logging.info(\"7za return code: %s\", ret)\n        nzo.fail_msg = msg\n        nzo.status = Status.FAILED\n    else:\n        msg = T(\"Unpacked %s files/folders in %s\") % (len(new_files), format_time_string(time.time() - start))\n        nzo.set_unpack_info(\"Unpack\", msg, seven_set)\n        logging.info(msg)\n\n    return ret, new_files\n\n\n##############################################################################\n# PAR2 Functions\n##############################################################################\ndef par2_repair(nzo: NzbObject, setname: str) -> Tuple[bool, bool]:\n    \"\"\"Try to repair a set, return readd and correctness\"\"\"\n    # Check which of the files exists\n    for new_par in nzo.extrapars[setname]:\n        test_parfile = os.path.join(nzo.download_path, new_par.filename)\n        if os.path.exists(test_parfile):\n            parfile_nzf = new_par\n            break\n    else:\n        # No file was found, we assume this set already finished\n        logging.info(\"No par2 files found on disk for set %s\", setname)\n        return False, True\n\n    parfile = os.path.join(nzo.download_path, parfile_nzf.filename)\n    old_dir_content = os.listdir(nzo.download_path)\n    used_joinables = ()\n    joinables = ()\n    used_for_repair = ()\n    result = readd = False\n\n    # Need to copy now, gets pop-ed during repair\n    setpars = nzo.extrapars[setname][:]\n\n    # Start QuickCheck\n    nzo.status = Status.QUICK_CHECK\n    nzo.set_action_line(T(\"Repair\"), T(\"Quick Checking\"))\n    qc_result = quick_check_set(setname, nzo)\n    if qc_result:\n        logging.info(\"Quick-check for %s is OK, skipping repair\", setname)\n        nzo.set_unpack_info(\"Repair\", T(\"[%s] Quick Check OK\") % setname)\n        result = True\n\n    if not result and cfg.enable_all_par():\n        # Download all par2 files that haven't been downloaded yet\n        readd = False\n        for extrapar in nzo.extrapars[setname][:]:\n            # Make sure we only get new par2 files\n            if nzo.add_parfile(extrapar):\n                readd = True\n        if readd:\n            return readd, result\n\n    if not result:\n        nzo.status = Status.REPAIRING\n        result = False\n        readd = False\n        try:\n            nzo.set_action_line(T(\"Repair\"), T(\"Starting Repair\"))\n            logging.info('Scanning \"%s\"', parfile)\n\n            joinables, _, _, _, _ = build_filelists(nzo.download_path, check_rar=False)\n\n            # Multipar on Windows, par2cmdline on the other platforms\n            if sabnzbd.WIN32:\n                finished, readd, used_joinables, used_for_repair = multipar_verify(parfile, nzo, setname, joinables)\n            else:\n                finished, readd, used_joinables, used_for_repair = par2cmdline_verify(parfile, nzo, setname, joinables)\n\n            if finished:\n                result = True\n                logging.info(\"Par verify finished ok on %s!\", parfile)\n            else:\n                logging.info(\"Par verify failed on %s!\", parfile)\n                return readd, False\n        except:\n            msg = sys.exc_info()[1]\n            nzo.fail_msg = T(\"Repairing failed, %s\") % msg\n            logging.error(T(\"Error %s while running par2_repair on set %s\"), msg, setname)\n            logging.info(\"Traceback: \", exc_info=True)\n            return readd, result\n\n    try:\n        if cfg.enable_par_cleanup():\n            deletables = []\n            new_dir_content = os.listdir(nzo.download_path)\n\n            # If Multipar or par2cmdline repairs a broken part of a joinable, it doesn't list it as such.\n            # So we need to manually add all joinables of the set to the list of used joinables.\n            # We assume at least 1 of them was not broken, so we can use it as a base to find the rest.\n            if used_joinables:\n                for used_jn in used_joinables[:]:\n                    for jn in joinables:\n                        if get_filename(jn).startswith(setname_from_path(used_jn)) and jn not in used_joinables:\n                            used_joinables.append(jn)\n\n            # Remove extra files created during repair and par2 base files\n            for path in new_dir_content:\n                if os.path.splitext(path)[1] == \".1\" and path not in old_dir_content:\n                    deletables.append(os.path.join(nzo.download_path, path))\n            deletables.append(os.path.join(nzo.download_path, setname + \".par2\"))\n            deletables.append(os.path.join(nzo.download_path, setname + \".PAR2\"))\n            deletables.append(parfile)\n\n            # Add output of par2-repair to remove\n            deletables.extend(used_joinables)\n            deletables.extend([os.path.join(nzo.download_path, f) for f in used_for_repair])\n\n            # Delete pars of the set\n            deletables.extend([os.path.join(nzo.download_path, nzf.filename) for nzf in setpars])\n\n            for filepath in deletables:\n                if filepath in joinables:\n                    joinables.remove(filepath)\n                if os.path.exists(filepath):\n                    try:\n                        remove_file(filepath)\n                    except OSError:\n                        logging.warning(T(\"Deleting %s failed!\"), filepath)\n    except:\n        msg = sys.exc_info()[1]\n        nzo.fail_msg = T(\"Repairing failed, %s\") % msg\n        logging.error(T('Error \"%s\" while running par2_repair on set %s'), msg, setname, exc_info=True)\n\n    return readd, result\n\n\ndef par2cmdline_verify(\n    parfile: str, nzo: NzbObject, setname: str, joinables: List[str]\n) -> Tuple[bool, bool, List[str], List[str]]:\n    \"\"\"Run par2 on par-set\"\"\"\n    used_joinables = []\n    used_for_repair = []\n    # set the current nzo status to \"Verifying...\". Used in History\n    nzo.status = Status.VERIFYING\n    start = time.time()\n\n    # Build command and add extra options\n    command = [str(PAR2_COMMAND), \"r\", parfile]\n    options = cfg.par_option().strip().split()\n    if options:\n        for option in options:\n            command.insert(2, option)\n\n    # Append the wildcard for this set\n    parfolder = os.path.split(parfile)[0]\n    if len(nzo.extrapars) == 1 or len(globber(parfolder, setname + \"*\")) < 2:\n        # Support bizarre naming conventions\n        wildcard = \"*\"\n    else:\n        # Normal case, everything is named after set\n        wildcard = setname + \"*\"\n\n    if sabnzbd.MACOS:\n        command.append(os.path.join(parfolder, wildcard))\n    else:\n        # For Unix systems, remove folders, due to bug in some par2cmdline versions\n        flist = [item for item in globber_full(parfolder, wildcard) if os.path.isfile(item)]\n        command.extend(flist)\n\n    # We need to check for the bad par2cmdline that skips blocks\n    # Or the one that complains about basepath\n    # Only if we're not doing multicore\n    if not sabnzbd.MACOS:\n        par2text = run_command([command[0], \"-h\"])\n        if \"No data skipping\" in par2text:\n            logging.info(\"Detected par2cmdline version that skips blocks, adding -N parameter\")\n            command.insert(2, \"-N\")\n        if \"Set the basepath\" in par2text:\n            logging.info(\"Detected par2cmdline version that needs basepath, adding -B<path> parameter\")\n            command.insert(2, \"-B\")\n            command.insert(3, parfolder)\n\n    # Run the external command\n    p = build_and_run_command(command)\n    sabnzbd.PostProcessor.external_process = p\n\n    # Set up our variables\n    lines = []\n    renames = {}\n    reconstructed = []\n\n    linebuf = \"\"\n    finished = False\n    readd = False\n\n    verifynum = 0\n    verifytotal = 0\n    verified = 0\n    perc = 0\n\n    in_verify = False\n    in_extra_files = False\n    in_verify_repaired = False\n\n    # Loop over the output, whee\n    while 1:\n        char = p.stdout.read(1)\n        if not char:\n            break\n\n        # Line not complete yet\n        if char not in (\"\\n\", \"\\r\"):\n            linebuf += char\n            continue\n\n        line = linebuf.strip()\n        linebuf = \"\"\n\n        # Skip empty lines\n        if line == \"\":\n            continue\n\n        if not line.startswith((\"Repairing:\", \"Scanning:\", \"Loading:\", \"Solving:\", \"Constructing:\")):\n            lines.append(line)\n\n        if line.startswith((\"Invalid option specified\", \"Invalid thread option\", \"Cannot specify recovery file count\")):\n            msg = T(\"[%s] PAR2 received incorrect options, check your Config->Switches settings\") % setname\n            nzo.set_unpack_info(\"Repair\", msg)\n            nzo.status = Status.FAILED\n            logging.error(msg)\n\n        elif line.startswith(\"All files are correct\"):\n            msg = T(\"[%s] Verified in %s, all files correct\") % (setname, format_time_string(time.time() - start))\n            nzo.set_unpack_info(\"Repair\", msg)\n            logging.info(\"Verified in %s, all files correct\", format_time_string(time.time() - start))\n            finished = True\n\n        elif line.startswith(\"Repair is required\"):\n            msg = T(\"[%s] Verified in %s, repair is required\") % (setname, format_time_string(time.time() - start))\n            nzo.set_unpack_info(\"Repair\", msg)\n            logging.info(\"Verified in %s, repair is required\", format_time_string(time.time() - start))\n            start = time.time()\n            verified = 1\n            # Reset to use them again for verification of repair\n            verifytotal = 0\n            verifynum = 0\n\n        elif line.startswith(\"Main packet not found\") or \"The recovery file does not exist\" in line:\n            # Initialparfile probably didn't decode properly or bad user parameters\n            # We will try to get another par2 file, but 99% of time it's user parameters\n            msg = T(\"Invalid par2 files or invalid PAR2 parameters, cannot verify or repair\")\n            logging.info(msg)\n            logging.info(\"Extra pars = %s\", nzo.extrapars[setname])\n\n            # Look for the smallest par2file\n            block_table = {}\n            for nzf in nzo.extrapars[setname]:\n                if not nzf.completed:\n                    block_table[nzf.blocks] = nzf\n\n            if block_table:\n                nzf = block_table[min(block_table)]\n                logging.info(\"Found new par2file %s\", nzf.filename)\n\n                # Move from extrapar list to files to be downloaded\n                # and remove it from the extrapars list\n                nzo.add_parfile(nzf)\n                readd = True\n            else:\n                nzo.fail_msg = msg\n                nzo.set_unpack_info(\"Repair\", msg, setname)\n                nzo.status = Status.FAILED\n\n        elif line.startswith(\"You need\"):\n            # We need more blocks, but are they available?\n            chunks = line.split()\n            needed_blocks = int(chunks[2])\n\n            # Check if we have enough blocks\n            added_blocks = nzo.get_extra_blocks(setname, needed_blocks)\n            if added_blocks:\n                msg = T(\"Fetching %s blocks...\") % str(added_blocks)\n                nzo.set_action_line(T(\"Fetching\"), msg)\n                readd = True\n            else:\n                # Failed\n                msg = T(\"Repair failed, not enough repair blocks (%s short)\") % str(needed_blocks)\n                nzo.fail_msg = msg\n                nzo.set_unpack_info(\"Repair\", msg, setname)\n                nzo.status = Status.FAILED\n\n        elif line.startswith(\"Repair is possible\"):\n            start = time.time()\n            nzo.set_action_line(T(\"Repairing\"), \"%2d%%\" % 0)\n\n        elif line.startswith((\"Repairing:\", \"Processing:\")):\n            # \"Processing\" is shown when it is only joining files without repairing\n            chunks = line.split()\n            new_perc = float(chunks[-1][:-1])\n            # Only send updates for whole-percentage updates\n            if new_perc - perc > 1:\n                perc = new_perc\n                nzo.set_action_line(T(\"Repairing\"), \"%2d%% %s\" % (perc, add_time_left(perc, start)))\n                nzo.status = Status.REPAIRING\n\n        elif line.startswith(\"Repair complete\"):\n            msg = T(\"[%s] Repaired in %s\") % (setname, format_time_string(time.time() - start))\n            nzo.set_unpack_info(\"Repair\", msg)\n            logging.info(\"Repaired in %s\", format_time_string(time.time() - start))\n            finished = True\n\n        elif verified and line.endswith((\"are missing.\", \"exist but are damaged.\")):\n            # Files that will later be verified after repair\n            chunks = line.split()\n            verifytotal += int(chunks[0])\n\n        elif line.startswith(\"Verifying repaired files\"):\n            in_verify_repaired = True\n\n        elif in_verify_repaired and line.startswith(\"Target\"):\n            verifynum += 1\n            if verifynum <= verifytotal:\n                nzo.set_action_line(T(\"Verifying repair\"), \"%02d/%02d\" % (verifynum, verifytotal))\n\n        elif \"Could not write\" in line and \"at offset 0:\" in line:\n            # If there are joinables, this error will only happen in case of 100% complete files\n            # We can just skip the retry, because par2cmdline will fail in those cases\n            # because it refuses to scan the \".001\" file\n            if joinables:\n                finished = True\n                used_joinables = []\n\n        elif \" cannot be renamed to \" in line:\n            msg = line.strip()\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n\n        elif \"There is not enough space on the disk\" in line:\n            # Oops, disk is full!\n            msg = T(\"Repairing failed, %s\") % T(\"Disk full\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n\n        elif \"No details available for recoverable file\" in line:\n            msg = line.strip()\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n\n        elif line.startswith(\"Repair Failed.\"):\n            # Unknown repair problem\n            msg = T(\"Repairing failed, %s\") % line\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n            finished = False\n\n        elif not verified:\n            if line.startswith(\"Scanning:\"):\n                pass\n\n            if in_extra_files:\n                if \"is a match for\" in line or line.find(\"data blocks from\") > 0:\n                    # Baldy named ones\n                    m_rename = PAR2_IS_MATCH_FOR_RE.search(line)\n                    if m_rename:\n                        old_name = m_rename.group(1)\n                        new_name = m_rename.group(2)\n                        logging.debug('PAR2 will rename \"%s\" to \"%s\"', old_name, new_name)\n                        renames[new_name] = old_name\n\n                    # Obfuscated and also damaged\n                    m_block = PAR2_BLOCK_FOUND_RE.search(line)\n                    if m_block:\n                        workdir = os.path.split(parfile)[0]\n                        old_name = m_block.group(1)\n                        new_name = m_block.group(2)\n                        if joinables:\n                            # Find out if a joinable file has been used for joining\n                            for jn in joinables:\n                                if get_filename(jn) == old_name:\n                                    used_joinables.append(jn)\n                                    break\n                            # Special case of joined RAR files, the \"of\" and \"from\" must both be RAR files\n                            # This prevents the joined rars files from being seen as an extra rar-set\n                            if \".rar\" in old_name.lower() and \".rar\" in new_name.lower():\n                                used_joinables.append(os.path.join(workdir, old_name))\n                        else:\n                            logging.debug('PAR2 will reconstruct \"%s\" from \"%s\"', new_name, old_name)\n                            reconstructed.append(os.path.join(workdir, old_name))\n                            renames[new_name] = old_name\n\n                    if m_block or m_rename:\n                        # Show progress\n                        verifynum += 1\n                        nzo.set_action_line(T(\"Checking extra files\"), \"%02d\" % verifynum)\n\n            elif not in_verify:\n                # Total number to verify\n                m = re.match(r\"There are (\\d+) recoverable files\", line)\n                if m:\n                    verifytotal = int(m.group(1))\n\n                if line.startswith(\"Verifying source files:\"):\n                    in_verify = True\n                    nzo.status = Status.VERIFYING\n            elif line.startswith(\"Scanning extra files:\"):\n                in_verify = False\n                in_extra_files = True\n                verifynum = 0\n            else:\n                # Target files for verification\n                m = PAR2_TARGET_RE.match(line)\n                if m:\n                    verifynum += 1\n                    nzo.set_action_line(T(\"Verifying\"), \"%02d/%02d\" % (verifynum, verifytotal))\n\n                    # Remove redundant extra files that are just duplicates of original ones\n                    if \"duplicate data blocks\" in line:\n                        used_for_repair.append(m.group(1))\n\n    p.wait()\n\n    # Also log what is shown to user in history\n    if nzo.fail_msg:\n        logging.info(nzo.fail_msg)\n\n    logging.debug(\"PAR2 output was\\n%s\", \"\\n\".join(lines))\n\n    # If successful, add renamed files to the collection\n    if finished and renames:\n        nzo.renamed_file(renames)\n\n    # If successful and files were reconstructed, remove incomplete original files\n    if finished and reconstructed:\n        # Use 'used_joinables' as a vehicle to get rid of the files\n        used_joinables.extend(reconstructed)\n\n    return finished, readd, used_joinables, used_for_repair\n\n\ndef multipar_verify(\n    parfile: str, nzo: NzbObject, setname: str, joinables: List[str]\n) -> Tuple[bool, bool, List[str], List[str]]:\n    \"\"\"Run par2 on par-set\"\"\"\n    parfolder = os.path.split(parfile)[0]\n    used_joinables = []\n    used_for_repair = []\n\n    # set the current nzo status to \"Verifying...\". Used in History\n    nzo.status = Status.VERIFYING\n    start = time.time()\n\n    # Caching of verification implemented by adding -vs/-vd\n    # But not really required due to prospective-par2\n    # Force output of utf-8 by adding -uo\n    command = [str(MULTIPAR_COMMAND), \"r\", \"-uo\", \"-vs2\", \"-vd%s\" % nzo.admin_path, parfile]\n\n    # Only add user-options if supplied\n    options = cfg.par_option().strip().split()\n    if options:\n        for option in options:\n            # We wrongly instructed users to use /x parameter style instead of -x\n            option = option.replace(\"/\", \"-\", 1)\n            command.insert(2, option)\n\n    # Support bizarre naming conventions by scanning all files\n    if len(nzo.extrapars) == 1 or len(globber(parfolder, setname + \"*\")) < 2:\n        command.insert(2, \"-vl2\")\n\n    # Run MultiPar\n    p = build_and_run_command(command)\n    sabnzbd.PostProcessor.external_process = p\n\n    # Set up our variables\n    lines = []\n    renames = {}\n    reconstructed = []\n\n    linebuf = \"\"\n    finished = False\n    readd = False\n\n    verifynum = 0\n    verifytotal = 0\n    verifyextratotal = 0\n\n    in_check = False\n    in_verify = False\n    in_repair = False\n    in_verify_repaired = False\n    misnamed_files = False\n    old_name = None\n\n    # Loop over the output, whee\n    while 1:\n        char = p.stdout.read(1)\n        if not char:\n            break\n\n        # Line not complete yet\n        if char not in (\"\\n\", \"\\r\"):\n            linebuf += char\n            continue\n\n        line = linebuf.strip()\n        linebuf = \"\"\n\n        # Skip empty lines\n        if line == \"\":\n            continue\n\n        # Save it all\n        lines.append(line)\n\n        # ----------------- Startup\n        if line.startswith(\"invalid option\"):\n            # Option error\n            msg = T(\"[%s] PAR2 received incorrect options, check your Config->Switches settings\") % setname\n            nzo.set_unpack_info(\"Repair\", msg)\n            nzo.status = Status.FAILED\n            logging.error(msg)\n\n        elif line.startswith(\"valid file is not found\"):\n            # Initialparfile probably didn't decode properly, or bad user parameters\n            # We will try to get another par2 file, but 99% of time it's user parameters\n            msg = T(\"Invalid par2 files or invalid PAR2 parameters, cannot verify or repair\")\n            logging.info(msg)\n            logging.info(\"Extra pars = %s\", nzo.extrapars[setname])\n\n            # Look for the smallest par2file\n            block_table = {}\n            for nzf in nzo.extrapars[setname]:\n                if not nzf.completed:\n                    block_table[nzf.blocks] = nzf\n\n            if block_table:\n                nzf = block_table[min(block_table)]\n                logging.info(\"Found new par2file %s\", nzf.filename)\n\n                # Move from extrapar list to files to be downloaded\n                # and remove it from the extrapars list\n                nzo.add_parfile(nzf)\n                readd = True\n            else:\n                nzo.fail_msg = msg\n                nzo.set_unpack_info(\"Repair\", msg, setname)\n                nzo.status = Status.FAILED\n\n        elif line.startswith(\"There is not enough space on the disk\"):\n            msg = T(\"Repairing failed, %s\") % T(\"Disk full\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n\n        # ----------------- Start check/verify stage\n        elif line.startswith(\"Recovery Set ID\"):\n            # Remove files were MultiPar stores verification result when repaired successful\n            recovery_id = line.split()[-1]\n            used_for_repair.append(os.path.join(JOB_ADMIN, \"2_%s.bin\" % recovery_id))\n            used_for_repair.append(os.path.join(JOB_ADMIN, \"2_%s.ini\" % recovery_id))\n\n        elif line.startswith(\"Input File total count\"):\n            # How many files will it try to find?\n            verifytotal = int(line.split()[-1])\n\n        # ----------------- Misnamed-detection stage\n        # Misnamed files\n        elif line.startswith(\"Searching misnamed file\"):\n            # We are in the misnamed files block\n            # How many misnamed files will it try to find?\n            verifyextratotal = int(line.split()[-1])\n            verifynum = 0\n            misnamed_files = True\n        elif misnamed_files and \"Found\" in line:\n            # First it reports the current filename\n            m = PAR2_FILENAME_RE.search(line)\n            if m:\n                verifynum += 1\n                nzo.set_action_line(T(\"Checking extra files\"), \"%02d/%02d\" % (verifynum, verifyextratotal))\n                old_name = m.group(1)\n        elif misnamed_files and \"Misnamed\" in line:\n            # Then it finds the actual\n            m = PAR2_FILENAME_RE.search(line)\n            if m and old_name:\n                new_name = m.group(1)\n                logging.debug('MultiPar will rename \"%s\" to \"%s\"', old_name, new_name)\n                renames[new_name] = old_name\n                # New name is also part of data!\n                reconstructed.append(old_name)\n\n        # ----------------- Checking stage\n        # Checking input files\n        elif line.startswith(\"Complete file count\"):\n            in_check = False\n            verifynum = 0\n            old_name = None\n        elif line.startswith(\"Verifying Input File\"):\n            in_check = True\n            nzo.status = Status.VERIFYING\n        elif in_check:\n            m = PAR2_FILENAME_RE.search(line)\n            if m:\n                # Only increase counter if it was really the detection line\n                if line.startswith(\"= \") or \"%\" not in line:\n                    verifynum += 1\n                nzo.set_action_line(T(\"Checking\"), \"%02d/%02d\" % (verifynum, verifytotal))\n                old_name = m.group(1)\n\n        # ----------------- Verify stage\n        # Which files need extra verification?\n        elif line.startswith(\"Damaged file count\"):\n            verifytotal = int(line.split()[-1])\n\n        elif line.startswith(\"Missing file count\"):\n            verifytotal += int(line.split()[-1])\n\n        # Actual verification\n        elif line.startswith(\"Input File Slice found\"):\n            # End of verification AND end of misnamed file search\n            in_verify = False\n            misnamed_files = False\n            old_name = None\n        elif line.startswith(\"Finding available slice\"):\n            # The actual scanning of the files\n            in_verify = True\n            verifynum = 0\n        elif in_verify:\n            m = PAR2_FILENAME_RE.search(line)\n            if m:\n                # It prints the filename couple of times, so we save it to check\n                nzo.status = Status.VERIFYING\n                if line.split()[1] in (\"Damaged\", \"Found\"):\n                    verifynum += 1\n\n                    # Set old_name in case it was misnamed and found (not when we are joining)\n                    old_name = None\n                    if line.split()[1] == \"Found\" and not joinables:\n                        old_name = m.group(1)\n\n                    # Sometimes we don't know the total (filejoin)\n                    if verifytotal <= 1 or verifynum > verifytotal:\n                        nzo.set_action_line(T(\"Verifying\"), \"%02d\" % verifynum)\n                    else:\n                        nzo.set_action_line(T(\"Verifying\"), \"%02d/%02d\" % (verifynum, verifytotal))\n\n                elif old_name and old_name != m.group(1):\n                    # Hey we found another misnamed one!\n                    new_name = m.group(1)\n                    logging.debug('MultiPar will rename \"%s\" to \"%s\"', old_name, new_name)\n                    renames[new_name] = old_name\n                    # Need to remove the old file after repair (Multipar keeps it)\n                    used_for_repair.append(old_name)\n                    # Need to reset it to avoid collision\n                    old_name = None\n\n                if joinables:\n                    # Find out if a joinable file has been used for joining\n                    for jn in joinables:\n                        if get_filename(jn) == m.group(1):\n                            used_joinables.append(jn)\n                            break\n\n        elif line.startswith(\"Need\"):\n            # We need more blocks, but are they available?\n            chunks = line.split()\n            needed_blocks = int(chunks[1])\n\n            # Check if we have enough blocks\n            added_blocks = nzo.get_extra_blocks(setname, needed_blocks)\n            if added_blocks:\n                msg = T(\"Fetching %s blocks...\") % str(added_blocks)\n                nzo.set_action_line(T(\"Fetching\"), msg)\n                readd = True\n            else:\n                # Failed\n                msg = T(\"Repair failed, not enough repair blocks (%s short)\") % str(needed_blocks)\n                nzo.fail_msg = msg\n                nzo.set_unpack_info(\"Repair\", msg, setname)\n                nzo.status = Status.FAILED\n\n            # MultiPar can say 'PAR File(s) Incomplete' also when it needs more blocks\n            # But the Need-more-blocks message is always last, so force failure\n            finished = False\n\n        # Result of verification\n        elif line.startswith(\"All Files Complete\") or line.endswith(\"PAR File(s) Incomplete\"):\n            # 'PAR File(s) Incomplete' is also reported for success when there are very similar filenames in the folder\n            # See: https://github.com/Yutaka-Sawada/MultiPar/issues/54\n            # Check if there was damage, by inspecting the number of missing blocks\n            if \"Input File Slice lost\" in lines[-2] and int(lines[-2].split()[-1]) == 0:\n                # Completed without damage!\n                msg = T(\"[%s] Verified in %s, all files correct\") % (setname, format_time_string(time.time() - start))\n                nzo.set_unpack_info(\"Repair\", msg)\n                logging.info(\"Verified in %s, all files correct\", format_time_string(time.time() - start))\n                finished = True\n\n        elif line.startswith((\"Ready to repair\", \"Ready to rejoin\")):\n            # Ready to repair!\n            # Or we are re-joining a split file when there's no damage but takes time\n            msg = T(\"[%s] Verified in %s, repair is required\") % (setname, format_time_string(time.time() - start))\n            nzo.set_unpack_info(\"Repair\", msg)\n            logging.info(\"Verified in %s, repair is required\", format_time_string(time.time() - start))\n            start = time.time()\n\n            # Set message for user in case of joining\n            if line.startswith(\"Ready to rejoin\"):\n                # There is no status-update when it is joining\n                nzo.set_action_line(T(\"Joining\"), \"%2d\" % len(used_joinables))\n\n        # ----------------- Repair stage\n        elif \"Recovering slice\" in line:\n            # Before this it will calculate matrix, here is where it starts\n            start = time.time()\n            in_repair = True\n            nzo.set_action_line(T(\"Repairing\"), \"%2d%%\" % 0)\n\n        elif line.startswith(\"Verifying repair\"):\n            in_repair = False\n            in_verify_repaired = True\n            # How many will be checked?\n            verifytotal = int(line.split()[-1])\n            verifynum = 0\n\n        elif in_repair:\n            try:\n                # Line with percentage of repair (nothing else)\n                perc = float(line[:-1])\n                nzo.set_action_line(T(\"Repairing\"), \"%2d%% %s\" % (perc, add_time_left(perc, start)))\n                nzo.status = Status.REPAIRING\n            except:\n                # Checksum error\n                if \"checksum\" in line:\n                    # Failed due to checksum error of multipar\n                    msg = T(\"Repairing failed, %s\") % line\n                    nzo.fail_msg = msg\n                    nzo.set_unpack_info(\"Repair\", msg, setname)\n                    nzo.status = Status.FAILED\n                else:\n                    # Not sure, log error\n                    logging.info(\"Traceback: \", exc_info=True)\n\n        elif line.startswith(\"Repaired successfully\"):\n            msg = T(\"[%s] Repaired in %s\") % (setname, format_time_string(time.time() - start))\n            nzo.set_unpack_info(\"Repair\", msg)\n            logging.info(\"Repaired in %s\", format_time_string(time.time() - start))\n            finished = True\n\n        elif in_verify_repaired and line.startswith(\"Repaired :\"):\n            # Track verification of repaired files (can sometimes take a while)\n            verifynum += 1\n            nzo.set_action_line(T(\"Verifying repair\"), \"%02d/%02d\" % (verifynum, verifytotal))\n\n        elif line.startswith(\"Failed to repair\") and not readd:\n            # Unknown repair problem\n            msg = T(\"Repairing failed, %s\") % line\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n            finished = True\n\n    p.wait()\n\n    # Also log what is shown to user in history\n    if nzo.fail_msg:\n        logging.info(nzo.fail_msg)\n\n    logging.debug(\"MultiPar output was\\n%s\", \"\\n\".join(lines))\n\n    # Add renamed files to the collection\n    # MultiPar always automatically renames whatever it can in the 'Searching misnamed file:'-section\n    # Even if the repair did not complete fully it will rename those!\n    # But the ones in 'Finding available slices'-section will only be renamed after successful repair\n    if renames:\n        # If success, we also remove the possibly previously renamed ones\n        if finished:\n            reconstructed.extend(list(renames.values()))\n\n        # Adding to the collection\n        nzo.renamed_file(renames)\n\n        # Remove renamed original files\n        workdir = os.path.split(parfile)[0]\n        used_joinables.extend([os.path.join(workdir, name) for name in reconstructed])\n\n    return finished, readd, used_joinables, used_for_repair\n\n\ndef create_env(nzo: Optional[NzbObject] = None, extra_env_fields: Dict[str, Any] = {}) -> Optional[Dict[str, Any]]:\n    \"\"\"Modify the environment for pp-scripts with extra information\n    macOS: Return copy of environment without PYTHONPATH and PYTHONHOME\n    other: return None\n    \"\"\"\n    env = os.environ.copy()\n\n    # Are we adding things?\n    if nzo:\n        # Add basic info\n        for field in ENV_NZO_FIELDS:\n            try:\n                field_value = getattr(nzo, field)\n                # Special filters for Python types\n                if field_value is None:\n                    env[\"SAB_\" + field.upper()] = \"\"\n                elif isinstance(field_value, bool):\n                    env[\"SAB_\" + field.upper()] = str(field_value * 1)\n                else:\n                    env[\"SAB_\" + field.upper()] = str(field_value)\n            except:\n                # Catch key errors\n                pass\n\n    # Always supply basic info\n    extra_env_fields.update(\n        {\n            \"program_dir\": sabnzbd.DIR_PROG,\n            \"par2_command\": sabnzbd.newsunpack.PAR2_COMMAND,\n            \"multipar_command\": sabnzbd.newsunpack.MULTIPAR_COMMAND,\n            \"rar_command\": sabnzbd.newsunpack.RAR_COMMAND,\n            \"zip_command\": sabnzbd.newsunpack.ZIP_COMMAND,\n            \"7zip_command\": sabnzbd.newsunpack.SEVENZIP_COMMAND,\n            \"version\": sabnzbd.__version__,\n        }\n    )\n\n    # Add extra fields\n    for field in extra_env_fields:\n        try:\n            if extra_env_fields[field] is not None:\n                env[\"SAB_\" + field.upper()] = str(extra_env_fields[field])\n            else:\n                env[\"SAB_\" + field.upper()] = \"\"\n        except:\n            # Catch key errors\n            pass\n\n    if sabnzbd.MACOS:\n        if \"PYTHONPATH\" in env:\n            del env[\"PYTHONPATH\"]\n        if \"PYTHONHOME\" in env:\n            del env[\"PYTHONHOME\"]\n    elif not nzo:\n        # No modification\n        return None\n\n    return env\n\n\ndef rar_volumelist(rarfile_path: str, password: str, known_volumes: List[str]) -> List[str]:\n    \"\"\"List volumes that are part of this rarset\n    and merge them with parsed paths list, removing duplicates.\n    We assume RarFile is right and use parsed paths as backup.\n    \"\"\"\n    # UnRar is required to read some RAR files\n    # RarFile can fail in special cases\n    try:\n        zf = rarfile.RarFile(rarfile_path)\n\n        # setpassword can fail due to bugs in RarFile\n        if password:\n            try:\n                zf.setpassword(password)\n            except:\n                pass\n        zf_volumes = zf.volumelist()\n    except:\n        zf_volumes = []\n\n    # Remove duplicates\n    zf_volumes_base = [os.path.basename(vol) for vol in zf_volumes]\n    for known_volume in known_volumes:\n        if os.path.basename(known_volume) not in zf_volumes_base:\n            # Long-path notation just to be sure\n            zf_volumes.append(long_path(known_volume))\n    return zf_volumes\n\n\n# Sort the various RAR filename formats properly :\\\ndef rar_sort(a: str, b: str) -> int:\n    \"\"\"Define sort method for rar file names\"\"\"\n    aext = a.split(\".\")[-1]\n    bext = b.split(\".\")[-1]\n\n    if aext == \"rar\" and bext == \"rar\":\n        return cmp(a, b)\n    elif aext == \"rar\":\n        return -1\n    elif bext == \"rar\":\n        return 1\n    else:\n        return cmp(a, b)\n\n\ndef quick_check_set(setname: str, nzo: NzbObject) -> bool:\n    \"\"\"Check all on-the-fly crc32s of a set\"\"\"\n    par2pack = nzo.par2packs.get(setname)\n    if par2pack is None:\n        return False\n\n    # We use bitwise assignment (&=) so False always wins in case of failure\n    # This way the renames always get saved!\n    result = True\n    nzf_list = nzo.finished_files\n    renames = {}\n\n    # Files to ignore\n    ignore_ext = cfg.quick_check_ext_ignore()\n\n    for file in par2pack:\n        par2info = par2pack[file]\n        found = False\n        file_to_ignore = get_ext(file).replace(\".\", \"\") in ignore_ext\n        for nzf in nzf_list:\n            # Do a simple filename based check\n            if file == nzf.filename:\n                found = True\n                if (\n                    nzf.crc32 is not None\n                    and nzf.crc32 == par2info.filehash\n                    and is_size(nzf.filepath, par2info.filesize)\n                ):\n                    logging.debug(\"Quick-check of file %s OK\", file)\n                    result &= True\n                elif file_to_ignore:\n                    # We don't care about these files\n                    logging.debug(\"Quick-check ignoring file %s\", file)\n                    result &= True\n                else:\n                    logging.info(\"Quick-check of file %s failed!\", file)\n                    result = False\n                break\n\n            # Now let's do obfuscation check\n            if nzf.crc32 is not None and nzf.crc32 == par2info.filehash and is_size(nzf.filepath, par2info.filesize):\n                try:\n                    logging.debug(\"Quick-check will rename %s to %s\", nzf.filename, file)\n\n                    # Note: file can and is allowed to be in a subdirectory.\n                    # Subdirectories in par2 always contain \"/\", not \"\\\"\n                    renamer(\n                        os.path.join(nzo.download_path, nzf.filename),\n                        os.path.join(nzo.download_path, file),\n                        create_local_directories=True,\n                    )\n                    renames[file] = nzf.filename\n                    nzf.filename = file\n                    result &= True\n                    found = True\n                    break\n                except IOError:\n                    # Renamed failed for some reason, probably already done\n                    break\n\n        if not found:\n            if file_to_ignore:\n                # We don't care about these files\n                logging.debug(\"Quick-check ignoring missing file %s\", file)\n                continue\n\n            logging.info(\"Cannot Quick-check missing file %s!\", file)\n            result = False\n\n    # Save renames\n    if renames:\n        nzo.renamed_file(renames)\n\n    return result\n\n\ndef unrar_check(rar: str) -> Tuple[int, bool]:\n    \"\"\"Return version number of unrar, where \"5.01\" returns 501\n    Also return whether an original version is found\n    (version, original)\n    \"\"\"\n    version = 0\n    original = False\n    if rar:\n        try:\n            version = run_command([rar])\n        except:\n            return version, original\n        original = \"Alexander Roshal\" in version\n        m = re.search(r\"RAR\\s(\\d+)\\.(\\d+)\", version)\n        if m:\n            version = int(m.group(1)) * 100 + int(m.group(2))\n        else:\n            version = 0\n    return version, original\n\n\ndef sevenzip_check(sevenzip: str) -> str:\n    \"\"\"Return version of 7zip, currently as a string\"\"\"\n    if sevenzip:\n        try:\n            seven_command_output = run_command([sevenzip])\n            # Example: 7-Zip (z) 21.06 (x64) : Copyright (c) 1999-2021 Igor Pavlov : 2021-11-24\n            return re.search(r\"(\\d+\\.\\d+).*Copyright\", seven_command_output).group(1)\n        except:\n            pass\n    return \"\"\n\n\ndef par2_mt_check(par2_path: str) -> bool:\n    \"\"\"Detect if we have multicore par2 variants\"\"\"\n    try:\n        par2_version = run_command([par2_path, \"-h\"])\n        # Look for a threads option\n        if \"-t<\" in par2_version:\n            return True\n    except:\n        pass\n    return False\n\n\ndef is_sfv_file(myfile: str) -> bool:\n    \"\"\"Checks if given file is a SFV file, and returns result as boolean\"\"\"\n    # based on https://stackoverflow.com/a/7392391/5235502\n    textchars = bytearray({7, 8, 9, 10, 12, 13, 27} | set(range(0x20, 0x100)) - {0x7F})\n    is_ascii_string = lambda input_bytes: not bool(input_bytes.translate(None, textchars))\n\n    # first check if it's plain text (ASCII or Unicode)\n    try:\n        with open(myfile, \"rb\") as f:\n            # get first 10000 bytes to check\n            myblock = f.read(10000)\n            if is_ascii_string(myblock):\n                # ASCII, so store lines for further inspection\n                try:\n                    lines = ubtou(myblock).split(\"\\n\")\n                except UnicodeDecodeError:\n                    return False\n            else:\n                # non-ASCII, so not SFV\n                return False\n    except:\n        # the with-open() went wrong, so not an existing file, so certainly not a SFV file\n        return False\n\n    sfv_info_line_counter = 0\n    for line in lines:\n        line = line.strip()\n        if re.search(r\"^[^;].*\\ +[A-Fa-f0-9]{8}$\", line):\n            # valid, useful SFV line: some text, then one or more space, and a 8-digit hex number\n            sfv_info_line_counter += 1\n            if sfv_info_line_counter >= 10:\n                # with 10 valid, useful lines we're confident enough\n                # (note: if we find less lines (even just 1 line), with no negatives, it is OK. See below)\n                break\n        elif not line or line.startswith(\";\"):\n            # comment line or just spaces, so continue to next line\n            continue\n        else:\n            # not a valid SFV line, so not a SFV file:\n            return False\n    # if we get here, no negatives were found, and at least 1 valid line is OK\n    return sfv_info_line_counter >= 1\n\n\ndef sfv_check(sfvs: List[str], nzo: NzbObject) -> bool:\n    \"\"\"Verify files using SFV files\"\"\"\n    # Update status\n    nzo.status = Status.VERIFYING\n    nzo.set_action_line(T(\"Trying SFV verification\"), \"...\")\n\n    # We use bitwise assignment (&=) so False always wins in case of failure\n    # This way the renames always get saved!\n    result = True\n    nzf_list = nzo.finished_files\n    renames = {}\n\n    # Files to ignore\n    ignore_ext = cfg.quick_check_ext_ignore()\n\n    # We need the crc32 of all files\n    calculated_crc32 = {}\n    verifytotal = len(nzo.finished_files)\n    verifynum = 0\n    for nzf in nzf_list:\n        if nzf.crc32 is not None:\n            verifynum += 1\n            nzo.set_action_line(T(\"Verifying\"), \"%02d/%02d\" % (verifynum, verifytotal))\n            calculated_crc32[nzf.filename] = b\"%08x\" % (nzf.crc32 & 0xFFFFFFFF)\n\n    sfv_parse_results = {}\n    nzo.set_action_line(T(\"Trying SFV verification\"), \"...\")\n    for sfv in sfvs:\n        setname = setname_from_path(sfv)\n        nzo.set_unpack_info(\"Repair\", T(\"Trying SFV verification\"), setname)\n\n        # Parse the sfv and add to the already found results\n        # Duplicates will be replaced\n        sfv_parse_results.update(parse_sfv(sfv))\n\n    for file in sfv_parse_results:\n        found = False\n        file_to_ignore = get_ext(file).replace(\".\", \"\") in ignore_ext\n        for nzf in nzf_list:\n            # Do a simple filename based check\n            if file == nzf.filename:\n                found = True\n                if calculated_crc32.get(nzf.filename, \"\") == sfv_parse_results[file]:\n                    logging.debug(\"SFV-check of file %s OK\", file)\n                    result &= True\n                elif file_to_ignore:\n                    # We don't care about these files\n                    logging.debug(\"SFV-check ignoring file %s\", file)\n                    result &= True\n                else:\n                    logging.info(\"SFV-check of file %s failed!\", file)\n                    result = False\n                break\n\n            # Now lets do obfuscation check\n            if calculated_crc32.get(nzf.filename, \"\") == sfv_parse_results[file]:\n                try:\n                    logging.debug(\"SFV-check will rename %s to %s\", nzf.filename, file)\n                    renamer(os.path.join(nzo.download_path, nzf.filename), os.path.join(nzo.download_path, file))\n                    renames[file] = nzf.filename\n                    nzf.filename = file\n                    result &= True\n                    found = True\n                    break\n                except IOError:\n                    # Renamed failed for some reason, probably already done\n                    break\n\n        if not found:\n            if file_to_ignore:\n                # We don't care about these files\n                logging.debug(\"SFV-check ignoring missing file %s\", file)\n                continue\n\n            logging.info(\"Cannot SFV-check missing file %s!\", file)\n            result = False\n\n    # Save renames\n    if renames:\n        nzo.renamed_file(renames)\n\n    return result\n\n\ndef parse_sfv(sfv_filename):\n    \"\"\"Parse SFV file and return dictionary of crc32's and filenames\"\"\"\n    results = {}\n    with open(sfv_filename, mode=\"rb\") as sfv_list:\n        for sfv_item in sfv_list:\n            sfv_item = sfv_item.strip()\n            # Ignore comment-lines\n            if sfv_item.startswith(b\";\"):\n                continue\n            # Parse out the filename and crc32\n            filename, expected_crc32 = sfv_item.strip().rsplit(maxsplit=1)\n            # We don't know what encoding is used when it was created\n            results[correct_unknown_encoding(filename)] = expected_crc32.lower()\n    return results\n\n\ndef add_time_left(perc: float, start_time: Optional[float] = None, time_used: Optional[float] = None) -> str:\n    \"\"\"Calculate time left based on current progress, if it is taking more than 10 seconds\"\"\"\n    if not time_used:\n        time_used = time.time() - start_time\n    if time_used > 10:\n        return \" - %s %s\" % (format_time_left(int((100 - perc) / (perc / time_used)), short_format=True), T(\"left\"))\n    return \"\"\n\n\ndef analyse_show(name: str) -> Dict[str, str]:\n    \"\"\"Use the Sorter to collect some basic info on series\"\"\"\n    job = Sorter(\n        None,\n        name,\n        None,\n        None,\n        force=True,\n        sorter_config={\n            \"name\": \"newsunpack__analyse_show\",\n            \"order\": 0,\n            \"min_size\": -1,\n            \"multipart_label\": \"\",\n            \"sort_string\": \"\",\n            \"sort_cats\": [],  # Categories and types are ignored when using the force\n            \"sort_type\": [],\n            \"is_active\": 1,\n        },\n    )\n    job.get_values()\n    return {\n        \"title\": job.info.get(\"title\", \"\"),\n        \"season\": job.info.get(\"season_num\", \"\"),\n        \"episode\": job.info.get(\"episode_num\", \"\"),\n        \"episode_name\": job.info.get(\"ep_name\", \"\"),\n        \"is_proper\": str(job.is_proper()),\n        \"resolution\": job.info.get(\"resolution\", \"\"),\n        \"decade\": job.info.get(\"decade\", \"\"),\n        \"year\": job.info.get(\"year\", \"\"),\n        \"month\": job.info.get(\"month\", \"\"),\n        \"day\": job.info.get(\"day\", \"\"),\n        \"job_type\": job.type,\n    }\n\n\ndef pre_queue(nzo: NzbObject, pp, cat):\n    \"\"\"Run pre-queue script (if any) and process results.\n    pp and cat are supplied separate since they can change.\n    \"\"\"\n\n    def fix(p):\n        # If added via API, some items can still be \"None\" (as a string)\n        if not p or str(p).lower() == \"none\":\n            return \"\"\n        return str(p)\n\n    values = [1, nzo.final_name_with_password, pp, cat, nzo.script, nzo.priority, None]\n    script_path = make_script_path(cfg.pre_script())\n    if script_path:\n        # Basic command-line parameters\n        command = [\n            script_path,\n            nzo.final_name_with_password,\n            pp,\n            cat,\n            nzo.script,\n            nzo.priority,\n            str(nzo.bytes),\n            \" \".join(nzo.groups),\n        ]\n        command.extend(list(analyse_show(nzo.final_name_with_password).values()))\n        command = [fix(arg) for arg in command]\n\n        # Fields not in the NZO directly\n        extra_env_fields = {\n            \"groups\": \" \".join(nzo.groups),\n            \"show_name\": command[8],\n            \"show_season\": command[9],\n            \"show_episode\": command[10],\n            \"show_episode_name\": command[11],\n            \"proper\": command[12],\n            \"resolution\": command[13],\n            \"decade\": command[14],\n            \"year\": command[15],\n            \"month\": command[16],\n            \"day\": command[17],\n            \"type\": command[18],\n        }\n\n        try:\n            p = build_and_run_command(command, env=create_env(nzo, extra_env_fields))\n        except:\n            logging.debug(\"Failed script %s, Traceback: \", script_path, exc_info=True)\n            return values\n\n        output = p.stdout.read()\n        ret = p.wait()\n        logging.info(\"Pre-queue script returned %s and output=\\n%s\", ret, output)\n        if ret == 0:\n            split_output = output.splitlines()\n            try:\n                # Extract category line from pre-queue output\n                pre_queue_category = split_output[3].strip(\" '\\\"\")\n            except IndexError:\n                pre_queue_category = None\n\n            for index, line in enumerate(split_output):\n                line = line.strip(\" '\\\"\")\n                if index < len(values):\n                    if line:\n                        values[index] = line\n                    elif pre_queue_category and index in (2, 4, 5):\n                        # Preserve empty pp, script, and priority lines to prevent\n                        # pre-existing values from overriding category-based settings\n                        values[index] = \"\"\n\n        accept = int_conv(values[0])\n        if accept < 1:\n            logging.info(\"Pre-Q refuses %s\", nzo.final_name)\n        elif accept == 2:\n            logging.info(\"Pre-Q accepts&fails %s\", nzo.final_name)\n        else:\n            logging.info(\"Pre-Q accepts %s\", nzo.final_name)\n\n    return values\n\n\ndef is_sevenfile(path: str) -> bool:\n    \"\"\"Return True if path has 7Zip-signature and 7Zip is detected\"\"\"\n    with open(path, \"rb\") as sevenzip:\n        if sevenzip.read(6) == SEVENZIP_ID:\n            return bool(SEVENZIP_COMMAND)\n    return False\n\n\nclass SevenZip:\n    \"\"\"Minimal emulation of ZipFile class for 7Zip\"\"\"\n\n    def __init__(self, path: str):\n        self.path = path\n        # Check if it's actually a 7Zip-file\n        if not is_sevenfile(self.path):\n            raise TypeError(\"File is not a 7zip file\")\n\n    def namelist(self) -> List[str]:\n        \"\"\"Return list of names in 7Zip\"\"\"\n        names = []\n        command = [SEVENZIP_COMMAND, \"l\", \"-p\", \"-y\", \"-slt\", \"-sccUTF-8\", self.path]\n        output = run_command(command)\n\n        for line in output.split(\"\\n\"):\n            m = SEVENZIP_PATH_RE.search(line)\n            if m:\n                names.append(m.group(1).strip(\"\\r\"))\n        if names:\n            # Remove name of archive itself\n            del names[0]\n        return names\n\n    def open(self, name: str) -> BinaryIO:\n        \"\"\"Read named file from 7Zip and return data\"\"\"\n        command = [SEVENZIP_COMMAND, \"e\", \"-p\", \"-y\", \"-so\", self.path, name]\n        # Ignore diagnostic output, otherwise it will be appended to content\n        with build_and_run_command(command, text_mode=False, stderr=subprocess.DEVNULL) as p:\n            data = io.BytesIO(p.stdout.read())\n            p.wait()\n        return data\n\n    def close(self):\n        \"\"\"Close file\"\"\"\n        pass\n", "#!/usr/bin/python3 -OO\n# Copyright 2007-2023 The SABnzbd-Team <team@sabnzbd.org>\n#\n# This program is free software; you can redistribute it and/or\n# modify it under the terms of the GNU General Public License\n# as published by the Free Software Foundation; either version 2\n# of the License, or (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n#\n\n\"\"\"\nsabnzbd.notifier - Send notifications to any notification services\n\"\"\"\n\n\nimport os.path\nimport logging\nimport urllib.request\nimport urllib.parse\nimport http.client\nimport json\nfrom threading import Thread\n\nimport sabnzbd\nimport sabnzbd.cfg\nfrom sabnzbd.encoding import utob\nfrom sabnzbd.filesystem import make_script_path\nfrom sabnzbd.misc import build_and_run_command\nfrom sabnzbd.newsunpack import create_env\n\nif sabnzbd.FOUNDATION:\n    import Foundation\n    import objc\n\ntry:\n    import notify2\n\n    _HAVE_NTFOSD = True\n\n    # Check for working version, not all pynotify are the same\n    # Without DISPLAY, notify2 cannot autolaunch a dbus-daemon\n    if not hasattr(notify2, \"init\") or \"DISPLAY\" not in os.environ:\n        _HAVE_NTFOSD = False\nexcept:\n    _HAVE_NTFOSD = False\n\n\n##############################################################################\n# Define translatable message table\n##############################################################################\nTT = lambda x: x\nNOTIFICATION = {\n    \"startup\": TT(\"Startup/Shutdown\"),  #: Notification\n    \"pause_resume\": TT(\"Pause\") + \"/\" + TT(\"Resume\"),  #: Notification\n    \"download\": TT(\"Added NZB\"),  #: Notification\n    \"pp\": TT(\"Post-processing started\"),  # : Notification\n    \"complete\": TT(\"Job finished\"),  #: Notification\n    \"failed\": TT(\"Job failed\"),  #: Notification\n    \"warning\": TT(\"Warning\"),  #: Notification\n    \"error\": TT(\"Error\"),  #: Notification\n    \"disk_full\": TT(\"Disk full\"),  #: Notification\n    \"queue_done\": TT(\"Queue finished\"),  #: Notification\n    \"new_login\": TT(\"User logged in\"),  #: Notification\n    \"other\": TT(\"Other Messages\"),  #: Notification\n}\n\n\ndef get_icon():\n    icon = os.path.join(sabnzbd.DIR_PROG, \"icons\", \"sabnzbd.ico\")\n    with open(icon, \"rb\") as fp:\n        return fp.read()\n\n\ndef have_ntfosd():\n    \"\"\"Return if any PyNotify (notify2) support is present\"\"\"\n    return bool(_HAVE_NTFOSD)\n\n\ndef check_classes(gtype, section):\n    \"\"\"Check if `gtype` is enabled in `section`\"\"\"\n    try:\n        return sabnzbd.config.get_config(section, \"%s_prio_%s\" % (section, gtype))() > 0\n    except TypeError:\n        logging.debug(\"Incorrect Notify option %s:%s_prio_%s\", section, section, gtype)\n        return False\n\n\ndef get_prio(gtype, section):\n    \"\"\"Check prio of `gtype` in `section`\"\"\"\n    try:\n        return sabnzbd.config.get_config(section, \"%s_prio_%s\" % (section, gtype))()\n    except TypeError:\n        logging.debug(\"Incorrect Notify option %s:%s_prio_%s\", section, section, gtype)\n        return -1000\n\n\ndef check_cat(section, job_cat, keyword=None):\n    \"\"\"Check if `job_cat` is enabled in `section`.\n    * = All, if no other categories selected.\n    \"\"\"\n    if not job_cat:\n        return True\n    try:\n        if not keyword:\n            keyword = section\n        section_cats = sabnzbd.config.get_config(section, \"%s_cats\" % keyword)()\n        return [\"*\"] == section_cats or job_cat in section_cats\n    except TypeError:\n        logging.debug(\"Incorrect Notify option %s:%s_cats\", section, section)\n        return True\n\n\ndef send_notification(title, msg, gtype, job_cat=None):\n    \"\"\"Send Notification message\"\"\"\n    logging.info(\"Sending notification: %s - %s (type=%s, job_cat=%s)\", title, msg, gtype, job_cat)\n    # Notification Center\n    if sabnzbd.MACOS and sabnzbd.cfg.ncenter_enable():\n        if check_classes(gtype, \"ncenter\") and check_cat(\"ncenter\", job_cat):\n            send_notification_center(title, msg, gtype)\n\n    # Windows\n    if sabnzbd.WIN32 and sabnzbd.cfg.acenter_enable():\n        if check_classes(gtype, \"acenter\") and check_cat(\"acenter\", job_cat):\n            send_windows(title, msg, gtype)\n\n    # Prowl\n    if sabnzbd.cfg.prowl_enable() and check_cat(\"prowl\", job_cat):\n        if sabnzbd.cfg.prowl_apikey():\n            Thread(target=send_prowl, args=(title, msg, gtype)).start()\n\n    # Pushover\n    if sabnzbd.cfg.pushover_enable() and check_cat(\"pushover\", job_cat):\n        if sabnzbd.cfg.pushover_token():\n            Thread(target=send_pushover, args=(title, msg, gtype)).start()\n\n    # Pushbullet\n    if sabnzbd.cfg.pushbullet_enable() and check_cat(\"pushbullet\", job_cat):\n        if sabnzbd.cfg.pushbullet_apikey() and check_classes(gtype, \"pushbullet\"):\n            Thread(target=send_pushbullet, args=(title, msg, gtype)).start()\n\n    # Notification script.\n    if sabnzbd.cfg.nscript_enable() and check_cat(\"nscript\", job_cat):\n        if sabnzbd.cfg.nscript_script():\n            Thread(target=send_nscript, args=(title, msg, gtype)).start()\n\n    # NTFOSD\n    if have_ntfosd() and sabnzbd.cfg.ntfosd_enable():\n        if check_classes(gtype, \"ntfosd\") and check_cat(\"ntfosd\", job_cat):\n            send_notify_osd(title, msg)\n\n\n##############################################################################\n# Ubuntu NotifyOSD Support\n##############################################################################\n_NTFOSD = False\n\n\ndef send_notify_osd(title, message):\n    \"\"\"Send a message to NotifyOSD\"\"\"\n    global _NTFOSD\n    if not _HAVE_NTFOSD:\n        return T(\"Not available\")  # : Function is not available on this OS\n\n    error = \"NotifyOSD not working\"\n    icon = os.path.join(sabnzbd.DIR_PROG, \"interfaces/Config/templates/staticcfg/images/logo-arrow.svg\")\n\n    # Wrap notify2.init to prevent blocking in dbus\n    # when there's no active notification daemon\n    try:\n        _NTFOSD = _NTFOSD or notify2.init(\"SABnzbd\")\n    except:\n        _NTFOSD = False\n\n    if _NTFOSD:\n        logging.info(\"Send to NotifyOSD: %s / %s\", title, message)\n        try:\n            note = notify2.Notification(title, message, icon)\n            note.show()\n        except:\n            # Apparently not implemented on this system\n            logging.info(error)\n            return error\n        return None\n    else:\n        return error\n\n\ndef send_notification_center(title, msg, gtype):\n    \"\"\"Send message to macOS Notification Center\"\"\"\n    try:\n        NSUserNotification = objc.lookUpClass(\"NSUserNotification\")\n        NSUserNotificationCenter = objc.lookUpClass(\"NSUserNotificationCenter\")\n        notification = NSUserNotification.alloc().init()\n        notification.setTitle_(title)\n        notification.setSubtitle_(T(NOTIFICATION.get(gtype, \"other\")))\n        notification.setInformativeText_(msg)\n        notification.setSoundName_(\"NSUserNotificationDefaultSoundName\")\n        notification.setDeliveryDate_(Foundation.NSDate.dateWithTimeInterval_sinceDate_(0, Foundation.NSDate.date()))\n        NSUserNotificationCenter.defaultUserNotificationCenter().scheduleNotification_(notification)\n    except:\n        logging.info(T(\"Failed to send macOS notification\"))\n        logging.debug(\"Traceback: \", exc_info=True)\n        return T(\"Failed to send macOS notification\")\n\n\ndef send_prowl(title, msg, gtype, force=False, test=None):\n    \"\"\"Send message to Prowl\"\"\"\n\n    if test:\n        apikey = test.get(\"prowl_apikey\")\n    else:\n        apikey = sabnzbd.cfg.prowl_apikey()\n    if not apikey:\n        return T(\"Cannot send, missing required data\")\n\n    title = T(NOTIFICATION.get(gtype, \"other\"))\n    title = urllib.parse.quote(utob(title))\n    msg = urllib.parse.quote(utob(msg))\n    prio = get_prio(gtype, \"prowl\")\n\n    if force:\n        prio = 0\n\n    if prio > -3:\n        url = (\n            \"https://api.prowlapp.com/publicapi/add?apikey=%s&application=SABnzbd\"\n            \"&event=%s&description=%s&priority=%d\" % (apikey, title, msg, prio)\n        )\n        try:\n            urllib.request.urlopen(url)\n            return \"\"\n        except:\n            logging.warning(T(\"Failed to send Prowl message\"))\n            logging.info(\"Traceback: \", exc_info=True)\n            return T(\"Failed to send Prowl message\")\n    return \"\"\n\n\ndef send_pushover(title, msg, gtype, force=False, test=None):\n    \"\"\"Send message to pushover\"\"\"\n\n    if test:\n        apikey = test.get(\"pushover_token\")\n        userkey = test.get(\"pushover_userkey\")\n        device = test.get(\"pushover_device\")\n    else:\n        apikey = sabnzbd.cfg.pushover_token()\n        userkey = sabnzbd.cfg.pushover_userkey()\n        device = sabnzbd.cfg.pushover_device()\n        emergency_retry = sabnzbd.cfg.pushover_emergency_retry()\n        emergency_expire = sabnzbd.cfg.pushover_emergency_expire()\n    if not apikey or not userkey:\n        return T(\"Cannot send, missing required data\")\n\n    title = T(NOTIFICATION.get(gtype, \"other\"))\n    prio = get_prio(gtype, \"pushover\")\n\n    if force:\n        prio = 1\n\n    if prio == 2:\n        body = {\n            \"token\": apikey,\n            \"user\": userkey,\n            \"device\": device,\n            \"title\": title,\n            \"message\": msg,\n            \"priority\": prio,\n            \"retry\": emergency_retry,\n            \"expire\": emergency_expire,\n        }\n        return do_send_pushover(body)\n    if -3 < prio < 2:\n        body = {\n            \"token\": apikey,\n            \"user\": userkey,\n            \"device\": device,\n            \"title\": title,\n            \"message\": msg,\n            \"priority\": prio,\n        }\n        return do_send_pushover(body)\n\n\ndef do_send_pushover(body):\n    try:\n        conn = http.client.HTTPSConnection(\"api.pushover.net:443\")\n        conn.request(\n            \"POST\",\n            \"/1/messages.json\",\n            urllib.parse.urlencode(body),\n            {\"Content-type\": \"application/x-www-form-urlencoded\"},\n        )\n        res = conn.getresponse()\n        if res.status != 200:\n            logging.error(T(\"Bad response from Pushover (%s): %s\"), res.status, res.read())\n            return T(\"Failed to send pushover message\")\n        else:\n            return \"\"\n    except:\n        logging.warning(T(\"Failed to send pushover message\"))\n        logging.info(\"Traceback: \", exc_info=True)\n        return T(\"Failed to send pushover message\")\n\n\ndef send_pushbullet(title, msg, gtype, force=False, test=None):\n    \"\"\"Send message to Pushbullet\"\"\"\n\n    if test:\n        apikey = test.get(\"pushbullet_apikey\")\n        device = test.get(\"pushbullet_device\")\n    else:\n        apikey = sabnzbd.cfg.pushbullet_apikey()\n        device = sabnzbd.cfg.pushbullet_device()\n    if not apikey:\n        return T(\"Cannot send, missing required data\")\n\n    title = \"SABnzbd: \" + T(NOTIFICATION.get(gtype, \"other\"))\n\n    try:\n        conn = http.client.HTTPSConnection(\"api.pushbullet.com:443\")\n        conn.request(\n            \"POST\",\n            \"/v2/pushes\",\n            json.dumps({\"type\": \"note\", \"device\": device, \"title\": title, \"body\": msg}),\n            headers={\"Authorization\": \"Bearer \" + apikey, \"Content-type\": \"application/json\"},\n        )\n        res = conn.getresponse()\n        if res.status != 200:\n            logging.error(T(\"Bad response from Pushbullet (%s): %s\"), res.status, res.read())\n        else:\n            logging.info(\"Successfully sent to Pushbullet\")\n\n    except:\n        logging.warning(T(\"Failed to send pushbullet message\"))\n        logging.info(\"Traceback: \", exc_info=True)\n        return T(\"Failed to send pushbullet message\")\n    return \"\"\n\n\ndef send_nscript(title, msg, gtype, force=False, test=None):\n    \"\"\"Run user's notification script\"\"\"\n    if test:\n        script = test.get(\"nscript_script\")\n        env = {\"notification_parameters\": test.get(\"nscript_parameters\")}\n    else:\n        script = sabnzbd.cfg.nscript_script()\n        env = {\"notification_parameters\": sabnzbd.cfg.nscript_parameters()}\n\n    if not script:\n        return T(\"Cannot send, missing required data\")\n    title = \"SABnzbd: \" + T(NOTIFICATION.get(gtype, \"other\"))\n\n    if force or check_classes(gtype, \"nscript\"):\n        script_path = make_script_path(script)\n        if script_path:\n            ret = -1\n            output = None\n            try:\n                p = build_and_run_command([script_path, gtype, title, msg], env=create_env(extra_env_fields=env))\n                output = p.stdout.read()\n                ret = p.wait()\n            except:\n                logging.info(\"Failed script %s, Traceback: \", script, exc_info=True)\n\n            if ret:\n                logging.error(T('Script returned exit code %s and output \"%s\"'), ret, output)\n                return T('Script returned exit code %s and output \"%s\"') % (ret, output)\n            else:\n                logging.info(\"Successfully executed notification script %s\", script_path)\n        else:\n            return T('Notification script \"%s\" does not exist') % script_path\n    return \"\"\n\n\ndef send_windows(title, msg, gtype):\n    if sabnzbd.WINTRAY and not sabnzbd.WINTRAY.terminate:\n        try:\n            sabnzbd.WINTRAY.sendnotification(title, msg)\n        except:\n            logging.info(T(\"Failed to send Windows notification\"))\n            logging.debug(\"Traceback: \", exc_info=True)\n            return T(\"Failed to send Windows notification\")\n    return None\n"], "fixing_code": ["#!/usr/bin/python3 -OO\n# Copyright 2007-2023 The SABnzbd-Team <team@sabnzbd.org>\n#\n# This program is free software; you can redistribute it and/or\n# modify it under the terms of the GNU General Public License\n# as published by the Free Software Foundation; either version 2\n# of the License, or (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n\n\"\"\"\nsabnzbd.newsunpack\n\"\"\"\n\nimport os\nimport sys\nimport re\nimport subprocess\nimport logging\nimport time\nimport io\nimport shutil\nimport functools\nfrom typing import Tuple, List, BinaryIO, Optional, Dict, Any, Union\n\nimport sabnzbd\nfrom sabnzbd.encoding import correct_unknown_encoding, ubtou\nimport sabnzbd.utils.rarfile as rarfile\nfrom sabnzbd.misc import (\n    format_time_string,\n    find_on_path,\n    int_conv,\n    get_all_passwords,\n    calc_age,\n    cmp,\n    run_command,\n    build_and_run_command,\n    format_time_left,\n)\nfrom sabnzbd.filesystem import (\n    make_script_path,\n    real_path,\n    globber,\n    globber_full,\n    renamer,\n    clip_path,\n    long_path,\n    remove_file,\n    listdir_full,\n    setname_from_path,\n    get_ext,\n    TS_RE,\n    build_filelists,\n    get_filename,\n    SEVENMULTI_RE,\n    is_size,\n)\nfrom sabnzbd.nzbstuff import NzbObject\nimport sabnzbd.cfg as cfg\nfrom sabnzbd.constants import Status, JOB_ADMIN\nfrom sabnzbd.sorting import Sorter\n\n# Regex globals\nRAR_V3_RE = re.compile(r\"\\.(?P<ext>part\\d*)$\", re.I)\nRAR_EXTRACTFROM_RE = re.compile(r\"^Extracting\\sfrom\\s(.+)\")\nRAR_EXTRACTED_RE = re.compile(r\"^(Extracting|Creating|...)\\s+(.*?)\\s+OK\\s*$\")\nSEVENZIP_PATH_RE = re.compile(\"^Path = (.+)\")\nPAR2_TARGET_RE = re.compile(r'^(?:File|Target): \"(.+)\" -')\nPAR2_BLOCK_FOUND_RE = re.compile(r'File: \"([^\"]+)\" - found \\d+ of \\d+ data blocks from \"([^\"]+)\"')\nPAR2_IS_MATCH_FOR_RE = re.compile(r'File: \"([^\"]+)\" - is a match for \"([^\"]+)\"')\nPAR2_FILENAME_RE = re.compile(r'\"([^\"]+)\"')\n\n# Constants\nSEVENZIP_ID = b\"7z\\xbc\\xaf'\\x1c\"\nPAR2_COMMAND = None\nMULTIPAR_COMMAND = None\nRAR_COMMAND = None\nNICE_COMMAND = None\nZIP_COMMAND = None\nSEVENZIP_COMMAND = None\nIONICE_COMMAND = None\nRAR_PROBLEM = False\nPAR2_MT = True\nRAR_VERSION = 0\nSEVENZIP_VERSION = \"\"\n\n\ndef find_programs(curdir: str):\n    \"\"\"Find external programs\"\"\"\n\n    def check(path: str, program: str) -> Optional[str]:\n        p = os.path.abspath(os.path.join(path, program))\n        if os.access(p, os.X_OK):\n            return p\n        else:\n            return None\n\n    if sabnzbd.MACOS:\n        if sabnzbd.MACOSARM64:\n            # M1 (ARM64) versions\n            sabnzbd.newsunpack.PAR2_COMMAND = check(curdir, \"osx/par2/arm64/par2\")\n            sabnzbd.newsunpack.RAR_COMMAND = check(curdir, \"osx/unrar/arm64/unrar\")\n        else:\n            # Regular x64 versions\n            sabnzbd.newsunpack.PAR2_COMMAND = check(curdir, \"osx/par2/par2-sl64\")\n            sabnzbd.newsunpack.RAR_COMMAND = check(curdir, \"osx/unrar/unrar\")\n        # The 7zip binary is universal2\n        sabnzbd.newsunpack.SEVENZIP_COMMAND = check(curdir, \"osx/7zip/7zz\")\n\n    if sabnzbd.WIN32:\n        if sabnzbd.WIN64:\n            # 64 bit versions\n            sabnzbd.newsunpack.MULTIPAR_COMMAND = check(curdir, \"win/multipar/par2j64.exe\")\n            sabnzbd.newsunpack.RAR_COMMAND = check(curdir, \"win/unrar/x64/UnRAR.exe\")\n        else:\n            # 32 bit versions\n            sabnzbd.newsunpack.MULTIPAR_COMMAND = check(curdir, \"win/multipar/par2j.exe\")\n            sabnzbd.newsunpack.RAR_COMMAND = check(curdir, \"win/unrar/UnRAR.exe\")\n        # We just use the 32 bit version\n        sabnzbd.newsunpack.SEVENZIP_COMMAND = check(curdir, \"win/7zip/7za.exe\")\n    else:\n        if not sabnzbd.newsunpack.PAR2_COMMAND:\n            sabnzbd.newsunpack.PAR2_COMMAND = find_on_path(\"par2\")\n        if not sabnzbd.newsunpack.RAR_COMMAND:\n            sabnzbd.newsunpack.RAR_COMMAND = find_on_path(\n                (\n                    \"unrar\",\n                    \"rar\",\n                    \"unrar3\",\n                    \"rar3\",\n                )\n            )\n        sabnzbd.newsunpack.NICE_COMMAND = find_on_path(\"nice\")\n        sabnzbd.newsunpack.IONICE_COMMAND = find_on_path(\"ionice\")\n        if not sabnzbd.newsunpack.ZIP_COMMAND:\n            sabnzbd.newsunpack.ZIP_COMMAND = find_on_path(\"unzip\")\n        if not sabnzbd.newsunpack.SEVENZIP_COMMAND:\n            sabnzbd.newsunpack.SEVENZIP_COMMAND = find_on_path(\"7za\")  # 7za = 7z stand-alone executable\n        if not sabnzbd.newsunpack.SEVENZIP_COMMAND:\n            sabnzbd.newsunpack.SEVENZIP_COMMAND = find_on_path(\"7z\")\n\n    if not (sabnzbd.WIN32 or sabnzbd.MACOS):\n        # Run check on rar version\n        version, original = unrar_check(sabnzbd.newsunpack.RAR_COMMAND)\n        sabnzbd.newsunpack.RAR_PROBLEM = not original or version < sabnzbd.constants.REC_RAR_VERSION\n        sabnzbd.newsunpack.RAR_VERSION = version\n\n        # Run check on 7zip\n        sabnzbd.newsunpack.SEVENZIP_VERSION = sevenzip_check(sabnzbd.newsunpack.SEVENZIP_COMMAND)\n\n        # Run check on par2-multicore\n        sabnzbd.newsunpack.PAR2_MT = par2_mt_check(sabnzbd.newsunpack.PAR2_COMMAND)\n\n    # Set the path for rarfile\n    rarfile.UNRAR_TOOL = sabnzbd.newsunpack.RAR_COMMAND\n\n\nENV_NZO_FIELDS = [\n    \"bytes\",\n    \"bytes_downloaded\",\n    \"bytes_tried\",\n    \"cat\",\n    \"correct_password\",\n    \"duplicate\",\n    \"encrypted\",\n    \"fail_msg\",\n    \"filename\",\n    \"final_name\",\n    \"group\",\n    \"nzo_id\",\n    \"oversized\",\n    \"password\",\n    \"pp\",\n    \"priority\",\n    \"repair\",\n    \"script\",\n    \"status\",\n    \"unpack\",\n    \"unwanted_ext\",\n    \"url\",\n]\n\n\ndef external_processing(\n    extern_proc: str, nzo: NzbObject, complete_dir: str, nicename: str, status: int\n) -> Tuple[str, int]:\n    \"\"\"Run a user postproc script, return console output and exit value\"\"\"\n    failure_url = nzo.nzo_info.get(\"failure\", \"\")\n    # Items can be bool or null, causing POpen to fail\n    command = [\n        str(extern_proc),\n        str(complete_dir),\n        str(nzo.filename),\n        str(nicename),\n        \"\",\n        str(nzo.cat),\n        str(nzo.group),\n        str(status),\n        str(failure_url),\n    ]\n\n    # Add path to original NZB\n    nzb_paths = globber_full(nzo.admin_path, \"*.gz\")\n\n    # Fields not in the NZO directly\n    extra_env_fields = {\n        \"failure_url\": failure_url,\n        \"complete_dir\": complete_dir,\n        \"pp_status\": status,\n        \"download_time\": nzo.nzo_info.get(\"download_time\", \"\"),\n        \"avg_bps\": int(nzo.avg_bps_total / nzo.avg_bps_freq) if nzo.avg_bps_freq else 0,\n        \"age\": calc_age(nzo.avg_date),\n        \"orig_nzb_gz\": clip_path(nzb_paths[0]) if nzb_paths else \"\",\n    }\n\n    # Make sure that if we run a Python script it's output is unbuffered, so we can show it to the user\n    if extern_proc.endswith(\".py\"):\n        extra_env_fields[\"pythonunbuffered\"] = True\n\n    try:\n        p = build_and_run_command(command, env=create_env(nzo, extra_env_fields))\n        sabnzbd.PostProcessor.external_process = p\n\n        # Follow the output, so we can abort it\n        lines = []\n        while 1:\n            line = p.stdout.readline()\n            if not line:\n                break\n            line = line.strip()\n            lines.append(line)\n\n            # Show current line in history\n            nzo.set_action_line(T(\"Running script\"), line)\n    except:\n        logging.debug(\"Failed script %s, Traceback: \", extern_proc, exc_info=True)\n        return \"Cannot run script %s\\r\\n\" % extern_proc, -1\n\n    output = \"\\n\".join(lines)\n    ret = p.wait()\n    return output, ret\n\n\ndef unpacker(\n    nzo: NzbObject,\n    workdir_complete: str,\n    one_folder: bool,\n    joinables: List[str] = [],\n    zips: List[str] = [],\n    rars: List[str] = [],\n    sevens: List[str] = [],\n    ts: List[str] = [],\n    depth: int = 0,\n) -> Tuple[Union[int, bool], List[str]]:\n    \"\"\"Do a recursive unpack from all archives in 'download_path' to 'workdir_complete'\"\"\"\n    if depth > 5:\n        logging.warning(T(\"Unpack nesting too deep [%s]\"), nzo.final_name)\n        return False, []\n    depth += 1\n\n    if depth == 1:\n        # First time, ignore anything in workdir_complete\n        xjoinables, xzips, xrars, xsevens, xts = build_filelists(nzo.download_path)\n    else:\n        xjoinables, xzips, xrars, xsevens, xts = build_filelists(\n            nzo.download_path, workdir_complete, check_both=nzo.delete\n        )\n\n    force_rerun = False\n    newfiles = []\n    error = None\n    new_joins = new_ts = None\n\n    if cfg.enable_filejoin():\n        new_joins = [jn for jn in xjoinables if jn not in joinables]\n        if new_joins:\n            logging.info(\"Filejoin starting on %s\", nzo.download_path)\n            error, newf = file_join(nzo, workdir_complete, new_joins)\n            if newf:\n                newfiles.extend(newf)\n            logging.info(\"Filejoin finished on %s\", nzo.download_path)\n\n    if cfg.enable_unrar():\n        new_rars = [rar for rar in xrars if rar not in rars]\n        if new_rars:\n            logging.info(\"Unrar starting on %s\", nzo.download_path)\n            error, newf = rar_unpack(nzo, workdir_complete, one_folder, new_rars)\n            if newf:\n                newfiles.extend(newf)\n            logging.info(\"Unrar finished on %s\", nzo.download_path)\n\n    if cfg.enable_7zip():\n        new_sevens = [seven for seven in xsevens if seven not in sevens]\n        if new_sevens:\n            logging.info(\"7za starting on %s\", nzo.download_path)\n            error, newf = unseven(nzo, workdir_complete, one_folder, new_sevens)\n            if newf:\n                newfiles.extend(newf)\n            logging.info(\"7za finished on %s\", nzo.download_path)\n\n    if cfg.enable_unzip():\n        new_zips = [zipfile for zipfile in xzips if zipfile not in zips]\n        if new_zips:\n            logging.info(\"Unzip starting on %s\", nzo.download_path)\n            if SEVENZIP_COMMAND:\n                error, newf = unseven(nzo, workdir_complete, one_folder, new_zips)\n            else:\n                error, newf = unzip(nzo, workdir_complete, one_folder, new_zips)\n            if newf:\n                newfiles.extend(newf)\n            logging.info(\"Unzip finished on %s\", nzo.download_path)\n\n    if cfg.enable_tsjoin():\n        new_ts = [_ts for _ts in xts if _ts not in ts]\n        if new_ts:\n            logging.info(\"TS Joining starting on %s\", nzo.download_path)\n            error, newf = file_join(nzo, workdir_complete, new_ts)\n            if newf:\n                newfiles.extend(newf)\n            logging.info(\"TS Joining finished on %s\", nzo.download_path)\n\n    # Refresh history and set output\n    nzo.set_action_line()\n\n    # Only re-run if something was unpacked and it was success\n    rerun = error in (False, 0)\n\n    # During a Retry we might miss files in the complete folder\n    # that failed during recursive unpack in the first run\n    if nzo.reuse and depth == 1 and any(build_filelists(workdir=None, workdir_complete=workdir_complete)):\n        rerun = True\n\n    # We can't recursive unpack on long paths on Windows\n    # See: https://github.com/sabnzbd/sabnzbd/pull/771\n    if sabnzbd.WIN32 and len(workdir_complete) > 256:\n        rerun = False\n\n    # Double-check that we didn't miss any files in workdir\n    # But only if dele=True, otherwise of course there will be files left\n    if rerun and nzo.delete and depth == 1 and any(build_filelists(nzo.download_path)):\n        force_rerun = True\n        # Clear lists to force re-scan of files\n        xjoinables, xzips, xrars, xsevens, xts = ([], [], [], [], [])\n\n    if rerun and (cfg.enable_recursive() or new_ts or new_joins or force_rerun):\n        z, y = unpacker(nzo, workdir_complete, one_folder, xjoinables, xzips, xrars, xsevens, xts, depth)\n        if z:\n            error = z\n        if y:\n            newfiles.extend(y)\n\n    return error, newfiles\n\n\n##############################################################################\n# Filejoin Functions\n##############################################################################\ndef match_ts(file: str) -> Tuple[str, int]:\n    \"\"\"Return True if file is a joinable TS file\"\"\"\n    match = TS_RE.search(file)\n    if not match:\n        return \"\", 0\n\n    num = int(match.group(1))\n    try:\n        setname = file[: match.start()]\n        setname += \".ts\"\n    except:\n        setname = \"\"\n    return setname, num\n\n\ndef clean_up_joinables(names: List[str]):\n    \"\"\"Remove joinable files and their .1 backups\"\"\"\n    for name in names:\n        if os.path.exists(name):\n            try:\n                remove_file(name)\n            except:\n                pass\n        name1 = name + \".1\"\n        if os.path.exists(name1):\n            try:\n                remove_file(name1)\n            except:\n                pass\n\n\ndef get_seq_number(name: str) -> int:\n    \"\"\"Return sequence number if name as an int\"\"\"\n    head, tail = os.path.splitext(name)\n    if tail == \".ts\":\n        _, num = match_ts(name)\n    else:\n        num = tail[1:]\n    if num.isdigit():\n        return int(num)\n    else:\n        return 0\n\n\ndef file_join(nzo: NzbObject, workdir_complete: str, joinables: List[str]) -> Tuple[bool, List[str]]:\n    \"\"\"Join and joinable files in 'workdir' to 'workdir_complete' and\n    when successful, delete originals\n    \"\"\"\n    newfiles = []\n    bufsize = 24 * 1024 * 1024\n\n    # Create matching sets from the list of files\n    joinable_sets = {}\n    joinable_set = None\n    for joinable in joinables:\n        head, tail = os.path.splitext(joinable)\n        if tail == \".ts\":\n            head, _ = match_ts(joinable)\n        if head not in joinable_sets:\n            joinable_sets[head] = []\n        joinable_sets[head].append(joinable)\n    logging.debug(\"joinable_sets: %s\", joinable_sets)\n\n    try:\n        # Handle each set\n        for joinable_set in joinable_sets:\n            current = joinable_sets[joinable_set]\n            joinable_sets[joinable_set].sort()\n\n            # If par2 already did the work, just remove the files\n            if os.path.exists(joinable_set):\n                logging.debug(\"file_join(): Skipping %s, (probably) joined by par2\", joinable_set)\n                if nzo.delete:\n                    clean_up_joinables(current)\n                # done, go to next set\n                continue\n\n            # Only join when there is more than one file\n            size = len(current)\n            if size < 2:\n                continue\n\n            # Prepare joined file\n            filename = joinable_set\n            if workdir_complete:\n                filename = filename.replace(nzo.download_path, workdir_complete)\n            logging.debug(\"file_join(): Assembling %s\", filename)\n\n            # Join the segments\n            with open(filename, \"ab\") as joined_file:\n                n = get_seq_number(current[0])\n                seq_error = n > 1\n                for joinable in current:\n                    if get_seq_number(joinable) != n:\n                        seq_error = True\n                    perc = (100.0 / size) * n\n                    logging.debug(\"Processing %s\", joinable)\n                    nzo.set_action_line(T(\"Joining\"), \"%.0f%%\" % perc)\n                    with open(joinable, \"rb\") as f:\n                        shutil.copyfileobj(f, joined_file, bufsize)\n                    if nzo.delete:\n                        remove_file(joinable)\n                    n += 1\n\n            # Remove any remaining .1 files\n            clean_up_joinables(current)\n\n            # Finish up\n            newfiles.append(filename)\n\n            setname = setname_from_path(joinable_set)\n            if seq_error:\n                msg = T(\"Incomplete sequence of joinable files\")\n                nzo.fail_msg = T(\"File join of %s failed\") % setname\n                nzo.set_unpack_info(\"Filejoin\", T('[%s] Error \"%s\" while joining files') % (setname, msg))\n                logging.error(T('Error \"%s\" while running file_join on %s'), msg, nzo.final_name)\n                return True, []\n            else:\n                msg = T(\"[%s] Joined %s files\") % (joinable_set, size)\n                nzo.set_unpack_info(\"Filejoin\", msg, setname)\n    except:\n        msg = sys.exc_info()[1]\n        nzo.fail_msg = T(\"File join of %s failed\") % msg\n        nzo.set_unpack_info(\n            \"Filejoin\", T('[%s] Error \"%s\" while joining files') % (setname_from_path(joinable_set), msg)\n        )\n        logging.error(T('Error \"%s\" while running file_join on %s'), msg, nzo.final_name)\n        return True, []\n\n    return False, newfiles\n\n\n##############################################################################\n# (Un)Rar Functions\n##############################################################################\ndef rar_unpack(nzo: NzbObject, workdir_complete: str, one_folder: bool, rars: List[str]) -> Tuple[int, List[str]]:\n    \"\"\"Unpack multiple sets 'rars' of RAR files from 'download_path' to 'workdir_complete.\n    When 'delete' is set, originals will be deleted.\n    When 'one_folder' is set, all files will be in a single folder\n    \"\"\"\n    fail = 0\n    newfiles = extracted_files = []\n    rar_sets = {}\n    for rar in rars:\n        rar_set = setname_from_path(rar)\n        if RAR_V3_RE.search(rar_set):\n            # Remove the \".partXX\" part\n            rar_set = os.path.splitext(rar_set)[0]\n        if rar_set not in rar_sets:\n            rar_sets[rar_set] = []\n        rar_sets[rar_set].append(rar)\n\n    logging.debug(\"Rar_sets: %s\", rar_sets)\n\n    for rar_set in rar_sets:\n        # Run the RAR extractor\n        rar_sets[rar_set].sort(key=functools.cmp_to_key(rar_sort))\n\n        rarpath = rar_sets[rar_set][0]\n\n        if workdir_complete and rarpath.startswith(nzo.download_path):\n            extraction_path = workdir_complete\n        else:\n            extraction_path = os.path.split(rarpath)[0]\n\n        # Is the direct-unpacker still running? We wait for it\n        if nzo.direct_unpacker:\n            wait_count = 0\n            last_stats = nzo.direct_unpacker.get_formatted_stats()\n            while nzo.direct_unpacker.is_alive():\n                logging.debug(\"DirectUnpacker still alive for %s: %s\", nzo.final_name, last_stats)\n\n                # Bump the file-lock in case it's stuck\n                with nzo.direct_unpacker.next_file_lock:\n                    nzo.direct_unpacker.next_file_lock.notify()\n                time.sleep(2)\n\n                # Did something change? Might be stuck\n                if last_stats == nzo.direct_unpacker.get_formatted_stats():\n                    wait_count += 1\n                    if wait_count > 60:\n                        # We abort after 2 minutes of no changes\n                        nzo.direct_unpacker.abort()\n                else:\n                    wait_count = 0\n                last_stats = nzo.direct_unpacker.get_formatted_stats()\n\n        # Did we already direct-unpack it? Not when recursive-unpacking\n        if nzo.direct_unpacker and rar_set in nzo.direct_unpacker.success_sets:\n            logging.info(\"Set %s completed by DirectUnpack\", rar_set)\n            fail = 0\n            success = True\n            rars, newfiles = nzo.direct_unpacker.success_sets.pop(rar_set)\n        else:\n            logging.info(\"Extracting rarfile %s (belonging to %s) to %s\", rarpath, rar_set, extraction_path)\n            try:\n                fail, newfiles, rars = rar_extract(\n                    rarpath, len(rar_sets[rar_set]), one_folder, nzo, rar_set, extraction_path\n                )\n                success = not fail\n            except:\n                success = False\n                fail = 1\n                msg = sys.exc_info()[1]\n                nzo.fail_msg = T(\"Unpacking failed, %s\") % msg\n                setname = nzo.final_name\n                nzo.set_unpack_info(\"Unpack\", T('[%s] Error \"%s\" while unpacking RAR files') % (setname, msg))\n\n                logging.error(T('Error \"%s\" while running rar_unpack on %s'), msg, setname)\n                logging.debug(\"Traceback: \", exc_info=True)\n\n        if success:\n            logging.debug(\"rar_unpack(): Rars: %s\", rars)\n            logging.debug(\"rar_unpack(): Newfiles: %s\", newfiles)\n            extracted_files.extend(newfiles)\n\n        # Do not fail if this was a recursive unpack\n        if fail and rarpath.startswith(workdir_complete):\n            # Do not delete the files, leave it to user!\n            logging.info(\"Ignoring failure to do recursive unpack of %s\", rarpath)\n            fail = 0\n            success = True\n            newfiles = []\n\n        # Do not fail if this was maybe just some duplicate fileset\n        # Multipar and par2tbb will detect and log them, par2cmdline will not\n        if fail and rar_set.endswith((\".1\", \".2\")):\n            # Just in case, we leave the raw files\n            logging.info(\"Ignoring failure of unpack for possible duplicate file %s\", rarpath)\n            fail = 0\n            success = True\n            newfiles = []\n\n        # Delete the old files if we have to\n        if success and nzo.delete and newfiles:\n            for rar in rars:\n                try:\n                    remove_file(rar)\n                except OSError:\n                    if os.path.exists(rar):\n                        logging.warning(T(\"Deleting %s failed!\"), rar)\n\n                brokenrar = \"%s.1\" % rar\n\n                if os.path.exists(brokenrar):\n                    logging.info(\"Deleting %s\", brokenrar)\n                    try:\n                        remove_file(brokenrar)\n                    except OSError:\n                        if os.path.exists(brokenrar):\n                            logging.warning(T(\"Deleting %s failed!\"), brokenrar)\n\n    return fail, extracted_files\n\n\ndef rar_extract(\n    rarfile_path: str, numrars: int, one_folder: bool, nzo: NzbObject, setname: str, extraction_path: str\n) -> Tuple[int, List[str], List[str]]:\n    \"\"\"Unpack single rar set 'rarfile' to 'extraction_path',\n    with password tries\n    Return fail==0(ok)/fail==1(error)/fail==2(wrong password)/fail==3(crc-error), new_files, rars\n    \"\"\"\n    fail = 0\n    new_files = []\n    rars = []\n    passwords = get_all_passwords(nzo)\n\n    for password in passwords:\n        if password:\n            logging.debug('Trying unrar with password \"%s\"', password)\n            msg = T('Trying unrar with password \"%s\"') % password\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n        fail, new_files, rars = rar_extract_core(\n            rarfile_path, numrars, one_folder, nzo, setname, extraction_path, password\n        )\n        if fail != 2:\n            break\n\n    return fail, new_files, rars\n\n\ndef rar_extract_core(\n    rarfile_path: str, numrars: int, one_folder: bool, nzo: NzbObject, setname: str, extraction_path: str, password: str\n) -> Tuple[int, List[str], List[str]]:\n    \"\"\"Unpack single rar set 'rarfile_path' to 'extraction_path'\n    Return fail==0(ok)/fail==1(error)/fail==2(wrong password)/fail==3(crc-error), new_files, rars\n    \"\"\"\n    start = time.time()\n\n    logging.debug(\"rar_extract(): Extractionpath: %s\", extraction_path)\n\n    if password:\n        password_command = \"-p%s\" % password\n    else:\n        password_command = \"-p-\"\n\n    ############################################################################\n\n    if one_folder or cfg.flat_unpack():\n        action = \"e\"\n    else:\n        action = \"x\"\n    if cfg.overwrite_files():\n        overwrite = \"-o+\"  # Enable overwrite\n        rename = \"-o+\"  # Dummy\n    else:\n        overwrite = \"-o-\"  # Disable overwrite\n        rename = \"-or\"  # Auto renaming\n\n    if sabnzbd.WIN32:\n        # On Windows, UnRar uses a custom argument parser\n        # See: https://github.com/sabnzbd/sabnzbd/issues/1043\n        # The -scf forces the output to be UTF8\n        command = [\n            RAR_COMMAND,\n            action,\n            \"-idp\",\n            \"-scf\",\n            overwrite,\n            rename,\n            \"-ai\",\n            password_command,\n            rarfile_path,\n            \"%s\\\\\" % long_path(extraction_path),\n        ]\n\n    elif RAR_PROBLEM:\n        # Use only oldest options, specifically no \"-or\" or \"-scf\"\n        command = [\n            RAR_COMMAND,\n            action,\n            \"-idp\",\n            overwrite,\n            password_command,\n            rarfile_path,\n            \"%s/\" % extraction_path,\n        ]\n    else:\n        # The -scf forces the output to be UTF8\n        command = [\n            RAR_COMMAND,\n            action,\n            \"-idp\",\n            \"-scf\",\n            overwrite,\n            rename,\n            \"-ai\",\n            password_command,\n            rarfile_path,\n            \"%s/\" % extraction_path,\n        ]\n\n    if cfg.ignore_unrar_dates():\n        command.insert(3, \"-tsm-\")\n\n    # Get list of all the volumes part of this set\n    logging.debug(\"Analyzing rar file ... %s found\", rarfile.is_rarfile(rarfile_path))\n    p = build_and_run_command(command, windows_unrar_command=True)\n    sabnzbd.PostProcessor.external_process = p\n\n    nzo.set_action_line(T(\"Unpacking\"), \"00/%02d\" % numrars)\n\n    # Loop over the output from rar!\n    curr = 0\n    extracted = []\n    rarfiles = []\n    fail = 0\n    inrecovery = False\n    lines = []\n\n    while 1:\n        line = p.stdout.readline()\n        if not line:\n            break\n\n        line = line.strip()\n        lines.append(line)\n\n        if line.startswith(\"Extracting from\"):\n            filename = re.search(RAR_EXTRACTFROM_RE, line).group(1)\n            if filename not in rarfiles:\n                rarfiles.append(filename)\n            curr += 1\n            perc = (curr / numrars) * 100\n            nzo.set_action_line(T(\"Unpacking\"), \"%02d/%02d %s\" % (curr, numrars, add_time_left(perc, start)))\n\n        elif line.find(\"recovery volumes found\") > -1:\n            inrecovery = True  # and thus start ignoring \"Cannot find volume\" for a while\n            logging.debug(\"unrar recovery start: %s\" % line)\n        elif line.startswith(\"Reconstruct\"):\n            # end of reconstruction: 'Reconstructing... 100%' or 'Reconstructing... ' (both success), or 'Reconstruction impossible'\n            inrecovery = False\n            logging.debug(\"unrar recovery result: %s\" % line)\n\n        elif line.startswith(\"Cannot find volume\") and not inrecovery:\n            filename = os.path.basename(line[19:])\n            msg = T(\"Unpacking failed, unable to find %s\") % filename\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 1\n\n        elif line.endswith(\"- CRC failed\"):\n            msg = T(\"Unpacking failed, CRC error\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 2  # Older unrar versions report a wrong password as a CRC error\n\n        elif line.startswith(\"File too large\"):\n            msg = T(\"Unpacking failed, file too large for filesystem (FAT?)\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 1\n\n        elif line.startswith(\"Write error\"):\n            msg = \"%s %s\" % (T(\"Unpacking failed, write error or disk is full?\"), line[11:])\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 1\n\n        elif line.startswith(\"Cannot create\"):\n            line2 = p.stdout.readline()\n            if \"must not exceed 260\" in line2:\n                msg = \"%s: %s\" % (T(\"Unpacking failed, path is too long\"), line[13:])\n            else:\n                msg = \"%s %s\" % (T(\"Unpacking failed, write error or disk is full?\"), line[13:])\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 1\n            # Kill the process (can stay in endless loop on Windows Server)\n            p.kill()\n\n        elif line.startswith(\"ERROR: \"):\n            nzo.fail_msg = line\n            nzo.set_unpack_info(\"Unpack\", line, setname)\n            fail = 1\n\n        elif (\n            \"The specified password is incorrect\" in line\n            or \"Incorrect password\" in line\n            or (\"ncrypted file\" in line and ((\"CRC failed\" in line) or (\"Checksum error\" in line)))\n        ):\n            # unrar 3.x: \"Encrypted file: CRC failed in oLKQfrcNVivzdzSG22a2xo7t001.part1.rar (password incorrect ?)\"\n            # unrar 4.x: \"CRC failed in the encrypted file oLKQfrcNVivzdzSG22a2xo7t001.part1.rar. Corrupt file or wrong password.\"\n            # unrar 5.x: \"Checksum error in the encrypted file oLKQfrcNVivzdzSG22a2xo7t001.part1.rar. Corrupt file or wrong password.\"\n            # unrar 5.01: \"The specified password is incorrect.\"\n            # unrar 5.80: \"Incorrect password for oLKQfrcNVivzdzSG22a2xo7t001.part1.rar\"\n            msg = T(\"Unpacking failed, archive requires a password\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 2\n\n        elif \"is not RAR archive\" in line:\n            # Unrecognizable RAR file\n            msg = T(\"Unusable RAR file\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 3\n\n        elif \"checksum error\" in line or \"Unexpected end of archive\" in line:\n            # Corrupt archive or passworded, we can't know\n            # packed data checksum error in volume FILE\n            msg = T(\"Corrupt RAR file\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Unpack\", msg, setname)\n            fail = 3\n\n        else:\n            m = re.search(RAR_EXTRACTED_RE, line)\n            if m:\n                # In case of flat-unpack, UnRar still prints the whole path (?!)\n                unpacked_file = m.group(2)\n                if cfg.flat_unpack():\n                    unpacked_file = os.path.basename(unpacked_file)\n                extracted.append(real_path(extraction_path, unpacked_file))\n\n        if fail:\n            if p.stdout:\n                p.stdout.close()\n            p.wait()\n            logging.debug(\"UNRAR output %s\", \"\\n\".join(lines))\n            return fail, [], []\n\n    if p.stdout:\n        p.stdout.close()\n    p.wait()\n\n    # Which files did we use to extract this?\n    rarfiles = rar_volumelist(rarfile_path, password, rarfiles)\n\n    logging.debug(\"UNRAR output %s\", \"\\n\".join(lines))\n    msg = T(\"Unpacked %s files/folders in %s\") % (len(extracted), format_time_string(time.time() - start))\n    nzo.set_unpack_info(\"Unpack\", msg, setname)\n    logging.info(msg)\n\n    return 0, extracted, rarfiles\n\n\n##############################################################################\n# (Un)Zip Functions\n##############################################################################\ndef unzip(nzo: NzbObject, workdir_complete: str, one_folder: bool, zips: List[str]):\n    \"\"\"Unpack multiple sets 'zips' of ZIP files from 'download_path' to 'workdir_complete.\n    When 'delete' is ste, originals will be deleted.\n    \"\"\"\n\n    try:\n        i = 0\n        unzip_failed = False\n        tms = time.time()\n\n        # For file-bookkeeping\n        orig_dir_content = listdir_full(workdir_complete)\n\n        for _zip in zips:\n            logging.info(\"Starting extract on zipfile: %s \", _zip)\n            nzo.set_action_line(T(\"Unpacking\"), \"%s\" % setname_from_path(_zip))\n\n            if workdir_complete and _zip.startswith(nzo.download_path):\n                extraction_path = workdir_complete\n            else:\n                extraction_path = os.path.split(_zip)[0]\n\n            if unzip_core(_zip, extraction_path, one_folder):\n                unzip_failed = True\n            else:\n                i += 1\n\n        msg = T(\"%s files in %s\") % (str(i), format_time_string(time.time() - tms))\n        nzo.set_unpack_info(\"Unpack\", msg)\n\n        # What's new? Use symmetric difference\n        new_files = list(set(orig_dir_content) ^ set(listdir_full(workdir_complete)))\n\n        # Delete the old files if we have to\n        if nzo.delete and not unzip_failed:\n            i = 0\n\n            for _zip in zips:\n                try:\n                    remove_file(_zip)\n                    i += 1\n                except OSError:\n                    logging.warning(T(\"Deleting %s failed!\"), _zip)\n\n                brokenzip = \"%s.1\" % _zip\n\n                if os.path.exists(brokenzip):\n                    try:\n                        remove_file(brokenzip)\n                        i += 1\n                    except OSError:\n                        logging.warning(T(\"Deleting %s failed!\"), brokenzip)\n\n        return unzip_failed, new_files\n    except:\n        msg = sys.exc_info()[1]\n        nzo.fail_msg = T(\"Unpacking failed, %s\") % msg\n        logging.error(T('Error \"%s\" while running unzip() on %s'), msg, nzo.final_name)\n        return True, []\n\n\ndef unzip_core(zipfile, extraction_path, one_folder):\n    \"\"\"Unzip single zip set 'zipfile' to 'extraction_path'\"\"\"\n    command = [\"%s\" % ZIP_COMMAND, \"-o\", \"-Pnone\", \"%s\" % clip_path(zipfile), \"-d%s\" % extraction_path]\n\n    if one_folder or cfg.flat_unpack():\n        command.insert(3, \"-j\")  # Unpack without folders\n\n    p = build_and_run_command(command)\n    logging.debug(\"unzip output: \\n%s\", p.stdout.read())\n    return p.wait()\n\n\n##############################################################################\n# 7Zip Functions\n##############################################################################\ndef unseven(nzo: NzbObject, workdir_complete: str, one_folder: bool, sevens: List[str]):\n    \"\"\"Unpack multiple sets '7z' of 7Zip files from 'download_path' to 'workdir_complete.\n    When 'delete' is set, originals will be deleted.\n    \"\"\"\n    # Before we start, make sure the 7z binary SEVENZIP_COMMAND is defined\n    if not SEVENZIP_COMMAND:\n        msg = T('No 7za binary found, cannot unpack \"%s\"') % nzo.final_name\n        logging.error(msg)\n        nzo.fail_msg = msg\n        nzo.status = Status.FAILED\n        nzo.set_unpack_info(\"Unpack\", msg)\n        return 1, []\n\n    unseven_failed = False\n    new_files = []\n\n    # Find multi-volume sets, because 7zip will not provide actual set members\n    seven_sets = {}\n    for seven in sevens:\n        setname = setname_from_path(seven)\n        if SEVENMULTI_RE.search(setname):\n            # Remove the \".001\" part\n            setname = os.path.splitext(setname)[0]\n        if setname not in seven_sets:\n            seven_sets[setname] = []\n        seven_sets[setname].append(seven)\n\n    # Unpack each set\n    for seven_set in seven_sets:\n        logging.info(\"Starting extract on 7zip set/file: %s \", seven_set)\n        nzo.set_action_line(T(\"Unpacking\"), setname_from_path(seven_set))\n\n        # Sort, so that x.001 is the first one\n        seven_sets[seven_set].sort()\n        seven_path = seven_sets[seven_set][0]\n\n        if workdir_complete and seven_path.startswith(nzo.download_path):\n            extraction_path = workdir_complete\n        else:\n            extraction_path = os.path.split(seven_path)[0]\n\n        res, new_files_set = seven_extract(nzo, seven_path, seven_set, extraction_path, one_folder)\n        if res:\n            unseven_failed = True\n        elif nzo.delete:\n            for seven in seven_sets[seven_set]:\n                try:\n                    remove_file(seven)\n                except:\n                    logging.warning(T(\"Deleting %s failed!\"), seven)\n        new_files.extend(new_files_set)\n\n    return unseven_failed, new_files\n\n\ndef seven_extract(\n    nzo: NzbObject, seven_path: str, seven_set: str, extraction_path: str, one_folder: bool\n) -> Tuple[int, List[str]]:\n    \"\"\"Unpack single set 'sevenset' to 'extraction_path', with password tries\n    Return fail==0(ok)/fail==1(error)/fail==2(wrong password), new_files, sevens\n    \"\"\"\n    fail = 0\n    new_files = []\n\n    passwords = get_all_passwords(nzo)\n\n    for password in passwords:\n        if password:\n            msg = T('Trying 7zip with password \"%s\"') % password\n            logging.debug(msg)\n            nzo.set_unpack_info(\"Unpack\", msg, seven_set)\n        fail, new_files = seven_extract_core(nzo, seven_path, extraction_path, seven_set, one_folder, password)\n        if fail != 2:\n            # anything else than a password problem (so: OK, or disk problem):\n            break\n\n    return fail, new_files\n\n\ndef seven_extract_core(\n    nzo: NzbObject, seven_path: str, extraction_path: str, seven_set: str, one_folder: bool, password: str\n) -> Tuple[int, List[str]]:\n    \"\"\"Unpack single 7Z set 'sevenset' to 'extraction_path'\n    Return fail==0(ok)/fail==1(error)/fail==2(wrong password), new_files, message\n    \"\"\"\n    start = time.time()\n    if one_folder:\n        method = \"e\"  # Unpack without folders\n    else:\n        method = \"x\"  # Unpack with folders\n    if sabnzbd.WIN32 or sabnzbd.MACOS:\n        case = \"-ssc-\"  # Case insensitive\n    else:\n        case = \"-ssc\"  # Case sensitive\n    if cfg.overwrite_files():\n        overwrite = \"-aoa\"\n    else:\n        overwrite = \"-aou\"\n    if password:\n        password = \"-p%s\" % password\n    else:\n        password = \"-p\"\n\n    # For file-bookkeeping\n    orig_dir_content = listdir_full(extraction_path)\n\n    command = [SEVENZIP_COMMAND, method, \"-y\", overwrite, case, password, \"-o%s\" % extraction_path, seven_path]\n    p = build_and_run_command(command)\n    sabnzbd.PostProcessor.external_process = p\n    output = p.stdout.read()\n    logging.debug(\"7za output: %s\", output)\n\n    # ret contains the 7z/7za exit code: 0 = Normal, 1 = Warning, 2 = Fatal error, etc\n    ret = p.wait()\n\n    # What's new? Use symmetric difference\n    new_files = list(set(orig_dir_content) ^ set(listdir_full(extraction_path)))\n\n    # Anything else than 0 as RC: 7z unpack had a problem\n    if ret > 0:\n        # Let's try to find the cause:\n        if \"Data Error in encrypted file. Wrong password?\" in output:\n            msg = T(\"Unpacking failed, archive requires a password\")\n        elif \"Disk full.\" in output or \"No space left on device\" in output:\n            # note: the above does not work with 7z version 16.02, and does work with 7z 19.00 and higher\n            ret = 1\n            msg = T(\"Unpacking failed, write error or disk is full?\")\n        elif \"ERROR: CRC Failed\" in output:\n            ret = 1\n            msg = T(\"Unpacking failed, CRC error\")\n        else:\n            # Default message\n            msg = T(\"Unpacking failed, %s\") % T(\"see logfile\")\n            logging.info(\"7za return code: %s\", ret)\n        nzo.fail_msg = msg\n        nzo.status = Status.FAILED\n    else:\n        msg = T(\"Unpacked %s files/folders in %s\") % (len(new_files), format_time_string(time.time() - start))\n        nzo.set_unpack_info(\"Unpack\", msg, seven_set)\n        logging.info(msg)\n\n    return ret, new_files\n\n\n##############################################################################\n# PAR2 Functions\n##############################################################################\ndef par2_repair(nzo: NzbObject, setname: str) -> Tuple[bool, bool]:\n    \"\"\"Try to repair a set, return readd and correctness\"\"\"\n    # Check which of the files exists\n    for new_par in nzo.extrapars[setname]:\n        test_parfile = os.path.join(nzo.download_path, new_par.filename)\n        if os.path.exists(test_parfile):\n            parfile_nzf = new_par\n            break\n    else:\n        # No file was found, we assume this set already finished\n        logging.info(\"No par2 files found on disk for set %s\", setname)\n        return False, True\n\n    parfile = os.path.join(nzo.download_path, parfile_nzf.filename)\n    old_dir_content = os.listdir(nzo.download_path)\n    used_joinables = ()\n    joinables = ()\n    used_for_repair = ()\n    result = readd = False\n\n    # Need to copy now, gets pop-ed during repair\n    setpars = nzo.extrapars[setname][:]\n\n    # Start QuickCheck\n    nzo.status = Status.QUICK_CHECK\n    nzo.set_action_line(T(\"Repair\"), T(\"Quick Checking\"))\n    qc_result = quick_check_set(setname, nzo)\n    if qc_result:\n        logging.info(\"Quick-check for %s is OK, skipping repair\", setname)\n        nzo.set_unpack_info(\"Repair\", T(\"[%s] Quick Check OK\") % setname)\n        result = True\n\n    if not result and cfg.enable_all_par():\n        # Download all par2 files that haven't been downloaded yet\n        readd = False\n        for extrapar in nzo.extrapars[setname][:]:\n            # Make sure we only get new par2 files\n            if nzo.add_parfile(extrapar):\n                readd = True\n        if readd:\n            return readd, result\n\n    if not result:\n        nzo.status = Status.REPAIRING\n        result = False\n        readd = False\n        try:\n            nzo.set_action_line(T(\"Repair\"), T(\"Starting Repair\"))\n            logging.info('Scanning \"%s\"', parfile)\n\n            joinables, _, _, _, _ = build_filelists(nzo.download_path, check_rar=False)\n\n            # Multipar on Windows, par2cmdline on the other platforms\n            if sabnzbd.WIN32:\n                finished, readd, used_joinables, used_for_repair = multipar_verify(parfile, nzo, setname, joinables)\n            else:\n                finished, readd, used_joinables, used_for_repair = par2cmdline_verify(parfile, nzo, setname, joinables)\n\n            if finished:\n                result = True\n                logging.info(\"Par verify finished ok on %s!\", parfile)\n            else:\n                logging.info(\"Par verify failed on %s!\", parfile)\n                return readd, False\n        except:\n            msg = sys.exc_info()[1]\n            nzo.fail_msg = T(\"Repairing failed, %s\") % msg\n            logging.error(T(\"Error %s while running par2_repair on set %s\"), msg, setname)\n            logging.info(\"Traceback: \", exc_info=True)\n            return readd, result\n\n    try:\n        if cfg.enable_par_cleanup():\n            deletables = []\n            new_dir_content = os.listdir(nzo.download_path)\n\n            # If Multipar or par2cmdline repairs a broken part of a joinable, it doesn't list it as such.\n            # So we need to manually add all joinables of the set to the list of used joinables.\n            # We assume at least 1 of them was not broken, so we can use it as a base to find the rest.\n            if used_joinables:\n                for used_jn in used_joinables[:]:\n                    for jn in joinables:\n                        if get_filename(jn).startswith(setname_from_path(used_jn)) and jn not in used_joinables:\n                            used_joinables.append(jn)\n\n            # Remove extra files created during repair and par2 base files\n            for path in new_dir_content:\n                if os.path.splitext(path)[1] == \".1\" and path not in old_dir_content:\n                    deletables.append(os.path.join(nzo.download_path, path))\n            deletables.append(os.path.join(nzo.download_path, setname + \".par2\"))\n            deletables.append(os.path.join(nzo.download_path, setname + \".PAR2\"))\n            deletables.append(parfile)\n\n            # Add output of par2-repair to remove\n            deletables.extend(used_joinables)\n            deletables.extend([os.path.join(nzo.download_path, f) for f in used_for_repair])\n\n            # Delete pars of the set\n            deletables.extend([os.path.join(nzo.download_path, nzf.filename) for nzf in setpars])\n\n            for filepath in deletables:\n                if filepath in joinables:\n                    joinables.remove(filepath)\n                if os.path.exists(filepath):\n                    try:\n                        remove_file(filepath)\n                    except OSError:\n                        logging.warning(T(\"Deleting %s failed!\"), filepath)\n    except:\n        msg = sys.exc_info()[1]\n        nzo.fail_msg = T(\"Repairing failed, %s\") % msg\n        logging.error(T('Error \"%s\" while running par2_repair on set %s'), msg, setname, exc_info=True)\n\n    return readd, result\n\n\ndef par2cmdline_verify(\n    parfile: str, nzo: NzbObject, setname: str, joinables: List[str]\n) -> Tuple[bool, bool, List[str], List[str]]:\n    \"\"\"Run par2 on par-set\"\"\"\n    used_joinables = []\n    used_for_repair = []\n    # set the current nzo status to \"Verifying...\". Used in History\n    nzo.status = Status.VERIFYING\n    start = time.time()\n\n    # Build command and add extra options\n    command = [str(PAR2_COMMAND), \"r\", parfile]\n    options = cfg.par_option().strip().split()\n    if options:\n        for option in options:\n            command.insert(2, option)\n\n    # Append the wildcard for this set\n    parfolder = os.path.split(parfile)[0]\n    if len(nzo.extrapars) == 1 or len(globber(parfolder, setname + \"*\")) < 2:\n        # Support bizarre naming conventions\n        wildcard = \"*\"\n    else:\n        # Normal case, everything is named after set\n        wildcard = setname + \"*\"\n\n    if sabnzbd.MACOS:\n        command.append(os.path.join(parfolder, wildcard))\n    else:\n        # For Unix systems, remove folders, due to bug in some par2cmdline versions\n        flist = [item for item in globber_full(parfolder, wildcard) if os.path.isfile(item)]\n        command.extend(flist)\n\n    # We need to check for the bad par2cmdline that skips blocks\n    # Or the one that complains about basepath\n    # Only if we're not doing multicore\n    if not sabnzbd.MACOS:\n        par2text = run_command([command[0], \"-h\"])\n        if \"No data skipping\" in par2text:\n            logging.info(\"Detected par2cmdline version that skips blocks, adding -N parameter\")\n            command.insert(2, \"-N\")\n        if \"Set the basepath\" in par2text:\n            logging.info(\"Detected par2cmdline version that needs basepath, adding -B<path> parameter\")\n            command.insert(2, \"-B\")\n            command.insert(3, parfolder)\n\n    # Run the external command\n    p = build_and_run_command(command)\n    sabnzbd.PostProcessor.external_process = p\n\n    # Set up our variables\n    lines = []\n    renames = {}\n    reconstructed = []\n\n    linebuf = \"\"\n    finished = False\n    readd = False\n\n    verifynum = 0\n    verifytotal = 0\n    verified = 0\n    perc = 0\n\n    in_verify = False\n    in_extra_files = False\n    in_verify_repaired = False\n\n    # Loop over the output, whee\n    while 1:\n        char = p.stdout.read(1)\n        if not char:\n            break\n\n        # Line not complete yet\n        if char not in (\"\\n\", \"\\r\"):\n            linebuf += char\n            continue\n\n        line = linebuf.strip()\n        linebuf = \"\"\n\n        # Skip empty lines\n        if line == \"\":\n            continue\n\n        if not line.startswith((\"Repairing:\", \"Scanning:\", \"Loading:\", \"Solving:\", \"Constructing:\")):\n            lines.append(line)\n\n        if line.startswith((\"Invalid option specified\", \"Invalid thread option\", \"Cannot specify recovery file count\")):\n            msg = T(\"[%s] PAR2 received incorrect options, check your Config->Switches settings\") % setname\n            nzo.set_unpack_info(\"Repair\", msg)\n            nzo.status = Status.FAILED\n            logging.error(msg)\n\n        elif line.startswith(\"All files are correct\"):\n            msg = T(\"[%s] Verified in %s, all files correct\") % (setname, format_time_string(time.time() - start))\n            nzo.set_unpack_info(\"Repair\", msg)\n            logging.info(\"Verified in %s, all files correct\", format_time_string(time.time() - start))\n            finished = True\n\n        elif line.startswith(\"Repair is required\"):\n            msg = T(\"[%s] Verified in %s, repair is required\") % (setname, format_time_string(time.time() - start))\n            nzo.set_unpack_info(\"Repair\", msg)\n            logging.info(\"Verified in %s, repair is required\", format_time_string(time.time() - start))\n            start = time.time()\n            verified = 1\n            # Reset to use them again for verification of repair\n            verifytotal = 0\n            verifynum = 0\n\n        elif line.startswith(\"Main packet not found\") or \"The recovery file does not exist\" in line:\n            # Initialparfile probably didn't decode properly or bad user parameters\n            # We will try to get another par2 file, but 99% of time it's user parameters\n            msg = T(\"Invalid par2 files or invalid PAR2 parameters, cannot verify or repair\")\n            logging.info(msg)\n            logging.info(\"Extra pars = %s\", nzo.extrapars[setname])\n\n            # Look for the smallest par2file\n            block_table = {}\n            for nzf in nzo.extrapars[setname]:\n                if not nzf.completed:\n                    block_table[nzf.blocks] = nzf\n\n            if block_table:\n                nzf = block_table[min(block_table)]\n                logging.info(\"Found new par2file %s\", nzf.filename)\n\n                # Move from extrapar list to files to be downloaded\n                # and remove it from the extrapars list\n                nzo.add_parfile(nzf)\n                readd = True\n            else:\n                nzo.fail_msg = msg\n                nzo.set_unpack_info(\"Repair\", msg, setname)\n                nzo.status = Status.FAILED\n\n        elif line.startswith(\"You need\"):\n            # We need more blocks, but are they available?\n            chunks = line.split()\n            needed_blocks = int(chunks[2])\n\n            # Check if we have enough blocks\n            added_blocks = nzo.get_extra_blocks(setname, needed_blocks)\n            if added_blocks:\n                msg = T(\"Fetching %s blocks...\") % str(added_blocks)\n                nzo.set_action_line(T(\"Fetching\"), msg)\n                readd = True\n            else:\n                # Failed\n                msg = T(\"Repair failed, not enough repair blocks (%s short)\") % str(needed_blocks)\n                nzo.fail_msg = msg\n                nzo.set_unpack_info(\"Repair\", msg, setname)\n                nzo.status = Status.FAILED\n\n        elif line.startswith(\"Repair is possible\"):\n            start = time.time()\n            nzo.set_action_line(T(\"Repairing\"), \"%2d%%\" % 0)\n\n        elif line.startswith((\"Repairing:\", \"Processing:\")):\n            # \"Processing\" is shown when it is only joining files without repairing\n            chunks = line.split()\n            new_perc = float(chunks[-1][:-1])\n            # Only send updates for whole-percentage updates\n            if new_perc - perc > 1:\n                perc = new_perc\n                nzo.set_action_line(T(\"Repairing\"), \"%2d%% %s\" % (perc, add_time_left(perc, start)))\n                nzo.status = Status.REPAIRING\n\n        elif line.startswith(\"Repair complete\"):\n            msg = T(\"[%s] Repaired in %s\") % (setname, format_time_string(time.time() - start))\n            nzo.set_unpack_info(\"Repair\", msg)\n            logging.info(\"Repaired in %s\", format_time_string(time.time() - start))\n            finished = True\n\n        elif verified and line.endswith((\"are missing.\", \"exist but are damaged.\")):\n            # Files that will later be verified after repair\n            chunks = line.split()\n            verifytotal += int(chunks[0])\n\n        elif line.startswith(\"Verifying repaired files\"):\n            in_verify_repaired = True\n\n        elif in_verify_repaired and line.startswith(\"Target\"):\n            verifynum += 1\n            if verifynum <= verifytotal:\n                nzo.set_action_line(T(\"Verifying repair\"), \"%02d/%02d\" % (verifynum, verifytotal))\n\n        elif \"Could not write\" in line and \"at offset 0:\" in line:\n            # If there are joinables, this error will only happen in case of 100% complete files\n            # We can just skip the retry, because par2cmdline will fail in those cases\n            # because it refuses to scan the \".001\" file\n            if joinables:\n                finished = True\n                used_joinables = []\n\n        elif \" cannot be renamed to \" in line:\n            msg = line.strip()\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n\n        elif \"There is not enough space on the disk\" in line:\n            # Oops, disk is full!\n            msg = T(\"Repairing failed, %s\") % T(\"Disk full\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n\n        elif \"No details available for recoverable file\" in line:\n            msg = line.strip()\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n\n        elif line.startswith(\"Repair Failed.\"):\n            # Unknown repair problem\n            msg = T(\"Repairing failed, %s\") % line\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n            finished = False\n\n        elif not verified:\n            if line.startswith(\"Scanning:\"):\n                pass\n\n            if in_extra_files:\n                if \"is a match for\" in line or line.find(\"data blocks from\") > 0:\n                    # Baldy named ones\n                    m_rename = PAR2_IS_MATCH_FOR_RE.search(line)\n                    if m_rename:\n                        old_name = m_rename.group(1)\n                        new_name = m_rename.group(2)\n                        logging.debug('PAR2 will rename \"%s\" to \"%s\"', old_name, new_name)\n                        renames[new_name] = old_name\n\n                    # Obfuscated and also damaged\n                    m_block = PAR2_BLOCK_FOUND_RE.search(line)\n                    if m_block:\n                        workdir = os.path.split(parfile)[0]\n                        old_name = m_block.group(1)\n                        new_name = m_block.group(2)\n                        if joinables:\n                            # Find out if a joinable file has been used for joining\n                            for jn in joinables:\n                                if get_filename(jn) == old_name:\n                                    used_joinables.append(jn)\n                                    break\n                            # Special case of joined RAR files, the \"of\" and \"from\" must both be RAR files\n                            # This prevents the joined rars files from being seen as an extra rar-set\n                            if \".rar\" in old_name.lower() and \".rar\" in new_name.lower():\n                                used_joinables.append(os.path.join(workdir, old_name))\n                        else:\n                            logging.debug('PAR2 will reconstruct \"%s\" from \"%s\"', new_name, old_name)\n                            reconstructed.append(os.path.join(workdir, old_name))\n                            renames[new_name] = old_name\n\n                    if m_block or m_rename:\n                        # Show progress\n                        verifynum += 1\n                        nzo.set_action_line(T(\"Checking extra files\"), \"%02d\" % verifynum)\n\n            elif not in_verify:\n                # Total number to verify\n                m = re.match(r\"There are (\\d+) recoverable files\", line)\n                if m:\n                    verifytotal = int(m.group(1))\n\n                if line.startswith(\"Verifying source files:\"):\n                    in_verify = True\n                    nzo.status = Status.VERIFYING\n            elif line.startswith(\"Scanning extra files:\"):\n                in_verify = False\n                in_extra_files = True\n                verifynum = 0\n            else:\n                # Target files for verification\n                m = PAR2_TARGET_RE.match(line)\n                if m:\n                    verifynum += 1\n                    nzo.set_action_line(T(\"Verifying\"), \"%02d/%02d\" % (verifynum, verifytotal))\n\n                    # Remove redundant extra files that are just duplicates of original ones\n                    if \"duplicate data blocks\" in line:\n                        used_for_repair.append(m.group(1))\n\n    p.wait()\n\n    # Also log what is shown to user in history\n    if nzo.fail_msg:\n        logging.info(nzo.fail_msg)\n\n    logging.debug(\"PAR2 output was\\n%s\", \"\\n\".join(lines))\n\n    # If successful, add renamed files to the collection\n    if finished and renames:\n        nzo.renamed_file(renames)\n\n    # If successful and files were reconstructed, remove incomplete original files\n    if finished and reconstructed:\n        # Use 'used_joinables' as a vehicle to get rid of the files\n        used_joinables.extend(reconstructed)\n\n    return finished, readd, used_joinables, used_for_repair\n\n\ndef multipar_verify(\n    parfile: str, nzo: NzbObject, setname: str, joinables: List[str]\n) -> Tuple[bool, bool, List[str], List[str]]:\n    \"\"\"Run par2 on par-set\"\"\"\n    parfolder = os.path.split(parfile)[0]\n    used_joinables = []\n    used_for_repair = []\n\n    # set the current nzo status to \"Verifying...\". Used in History\n    nzo.status = Status.VERIFYING\n    start = time.time()\n\n    # Caching of verification implemented by adding -vs/-vd\n    # But not really required due to prospective-par2\n    # Force output of utf-8 by adding -uo\n    command = [str(MULTIPAR_COMMAND), \"r\", \"-uo\", \"-vs2\", \"-vd%s\" % nzo.admin_path, parfile]\n\n    # Only add user-options if supplied\n    options = cfg.par_option().strip().split()\n    if options:\n        for option in options:\n            # We wrongly instructed users to use /x parameter style instead of -x\n            option = option.replace(\"/\", \"-\", 1)\n            command.insert(2, option)\n\n    # Support bizarre naming conventions by scanning all files\n    if len(nzo.extrapars) == 1 or len(globber(parfolder, setname + \"*\")) < 2:\n        command.insert(2, \"-vl2\")\n\n    # Run MultiPar\n    p = build_and_run_command(command)\n    sabnzbd.PostProcessor.external_process = p\n\n    # Set up our variables\n    lines = []\n    renames = {}\n    reconstructed = []\n\n    linebuf = \"\"\n    finished = False\n    readd = False\n\n    verifynum = 0\n    verifytotal = 0\n    verifyextratotal = 0\n\n    in_check = False\n    in_verify = False\n    in_repair = False\n    in_verify_repaired = False\n    misnamed_files = False\n    old_name = None\n\n    # Loop over the output, whee\n    while 1:\n        char = p.stdout.read(1)\n        if not char:\n            break\n\n        # Line not complete yet\n        if char not in (\"\\n\", \"\\r\"):\n            linebuf += char\n            continue\n\n        line = linebuf.strip()\n        linebuf = \"\"\n\n        # Skip empty lines\n        if line == \"\":\n            continue\n\n        # Save it all\n        lines.append(line)\n\n        # ----------------- Startup\n        if line.startswith(\"invalid option\"):\n            # Option error\n            msg = T(\"[%s] PAR2 received incorrect options, check your Config->Switches settings\") % setname\n            nzo.set_unpack_info(\"Repair\", msg)\n            nzo.status = Status.FAILED\n            logging.error(msg)\n\n        elif line.startswith(\"valid file is not found\"):\n            # Initialparfile probably didn't decode properly, or bad user parameters\n            # We will try to get another par2 file, but 99% of time it's user parameters\n            msg = T(\"Invalid par2 files or invalid PAR2 parameters, cannot verify or repair\")\n            logging.info(msg)\n            logging.info(\"Extra pars = %s\", nzo.extrapars[setname])\n\n            # Look for the smallest par2file\n            block_table = {}\n            for nzf in nzo.extrapars[setname]:\n                if not nzf.completed:\n                    block_table[nzf.blocks] = nzf\n\n            if block_table:\n                nzf = block_table[min(block_table)]\n                logging.info(\"Found new par2file %s\", nzf.filename)\n\n                # Move from extrapar list to files to be downloaded\n                # and remove it from the extrapars list\n                nzo.add_parfile(nzf)\n                readd = True\n            else:\n                nzo.fail_msg = msg\n                nzo.set_unpack_info(\"Repair\", msg, setname)\n                nzo.status = Status.FAILED\n\n        elif line.startswith(\"There is not enough space on the disk\"):\n            msg = T(\"Repairing failed, %s\") % T(\"Disk full\")\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n\n        # ----------------- Start check/verify stage\n        elif line.startswith(\"Recovery Set ID\"):\n            # Remove files were MultiPar stores verification result when repaired successful\n            recovery_id = line.split()[-1]\n            used_for_repair.append(os.path.join(JOB_ADMIN, \"2_%s.bin\" % recovery_id))\n            used_for_repair.append(os.path.join(JOB_ADMIN, \"2_%s.ini\" % recovery_id))\n\n        elif line.startswith(\"Input File total count\"):\n            # How many files will it try to find?\n            verifytotal = int(line.split()[-1])\n\n        # ----------------- Misnamed-detection stage\n        # Misnamed files\n        elif line.startswith(\"Searching misnamed file\"):\n            # We are in the misnamed files block\n            # How many misnamed files will it try to find?\n            verifyextratotal = int(line.split()[-1])\n            verifynum = 0\n            misnamed_files = True\n        elif misnamed_files and \"Found\" in line:\n            # First it reports the current filename\n            m = PAR2_FILENAME_RE.search(line)\n            if m:\n                verifynum += 1\n                nzo.set_action_line(T(\"Checking extra files\"), \"%02d/%02d\" % (verifynum, verifyextratotal))\n                old_name = m.group(1)\n        elif misnamed_files and \"Misnamed\" in line:\n            # Then it finds the actual\n            m = PAR2_FILENAME_RE.search(line)\n            if m and old_name:\n                new_name = m.group(1)\n                logging.debug('MultiPar will rename \"%s\" to \"%s\"', old_name, new_name)\n                renames[new_name] = old_name\n                # New name is also part of data!\n                reconstructed.append(old_name)\n\n        # ----------------- Checking stage\n        # Checking input files\n        elif line.startswith(\"Complete file count\"):\n            in_check = False\n            verifynum = 0\n            old_name = None\n        elif line.startswith(\"Verifying Input File\"):\n            in_check = True\n            nzo.status = Status.VERIFYING\n        elif in_check:\n            m = PAR2_FILENAME_RE.search(line)\n            if m:\n                # Only increase counter if it was really the detection line\n                if line.startswith(\"= \") or \"%\" not in line:\n                    verifynum += 1\n                nzo.set_action_line(T(\"Checking\"), \"%02d/%02d\" % (verifynum, verifytotal))\n                old_name = m.group(1)\n\n        # ----------------- Verify stage\n        # Which files need extra verification?\n        elif line.startswith(\"Damaged file count\"):\n            verifytotal = int(line.split()[-1])\n\n        elif line.startswith(\"Missing file count\"):\n            verifytotal += int(line.split()[-1])\n\n        # Actual verification\n        elif line.startswith(\"Input File Slice found\"):\n            # End of verification AND end of misnamed file search\n            in_verify = False\n            misnamed_files = False\n            old_name = None\n        elif line.startswith(\"Finding available slice\"):\n            # The actual scanning of the files\n            in_verify = True\n            verifynum = 0\n        elif in_verify:\n            m = PAR2_FILENAME_RE.search(line)\n            if m:\n                # It prints the filename couple of times, so we save it to check\n                nzo.status = Status.VERIFYING\n                if line.split()[1] in (\"Damaged\", \"Found\"):\n                    verifynum += 1\n\n                    # Set old_name in case it was misnamed and found (not when we are joining)\n                    old_name = None\n                    if line.split()[1] == \"Found\" and not joinables:\n                        old_name = m.group(1)\n\n                    # Sometimes we don't know the total (filejoin)\n                    if verifytotal <= 1 or verifynum > verifytotal:\n                        nzo.set_action_line(T(\"Verifying\"), \"%02d\" % verifynum)\n                    else:\n                        nzo.set_action_line(T(\"Verifying\"), \"%02d/%02d\" % (verifynum, verifytotal))\n\n                elif old_name and old_name != m.group(1):\n                    # Hey we found another misnamed one!\n                    new_name = m.group(1)\n                    logging.debug('MultiPar will rename \"%s\" to \"%s\"', old_name, new_name)\n                    renames[new_name] = old_name\n                    # Need to remove the old file after repair (Multipar keeps it)\n                    used_for_repair.append(old_name)\n                    # Need to reset it to avoid collision\n                    old_name = None\n\n                if joinables:\n                    # Find out if a joinable file has been used for joining\n                    for jn in joinables:\n                        if get_filename(jn) == m.group(1):\n                            used_joinables.append(jn)\n                            break\n\n        elif line.startswith(\"Need\"):\n            # We need more blocks, but are they available?\n            chunks = line.split()\n            needed_blocks = int(chunks[1])\n\n            # Check if we have enough blocks\n            added_blocks = nzo.get_extra_blocks(setname, needed_blocks)\n            if added_blocks:\n                msg = T(\"Fetching %s blocks...\") % str(added_blocks)\n                nzo.set_action_line(T(\"Fetching\"), msg)\n                readd = True\n            else:\n                # Failed\n                msg = T(\"Repair failed, not enough repair blocks (%s short)\") % str(needed_blocks)\n                nzo.fail_msg = msg\n                nzo.set_unpack_info(\"Repair\", msg, setname)\n                nzo.status = Status.FAILED\n\n            # MultiPar can say 'PAR File(s) Incomplete' also when it needs more blocks\n            # But the Need-more-blocks message is always last, so force failure\n            finished = False\n\n        # Result of verification\n        elif line.startswith(\"All Files Complete\") or line.endswith(\"PAR File(s) Incomplete\"):\n            # 'PAR File(s) Incomplete' is also reported for success when there are very similar filenames in the folder\n            # See: https://github.com/Yutaka-Sawada/MultiPar/issues/54\n            # Check if there was damage, by inspecting the number of missing blocks\n            if \"Input File Slice lost\" in lines[-2] and int(lines[-2].split()[-1]) == 0:\n                # Completed without damage!\n                msg = T(\"[%s] Verified in %s, all files correct\") % (setname, format_time_string(time.time() - start))\n                nzo.set_unpack_info(\"Repair\", msg)\n                logging.info(\"Verified in %s, all files correct\", format_time_string(time.time() - start))\n                finished = True\n\n        elif line.startswith((\"Ready to repair\", \"Ready to rejoin\")):\n            # Ready to repair!\n            # Or we are re-joining a split file when there's no damage but takes time\n            msg = T(\"[%s] Verified in %s, repair is required\") % (setname, format_time_string(time.time() - start))\n            nzo.set_unpack_info(\"Repair\", msg)\n            logging.info(\"Verified in %s, repair is required\", format_time_string(time.time() - start))\n            start = time.time()\n\n            # Set message for user in case of joining\n            if line.startswith(\"Ready to rejoin\"):\n                # There is no status-update when it is joining\n                nzo.set_action_line(T(\"Joining\"), \"%2d\" % len(used_joinables))\n\n        # ----------------- Repair stage\n        elif \"Recovering slice\" in line:\n            # Before this it will calculate matrix, here is where it starts\n            start = time.time()\n            in_repair = True\n            nzo.set_action_line(T(\"Repairing\"), \"%2d%%\" % 0)\n\n        elif line.startswith(\"Verifying repair\"):\n            in_repair = False\n            in_verify_repaired = True\n            # How many will be checked?\n            verifytotal = int(line.split()[-1])\n            verifynum = 0\n\n        elif in_repair:\n            try:\n                # Line with percentage of repair (nothing else)\n                perc = float(line[:-1])\n                nzo.set_action_line(T(\"Repairing\"), \"%2d%% %s\" % (perc, add_time_left(perc, start)))\n                nzo.status = Status.REPAIRING\n            except:\n                # Checksum error\n                if \"checksum\" in line:\n                    # Failed due to checksum error of multipar\n                    msg = T(\"Repairing failed, %s\") % line\n                    nzo.fail_msg = msg\n                    nzo.set_unpack_info(\"Repair\", msg, setname)\n                    nzo.status = Status.FAILED\n                else:\n                    # Not sure, log error\n                    logging.info(\"Traceback: \", exc_info=True)\n\n        elif line.startswith(\"Repaired successfully\"):\n            msg = T(\"[%s] Repaired in %s\") % (setname, format_time_string(time.time() - start))\n            nzo.set_unpack_info(\"Repair\", msg)\n            logging.info(\"Repaired in %s\", format_time_string(time.time() - start))\n            finished = True\n\n        elif in_verify_repaired and line.startswith(\"Repaired :\"):\n            # Track verification of repaired files (can sometimes take a while)\n            verifynum += 1\n            nzo.set_action_line(T(\"Verifying repair\"), \"%02d/%02d\" % (verifynum, verifytotal))\n\n        elif line.startswith(\"Failed to repair\") and not readd:\n            # Unknown repair problem\n            msg = T(\"Repairing failed, %s\") % line\n            nzo.fail_msg = msg\n            nzo.set_unpack_info(\"Repair\", msg, setname)\n            nzo.status = Status.FAILED\n            finished = True\n\n    p.wait()\n\n    # Also log what is shown to user in history\n    if nzo.fail_msg:\n        logging.info(nzo.fail_msg)\n\n    logging.debug(\"MultiPar output was\\n%s\", \"\\n\".join(lines))\n\n    # Add renamed files to the collection\n    # MultiPar always automatically renames whatever it can in the 'Searching misnamed file:'-section\n    # Even if the repair did not complete fully it will rename those!\n    # But the ones in 'Finding available slices'-section will only be renamed after successful repair\n    if renames:\n        # If success, we also remove the possibly previously renamed ones\n        if finished:\n            reconstructed.extend(list(renames.values()))\n\n        # Adding to the collection\n        nzo.renamed_file(renames)\n\n        # Remove renamed original files\n        workdir = os.path.split(parfile)[0]\n        used_joinables.extend([os.path.join(workdir, name) for name in reconstructed])\n\n    return finished, readd, used_joinables, used_for_repair\n\n\ndef create_env(nzo: Optional[NzbObject] = None, extra_env_fields: Dict[str, Any] = {}) -> Optional[Dict[str, Any]]:\n    \"\"\"Modify the environment for pp-scripts with extra information\n    macOS: Return copy of environment without PYTHONPATH and PYTHONHOME\n    other: return None\n    \"\"\"\n    env = os.environ.copy()\n\n    # Are we adding things?\n    if nzo:\n        # Add basic info\n        for field in ENV_NZO_FIELDS:\n            try:\n                field_value = getattr(nzo, field)\n                # Special filters for Python types\n                if field_value is None:\n                    env[\"SAB_\" + field.upper()] = \"\"\n                elif isinstance(field_value, bool):\n                    env[\"SAB_\" + field.upper()] = str(field_value * 1)\n                else:\n                    env[\"SAB_\" + field.upper()] = str(field_value)\n            except:\n                # Catch key errors\n                pass\n\n    # Always supply basic info\n    extra_env_fields.update(\n        {\n            \"program_dir\": sabnzbd.DIR_PROG,\n            \"par2_command\": sabnzbd.newsunpack.PAR2_COMMAND,\n            \"multipar_command\": sabnzbd.newsunpack.MULTIPAR_COMMAND,\n            \"rar_command\": sabnzbd.newsunpack.RAR_COMMAND,\n            \"zip_command\": sabnzbd.newsunpack.ZIP_COMMAND,\n            \"7zip_command\": sabnzbd.newsunpack.SEVENZIP_COMMAND,\n            \"version\": sabnzbd.__version__,\n        }\n    )\n\n    # Add extra fields\n    for field in extra_env_fields:\n        try:\n            if extra_env_fields[field] is not None:\n                env[\"SAB_\" + field.upper()] = str(extra_env_fields[field])\n            else:\n                env[\"SAB_\" + field.upper()] = \"\"\n        except:\n            # Catch key errors\n            pass\n\n    if sabnzbd.MACOS:\n        if \"PYTHONPATH\" in env:\n            del env[\"PYTHONPATH\"]\n        if \"PYTHONHOME\" in env:\n            del env[\"PYTHONHOME\"]\n\n    return env\n\n\ndef rar_volumelist(rarfile_path: str, password: str, known_volumes: List[str]) -> List[str]:\n    \"\"\"List volumes that are part of this rarset\n    and merge them with parsed paths list, removing duplicates.\n    We assume RarFile is right and use parsed paths as backup.\n    \"\"\"\n    # UnRar is required to read some RAR files\n    # RarFile can fail in special cases\n    try:\n        zf = rarfile.RarFile(rarfile_path)\n\n        # setpassword can fail due to bugs in RarFile\n        if password:\n            try:\n                zf.setpassword(password)\n            except:\n                pass\n        zf_volumes = zf.volumelist()\n    except:\n        zf_volumes = []\n\n    # Remove duplicates\n    zf_volumes_base = [os.path.basename(vol) for vol in zf_volumes]\n    for known_volume in known_volumes:\n        if os.path.basename(known_volume) not in zf_volumes_base:\n            # Long-path notation just to be sure\n            zf_volumes.append(long_path(known_volume))\n    return zf_volumes\n\n\n# Sort the various RAR filename formats properly :\\\ndef rar_sort(a: str, b: str) -> int:\n    \"\"\"Define sort method for rar file names\"\"\"\n    aext = a.split(\".\")[-1]\n    bext = b.split(\".\")[-1]\n\n    if aext == \"rar\" and bext == \"rar\":\n        return cmp(a, b)\n    elif aext == \"rar\":\n        return -1\n    elif bext == \"rar\":\n        return 1\n    else:\n        return cmp(a, b)\n\n\ndef quick_check_set(setname: str, nzo: NzbObject) -> bool:\n    \"\"\"Check all on-the-fly crc32s of a set\"\"\"\n    par2pack = nzo.par2packs.get(setname)\n    if par2pack is None:\n        return False\n\n    # We use bitwise assignment (&=) so False always wins in case of failure\n    # This way the renames always get saved!\n    result = True\n    nzf_list = nzo.finished_files\n    renames = {}\n\n    # Files to ignore\n    ignore_ext = cfg.quick_check_ext_ignore()\n\n    for file in par2pack:\n        par2info = par2pack[file]\n        found = False\n        file_to_ignore = get_ext(file).replace(\".\", \"\") in ignore_ext\n        for nzf in nzf_list:\n            # Do a simple filename based check\n            if file == nzf.filename:\n                found = True\n                if (\n                    nzf.crc32 is not None\n                    and nzf.crc32 == par2info.filehash\n                    and is_size(nzf.filepath, par2info.filesize)\n                ):\n                    logging.debug(\"Quick-check of file %s OK\", file)\n                    result &= True\n                elif file_to_ignore:\n                    # We don't care about these files\n                    logging.debug(\"Quick-check ignoring file %s\", file)\n                    result &= True\n                else:\n                    logging.info(\"Quick-check of file %s failed!\", file)\n                    result = False\n                break\n\n            # Now let's do obfuscation check\n            if nzf.crc32 is not None and nzf.crc32 == par2info.filehash and is_size(nzf.filepath, par2info.filesize):\n                try:\n                    logging.debug(\"Quick-check will rename %s to %s\", nzf.filename, file)\n\n                    # Note: file can and is allowed to be in a subdirectory.\n                    # Subdirectories in par2 always contain \"/\", not \"\\\"\n                    renamer(\n                        os.path.join(nzo.download_path, nzf.filename),\n                        os.path.join(nzo.download_path, file),\n                        create_local_directories=True,\n                    )\n                    renames[file] = nzf.filename\n                    nzf.filename = file\n                    result &= True\n                    found = True\n                    break\n                except IOError:\n                    # Renamed failed for some reason, probably already done\n                    break\n\n        if not found:\n            if file_to_ignore:\n                # We don't care about these files\n                logging.debug(\"Quick-check ignoring missing file %s\", file)\n                continue\n\n            logging.info(\"Cannot Quick-check missing file %s!\", file)\n            result = False\n\n    # Save renames\n    if renames:\n        nzo.renamed_file(renames)\n\n    return result\n\n\ndef unrar_check(rar: str) -> Tuple[int, bool]:\n    \"\"\"Return version number of unrar, where \"5.01\" returns 501\n    Also return whether an original version is found\n    (version, original)\n    \"\"\"\n    version = 0\n    original = False\n    if rar:\n        try:\n            version = run_command([rar])\n        except:\n            return version, original\n        original = \"Alexander Roshal\" in version\n        m = re.search(r\"RAR\\s(\\d+)\\.(\\d+)\", version)\n        if m:\n            version = int(m.group(1)) * 100 + int(m.group(2))\n        else:\n            version = 0\n    return version, original\n\n\ndef sevenzip_check(sevenzip: str) -> str:\n    \"\"\"Return version of 7zip, currently as a string\"\"\"\n    if sevenzip:\n        try:\n            seven_command_output = run_command([sevenzip])\n            # Example: 7-Zip (z) 21.06 (x64) : Copyright (c) 1999-2021 Igor Pavlov : 2021-11-24\n            return re.search(r\"(\\d+\\.\\d+).*Copyright\", seven_command_output).group(1)\n        except:\n            pass\n    return \"\"\n\n\ndef par2_mt_check(par2_path: str) -> bool:\n    \"\"\"Detect if we have multicore par2 variants\"\"\"\n    try:\n        par2_version = run_command([par2_path, \"-h\"])\n        # Look for a threads option\n        if \"-t<\" in par2_version:\n            return True\n    except:\n        pass\n    return False\n\n\ndef is_sfv_file(myfile: str) -> bool:\n    \"\"\"Checks if given file is a SFV file, and returns result as boolean\"\"\"\n    # based on https://stackoverflow.com/a/7392391/5235502\n    textchars = bytearray({7, 8, 9, 10, 12, 13, 27} | set(range(0x20, 0x100)) - {0x7F})\n    is_ascii_string = lambda input_bytes: not bool(input_bytes.translate(None, textchars))\n\n    # first check if it's plain text (ASCII or Unicode)\n    try:\n        with open(myfile, \"rb\") as f:\n            # get first 10000 bytes to check\n            myblock = f.read(10000)\n            if is_ascii_string(myblock):\n                # ASCII, so store lines for further inspection\n                try:\n                    lines = ubtou(myblock).split(\"\\n\")\n                except UnicodeDecodeError:\n                    return False\n            else:\n                # non-ASCII, so not SFV\n                return False\n    except:\n        # the with-open() went wrong, so not an existing file, so certainly not a SFV file\n        return False\n\n    sfv_info_line_counter = 0\n    for line in lines:\n        line = line.strip()\n        if re.search(r\"^[^;].*\\ +[A-Fa-f0-9]{8}$\", line):\n            # valid, useful SFV line: some text, then one or more space, and a 8-digit hex number\n            sfv_info_line_counter += 1\n            if sfv_info_line_counter >= 10:\n                # with 10 valid, useful lines we're confident enough\n                # (note: if we find less lines (even just 1 line), with no negatives, it is OK. See below)\n                break\n        elif not line or line.startswith(\";\"):\n            # comment line or just spaces, so continue to next line\n            continue\n        else:\n            # not a valid SFV line, so not a SFV file:\n            return False\n    # if we get here, no negatives were found, and at least 1 valid line is OK\n    return sfv_info_line_counter >= 1\n\n\ndef sfv_check(sfvs: List[str], nzo: NzbObject) -> bool:\n    \"\"\"Verify files using SFV files\"\"\"\n    # Update status\n    nzo.status = Status.VERIFYING\n    nzo.set_action_line(T(\"Trying SFV verification\"), \"...\")\n\n    # We use bitwise assignment (&=) so False always wins in case of failure\n    # This way the renames always get saved!\n    result = True\n    nzf_list = nzo.finished_files\n    renames = {}\n\n    # Files to ignore\n    ignore_ext = cfg.quick_check_ext_ignore()\n\n    # We need the crc32 of all files\n    calculated_crc32 = {}\n    verifytotal = len(nzo.finished_files)\n    verifynum = 0\n    for nzf in nzf_list:\n        if nzf.crc32 is not None:\n            verifynum += 1\n            nzo.set_action_line(T(\"Verifying\"), \"%02d/%02d\" % (verifynum, verifytotal))\n            calculated_crc32[nzf.filename] = b\"%08x\" % (nzf.crc32 & 0xFFFFFFFF)\n\n    sfv_parse_results = {}\n    nzo.set_action_line(T(\"Trying SFV verification\"), \"...\")\n    for sfv in sfvs:\n        setname = setname_from_path(sfv)\n        nzo.set_unpack_info(\"Repair\", T(\"Trying SFV verification\"), setname)\n\n        # Parse the sfv and add to the already found results\n        # Duplicates will be replaced\n        sfv_parse_results.update(parse_sfv(sfv))\n\n    for file in sfv_parse_results:\n        found = False\n        file_to_ignore = get_ext(file).replace(\".\", \"\") in ignore_ext\n        for nzf in nzf_list:\n            # Do a simple filename based check\n            if file == nzf.filename:\n                found = True\n                if calculated_crc32.get(nzf.filename, \"\") == sfv_parse_results[file]:\n                    logging.debug(\"SFV-check of file %s OK\", file)\n                    result &= True\n                elif file_to_ignore:\n                    # We don't care about these files\n                    logging.debug(\"SFV-check ignoring file %s\", file)\n                    result &= True\n                else:\n                    logging.info(\"SFV-check of file %s failed!\", file)\n                    result = False\n                break\n\n            # Now lets do obfuscation check\n            if calculated_crc32.get(nzf.filename, \"\") == sfv_parse_results[file]:\n                try:\n                    logging.debug(\"SFV-check will rename %s to %s\", nzf.filename, file)\n                    renamer(os.path.join(nzo.download_path, nzf.filename), os.path.join(nzo.download_path, file))\n                    renames[file] = nzf.filename\n                    nzf.filename = file\n                    result &= True\n                    found = True\n                    break\n                except IOError:\n                    # Renamed failed for some reason, probably already done\n                    break\n\n        if not found:\n            if file_to_ignore:\n                # We don't care about these files\n                logging.debug(\"SFV-check ignoring missing file %s\", file)\n                continue\n\n            logging.info(\"Cannot SFV-check missing file %s!\", file)\n            result = False\n\n    # Save renames\n    if renames:\n        nzo.renamed_file(renames)\n\n    return result\n\n\ndef parse_sfv(sfv_filename):\n    \"\"\"Parse SFV file and return dictionary of crc32's and filenames\"\"\"\n    results = {}\n    with open(sfv_filename, mode=\"rb\") as sfv_list:\n        for sfv_item in sfv_list:\n            sfv_item = sfv_item.strip()\n            # Ignore comment-lines\n            if sfv_item.startswith(b\";\"):\n                continue\n            # Parse out the filename and crc32\n            filename, expected_crc32 = sfv_item.strip().rsplit(maxsplit=1)\n            # We don't know what encoding is used when it was created\n            results[correct_unknown_encoding(filename)] = expected_crc32.lower()\n    return results\n\n\ndef add_time_left(perc: float, start_time: Optional[float] = None, time_used: Optional[float] = None) -> str:\n    \"\"\"Calculate time left based on current progress, if it is taking more than 10 seconds\"\"\"\n    if not time_used:\n        time_used = time.time() - start_time\n    if time_used > 10:\n        return \" - %s %s\" % (format_time_left(int((100 - perc) / (perc / time_used)), short_format=True), T(\"left\"))\n    return \"\"\n\n\ndef analyse_show(name: str) -> Dict[str, str]:\n    \"\"\"Use the Sorter to collect some basic info on series\"\"\"\n    job = Sorter(\n        None,\n        name,\n        None,\n        None,\n        force=True,\n        sorter_config={\n            \"name\": \"newsunpack__analyse_show\",\n            \"order\": 0,\n            \"min_size\": -1,\n            \"multipart_label\": \"\",\n            \"sort_string\": \"\",\n            \"sort_cats\": [],  # Categories and types are ignored when using the force\n            \"sort_type\": [],\n            \"is_active\": 1,\n        },\n    )\n    job.get_values()\n    return {\n        \"title\": job.info.get(\"title\", \"\"),\n        \"season\": job.info.get(\"season_num\", \"\"),\n        \"episode\": job.info.get(\"episode_num\", \"\"),\n        \"episode_name\": job.info.get(\"ep_name\", \"\"),\n        \"is_proper\": str(job.is_proper()),\n        \"resolution\": job.info.get(\"resolution\", \"\"),\n        \"decade\": job.info.get(\"decade\", \"\"),\n        \"year\": job.info.get(\"year\", \"\"),\n        \"month\": job.info.get(\"month\", \"\"),\n        \"day\": job.info.get(\"day\", \"\"),\n        \"job_type\": job.type,\n    }\n\n\ndef pre_queue(nzo: NzbObject, pp, cat):\n    \"\"\"Run pre-queue script (if any) and process results.\n    pp and cat are supplied separate since they can change.\n    \"\"\"\n\n    def fix(p):\n        # If added via API, some items can still be \"None\" (as a string)\n        if not p or str(p).lower() == \"none\":\n            return \"\"\n        return str(p)\n\n    values = [1, nzo.final_name_with_password, pp, cat, nzo.script, nzo.priority, None]\n    script_path = make_script_path(cfg.pre_script())\n    if script_path:\n        # Basic command-line parameters\n        command = [\n            script_path,\n            nzo.final_name_with_password,\n            pp,\n            cat,\n            nzo.script,\n            nzo.priority,\n            str(nzo.bytes),\n            \" \".join(nzo.groups),\n        ]\n        command.extend(list(analyse_show(nzo.final_name_with_password).values()))\n        command = [fix(arg) for arg in command]\n\n        # Fields not in the NZO directly\n        extra_env_fields = {\n            \"groups\": \" \".join(nzo.groups),\n            \"show_name\": command[8],\n            \"show_season\": command[9],\n            \"show_episode\": command[10],\n            \"show_episode_name\": command[11],\n            \"proper\": command[12],\n            \"resolution\": command[13],\n            \"decade\": command[14],\n            \"year\": command[15],\n            \"month\": command[16],\n            \"day\": command[17],\n            \"type\": command[18],\n        }\n\n        try:\n            p = build_and_run_command(command, env=create_env(nzo, extra_env_fields))\n        except:\n            logging.debug(\"Failed script %s, Traceback: \", script_path, exc_info=True)\n            return values\n\n        output = p.stdout.read()\n        ret = p.wait()\n        logging.info(\"Pre-queue script returned %s and output=\\n%s\", ret, output)\n        if ret == 0:\n            split_output = output.splitlines()\n            try:\n                # Extract category line from pre-queue output\n                pre_queue_category = split_output[3].strip(\" '\\\"\")\n            except IndexError:\n                pre_queue_category = None\n\n            for index, line in enumerate(split_output):\n                line = line.strip(\" '\\\"\")\n                if index < len(values):\n                    if line:\n                        values[index] = line\n                    elif pre_queue_category and index in (2, 4, 5):\n                        # Preserve empty pp, script, and priority lines to prevent\n                        # pre-existing values from overriding category-based settings\n                        values[index] = \"\"\n\n        accept = int_conv(values[0])\n        if accept < 1:\n            logging.info(\"Pre-Q refuses %s\", nzo.final_name)\n        elif accept == 2:\n            logging.info(\"Pre-Q accepts&fails %s\", nzo.final_name)\n        else:\n            logging.info(\"Pre-Q accepts %s\", nzo.final_name)\n\n    return values\n\n\ndef is_sevenfile(path: str) -> bool:\n    \"\"\"Return True if path has 7Zip-signature and 7Zip is detected\"\"\"\n    with open(path, \"rb\") as sevenzip:\n        if sevenzip.read(6) == SEVENZIP_ID:\n            return bool(SEVENZIP_COMMAND)\n    return False\n\n\nclass SevenZip:\n    \"\"\"Minimal emulation of ZipFile class for 7Zip\"\"\"\n\n    def __init__(self, path: str):\n        self.path = path\n        # Check if it's actually a 7Zip-file\n        if not is_sevenfile(self.path):\n            raise TypeError(\"File is not a 7zip file\")\n\n    def namelist(self) -> List[str]:\n        \"\"\"Return list of names in 7Zip\"\"\"\n        names = []\n        command = [SEVENZIP_COMMAND, \"l\", \"-p\", \"-y\", \"-slt\", \"-sccUTF-8\", self.path]\n        output = run_command(command)\n\n        for line in output.split(\"\\n\"):\n            m = SEVENZIP_PATH_RE.search(line)\n            if m:\n                names.append(m.group(1).strip(\"\\r\"))\n        if names:\n            # Remove name of archive itself\n            del names[0]\n        return names\n\n    def open(self, name: str) -> BinaryIO:\n        \"\"\"Read named file from 7Zip and return data\"\"\"\n        command = [SEVENZIP_COMMAND, \"e\", \"-p\", \"-y\", \"-so\", self.path, name]\n        # Ignore diagnostic output, otherwise it will be appended to content\n        with build_and_run_command(command, text_mode=False, stderr=subprocess.DEVNULL) as p:\n            data = io.BytesIO(p.stdout.read())\n            p.wait()\n        return data\n\n    def close(self):\n        \"\"\"Close file\"\"\"\n        pass\n", "#!/usr/bin/python3 -OO\n# Copyright 2007-2023 The SABnzbd-Team <team@sabnzbd.org>\n#\n# This program is free software; you can redistribute it and/or\n# modify it under the terms of the GNU General Public License\n# as published by the Free Software Foundation; either version 2\n# of the License, or (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n#\n\n\"\"\"\nsabnzbd.notifier - Send notifications to any notification services\n\"\"\"\n\n\nimport os.path\nimport logging\nimport urllib.request\nimport urllib.parse\nimport http.client\nimport json\nfrom threading import Thread\n\nimport sabnzbd\nimport sabnzbd.cfg\nfrom sabnzbd.encoding import utob\nfrom sabnzbd.filesystem import make_script_path\nfrom sabnzbd.misc import build_and_run_command\nfrom sabnzbd.newsunpack import create_env\n\nif sabnzbd.FOUNDATION:\n    import Foundation\n    import objc\n\ntry:\n    import notify2\n\n    _HAVE_NTFOSD = True\n\n    # Check for working version, not all pynotify are the same\n    # Without DISPLAY, notify2 cannot autolaunch a dbus-daemon\n    if not hasattr(notify2, \"init\") or \"DISPLAY\" not in os.environ:\n        _HAVE_NTFOSD = False\nexcept:\n    _HAVE_NTFOSD = False\n\n\n##############################################################################\n# Define translatable message table\n##############################################################################\nTT = lambda x: x\nNOTIFICATION = {\n    \"startup\": TT(\"Startup/Shutdown\"),  #: Notification\n    \"pause_resume\": TT(\"Pause\") + \"/\" + TT(\"Resume\"),  #: Notification\n    \"download\": TT(\"Added NZB\"),  #: Notification\n    \"pp\": TT(\"Post-processing started\"),  # : Notification\n    \"complete\": TT(\"Job finished\"),  #: Notification\n    \"failed\": TT(\"Job failed\"),  #: Notification\n    \"warning\": TT(\"Warning\"),  #: Notification\n    \"error\": TT(\"Error\"),  #: Notification\n    \"disk_full\": TT(\"Disk full\"),  #: Notification\n    \"queue_done\": TT(\"Queue finished\"),  #: Notification\n    \"new_login\": TT(\"User logged in\"),  #: Notification\n    \"other\": TT(\"Other Messages\"),  #: Notification\n}\n\n\ndef get_icon():\n    icon = os.path.join(sabnzbd.DIR_PROG, \"icons\", \"sabnzbd.ico\")\n    with open(icon, \"rb\") as fp:\n        return fp.read()\n\n\ndef have_ntfosd():\n    \"\"\"Return if any PyNotify (notify2) support is present\"\"\"\n    return bool(_HAVE_NTFOSD)\n\n\ndef check_classes(gtype, section):\n    \"\"\"Check if `gtype` is enabled in `section`\"\"\"\n    try:\n        return sabnzbd.config.get_config(section, \"%s_prio_%s\" % (section, gtype))() > 0\n    except TypeError:\n        logging.debug(\"Incorrect Notify option %s:%s_prio_%s\", section, section, gtype)\n        return False\n\n\ndef get_prio(gtype, section):\n    \"\"\"Check prio of `gtype` in `section`\"\"\"\n    try:\n        return sabnzbd.config.get_config(section, \"%s_prio_%s\" % (section, gtype))()\n    except TypeError:\n        logging.debug(\"Incorrect Notify option %s:%s_prio_%s\", section, section, gtype)\n        return -1000\n\n\ndef check_cat(section, job_cat, keyword=None):\n    \"\"\"Check if `job_cat` is enabled in `section`.\n    * = All, if no other categories selected.\n    \"\"\"\n    if not job_cat:\n        return True\n    try:\n        if not keyword:\n            keyword = section\n        section_cats = sabnzbd.config.get_config(section, \"%s_cats\" % keyword)()\n        return [\"*\"] == section_cats or job_cat in section_cats\n    except TypeError:\n        logging.debug(\"Incorrect Notify option %s:%s_cats\", section, section)\n        return True\n\n\ndef send_notification(title, msg, gtype, job_cat=None):\n    \"\"\"Send Notification message\"\"\"\n    logging.info(\"Sending notification: %s - %s (type=%s, job_cat=%s)\", title, msg, gtype, job_cat)\n    # Notification Center\n    if sabnzbd.MACOS and sabnzbd.cfg.ncenter_enable():\n        if check_classes(gtype, \"ncenter\") and check_cat(\"ncenter\", job_cat):\n            send_notification_center(title, msg, gtype)\n\n    # Windows\n    if sabnzbd.WIN32 and sabnzbd.cfg.acenter_enable():\n        if check_classes(gtype, \"acenter\") and check_cat(\"acenter\", job_cat):\n            send_windows(title, msg, gtype)\n\n    # Prowl\n    if sabnzbd.cfg.prowl_enable() and check_cat(\"prowl\", job_cat):\n        if sabnzbd.cfg.prowl_apikey():\n            Thread(target=send_prowl, args=(title, msg, gtype)).start()\n\n    # Pushover\n    if sabnzbd.cfg.pushover_enable() and check_cat(\"pushover\", job_cat):\n        if sabnzbd.cfg.pushover_token():\n            Thread(target=send_pushover, args=(title, msg, gtype)).start()\n\n    # Pushbullet\n    if sabnzbd.cfg.pushbullet_enable() and check_cat(\"pushbullet\", job_cat):\n        if sabnzbd.cfg.pushbullet_apikey() and check_classes(gtype, \"pushbullet\"):\n            Thread(target=send_pushbullet, args=(title, msg, gtype)).start()\n\n    # Notification script.\n    if sabnzbd.cfg.nscript_enable() and check_cat(\"nscript\", job_cat):\n        if sabnzbd.cfg.nscript_script():\n            Thread(target=send_nscript, args=(title, msg, gtype)).start()\n\n    # NTFOSD\n    if have_ntfosd() and sabnzbd.cfg.ntfosd_enable():\n        if check_classes(gtype, \"ntfosd\") and check_cat(\"ntfosd\", job_cat):\n            send_notify_osd(title, msg)\n\n\n##############################################################################\n# Ubuntu NotifyOSD Support\n##############################################################################\n_NTFOSD = False\n\n\ndef send_notify_osd(title, message):\n    \"\"\"Send a message to NotifyOSD\"\"\"\n    global _NTFOSD\n    if not _HAVE_NTFOSD:\n        return T(\"Not available\")  # : Function is not available on this OS\n\n    error = \"NotifyOSD not working\"\n    icon = os.path.join(sabnzbd.DIR_PROG, \"interfaces/Config/templates/staticcfg/images/logo-arrow.svg\")\n\n    # Wrap notify2.init to prevent blocking in dbus\n    # when there's no active notification daemon\n    try:\n        _NTFOSD = _NTFOSD or notify2.init(\"SABnzbd\")\n    except:\n        _NTFOSD = False\n\n    if _NTFOSD:\n        logging.info(\"Send to NotifyOSD: %s / %s\", title, message)\n        try:\n            note = notify2.Notification(title, message, icon)\n            note.show()\n        except:\n            # Apparently not implemented on this system\n            logging.info(error)\n            return error\n        return None\n    else:\n        return error\n\n\ndef send_notification_center(title, msg, gtype):\n    \"\"\"Send message to macOS Notification Center\"\"\"\n    try:\n        NSUserNotification = objc.lookUpClass(\"NSUserNotification\")\n        NSUserNotificationCenter = objc.lookUpClass(\"NSUserNotificationCenter\")\n        notification = NSUserNotification.alloc().init()\n        notification.setTitle_(title)\n        notification.setSubtitle_(T(NOTIFICATION.get(gtype, \"other\")))\n        notification.setInformativeText_(msg)\n        notification.setSoundName_(\"NSUserNotificationDefaultSoundName\")\n        notification.setDeliveryDate_(Foundation.NSDate.dateWithTimeInterval_sinceDate_(0, Foundation.NSDate.date()))\n        NSUserNotificationCenter.defaultUserNotificationCenter().scheduleNotification_(notification)\n    except:\n        logging.info(T(\"Failed to send macOS notification\"))\n        logging.debug(\"Traceback: \", exc_info=True)\n        return T(\"Failed to send macOS notification\")\n\n\ndef send_prowl(title, msg, gtype, force=False, test=None):\n    \"\"\"Send message to Prowl\"\"\"\n\n    if test:\n        apikey = test.get(\"prowl_apikey\")\n    else:\n        apikey = sabnzbd.cfg.prowl_apikey()\n    if not apikey:\n        return T(\"Cannot send, missing required data\")\n\n    title = T(NOTIFICATION.get(gtype, \"other\"))\n    title = urllib.parse.quote(utob(title))\n    msg = urllib.parse.quote(utob(msg))\n    prio = get_prio(gtype, \"prowl\")\n\n    if force:\n        prio = 0\n\n    if prio > -3:\n        url = (\n            \"https://api.prowlapp.com/publicapi/add?apikey=%s&application=SABnzbd\"\n            \"&event=%s&description=%s&priority=%d\" % (apikey, title, msg, prio)\n        )\n        try:\n            urllib.request.urlopen(url)\n            return \"\"\n        except:\n            logging.warning(T(\"Failed to send Prowl message\"))\n            logging.info(\"Traceback: \", exc_info=True)\n            return T(\"Failed to send Prowl message\")\n    return \"\"\n\n\ndef send_pushover(title, msg, gtype, force=False, test=None):\n    \"\"\"Send message to pushover\"\"\"\n\n    if test:\n        apikey = test.get(\"pushover_token\")\n        userkey = test.get(\"pushover_userkey\")\n        device = test.get(\"pushover_device\")\n    else:\n        apikey = sabnzbd.cfg.pushover_token()\n        userkey = sabnzbd.cfg.pushover_userkey()\n        device = sabnzbd.cfg.pushover_device()\n        emergency_retry = sabnzbd.cfg.pushover_emergency_retry()\n        emergency_expire = sabnzbd.cfg.pushover_emergency_expire()\n    if not apikey or not userkey:\n        return T(\"Cannot send, missing required data\")\n\n    title = T(NOTIFICATION.get(gtype, \"other\"))\n    prio = get_prio(gtype, \"pushover\")\n\n    if force:\n        prio = 1\n\n    if prio == 2:\n        body = {\n            \"token\": apikey,\n            \"user\": userkey,\n            \"device\": device,\n            \"title\": title,\n            \"message\": msg,\n            \"priority\": prio,\n            \"retry\": emergency_retry,\n            \"expire\": emergency_expire,\n        }\n        return do_send_pushover(body)\n    if -3 < prio < 2:\n        body = {\n            \"token\": apikey,\n            \"user\": userkey,\n            \"device\": device,\n            \"title\": title,\n            \"message\": msg,\n            \"priority\": prio,\n        }\n        return do_send_pushover(body)\n\n\ndef do_send_pushover(body):\n    try:\n        conn = http.client.HTTPSConnection(\"api.pushover.net:443\")\n        conn.request(\n            \"POST\",\n            \"/1/messages.json\",\n            urllib.parse.urlencode(body),\n            {\"Content-type\": \"application/x-www-form-urlencoded\"},\n        )\n        res = conn.getresponse()\n        if res.status != 200:\n            logging.error(T(\"Bad response from Pushover (%s): %s\"), res.status, res.read())\n            return T(\"Failed to send pushover message\")\n        else:\n            return \"\"\n    except:\n        logging.warning(T(\"Failed to send pushover message\"))\n        logging.info(\"Traceback: \", exc_info=True)\n        return T(\"Failed to send pushover message\")\n\n\ndef send_pushbullet(title, msg, gtype, force=False, test=None):\n    \"\"\"Send message to Pushbullet\"\"\"\n\n    if test:\n        apikey = test.get(\"pushbullet_apikey\")\n        device = test.get(\"pushbullet_device\")\n    else:\n        apikey = sabnzbd.cfg.pushbullet_apikey()\n        device = sabnzbd.cfg.pushbullet_device()\n    if not apikey:\n        return T(\"Cannot send, missing required data\")\n\n    title = \"SABnzbd: \" + T(NOTIFICATION.get(gtype, \"other\"))\n\n    try:\n        conn = http.client.HTTPSConnection(\"api.pushbullet.com:443\")\n        conn.request(\n            \"POST\",\n            \"/v2/pushes\",\n            json.dumps({\"type\": \"note\", \"device\": device, \"title\": title, \"body\": msg}),\n            headers={\"Authorization\": \"Bearer \" + apikey, \"Content-type\": \"application/json\"},\n        )\n        res = conn.getresponse()\n        if res.status != 200:\n            logging.error(T(\"Bad response from Pushbullet (%s): %s\"), res.status, res.read())\n        else:\n            logging.info(\"Successfully sent to Pushbullet\")\n\n    except:\n        logging.warning(T(\"Failed to send pushbullet message\"))\n        logging.info(\"Traceback: \", exc_info=True)\n        return T(\"Failed to send pushbullet message\")\n    return \"\"\n\n\ndef send_nscript(title, msg, gtype, force=False, test=None):\n    \"\"\"Run user's notification script\"\"\"\n    if test:\n        script = test.get(\"nscript_script\")\n        env_params = {\"notification_parameters\": test.get(\"nscript_parameters\")}\n    else:\n        script = sabnzbd.cfg.nscript_script()\n        env_params = {\"notification_parameters\": sabnzbd.cfg.nscript_parameters()}\n\n    if not script:\n        return T(\"Cannot send, missing required data\")\n    title = \"SABnzbd: \" + T(NOTIFICATION.get(gtype, \"other\"))\n\n    if force or check_classes(gtype, \"nscript\"):\n        script_path = make_script_path(script)\n        if script_path:\n            ret = -1\n            output = None\n            try:\n                p = build_and_run_command([script_path, gtype, title, msg], env=create_env(extra_env_fields=env_params))\n                output = p.stdout.read()\n                ret = p.wait()\n            except:\n                logging.info(\"Failed to run script %s\", script, exc_info=True)\n\n            if ret:\n                logging.error(T('Script returned exit code %s and output \"%s\"'), ret, output)\n                return T('Script returned exit code %s and output \"%s\"') % (ret, output)\n            else:\n                logging.info(\"Successfully executed notification script %s\", script_path)\n                logging.debug(\"Script output: %s\", output)\n        else:\n            return T('Notification script \"%s\" does not exist') % script_path\n    return \"\"\n\n\ndef send_windows(title, msg, gtype):\n    if sabnzbd.WINTRAY and not sabnzbd.WINTRAY.terminate:\n        try:\n            sabnzbd.WINTRAY.sendnotification(title, msg)\n        except:\n            logging.info(T(\"Failed to send Windows notification\"))\n            logging.debug(\"Traceback: \", exc_info=True)\n            return T(\"Failed to send Windows notification\")\n    return None\n"], "filenames": ["sabnzbd/newsunpack.py", "sabnzbd/notifier.py"], "buggy_code_start_loc": [1911, 353], "buggy_code_end_loc": [1914, 378], "fixing_code_start_loc": [1910, 353], "fixing_code_end_loc": [1910, 380], "type": "NVD-CWE-noinfo", "message": "SABnzbd is an open source automated Usenet download tool. A design flaw was discovered in SABnzbd that could allow remote code execution. Manipulating the Parameters setting in the Notification Script functionality allows code execution with the privileges of the SABnzbd process. Exploiting the vulnerabilities requires access to the web interface. Remote exploitation is possible if users[exposed their setup to the internet or other untrusted networks without setting a username/password. By default SABnzbd is only accessible from `localhost`, with no authentication required for the web interface. This issue has been patched in commits `e3a722` and `422b4f` which have been included in the 4.0.2 release. Users are advised to upgrade. Users unable to upgrade should ensure that a username and password have been set if their instance is web accessible.", "other": {"cve": {"id": "CVE-2023-34237", "sourceIdentifier": "security-advisories@github.com", "published": "2023-06-07T20:15:10.097", "lastModified": "2023-12-23T10:15:10.110", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "SABnzbd is an open source automated Usenet download tool. A design flaw was discovered in SABnzbd that could allow remote code execution. Manipulating the Parameters setting in the Notification Script functionality allows code execution with the privileges of the SABnzbd process. Exploiting the vulnerabilities requires access to the web interface. Remote exploitation is possible if users[exposed their setup to the internet or other untrusted networks without setting a username/password. By default SABnzbd is only accessible from `localhost`, with no authentication required for the web interface. This issue has been patched in commits `e3a722` and `422b4f` which have been included in the 4.0.2 release. Users are advised to upgrade. Users unable to upgrade should ensure that a username and password have been set if their instance is web accessible."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 5.9}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-94"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:sabnzbd:sabnzbd:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.1.0", "versionEndExcluding": "4.0.2", "matchCriteriaId": "0793A3BA-34F2-4029-8CF1-CDAB4F72F1B5"}]}]}], "references": [{"url": "https://github.com/sabnzbd/sabnzbd/commit/422b4fce7bfd56e95a315be0400cdfdc585df7cc", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/sabnzbd/sabnzbd/commit/e3a722664819d1c7c8fab97144cc299b1c18b429", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/sabnzbd/sabnzbd/security/advisories/GHSA-hhgh-xgh3-985r", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}, {"url": "https://sabnzbd.org/wiki/configuration/4.0/general", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}, {"url": "https://security.gentoo.org/glsa/202312-11", "source": "security-advisories@github.com"}]}, "github_commit_url": "https://github.com/sabnzbd/sabnzbd/commit/422b4fce7bfd56e95a315be0400cdfdc585df7cc"}}
{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0-only\n/*\n * xfrm_policy.c\n *\n * Changes:\n *\tMitsuru KANDA @USAGI\n * \tKazunori MIYAZAWA @USAGI\n * \tKunihiro Ishiguro <kunihiro@ipinfusion.com>\n * \t\tIPv6 support\n * \tKazunori MIYAZAWA @USAGI\n * \tYOSHIFUJI Hideaki\n * \t\tSplit up af-specific portion\n *\tDerek Atkins <derek@ihtfp.com>\t\tAdd the post_input processor\n *\n */\n\n#include <linux/err.h>\n#include <linux/slab.h>\n#include <linux/kmod.h>\n#include <linux/list.h>\n#include <linux/spinlock.h>\n#include <linux/workqueue.h>\n#include <linux/notifier.h>\n#include <linux/netdevice.h>\n#include <linux/netfilter.h>\n#include <linux/module.h>\n#include <linux/cache.h>\n#include <linux/cpu.h>\n#include <linux/audit.h>\n#include <linux/rhashtable.h>\n#include <linux/if_tunnel.h>\n#include <net/dst.h>\n#include <net/flow.h>\n#include <net/inet_ecn.h>\n#include <net/xfrm.h>\n#include <net/ip.h>\n#include <net/gre.h>\n#if IS_ENABLED(CONFIG_IPV6_MIP6)\n#include <net/mip6.h>\n#endif\n#ifdef CONFIG_XFRM_STATISTICS\n#include <net/snmp.h>\n#endif\n#ifdef CONFIG_XFRM_ESPINTCP\n#include <net/espintcp.h>\n#endif\n\n#include \"xfrm_hash.h\"\n\n#define XFRM_QUEUE_TMO_MIN ((unsigned)(HZ/10))\n#define XFRM_QUEUE_TMO_MAX ((unsigned)(60*HZ))\n#define XFRM_MAX_QUEUE_LEN\t100\n\nstruct xfrm_flo {\n\tstruct dst_entry *dst_orig;\n\tu8 flags;\n};\n\n/* prefixes smaller than this are stored in lists, not trees. */\n#define INEXACT_PREFIXLEN_IPV4\t16\n#define INEXACT_PREFIXLEN_IPV6\t48\n\nstruct xfrm_pol_inexact_node {\n\tstruct rb_node node;\n\tunion {\n\t\txfrm_address_t addr;\n\t\tstruct rcu_head rcu;\n\t};\n\tu8 prefixlen;\n\n\tstruct rb_root root;\n\n\t/* the policies matching this node, can be empty list */\n\tstruct hlist_head hhead;\n};\n\n/* xfrm inexact policy search tree:\n * xfrm_pol_inexact_bin = hash(dir,type,family,if_id);\n *  |\n * +---- root_d: sorted by daddr:prefix\n * |                 |\n * |        xfrm_pol_inexact_node\n * |                 |\n * |                 +- root: sorted by saddr/prefix\n * |                 |              |\n * |                 |         xfrm_pol_inexact_node\n * |                 |              |\n * |                 |              + root: unused\n * |                 |              |\n * |                 |              + hhead: saddr:daddr policies\n * |                 |\n * |                 +- coarse policies and all any:daddr policies\n * |\n * +---- root_s: sorted by saddr:prefix\n * |                 |\n * |        xfrm_pol_inexact_node\n * |                 |\n * |                 + root: unused\n * |                 |\n * |                 + hhead: saddr:any policies\n * |\n * +---- coarse policies and all any:any policies\n *\n * Lookups return four candidate lists:\n * 1. any:any list from top-level xfrm_pol_inexact_bin\n * 2. any:daddr list from daddr tree\n * 3. saddr:daddr list from 2nd level daddr tree\n * 4. saddr:any list from saddr tree\n *\n * This result set then needs to be searched for the policy with\n * the lowest priority.  If two results have same prio, youngest one wins.\n */\n\nstruct xfrm_pol_inexact_key {\n\tpossible_net_t net;\n\tu32 if_id;\n\tu16 family;\n\tu8 dir, type;\n};\n\nstruct xfrm_pol_inexact_bin {\n\tstruct xfrm_pol_inexact_key k;\n\tstruct rhash_head head;\n\t/* list containing '*:*' policies */\n\tstruct hlist_head hhead;\n\n\tseqcount_spinlock_t count;\n\t/* tree sorted by daddr/prefix */\n\tstruct rb_root root_d;\n\n\t/* tree sorted by saddr/prefix */\n\tstruct rb_root root_s;\n\n\t/* slow path below */\n\tstruct list_head inexact_bins;\n\tstruct rcu_head rcu;\n};\n\nenum xfrm_pol_inexact_candidate_type {\n\tXFRM_POL_CAND_BOTH,\n\tXFRM_POL_CAND_SADDR,\n\tXFRM_POL_CAND_DADDR,\n\tXFRM_POL_CAND_ANY,\n\n\tXFRM_POL_CAND_MAX,\n};\n\nstruct xfrm_pol_inexact_candidates {\n\tstruct hlist_head *res[XFRM_POL_CAND_MAX];\n};\n\nstatic DEFINE_SPINLOCK(xfrm_if_cb_lock);\nstatic struct xfrm_if_cb const __rcu *xfrm_if_cb __read_mostly;\n\nstatic DEFINE_SPINLOCK(xfrm_policy_afinfo_lock);\nstatic struct xfrm_policy_afinfo const __rcu *xfrm_policy_afinfo[AF_INET6 + 1]\n\t\t\t\t\t\t__read_mostly;\n\nstatic struct kmem_cache *xfrm_dst_cache __ro_after_init;\n\nstatic struct rhashtable xfrm_policy_inexact_table;\nstatic const struct rhashtable_params xfrm_pol_inexact_params;\n\nstatic void xfrm_init_pmtu(struct xfrm_dst **bundle, int nr);\nstatic int stale_bundle(struct dst_entry *dst);\nstatic int xfrm_bundle_ok(struct xfrm_dst *xdst);\nstatic void xfrm_policy_queue_process(struct timer_list *t);\n\nstatic void __xfrm_policy_link(struct xfrm_policy *pol, int dir);\nstatic struct xfrm_policy *__xfrm_policy_unlink(struct xfrm_policy *pol,\n\t\t\t\t\t\tint dir);\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup(struct net *net, u8 type, u16 family, u8 dir,\n\t\t\t   u32 if_id);\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup_rcu(struct net *net,\n\t\t\t       u8 type, u16 family, u8 dir, u32 if_id);\nstatic struct xfrm_policy *\nxfrm_policy_insert_list(struct hlist_head *chain, struct xfrm_policy *policy,\n\t\t\tbool excl);\nstatic void xfrm_policy_insert_inexact_list(struct hlist_head *chain,\n\t\t\t\t\t    struct xfrm_policy *policy);\n\nstatic bool\nxfrm_policy_find_inexact_candidates(struct xfrm_pol_inexact_candidates *cand,\n\t\t\t\t    struct xfrm_pol_inexact_bin *b,\n\t\t\t\t    const xfrm_address_t *saddr,\n\t\t\t\t    const xfrm_address_t *daddr);\n\nstatic inline bool xfrm_pol_hold_rcu(struct xfrm_policy *policy)\n{\n\treturn refcount_inc_not_zero(&policy->refcnt);\n}\n\nstatic inline bool\n__xfrm4_selector_match(const struct xfrm_selector *sel, const struct flowi *fl)\n{\n\tconst struct flowi4 *fl4 = &fl->u.ip4;\n\n\treturn  addr4_match(fl4->daddr, sel->daddr.a4, sel->prefixlen_d) &&\n\t\taddr4_match(fl4->saddr, sel->saddr.a4, sel->prefixlen_s) &&\n\t\t!((xfrm_flowi_dport(fl, &fl4->uli) ^ sel->dport) & sel->dport_mask) &&\n\t\t!((xfrm_flowi_sport(fl, &fl4->uli) ^ sel->sport) & sel->sport_mask) &&\n\t\t(fl4->flowi4_proto == sel->proto || !sel->proto) &&\n\t\t(fl4->flowi4_oif == sel->ifindex || !sel->ifindex);\n}\n\nstatic inline bool\n__xfrm6_selector_match(const struct xfrm_selector *sel, const struct flowi *fl)\n{\n\tconst struct flowi6 *fl6 = &fl->u.ip6;\n\n\treturn  addr_match(&fl6->daddr, &sel->daddr, sel->prefixlen_d) &&\n\t\taddr_match(&fl6->saddr, &sel->saddr, sel->prefixlen_s) &&\n\t\t!((xfrm_flowi_dport(fl, &fl6->uli) ^ sel->dport) & sel->dport_mask) &&\n\t\t!((xfrm_flowi_sport(fl, &fl6->uli) ^ sel->sport) & sel->sport_mask) &&\n\t\t(fl6->flowi6_proto == sel->proto || !sel->proto) &&\n\t\t(fl6->flowi6_oif == sel->ifindex || !sel->ifindex);\n}\n\nbool xfrm_selector_match(const struct xfrm_selector *sel, const struct flowi *fl,\n\t\t\t unsigned short family)\n{\n\tswitch (family) {\n\tcase AF_INET:\n\t\treturn __xfrm4_selector_match(sel, fl);\n\tcase AF_INET6:\n\t\treturn __xfrm6_selector_match(sel, fl);\n\t}\n\treturn false;\n}\n\nstatic const struct xfrm_policy_afinfo *xfrm_policy_get_afinfo(unsigned short family)\n{\n\tconst struct xfrm_policy_afinfo *afinfo;\n\n\tif (unlikely(family >= ARRAY_SIZE(xfrm_policy_afinfo)))\n\t\treturn NULL;\n\trcu_read_lock();\n\tafinfo = rcu_dereference(xfrm_policy_afinfo[family]);\n\tif (unlikely(!afinfo))\n\t\trcu_read_unlock();\n\treturn afinfo;\n}\n\n/* Called with rcu_read_lock(). */\nstatic const struct xfrm_if_cb *xfrm_if_get_cb(void)\n{\n\treturn rcu_dereference(xfrm_if_cb);\n}\n\nstruct dst_entry *__xfrm_dst_lookup(struct net *net, int tos, int oif,\n\t\t\t\t    const xfrm_address_t *saddr,\n\t\t\t\t    const xfrm_address_t *daddr,\n\t\t\t\t    int family, u32 mark)\n{\n\tconst struct xfrm_policy_afinfo *afinfo;\n\tstruct dst_entry *dst;\n\n\tafinfo = xfrm_policy_get_afinfo(family);\n\tif (unlikely(afinfo == NULL))\n\t\treturn ERR_PTR(-EAFNOSUPPORT);\n\n\tdst = afinfo->dst_lookup(net, tos, oif, saddr, daddr, mark);\n\n\trcu_read_unlock();\n\n\treturn dst;\n}\nEXPORT_SYMBOL(__xfrm_dst_lookup);\n\nstatic inline struct dst_entry *xfrm_dst_lookup(struct xfrm_state *x,\n\t\t\t\t\t\tint tos, int oif,\n\t\t\t\t\t\txfrm_address_t *prev_saddr,\n\t\t\t\t\t\txfrm_address_t *prev_daddr,\n\t\t\t\t\t\tint family, u32 mark)\n{\n\tstruct net *net = xs_net(x);\n\txfrm_address_t *saddr = &x->props.saddr;\n\txfrm_address_t *daddr = &x->id.daddr;\n\tstruct dst_entry *dst;\n\n\tif (x->type->flags & XFRM_TYPE_LOCAL_COADDR) {\n\t\tsaddr = x->coaddr;\n\t\tdaddr = prev_daddr;\n\t}\n\tif (x->type->flags & XFRM_TYPE_REMOTE_COADDR) {\n\t\tsaddr = prev_saddr;\n\t\tdaddr = x->coaddr;\n\t}\n\n\tdst = __xfrm_dst_lookup(net, tos, oif, saddr, daddr, family, mark);\n\n\tif (!IS_ERR(dst)) {\n\t\tif (prev_saddr != saddr)\n\t\t\tmemcpy(prev_saddr, saddr,  sizeof(*prev_saddr));\n\t\tif (prev_daddr != daddr)\n\t\t\tmemcpy(prev_daddr, daddr,  sizeof(*prev_daddr));\n\t}\n\n\treturn dst;\n}\n\nstatic inline unsigned long make_jiffies(long secs)\n{\n\tif (secs >= (MAX_SCHEDULE_TIMEOUT-1)/HZ)\n\t\treturn MAX_SCHEDULE_TIMEOUT-1;\n\telse\n\t\treturn secs*HZ;\n}\n\nstatic void xfrm_policy_timer(struct timer_list *t)\n{\n\tstruct xfrm_policy *xp = from_timer(xp, t, timer);\n\ttime64_t now = ktime_get_real_seconds();\n\ttime64_t next = TIME64_MAX;\n\tint warn = 0;\n\tint dir;\n\n\tread_lock(&xp->lock);\n\n\tif (unlikely(xp->walk.dead))\n\t\tgoto out;\n\n\tdir = xfrm_policy_id2dir(xp->index);\n\n\tif (xp->lft.hard_add_expires_seconds) {\n\t\ttime64_t tmo = xp->lft.hard_add_expires_seconds +\n\t\t\txp->curlft.add_time - now;\n\t\tif (tmo <= 0)\n\t\t\tgoto expired;\n\t\tif (tmo < next)\n\t\t\tnext = tmo;\n\t}\n\tif (xp->lft.hard_use_expires_seconds) {\n\t\ttime64_t tmo = xp->lft.hard_use_expires_seconds +\n\t\t\t(xp->curlft.use_time ? : xp->curlft.add_time) - now;\n\t\tif (tmo <= 0)\n\t\t\tgoto expired;\n\t\tif (tmo < next)\n\t\t\tnext = tmo;\n\t}\n\tif (xp->lft.soft_add_expires_seconds) {\n\t\ttime64_t tmo = xp->lft.soft_add_expires_seconds +\n\t\t\txp->curlft.add_time - now;\n\t\tif (tmo <= 0) {\n\t\t\twarn = 1;\n\t\t\ttmo = XFRM_KM_TIMEOUT;\n\t\t}\n\t\tif (tmo < next)\n\t\t\tnext = tmo;\n\t}\n\tif (xp->lft.soft_use_expires_seconds) {\n\t\ttime64_t tmo = xp->lft.soft_use_expires_seconds +\n\t\t\t(xp->curlft.use_time ? : xp->curlft.add_time) - now;\n\t\tif (tmo <= 0) {\n\t\t\twarn = 1;\n\t\t\ttmo = XFRM_KM_TIMEOUT;\n\t\t}\n\t\tif (tmo < next)\n\t\t\tnext = tmo;\n\t}\n\n\tif (warn)\n\t\tkm_policy_expired(xp, dir, 0, 0);\n\tif (next != TIME64_MAX &&\n\t    !mod_timer(&xp->timer, jiffies + make_jiffies(next)))\n\t\txfrm_pol_hold(xp);\n\nout:\n\tread_unlock(&xp->lock);\n\txfrm_pol_put(xp);\n\treturn;\n\nexpired:\n\tread_unlock(&xp->lock);\n\tif (!xfrm_policy_delete(xp, dir))\n\t\tkm_policy_expired(xp, dir, 1, 0);\n\txfrm_pol_put(xp);\n}\n\n/* Allocate xfrm_policy. Not used here, it is supposed to be used by pfkeyv2\n * SPD calls.\n */\n\nstruct xfrm_policy *xfrm_policy_alloc(struct net *net, gfp_t gfp)\n{\n\tstruct xfrm_policy *policy;\n\n\tpolicy = kzalloc(sizeof(struct xfrm_policy), gfp);\n\n\tif (policy) {\n\t\twrite_pnet(&policy->xp_net, net);\n\t\tINIT_LIST_HEAD(&policy->walk.all);\n\t\tINIT_HLIST_NODE(&policy->bydst_inexact_list);\n\t\tINIT_HLIST_NODE(&policy->bydst);\n\t\tINIT_HLIST_NODE(&policy->byidx);\n\t\trwlock_init(&policy->lock);\n\t\trefcount_set(&policy->refcnt, 1);\n\t\tskb_queue_head_init(&policy->polq.hold_queue);\n\t\ttimer_setup(&policy->timer, xfrm_policy_timer, 0);\n\t\ttimer_setup(&policy->polq.hold_timer,\n\t\t\t    xfrm_policy_queue_process, 0);\n\t}\n\treturn policy;\n}\nEXPORT_SYMBOL(xfrm_policy_alloc);\n\nstatic void xfrm_policy_destroy_rcu(struct rcu_head *head)\n{\n\tstruct xfrm_policy *policy = container_of(head, struct xfrm_policy, rcu);\n\n\tsecurity_xfrm_policy_free(policy->security);\n\tkfree(policy);\n}\n\n/* Destroy xfrm_policy: descendant resources must be released to this moment. */\n\nvoid xfrm_policy_destroy(struct xfrm_policy *policy)\n{\n\tBUG_ON(!policy->walk.dead);\n\n\tif (del_timer(&policy->timer) || del_timer(&policy->polq.hold_timer))\n\t\tBUG();\n\n\tcall_rcu(&policy->rcu, xfrm_policy_destroy_rcu);\n}\nEXPORT_SYMBOL(xfrm_policy_destroy);\n\n/* Rule must be locked. Release descendant resources, announce\n * entry dead. The rule must be unlinked from lists to the moment.\n */\n\nstatic void xfrm_policy_kill(struct xfrm_policy *policy)\n{\n\twrite_lock_bh(&policy->lock);\n\tpolicy->walk.dead = 1;\n\twrite_unlock_bh(&policy->lock);\n\n\tatomic_inc(&policy->genid);\n\n\tif (del_timer(&policy->polq.hold_timer))\n\t\txfrm_pol_put(policy);\n\tskb_queue_purge(&policy->polq.hold_queue);\n\n\tif (del_timer(&policy->timer))\n\t\txfrm_pol_put(policy);\n\n\txfrm_pol_put(policy);\n}\n\nstatic unsigned int xfrm_policy_hashmax __read_mostly = 1 * 1024 * 1024;\n\nstatic inline unsigned int idx_hash(struct net *net, u32 index)\n{\n\treturn __idx_hash(index, net->xfrm.policy_idx_hmask);\n}\n\n/* calculate policy hash thresholds */\nstatic void __get_hash_thresh(struct net *net,\n\t\t\t      unsigned short family, int dir,\n\t\t\t      u8 *dbits, u8 *sbits)\n{\n\tswitch (family) {\n\tcase AF_INET:\n\t\t*dbits = net->xfrm.policy_bydst[dir].dbits4;\n\t\t*sbits = net->xfrm.policy_bydst[dir].sbits4;\n\t\tbreak;\n\n\tcase AF_INET6:\n\t\t*dbits = net->xfrm.policy_bydst[dir].dbits6;\n\t\t*sbits = net->xfrm.policy_bydst[dir].sbits6;\n\t\tbreak;\n\n\tdefault:\n\t\t*dbits = 0;\n\t\t*sbits = 0;\n\t}\n}\n\nstatic struct hlist_head *policy_hash_bysel(struct net *net,\n\t\t\t\t\t    const struct xfrm_selector *sel,\n\t\t\t\t\t    unsigned short family, int dir)\n{\n\tunsigned int hmask = net->xfrm.policy_bydst[dir].hmask;\n\tunsigned int hash;\n\tu8 dbits;\n\tu8 sbits;\n\n\t__get_hash_thresh(net, family, dir, &dbits, &sbits);\n\thash = __sel_hash(sel, family, hmask, dbits, sbits);\n\n\tif (hash == hmask + 1)\n\t\treturn NULL;\n\n\treturn rcu_dereference_check(net->xfrm.policy_bydst[dir].table,\n\t\t     lockdep_is_held(&net->xfrm.xfrm_policy_lock)) + hash;\n}\n\nstatic struct hlist_head *policy_hash_direct(struct net *net,\n\t\t\t\t\t     const xfrm_address_t *daddr,\n\t\t\t\t\t     const xfrm_address_t *saddr,\n\t\t\t\t\t     unsigned short family, int dir)\n{\n\tunsigned int hmask = net->xfrm.policy_bydst[dir].hmask;\n\tunsigned int hash;\n\tu8 dbits;\n\tu8 sbits;\n\n\t__get_hash_thresh(net, family, dir, &dbits, &sbits);\n\thash = __addr_hash(daddr, saddr, family, hmask, dbits, sbits);\n\n\treturn rcu_dereference_check(net->xfrm.policy_bydst[dir].table,\n\t\t     lockdep_is_held(&net->xfrm.xfrm_policy_lock)) + hash;\n}\n\nstatic void xfrm_dst_hash_transfer(struct net *net,\n\t\t\t\t   struct hlist_head *list,\n\t\t\t\t   struct hlist_head *ndsttable,\n\t\t\t\t   unsigned int nhashmask,\n\t\t\t\t   int dir)\n{\n\tstruct hlist_node *tmp, *entry0 = NULL;\n\tstruct xfrm_policy *pol;\n\tunsigned int h0 = 0;\n\tu8 dbits;\n\tu8 sbits;\n\nredo:\n\thlist_for_each_entry_safe(pol, tmp, list, bydst) {\n\t\tunsigned int h;\n\n\t\t__get_hash_thresh(net, pol->family, dir, &dbits, &sbits);\n\t\th = __addr_hash(&pol->selector.daddr, &pol->selector.saddr,\n\t\t\t\tpol->family, nhashmask, dbits, sbits);\n\t\tif (!entry0) {\n\t\t\thlist_del_rcu(&pol->bydst);\n\t\t\thlist_add_head_rcu(&pol->bydst, ndsttable + h);\n\t\t\th0 = h;\n\t\t} else {\n\t\t\tif (h != h0)\n\t\t\t\tcontinue;\n\t\t\thlist_del_rcu(&pol->bydst);\n\t\t\thlist_add_behind_rcu(&pol->bydst, entry0);\n\t\t}\n\t\tentry0 = &pol->bydst;\n\t}\n\tif (!hlist_empty(list)) {\n\t\tentry0 = NULL;\n\t\tgoto redo;\n\t}\n}\n\nstatic void xfrm_idx_hash_transfer(struct hlist_head *list,\n\t\t\t\t   struct hlist_head *nidxtable,\n\t\t\t\t   unsigned int nhashmask)\n{\n\tstruct hlist_node *tmp;\n\tstruct xfrm_policy *pol;\n\n\thlist_for_each_entry_safe(pol, tmp, list, byidx) {\n\t\tunsigned int h;\n\n\t\th = __idx_hash(pol->index, nhashmask);\n\t\thlist_add_head(&pol->byidx, nidxtable+h);\n\t}\n}\n\nstatic unsigned long xfrm_new_hash_mask(unsigned int old_hmask)\n{\n\treturn ((old_hmask + 1) << 1) - 1;\n}\n\nstatic void xfrm_bydst_resize(struct net *net, int dir)\n{\n\tunsigned int hmask = net->xfrm.policy_bydst[dir].hmask;\n\tunsigned int nhashmask = xfrm_new_hash_mask(hmask);\n\tunsigned int nsize = (nhashmask + 1) * sizeof(struct hlist_head);\n\tstruct hlist_head *ndst = xfrm_hash_alloc(nsize);\n\tstruct hlist_head *odst;\n\tint i;\n\n\tif (!ndst)\n\t\treturn;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\twrite_seqcount_begin(&net->xfrm.xfrm_policy_hash_generation);\n\n\todst = rcu_dereference_protected(net->xfrm.policy_bydst[dir].table,\n\t\t\t\tlockdep_is_held(&net->xfrm.xfrm_policy_lock));\n\n\tfor (i = hmask; i >= 0; i--)\n\t\txfrm_dst_hash_transfer(net, odst + i, ndst, nhashmask, dir);\n\n\trcu_assign_pointer(net->xfrm.policy_bydst[dir].table, ndst);\n\tnet->xfrm.policy_bydst[dir].hmask = nhashmask;\n\n\twrite_seqcount_end(&net->xfrm.xfrm_policy_hash_generation);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tsynchronize_rcu();\n\n\txfrm_hash_free(odst, (hmask + 1) * sizeof(struct hlist_head));\n}\n\nstatic void xfrm_byidx_resize(struct net *net, int total)\n{\n\tunsigned int hmask = net->xfrm.policy_idx_hmask;\n\tunsigned int nhashmask = xfrm_new_hash_mask(hmask);\n\tunsigned int nsize = (nhashmask + 1) * sizeof(struct hlist_head);\n\tstruct hlist_head *oidx = net->xfrm.policy_byidx;\n\tstruct hlist_head *nidx = xfrm_hash_alloc(nsize);\n\tint i;\n\n\tif (!nidx)\n\t\treturn;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tfor (i = hmask; i >= 0; i--)\n\t\txfrm_idx_hash_transfer(oidx + i, nidx, nhashmask);\n\n\tnet->xfrm.policy_byidx = nidx;\n\tnet->xfrm.policy_idx_hmask = nhashmask;\n\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\txfrm_hash_free(oidx, (hmask + 1) * sizeof(struct hlist_head));\n}\n\nstatic inline int xfrm_bydst_should_resize(struct net *net, int dir, int *total)\n{\n\tunsigned int cnt = net->xfrm.policy_count[dir];\n\tunsigned int hmask = net->xfrm.policy_bydst[dir].hmask;\n\n\tif (total)\n\t\t*total += cnt;\n\n\tif ((hmask + 1) < xfrm_policy_hashmax &&\n\t    cnt > hmask)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic inline int xfrm_byidx_should_resize(struct net *net, int total)\n{\n\tunsigned int hmask = net->xfrm.policy_idx_hmask;\n\n\tif ((hmask + 1) < xfrm_policy_hashmax &&\n\t    total > hmask)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nvoid xfrm_spd_getinfo(struct net *net, struct xfrmk_spdinfo *si)\n{\n\tsi->incnt = net->xfrm.policy_count[XFRM_POLICY_IN];\n\tsi->outcnt = net->xfrm.policy_count[XFRM_POLICY_OUT];\n\tsi->fwdcnt = net->xfrm.policy_count[XFRM_POLICY_FWD];\n\tsi->inscnt = net->xfrm.policy_count[XFRM_POLICY_IN+XFRM_POLICY_MAX];\n\tsi->outscnt = net->xfrm.policy_count[XFRM_POLICY_OUT+XFRM_POLICY_MAX];\n\tsi->fwdscnt = net->xfrm.policy_count[XFRM_POLICY_FWD+XFRM_POLICY_MAX];\n\tsi->spdhcnt = net->xfrm.policy_idx_hmask;\n\tsi->spdhmcnt = xfrm_policy_hashmax;\n}\nEXPORT_SYMBOL(xfrm_spd_getinfo);\n\nstatic DEFINE_MUTEX(hash_resize_mutex);\nstatic void xfrm_hash_resize(struct work_struct *work)\n{\n\tstruct net *net = container_of(work, struct net, xfrm.policy_hash_work);\n\tint dir, total;\n\n\tmutex_lock(&hash_resize_mutex);\n\n\ttotal = 0;\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tif (xfrm_bydst_should_resize(net, dir, &total))\n\t\t\txfrm_bydst_resize(net, dir);\n\t}\n\tif (xfrm_byidx_should_resize(net, total))\n\t\txfrm_byidx_resize(net, total);\n\n\tmutex_unlock(&hash_resize_mutex);\n}\n\n/* Make sure *pol can be inserted into fastbin.\n * Useful to check that later insert requests will be successful\n * (provided xfrm_policy_lock is held throughout).\n */\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_alloc_bin(const struct xfrm_policy *pol, u8 dir)\n{\n\tstruct xfrm_pol_inexact_bin *bin, *prev;\n\tstruct xfrm_pol_inexact_key k = {\n\t\t.family = pol->family,\n\t\t.type = pol->type,\n\t\t.dir = dir,\n\t\t.if_id = pol->if_id,\n\t};\n\tstruct net *net = xp_net(pol);\n\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\twrite_pnet(&k.net, net);\n\tbin = rhashtable_lookup_fast(&xfrm_policy_inexact_table, &k,\n\t\t\t\t     xfrm_pol_inexact_params);\n\tif (bin)\n\t\treturn bin;\n\n\tbin = kzalloc(sizeof(*bin), GFP_ATOMIC);\n\tif (!bin)\n\t\treturn NULL;\n\n\tbin->k = k;\n\tINIT_HLIST_HEAD(&bin->hhead);\n\tbin->root_d = RB_ROOT;\n\tbin->root_s = RB_ROOT;\n\tseqcount_spinlock_init(&bin->count, &net->xfrm.xfrm_policy_lock);\n\n\tprev = rhashtable_lookup_get_insert_key(&xfrm_policy_inexact_table,\n\t\t\t\t\t\t&bin->k, &bin->head,\n\t\t\t\t\t\txfrm_pol_inexact_params);\n\tif (!prev) {\n\t\tlist_add(&bin->inexact_bins, &net->xfrm.inexact_bins);\n\t\treturn bin;\n\t}\n\n\tkfree(bin);\n\n\treturn IS_ERR(prev) ? NULL : prev;\n}\n\nstatic bool xfrm_pol_inexact_addr_use_any_list(const xfrm_address_t *addr,\n\t\t\t\t\t       int family, u8 prefixlen)\n{\n\tif (xfrm_addr_any(addr, family))\n\t\treturn true;\n\n\tif (family == AF_INET6 && prefixlen < INEXACT_PREFIXLEN_IPV6)\n\t\treturn true;\n\n\tif (family == AF_INET && prefixlen < INEXACT_PREFIXLEN_IPV4)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic bool\nxfrm_policy_inexact_insert_use_any_list(const struct xfrm_policy *policy)\n{\n\tconst xfrm_address_t *addr;\n\tbool saddr_any, daddr_any;\n\tu8 prefixlen;\n\n\taddr = &policy->selector.saddr;\n\tprefixlen = policy->selector.prefixlen_s;\n\n\tsaddr_any = xfrm_pol_inexact_addr_use_any_list(addr,\n\t\t\t\t\t\t       policy->family,\n\t\t\t\t\t\t       prefixlen);\n\taddr = &policy->selector.daddr;\n\tprefixlen = policy->selector.prefixlen_d;\n\tdaddr_any = xfrm_pol_inexact_addr_use_any_list(addr,\n\t\t\t\t\t\t       policy->family,\n\t\t\t\t\t\t       prefixlen);\n\treturn saddr_any && daddr_any;\n}\n\nstatic void xfrm_pol_inexact_node_init(struct xfrm_pol_inexact_node *node,\n\t\t\t\t       const xfrm_address_t *addr, u8 prefixlen)\n{\n\tnode->addr = *addr;\n\tnode->prefixlen = prefixlen;\n}\n\nstatic struct xfrm_pol_inexact_node *\nxfrm_pol_inexact_node_alloc(const xfrm_address_t *addr, u8 prefixlen)\n{\n\tstruct xfrm_pol_inexact_node *node;\n\n\tnode = kzalloc(sizeof(*node), GFP_ATOMIC);\n\tif (node)\n\t\txfrm_pol_inexact_node_init(node, addr, prefixlen);\n\n\treturn node;\n}\n\nstatic int xfrm_policy_addr_delta(const xfrm_address_t *a,\n\t\t\t\t  const xfrm_address_t *b,\n\t\t\t\t  u8 prefixlen, u16 family)\n{\n\tu32 ma, mb, mask;\n\tunsigned int pdw, pbi;\n\tint delta = 0;\n\n\tswitch (family) {\n\tcase AF_INET:\n\t\tif (prefixlen == 0)\n\t\t\treturn 0;\n\t\tmask = ~0U << (32 - prefixlen);\n\t\tma = ntohl(a->a4) & mask;\n\t\tmb = ntohl(b->a4) & mask;\n\t\tif (ma < mb)\n\t\t\tdelta = -1;\n\t\telse if (ma > mb)\n\t\t\tdelta = 1;\n\t\tbreak;\n\tcase AF_INET6:\n\t\tpdw = prefixlen >> 5;\n\t\tpbi = prefixlen & 0x1f;\n\n\t\tif (pdw) {\n\t\t\tdelta = memcmp(a->a6, b->a6, pdw << 2);\n\t\t\tif (delta)\n\t\t\t\treturn delta;\n\t\t}\n\t\tif (pbi) {\n\t\t\tmask = ~0U << (32 - pbi);\n\t\t\tma = ntohl(a->a6[pdw]) & mask;\n\t\t\tmb = ntohl(b->a6[pdw]) & mask;\n\t\t\tif (ma < mb)\n\t\t\t\tdelta = -1;\n\t\t\telse if (ma > mb)\n\t\t\t\tdelta = 1;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn delta;\n}\n\nstatic void xfrm_policy_inexact_list_reinsert(struct net *net,\n\t\t\t\t\t      struct xfrm_pol_inexact_node *n,\n\t\t\t\t\t      u16 family)\n{\n\tunsigned int matched_s, matched_d;\n\tstruct xfrm_policy *policy, *p;\n\n\tmatched_s = 0;\n\tmatched_d = 0;\n\n\tlist_for_each_entry_reverse(policy, &net->xfrm.policy_all, walk.all) {\n\t\tstruct hlist_node *newpos = NULL;\n\t\tbool matches_s, matches_d;\n\n\t\tif (!policy->bydst_reinsert)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(policy->family != family);\n\n\t\tpolicy->bydst_reinsert = false;\n\t\thlist_for_each_entry(p, &n->hhead, bydst) {\n\t\t\tif (policy->priority > p->priority)\n\t\t\t\tnewpos = &p->bydst;\n\t\t\telse if (policy->priority == p->priority &&\n\t\t\t\t policy->pos > p->pos)\n\t\t\t\tnewpos = &p->bydst;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (newpos)\n\t\t\thlist_add_behind_rcu(&policy->bydst, newpos);\n\t\telse\n\t\t\thlist_add_head_rcu(&policy->bydst, &n->hhead);\n\n\t\t/* paranoia checks follow.\n\t\t * Check that the reinserted policy matches at least\n\t\t * saddr or daddr for current node prefix.\n\t\t *\n\t\t * Matching both is fine, matching saddr in one policy\n\t\t * (but not daddr) and then matching only daddr in another\n\t\t * is a bug.\n\t\t */\n\t\tmatches_s = xfrm_policy_addr_delta(&policy->selector.saddr,\n\t\t\t\t\t\t   &n->addr,\n\t\t\t\t\t\t   n->prefixlen,\n\t\t\t\t\t\t   family) == 0;\n\t\tmatches_d = xfrm_policy_addr_delta(&policy->selector.daddr,\n\t\t\t\t\t\t   &n->addr,\n\t\t\t\t\t\t   n->prefixlen,\n\t\t\t\t\t\t   family) == 0;\n\t\tif (matches_s && matches_d)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(!matches_s && !matches_d);\n\t\tif (matches_s)\n\t\t\tmatched_s++;\n\t\tif (matches_d)\n\t\t\tmatched_d++;\n\t\tWARN_ON_ONCE(matched_s && matched_d);\n\t}\n}\n\nstatic void xfrm_policy_inexact_node_reinsert(struct net *net,\n\t\t\t\t\t      struct xfrm_pol_inexact_node *n,\n\t\t\t\t\t      struct rb_root *new,\n\t\t\t\t\t      u16 family)\n{\n\tstruct xfrm_pol_inexact_node *node;\n\tstruct rb_node **p, *parent;\n\n\t/* we should not have another subtree here */\n\tWARN_ON_ONCE(!RB_EMPTY_ROOT(&n->root));\nrestart:\n\tparent = NULL;\n\tp = &new->rb_node;\n\twhile (*p) {\n\t\tu8 prefixlen;\n\t\tint delta;\n\n\t\tparent = *p;\n\t\tnode = rb_entry(*p, struct xfrm_pol_inexact_node, node);\n\n\t\tprefixlen = min(node->prefixlen, n->prefixlen);\n\n\t\tdelta = xfrm_policy_addr_delta(&n->addr, &node->addr,\n\t\t\t\t\t       prefixlen, family);\n\t\tif (delta < 0) {\n\t\t\tp = &parent->rb_left;\n\t\t} else if (delta > 0) {\n\t\t\tp = &parent->rb_right;\n\t\t} else {\n\t\t\tbool same_prefixlen = node->prefixlen == n->prefixlen;\n\t\t\tstruct xfrm_policy *tmp;\n\n\t\t\thlist_for_each_entry(tmp, &n->hhead, bydst) {\n\t\t\t\ttmp->bydst_reinsert = true;\n\t\t\t\thlist_del_rcu(&tmp->bydst);\n\t\t\t}\n\n\t\t\tnode->prefixlen = prefixlen;\n\n\t\t\txfrm_policy_inexact_list_reinsert(net, node, family);\n\n\t\t\tif (same_prefixlen) {\n\t\t\t\tkfree_rcu(n, rcu);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\trb_erase(*p, new);\n\t\t\tkfree_rcu(n, rcu);\n\t\t\tn = node;\n\t\t\tgoto restart;\n\t\t}\n\t}\n\n\trb_link_node_rcu(&n->node, parent, p);\n\trb_insert_color(&n->node, new);\n}\n\n/* merge nodes v and n */\nstatic void xfrm_policy_inexact_node_merge(struct net *net,\n\t\t\t\t\t   struct xfrm_pol_inexact_node *v,\n\t\t\t\t\t   struct xfrm_pol_inexact_node *n,\n\t\t\t\t\t   u16 family)\n{\n\tstruct xfrm_pol_inexact_node *node;\n\tstruct xfrm_policy *tmp;\n\tstruct rb_node *rnode;\n\n\t/* To-be-merged node v has a subtree.\n\t *\n\t * Dismantle it and insert its nodes to n->root.\n\t */\n\twhile ((rnode = rb_first(&v->root)) != NULL) {\n\t\tnode = rb_entry(rnode, struct xfrm_pol_inexact_node, node);\n\t\trb_erase(&node->node, &v->root);\n\t\txfrm_policy_inexact_node_reinsert(net, node, &n->root,\n\t\t\t\t\t\t  family);\n\t}\n\n\thlist_for_each_entry(tmp, &v->hhead, bydst) {\n\t\ttmp->bydst_reinsert = true;\n\t\thlist_del_rcu(&tmp->bydst);\n\t}\n\n\txfrm_policy_inexact_list_reinsert(net, n, family);\n}\n\nstatic struct xfrm_pol_inexact_node *\nxfrm_policy_inexact_insert_node(struct net *net,\n\t\t\t\tstruct rb_root *root,\n\t\t\t\txfrm_address_t *addr,\n\t\t\t\tu16 family, u8 prefixlen, u8 dir)\n{\n\tstruct xfrm_pol_inexact_node *cached = NULL;\n\tstruct rb_node **p, *parent = NULL;\n\tstruct xfrm_pol_inexact_node *node;\n\n\tp = &root->rb_node;\n\twhile (*p) {\n\t\tint delta;\n\n\t\tparent = *p;\n\t\tnode = rb_entry(*p, struct xfrm_pol_inexact_node, node);\n\n\t\tdelta = xfrm_policy_addr_delta(addr, &node->addr,\n\t\t\t\t\t       node->prefixlen,\n\t\t\t\t\t       family);\n\t\tif (delta == 0 && prefixlen >= node->prefixlen) {\n\t\t\tWARN_ON_ONCE(cached); /* ipsec policies got lost */\n\t\t\treturn node;\n\t\t}\n\n\t\tif (delta < 0)\n\t\t\tp = &parent->rb_left;\n\t\telse\n\t\t\tp = &parent->rb_right;\n\n\t\tif (prefixlen < node->prefixlen) {\n\t\t\tdelta = xfrm_policy_addr_delta(addr, &node->addr,\n\t\t\t\t\t\t       prefixlen,\n\t\t\t\t\t\t       family);\n\t\t\tif (delta)\n\t\t\t\tcontinue;\n\n\t\t\t/* This node is a subnet of the new prefix. It needs\n\t\t\t * to be removed and re-inserted with the smaller\n\t\t\t * prefix and all nodes that are now also covered\n\t\t\t * by the reduced prefixlen.\n\t\t\t */\n\t\t\trb_erase(&node->node, root);\n\n\t\t\tif (!cached) {\n\t\t\t\txfrm_pol_inexact_node_init(node, addr,\n\t\t\t\t\t\t\t   prefixlen);\n\t\t\t\tcached = node;\n\t\t\t} else {\n\t\t\t\t/* This node also falls within the new\n\t\t\t\t * prefixlen. Merge the to-be-reinserted\n\t\t\t\t * node and this one.\n\t\t\t\t */\n\t\t\t\txfrm_policy_inexact_node_merge(net, node,\n\t\t\t\t\t\t\t       cached, family);\n\t\t\t\tkfree_rcu(node, rcu);\n\t\t\t}\n\n\t\t\t/* restart */\n\t\t\tp = &root->rb_node;\n\t\t\tparent = NULL;\n\t\t}\n\t}\n\n\tnode = cached;\n\tif (!node) {\n\t\tnode = xfrm_pol_inexact_node_alloc(addr, prefixlen);\n\t\tif (!node)\n\t\t\treturn NULL;\n\t}\n\n\trb_link_node_rcu(&node->node, parent, p);\n\trb_insert_color(&node->node, root);\n\n\treturn node;\n}\n\nstatic void xfrm_policy_inexact_gc_tree(struct rb_root *r, bool rm)\n{\n\tstruct xfrm_pol_inexact_node *node;\n\tstruct rb_node *rn = rb_first(r);\n\n\twhile (rn) {\n\t\tnode = rb_entry(rn, struct xfrm_pol_inexact_node, node);\n\n\t\txfrm_policy_inexact_gc_tree(&node->root, rm);\n\t\trn = rb_next(rn);\n\n\t\tif (!hlist_empty(&node->hhead) || !RB_EMPTY_ROOT(&node->root)) {\n\t\t\tWARN_ON_ONCE(rm);\n\t\t\tcontinue;\n\t\t}\n\n\t\trb_erase(&node->node, r);\n\t\tkfree_rcu(node, rcu);\n\t}\n}\n\nstatic void __xfrm_policy_inexact_prune_bin(struct xfrm_pol_inexact_bin *b, bool net_exit)\n{\n\twrite_seqcount_begin(&b->count);\n\txfrm_policy_inexact_gc_tree(&b->root_d, net_exit);\n\txfrm_policy_inexact_gc_tree(&b->root_s, net_exit);\n\twrite_seqcount_end(&b->count);\n\n\tif (!RB_EMPTY_ROOT(&b->root_d) || !RB_EMPTY_ROOT(&b->root_s) ||\n\t    !hlist_empty(&b->hhead)) {\n\t\tWARN_ON_ONCE(net_exit);\n\t\treturn;\n\t}\n\n\tif (rhashtable_remove_fast(&xfrm_policy_inexact_table, &b->head,\n\t\t\t\t   xfrm_pol_inexact_params) == 0) {\n\t\tlist_del(&b->inexact_bins);\n\t\tkfree_rcu(b, rcu);\n\t}\n}\n\nstatic void xfrm_policy_inexact_prune_bin(struct xfrm_pol_inexact_bin *b)\n{\n\tstruct net *net = read_pnet(&b->k.net);\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t__xfrm_policy_inexact_prune_bin(b, false);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n}\n\nstatic void __xfrm_policy_inexact_flush(struct net *net)\n{\n\tstruct xfrm_pol_inexact_bin *bin, *t;\n\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\tlist_for_each_entry_safe(bin, t, &net->xfrm.inexact_bins, inexact_bins)\n\t\t__xfrm_policy_inexact_prune_bin(bin, false);\n}\n\nstatic struct hlist_head *\nxfrm_policy_inexact_alloc_chain(struct xfrm_pol_inexact_bin *bin,\n\t\t\t\tstruct xfrm_policy *policy, u8 dir)\n{\n\tstruct xfrm_pol_inexact_node *n;\n\tstruct net *net;\n\n\tnet = xp_net(policy);\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\tif (xfrm_policy_inexact_insert_use_any_list(policy))\n\t\treturn &bin->hhead;\n\n\tif (xfrm_pol_inexact_addr_use_any_list(&policy->selector.daddr,\n\t\t\t\t\t       policy->family,\n\t\t\t\t\t       policy->selector.prefixlen_d)) {\n\t\twrite_seqcount_begin(&bin->count);\n\t\tn = xfrm_policy_inexact_insert_node(net,\n\t\t\t\t\t\t    &bin->root_s,\n\t\t\t\t\t\t    &policy->selector.saddr,\n\t\t\t\t\t\t    policy->family,\n\t\t\t\t\t\t    policy->selector.prefixlen_s,\n\t\t\t\t\t\t    dir);\n\t\twrite_seqcount_end(&bin->count);\n\t\tif (!n)\n\t\t\treturn NULL;\n\n\t\treturn &n->hhead;\n\t}\n\n\t/* daddr is fixed */\n\twrite_seqcount_begin(&bin->count);\n\tn = xfrm_policy_inexact_insert_node(net,\n\t\t\t\t\t    &bin->root_d,\n\t\t\t\t\t    &policy->selector.daddr,\n\t\t\t\t\t    policy->family,\n\t\t\t\t\t    policy->selector.prefixlen_d, dir);\n\twrite_seqcount_end(&bin->count);\n\tif (!n)\n\t\treturn NULL;\n\n\t/* saddr is wildcard */\n\tif (xfrm_pol_inexact_addr_use_any_list(&policy->selector.saddr,\n\t\t\t\t\t       policy->family,\n\t\t\t\t\t       policy->selector.prefixlen_s))\n\t\treturn &n->hhead;\n\n\twrite_seqcount_begin(&bin->count);\n\tn = xfrm_policy_inexact_insert_node(net,\n\t\t\t\t\t    &n->root,\n\t\t\t\t\t    &policy->selector.saddr,\n\t\t\t\t\t    policy->family,\n\t\t\t\t\t    policy->selector.prefixlen_s, dir);\n\twrite_seqcount_end(&bin->count);\n\tif (!n)\n\t\treturn NULL;\n\n\treturn &n->hhead;\n}\n\nstatic struct xfrm_policy *\nxfrm_policy_inexact_insert(struct xfrm_policy *policy, u8 dir, int excl)\n{\n\tstruct xfrm_pol_inexact_bin *bin;\n\tstruct xfrm_policy *delpol;\n\tstruct hlist_head *chain;\n\tstruct net *net;\n\n\tbin = xfrm_policy_inexact_alloc_bin(policy, dir);\n\tif (!bin)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tnet = xp_net(policy);\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\tchain = xfrm_policy_inexact_alloc_chain(bin, policy, dir);\n\tif (!chain) {\n\t\t__xfrm_policy_inexact_prune_bin(bin, false);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tdelpol = xfrm_policy_insert_list(chain, policy, excl);\n\tif (delpol && excl) {\n\t\t__xfrm_policy_inexact_prune_bin(bin, false);\n\t\treturn ERR_PTR(-EEXIST);\n\t}\n\n\tchain = &net->xfrm.policy_inexact[dir];\n\txfrm_policy_insert_inexact_list(chain, policy);\n\n\tif (delpol)\n\t\t__xfrm_policy_inexact_prune_bin(bin, false);\n\n\treturn delpol;\n}\n\nstatic void xfrm_hash_rebuild(struct work_struct *work)\n{\n\tstruct net *net = container_of(work, struct net,\n\t\t\t\t       xfrm.policy_hthresh.work);\n\tunsigned int hmask;\n\tstruct xfrm_policy *pol;\n\tstruct xfrm_policy *policy;\n\tstruct hlist_head *chain;\n\tstruct hlist_head *odst;\n\tstruct hlist_node *newpos;\n\tint i;\n\tint dir;\n\tunsigned seq;\n\tu8 lbits4, rbits4, lbits6, rbits6;\n\n\tmutex_lock(&hash_resize_mutex);\n\n\t/* read selector prefixlen thresholds */\n\tdo {\n\t\tseq = read_seqbegin(&net->xfrm.policy_hthresh.lock);\n\n\t\tlbits4 = net->xfrm.policy_hthresh.lbits4;\n\t\trbits4 = net->xfrm.policy_hthresh.rbits4;\n\t\tlbits6 = net->xfrm.policy_hthresh.lbits6;\n\t\trbits6 = net->xfrm.policy_hthresh.rbits6;\n\t} while (read_seqretry(&net->xfrm.policy_hthresh.lock, seq));\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\twrite_seqcount_begin(&net->xfrm.xfrm_policy_hash_generation);\n\n\t/* make sure that we can insert the indirect policies again before\n\t * we start with destructive action.\n\t */\n\tlist_for_each_entry(policy, &net->xfrm.policy_all, walk.all) {\n\t\tstruct xfrm_pol_inexact_bin *bin;\n\t\tu8 dbits, sbits;\n\n\t\tdir = xfrm_policy_id2dir(policy->index);\n\t\tif (policy->walk.dead || dir >= XFRM_POLICY_MAX)\n\t\t\tcontinue;\n\n\t\tif ((dir & XFRM_POLICY_MASK) == XFRM_POLICY_OUT) {\n\t\t\tif (policy->family == AF_INET) {\n\t\t\t\tdbits = rbits4;\n\t\t\t\tsbits = lbits4;\n\t\t\t} else {\n\t\t\t\tdbits = rbits6;\n\t\t\t\tsbits = lbits6;\n\t\t\t}\n\t\t} else {\n\t\t\tif (policy->family == AF_INET) {\n\t\t\t\tdbits = lbits4;\n\t\t\t\tsbits = rbits4;\n\t\t\t} else {\n\t\t\t\tdbits = lbits6;\n\t\t\t\tsbits = rbits6;\n\t\t\t}\n\t\t}\n\n\t\tif (policy->selector.prefixlen_d < dbits ||\n\t\t    policy->selector.prefixlen_s < sbits)\n\t\t\tcontinue;\n\n\t\tbin = xfrm_policy_inexact_alloc_bin(policy, dir);\n\t\tif (!bin)\n\t\t\tgoto out_unlock;\n\n\t\tif (!xfrm_policy_inexact_alloc_chain(bin, policy, dir))\n\t\t\tgoto out_unlock;\n\t}\n\n\t/* reset the bydst and inexact table in all directions */\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tstruct hlist_node *n;\n\n\t\thlist_for_each_entry_safe(policy, n,\n\t\t\t\t\t  &net->xfrm.policy_inexact[dir],\n\t\t\t\t\t  bydst_inexact_list) {\n\t\t\thlist_del_rcu(&policy->bydst);\n\t\t\thlist_del_init(&policy->bydst_inexact_list);\n\t\t}\n\n\t\thmask = net->xfrm.policy_bydst[dir].hmask;\n\t\todst = net->xfrm.policy_bydst[dir].table;\n\t\tfor (i = hmask; i >= 0; i--) {\n\t\t\thlist_for_each_entry_safe(policy, n, odst + i, bydst)\n\t\t\t\thlist_del_rcu(&policy->bydst);\n\t\t}\n\t\tif ((dir & XFRM_POLICY_MASK) == XFRM_POLICY_OUT) {\n\t\t\t/* dir out => dst = remote, src = local */\n\t\t\tnet->xfrm.policy_bydst[dir].dbits4 = rbits4;\n\t\t\tnet->xfrm.policy_bydst[dir].sbits4 = lbits4;\n\t\t\tnet->xfrm.policy_bydst[dir].dbits6 = rbits6;\n\t\t\tnet->xfrm.policy_bydst[dir].sbits6 = lbits6;\n\t\t} else {\n\t\t\t/* dir in/fwd => dst = local, src = remote */\n\t\t\tnet->xfrm.policy_bydst[dir].dbits4 = lbits4;\n\t\t\tnet->xfrm.policy_bydst[dir].sbits4 = rbits4;\n\t\t\tnet->xfrm.policy_bydst[dir].dbits6 = lbits6;\n\t\t\tnet->xfrm.policy_bydst[dir].sbits6 = rbits6;\n\t\t}\n\t}\n\n\t/* re-insert all policies by order of creation */\n\tlist_for_each_entry_reverse(policy, &net->xfrm.policy_all, walk.all) {\n\t\tif (policy->walk.dead)\n\t\t\tcontinue;\n\t\tdir = xfrm_policy_id2dir(policy->index);\n\t\tif (dir >= XFRM_POLICY_MAX) {\n\t\t\t/* skip socket policies */\n\t\t\tcontinue;\n\t\t}\n\t\tnewpos = NULL;\n\t\tchain = policy_hash_bysel(net, &policy->selector,\n\t\t\t\t\t  policy->family, dir);\n\n\t\tif (!chain) {\n\t\t\tvoid *p = xfrm_policy_inexact_insert(policy, dir, 0);\n\n\t\t\tWARN_ONCE(IS_ERR(p), \"reinsert: %ld\\n\", PTR_ERR(p));\n\t\t\tcontinue;\n\t\t}\n\n\t\thlist_for_each_entry(pol, chain, bydst) {\n\t\t\tif (policy->priority >= pol->priority)\n\t\t\t\tnewpos = &pol->bydst;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\t\tif (newpos)\n\t\t\thlist_add_behind_rcu(&policy->bydst, newpos);\n\t\telse\n\t\t\thlist_add_head_rcu(&policy->bydst, chain);\n\t}\n\nout_unlock:\n\t__xfrm_policy_inexact_flush(net);\n\twrite_seqcount_end(&net->xfrm.xfrm_policy_hash_generation);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tmutex_unlock(&hash_resize_mutex);\n}\n\nvoid xfrm_policy_hash_rebuild(struct net *net)\n{\n\tschedule_work(&net->xfrm.policy_hthresh.work);\n}\nEXPORT_SYMBOL(xfrm_policy_hash_rebuild);\n\n/* Generate new index... KAME seems to generate them ordered by cost\n * of an absolute inpredictability of ordering of rules. This will not pass. */\nstatic u32 xfrm_gen_index(struct net *net, int dir, u32 index)\n{\n\tstatic u32 idx_generator;\n\n\tfor (;;) {\n\t\tstruct hlist_head *list;\n\t\tstruct xfrm_policy *p;\n\t\tu32 idx;\n\t\tint found;\n\n\t\tif (!index) {\n\t\t\tidx = (idx_generator | dir);\n\t\t\tidx_generator += 8;\n\t\t} else {\n\t\t\tidx = index;\n\t\t\tindex = 0;\n\t\t}\n\n\t\tif (idx == 0)\n\t\t\tidx = 8;\n\t\tlist = net->xfrm.policy_byidx + idx_hash(net, idx);\n\t\tfound = 0;\n\t\thlist_for_each_entry(p, list, byidx) {\n\t\t\tif (p->index == idx) {\n\t\t\t\tfound = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!found)\n\t\t\treturn idx;\n\t}\n}\n\nstatic inline int selector_cmp(struct xfrm_selector *s1, struct xfrm_selector *s2)\n{\n\tu32 *p1 = (u32 *) s1;\n\tu32 *p2 = (u32 *) s2;\n\tint len = sizeof(struct xfrm_selector) / sizeof(u32);\n\tint i;\n\n\tfor (i = 0; i < len; i++) {\n\t\tif (p1[i] != p2[i])\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic void xfrm_policy_requeue(struct xfrm_policy *old,\n\t\t\t\tstruct xfrm_policy *new)\n{\n\tstruct xfrm_policy_queue *pq = &old->polq;\n\tstruct sk_buff_head list;\n\n\tif (skb_queue_empty(&pq->hold_queue))\n\t\treturn;\n\n\t__skb_queue_head_init(&list);\n\n\tspin_lock_bh(&pq->hold_queue.lock);\n\tskb_queue_splice_init(&pq->hold_queue, &list);\n\tif (del_timer(&pq->hold_timer))\n\t\txfrm_pol_put(old);\n\tspin_unlock_bh(&pq->hold_queue.lock);\n\n\tpq = &new->polq;\n\n\tspin_lock_bh(&pq->hold_queue.lock);\n\tskb_queue_splice(&list, &pq->hold_queue);\n\tpq->timeout = XFRM_QUEUE_TMO_MIN;\n\tif (!mod_timer(&pq->hold_timer, jiffies))\n\t\txfrm_pol_hold(new);\n\tspin_unlock_bh(&pq->hold_queue.lock);\n}\n\nstatic inline bool xfrm_policy_mark_match(const struct xfrm_mark *mark,\n\t\t\t\t\t  struct xfrm_policy *pol)\n{\n\treturn mark->v == pol->mark.v && mark->m == pol->mark.m;\n}\n\nstatic u32 xfrm_pol_bin_key(const void *data, u32 len, u32 seed)\n{\n\tconst struct xfrm_pol_inexact_key *k = data;\n\tu32 a = k->type << 24 | k->dir << 16 | k->family;\n\n\treturn jhash_3words(a, k->if_id, net_hash_mix(read_pnet(&k->net)),\n\t\t\t    seed);\n}\n\nstatic u32 xfrm_pol_bin_obj(const void *data, u32 len, u32 seed)\n{\n\tconst struct xfrm_pol_inexact_bin *b = data;\n\n\treturn xfrm_pol_bin_key(&b->k, 0, seed);\n}\n\nstatic int xfrm_pol_bin_cmp(struct rhashtable_compare_arg *arg,\n\t\t\t    const void *ptr)\n{\n\tconst struct xfrm_pol_inexact_key *key = arg->key;\n\tconst struct xfrm_pol_inexact_bin *b = ptr;\n\tint ret;\n\n\tif (!net_eq(read_pnet(&b->k.net), read_pnet(&key->net)))\n\t\treturn -1;\n\n\tret = b->k.dir ^ key->dir;\n\tif (ret)\n\t\treturn ret;\n\n\tret = b->k.type ^ key->type;\n\tif (ret)\n\t\treturn ret;\n\n\tret = b->k.family ^ key->family;\n\tif (ret)\n\t\treturn ret;\n\n\treturn b->k.if_id ^ key->if_id;\n}\n\nstatic const struct rhashtable_params xfrm_pol_inexact_params = {\n\t.head_offset\t\t= offsetof(struct xfrm_pol_inexact_bin, head),\n\t.hashfn\t\t\t= xfrm_pol_bin_key,\n\t.obj_hashfn\t\t= xfrm_pol_bin_obj,\n\t.obj_cmpfn\t\t= xfrm_pol_bin_cmp,\n\t.automatic_shrinking\t= true,\n};\n\nstatic void xfrm_policy_insert_inexact_list(struct hlist_head *chain,\n\t\t\t\t\t    struct xfrm_policy *policy)\n{\n\tstruct xfrm_policy *pol, *delpol = NULL;\n\tstruct hlist_node *newpos = NULL;\n\tint i = 0;\n\n\thlist_for_each_entry(pol, chain, bydst_inexact_list) {\n\t\tif (pol->type == policy->type &&\n\t\t    pol->if_id == policy->if_id &&\n\t\t    !selector_cmp(&pol->selector, &policy->selector) &&\n\t\t    xfrm_policy_mark_match(&policy->mark, pol) &&\n\t\t    xfrm_sec_ctx_match(pol->security, policy->security) &&\n\t\t    !WARN_ON(delpol)) {\n\t\t\tdelpol = pol;\n\t\t\tif (policy->priority > pol->priority)\n\t\t\t\tcontinue;\n\t\t} else if (policy->priority >= pol->priority) {\n\t\t\tnewpos = &pol->bydst_inexact_list;\n\t\t\tcontinue;\n\t\t}\n\t\tif (delpol)\n\t\t\tbreak;\n\t}\n\n\tif (newpos)\n\t\thlist_add_behind_rcu(&policy->bydst_inexact_list, newpos);\n\telse\n\t\thlist_add_head_rcu(&policy->bydst_inexact_list, chain);\n\n\thlist_for_each_entry(pol, chain, bydst_inexact_list) {\n\t\tpol->pos = i;\n\t\ti++;\n\t}\n}\n\nstatic struct xfrm_policy *xfrm_policy_insert_list(struct hlist_head *chain,\n\t\t\t\t\t\t   struct xfrm_policy *policy,\n\t\t\t\t\t\t   bool excl)\n{\n\tstruct xfrm_policy *pol, *newpos = NULL, *delpol = NULL;\n\n\thlist_for_each_entry(pol, chain, bydst) {\n\t\tif (pol->type == policy->type &&\n\t\t    pol->if_id == policy->if_id &&\n\t\t    !selector_cmp(&pol->selector, &policy->selector) &&\n\t\t    xfrm_policy_mark_match(&policy->mark, pol) &&\n\t\t    xfrm_sec_ctx_match(pol->security, policy->security) &&\n\t\t    !WARN_ON(delpol)) {\n\t\t\tif (excl)\n\t\t\t\treturn ERR_PTR(-EEXIST);\n\t\t\tdelpol = pol;\n\t\t\tif (policy->priority > pol->priority)\n\t\t\t\tcontinue;\n\t\t} else if (policy->priority >= pol->priority) {\n\t\t\tnewpos = pol;\n\t\t\tcontinue;\n\t\t}\n\t\tif (delpol)\n\t\t\tbreak;\n\t}\n\n\tif (newpos)\n\t\thlist_add_behind_rcu(&policy->bydst, &newpos->bydst);\n\telse\n\t\thlist_add_head_rcu(&policy->bydst, chain);\n\n\treturn delpol;\n}\n\nint xfrm_policy_insert(int dir, struct xfrm_policy *policy, int excl)\n{\n\tstruct net *net = xp_net(policy);\n\tstruct xfrm_policy *delpol;\n\tstruct hlist_head *chain;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = policy_hash_bysel(net, &policy->selector, policy->family, dir);\n\tif (chain)\n\t\tdelpol = xfrm_policy_insert_list(chain, policy, excl);\n\telse\n\t\tdelpol = xfrm_policy_inexact_insert(policy, dir, excl);\n\n\tif (IS_ERR(delpol)) {\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\treturn PTR_ERR(delpol);\n\t}\n\n\t__xfrm_policy_link(policy, dir);\n\n\t/* After previous checking, family can either be AF_INET or AF_INET6 */\n\tif (policy->family == AF_INET)\n\t\trt_genid_bump_ipv4(net);\n\telse\n\t\trt_genid_bump_ipv6(net);\n\n\tif (delpol) {\n\t\txfrm_policy_requeue(delpol, policy);\n\t\t__xfrm_policy_unlink(delpol, dir);\n\t}\n\tpolicy->index = delpol ? delpol->index : xfrm_gen_index(net, dir, policy->index);\n\thlist_add_head(&policy->byidx, net->xfrm.policy_byidx+idx_hash(net, policy->index));\n\tpolicy->curlft.add_time = ktime_get_real_seconds();\n\tpolicy->curlft.use_time = 0;\n\tif (!mod_timer(&policy->timer, jiffies + HZ))\n\t\txfrm_pol_hold(policy);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (delpol)\n\t\txfrm_policy_kill(delpol);\n\telse if (xfrm_bydst_should_resize(net, dir, NULL))\n\t\tschedule_work(&net->xfrm.policy_hash_work);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(xfrm_policy_insert);\n\nstatic struct xfrm_policy *\n__xfrm_policy_bysel_ctx(struct hlist_head *chain, const struct xfrm_mark *mark,\n\t\t\tu32 if_id, u8 type, int dir, struct xfrm_selector *sel,\n\t\t\tstruct xfrm_sec_ctx *ctx)\n{\n\tstruct xfrm_policy *pol;\n\n\tif (!chain)\n\t\treturn NULL;\n\n\thlist_for_each_entry(pol, chain, bydst) {\n\t\tif (pol->type == type &&\n\t\t    pol->if_id == if_id &&\n\t\t    xfrm_policy_mark_match(mark, pol) &&\n\t\t    !selector_cmp(sel, &pol->selector) &&\n\t\t    xfrm_sec_ctx_match(ctx, pol->security))\n\t\t\treturn pol;\n\t}\n\n\treturn NULL;\n}\n\nstruct xfrm_policy *\nxfrm_policy_bysel_ctx(struct net *net, const struct xfrm_mark *mark, u32 if_id,\n\t\t      u8 type, int dir, struct xfrm_selector *sel,\n\t\t      struct xfrm_sec_ctx *ctx, int delete, int *err)\n{\n\tstruct xfrm_pol_inexact_bin *bin = NULL;\n\tstruct xfrm_policy *pol, *ret = NULL;\n\tstruct hlist_head *chain;\n\n\t*err = 0;\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = policy_hash_bysel(net, sel, sel->family, dir);\n\tif (!chain) {\n\t\tstruct xfrm_pol_inexact_candidates cand;\n\t\tint i;\n\n\t\tbin = xfrm_policy_inexact_lookup(net, type,\n\t\t\t\t\t\t sel->family, dir, if_id);\n\t\tif (!bin) {\n\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (!xfrm_policy_find_inexact_candidates(&cand, bin,\n\t\t\t\t\t\t\t &sel->saddr,\n\t\t\t\t\t\t\t &sel->daddr)) {\n\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tpol = NULL;\n\t\tfor (i = 0; i < ARRAY_SIZE(cand.res); i++) {\n\t\t\tstruct xfrm_policy *tmp;\n\n\t\t\ttmp = __xfrm_policy_bysel_ctx(cand.res[i], mark,\n\t\t\t\t\t\t      if_id, type, dir,\n\t\t\t\t\t\t      sel, ctx);\n\t\t\tif (!tmp)\n\t\t\t\tcontinue;\n\n\t\t\tif (!pol || tmp->pos < pol->pos)\n\t\t\t\tpol = tmp;\n\t\t}\n\t} else {\n\t\tpol = __xfrm_policy_bysel_ctx(chain, mark, if_id, type, dir,\n\t\t\t\t\t      sel, ctx);\n\t}\n\n\tif (pol) {\n\t\txfrm_pol_hold(pol);\n\t\tif (delete) {\n\t\t\t*err = security_xfrm_policy_delete(pol->security);\n\t\t\tif (*err) {\n\t\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\t\treturn pol;\n\t\t\t}\n\t\t\t__xfrm_policy_unlink(pol, dir);\n\t\t}\n\t\tret = pol;\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (ret && delete)\n\t\txfrm_policy_kill(ret);\n\tif (bin && delete)\n\t\txfrm_policy_inexact_prune_bin(bin);\n\treturn ret;\n}\nEXPORT_SYMBOL(xfrm_policy_bysel_ctx);\n\nstruct xfrm_policy *\nxfrm_policy_byid(struct net *net, const struct xfrm_mark *mark, u32 if_id,\n\t\t u8 type, int dir, u32 id, int delete, int *err)\n{\n\tstruct xfrm_policy *pol, *ret;\n\tstruct hlist_head *chain;\n\n\t*err = -ENOENT;\n\tif (xfrm_policy_id2dir(id) != dir)\n\t\treturn NULL;\n\n\t*err = 0;\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = net->xfrm.policy_byidx + idx_hash(net, id);\n\tret = NULL;\n\thlist_for_each_entry(pol, chain, byidx) {\n\t\tif (pol->type == type && pol->index == id &&\n\t\t    pol->if_id == if_id && xfrm_policy_mark_match(mark, pol)) {\n\t\t\txfrm_pol_hold(pol);\n\t\t\tif (delete) {\n\t\t\t\t*err = security_xfrm_policy_delete(\n\t\t\t\t\t\t\t\tpol->security);\n\t\t\t\tif (*err) {\n\t\t\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\t\t\treturn pol;\n\t\t\t\t}\n\t\t\t\t__xfrm_policy_unlink(pol, dir);\n\t\t\t}\n\t\t\tret = pol;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (ret && delete)\n\t\txfrm_policy_kill(ret);\n\treturn ret;\n}\nEXPORT_SYMBOL(xfrm_policy_byid);\n\n#ifdef CONFIG_SECURITY_NETWORK_XFRM\nstatic inline int\nxfrm_policy_flush_secctx_check(struct net *net, u8 type, bool task_valid)\n{\n\tstruct xfrm_policy *pol;\n\tint err = 0;\n\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tif (pol->walk.dead ||\n\t\t    xfrm_policy_id2dir(pol->index) >= XFRM_POLICY_MAX ||\n\t\t    pol->type != type)\n\t\t\tcontinue;\n\n\t\terr = security_xfrm_policy_delete(pol->security);\n\t\tif (err) {\n\t\t\txfrm_audit_policy_delete(pol, 0, task_valid);\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn err;\n}\n#else\nstatic inline int\nxfrm_policy_flush_secctx_check(struct net *net, u8 type, bool task_valid)\n{\n\treturn 0;\n}\n#endif\n\nint xfrm_policy_flush(struct net *net, u8 type, bool task_valid)\n{\n\tint dir, err = 0, cnt = 0;\n\tstruct xfrm_policy *pol;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\n\terr = xfrm_policy_flush_secctx_check(net, type, task_valid);\n\tif (err)\n\t\tgoto out;\n\nagain:\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tdir = xfrm_policy_id2dir(pol->index);\n\t\tif (pol->walk.dead ||\n\t\t    dir >= XFRM_POLICY_MAX ||\n\t\t    pol->type != type)\n\t\t\tcontinue;\n\n\t\t__xfrm_policy_unlink(pol, dir);\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tcnt++;\n\t\txfrm_audit_policy_delete(pol, 1, task_valid);\n\t\txfrm_policy_kill(pol);\n\t\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tgoto again;\n\t}\n\tif (cnt)\n\t\t__xfrm_policy_inexact_flush(net);\n\telse\n\t\terr = -ESRCH;\nout:\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_policy_flush);\n\nint xfrm_policy_walk(struct net *net, struct xfrm_policy_walk *walk,\n\t\t     int (*func)(struct xfrm_policy *, int, int, void*),\n\t\t     void *data)\n{\n\tstruct xfrm_policy *pol;\n\tstruct xfrm_policy_walk_entry *x;\n\tint error = 0;\n\n\tif (walk->type >= XFRM_POLICY_TYPE_MAX &&\n\t    walk->type != XFRM_POLICY_TYPE_ANY)\n\t\treturn -EINVAL;\n\n\tif (list_empty(&walk->walk.all) && walk->seq != 0)\n\t\treturn 0;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tif (list_empty(&walk->walk.all))\n\t\tx = list_first_entry(&net->xfrm.policy_all, struct xfrm_policy_walk_entry, all);\n\telse\n\t\tx = list_first_entry(&walk->walk.all,\n\t\t\t\t     struct xfrm_policy_walk_entry, all);\n\n\tlist_for_each_entry_from(x, &net->xfrm.policy_all, all) {\n\t\tif (x->dead)\n\t\t\tcontinue;\n\t\tpol = container_of(x, struct xfrm_policy, walk);\n\t\tif (walk->type != XFRM_POLICY_TYPE_ANY &&\n\t\t    walk->type != pol->type)\n\t\t\tcontinue;\n\t\terror = func(pol, xfrm_policy_id2dir(pol->index),\n\t\t\t     walk->seq, data);\n\t\tif (error) {\n\t\t\tlist_move_tail(&walk->walk.all, &x->all);\n\t\t\tgoto out;\n\t\t}\n\t\twalk->seq++;\n\t}\n\tif (walk->seq == 0) {\n\t\terror = -ENOENT;\n\t\tgoto out;\n\t}\n\tlist_del_init(&walk->walk.all);\nout:\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\treturn error;\n}\nEXPORT_SYMBOL(xfrm_policy_walk);\n\nvoid xfrm_policy_walk_init(struct xfrm_policy_walk *walk, u8 type)\n{\n\tINIT_LIST_HEAD(&walk->walk.all);\n\twalk->walk.dead = 1;\n\twalk->type = type;\n\twalk->seq = 0;\n}\nEXPORT_SYMBOL(xfrm_policy_walk_init);\n\nvoid xfrm_policy_walk_done(struct xfrm_policy_walk *walk, struct net *net)\n{\n\tif (list_empty(&walk->walk.all))\n\t\treturn;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock); /*FIXME where is net? */\n\tlist_del(&walk->walk.all);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n}\nEXPORT_SYMBOL(xfrm_policy_walk_done);\n\n/*\n * Find policy to apply to this flow.\n *\n * Returns 0 if policy found, else an -errno.\n */\nstatic int xfrm_policy_match(const struct xfrm_policy *pol,\n\t\t\t     const struct flowi *fl,\n\t\t\t     u8 type, u16 family, int dir, u32 if_id)\n{\n\tconst struct xfrm_selector *sel = &pol->selector;\n\tint ret = -ESRCH;\n\tbool match;\n\n\tif (pol->family != family ||\n\t    pol->if_id != if_id ||\n\t    (fl->flowi_mark & pol->mark.m) != pol->mark.v ||\n\t    pol->type != type)\n\t\treturn ret;\n\n\tmatch = xfrm_selector_match(sel, fl, family);\n\tif (match)\n\t\tret = security_xfrm_policy_lookup(pol->security, fl->flowi_secid);\n\treturn ret;\n}\n\nstatic struct xfrm_pol_inexact_node *\nxfrm_policy_lookup_inexact_addr(const struct rb_root *r,\n\t\t\t\tseqcount_spinlock_t *count,\n\t\t\t\tconst xfrm_address_t *addr, u16 family)\n{\n\tconst struct rb_node *parent;\n\tint seq;\n\nagain:\n\tseq = read_seqcount_begin(count);\n\n\tparent = rcu_dereference_raw(r->rb_node);\n\twhile (parent) {\n\t\tstruct xfrm_pol_inexact_node *node;\n\t\tint delta;\n\n\t\tnode = rb_entry(parent, struct xfrm_pol_inexact_node, node);\n\n\t\tdelta = xfrm_policy_addr_delta(addr, &node->addr,\n\t\t\t\t\t       node->prefixlen, family);\n\t\tif (delta < 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_left);\n\t\t\tcontinue;\n\t\t} else if (delta > 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_right);\n\t\t\tcontinue;\n\t\t}\n\n\t\treturn node;\n\t}\n\n\tif (read_seqcount_retry(count, seq))\n\t\tgoto again;\n\n\treturn NULL;\n}\n\nstatic bool\nxfrm_policy_find_inexact_candidates(struct xfrm_pol_inexact_candidates *cand,\n\t\t\t\t    struct xfrm_pol_inexact_bin *b,\n\t\t\t\t    const xfrm_address_t *saddr,\n\t\t\t\t    const xfrm_address_t *daddr)\n{\n\tstruct xfrm_pol_inexact_node *n;\n\tu16 family;\n\n\tif (!b)\n\t\treturn false;\n\n\tfamily = b->k.family;\n\tmemset(cand, 0, sizeof(*cand));\n\tcand->res[XFRM_POL_CAND_ANY] = &b->hhead;\n\n\tn = xfrm_policy_lookup_inexact_addr(&b->root_d, &b->count, daddr,\n\t\t\t\t\t    family);\n\tif (n) {\n\t\tcand->res[XFRM_POL_CAND_DADDR] = &n->hhead;\n\t\tn = xfrm_policy_lookup_inexact_addr(&n->root, &b->count, saddr,\n\t\t\t\t\t\t    family);\n\t\tif (n)\n\t\t\tcand->res[XFRM_POL_CAND_BOTH] = &n->hhead;\n\t}\n\n\tn = xfrm_policy_lookup_inexact_addr(&b->root_s, &b->count, saddr,\n\t\t\t\t\t    family);\n\tif (n)\n\t\tcand->res[XFRM_POL_CAND_SADDR] = &n->hhead;\n\n\treturn true;\n}\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup_rcu(struct net *net, u8 type, u16 family,\n\t\t\t       u8 dir, u32 if_id)\n{\n\tstruct xfrm_pol_inexact_key k = {\n\t\t.family = family,\n\t\t.type = type,\n\t\t.dir = dir,\n\t\t.if_id = if_id,\n\t};\n\n\twrite_pnet(&k.net, net);\n\n\treturn rhashtable_lookup(&xfrm_policy_inexact_table, &k,\n\t\t\t\t xfrm_pol_inexact_params);\n}\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup(struct net *net, u8 type, u16 family,\n\t\t\t   u8 dir, u32 if_id)\n{\n\tstruct xfrm_pol_inexact_bin *bin;\n\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\trcu_read_lock();\n\tbin = xfrm_policy_inexact_lookup_rcu(net, type, family, dir, if_id);\n\trcu_read_unlock();\n\n\treturn bin;\n}\n\nstatic struct xfrm_policy *\n__xfrm_policy_eval_candidates(struct hlist_head *chain,\n\t\t\t      struct xfrm_policy *prefer,\n\t\t\t      const struct flowi *fl,\n\t\t\t      u8 type, u16 family, int dir, u32 if_id)\n{\n\tu32 priority = prefer ? prefer->priority : ~0u;\n\tstruct xfrm_policy *pol;\n\n\tif (!chain)\n\t\treturn NULL;\n\n\thlist_for_each_entry_rcu(pol, chain, bydst) {\n\t\tint err;\n\n\t\tif (pol->priority > priority)\n\t\t\tbreak;\n\n\t\terr = xfrm_policy_match(pol, fl, type, family, dir, if_id);\n\t\tif (err) {\n\t\t\tif (err != -ESRCH)\n\t\t\t\treturn ERR_PTR(err);\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (prefer) {\n\t\t\t/* matches.  Is it older than *prefer? */\n\t\t\tif (pol->priority == priority &&\n\t\t\t    prefer->pos < pol->pos)\n\t\t\t\treturn prefer;\n\t\t}\n\n\t\treturn pol;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct xfrm_policy *\nxfrm_policy_eval_candidates(struct xfrm_pol_inexact_candidates *cand,\n\t\t\t    struct xfrm_policy *prefer,\n\t\t\t    const struct flowi *fl,\n\t\t\t    u8 type, u16 family, int dir, u32 if_id)\n{\n\tstruct xfrm_policy *tmp;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(cand->res); i++) {\n\t\ttmp = __xfrm_policy_eval_candidates(cand->res[i],\n\t\t\t\t\t\t    prefer,\n\t\t\t\t\t\t    fl, type, family, dir,\n\t\t\t\t\t\t    if_id);\n\t\tif (!tmp)\n\t\t\tcontinue;\n\n\t\tif (IS_ERR(tmp))\n\t\t\treturn tmp;\n\t\tprefer = tmp;\n\t}\n\n\treturn prefer;\n}\n\nstatic struct xfrm_policy *xfrm_policy_lookup_bytype(struct net *net, u8 type,\n\t\t\t\t\t\t     const struct flowi *fl,\n\t\t\t\t\t\t     u16 family, u8 dir,\n\t\t\t\t\t\t     u32 if_id)\n{\n\tstruct xfrm_pol_inexact_candidates cand;\n\tconst xfrm_address_t *daddr, *saddr;\n\tstruct xfrm_pol_inexact_bin *bin;\n\tstruct xfrm_policy *pol, *ret;\n\tstruct hlist_head *chain;\n\tunsigned int sequence;\n\tint err;\n\n\tdaddr = xfrm_flowi_daddr(fl, family);\n\tsaddr = xfrm_flowi_saddr(fl, family);\n\tif (unlikely(!daddr || !saddr))\n\t\treturn NULL;\n\n\trcu_read_lock();\n retry:\n\tdo {\n\t\tsequence = read_seqcount_begin(&net->xfrm.xfrm_policy_hash_generation);\n\t\tchain = policy_hash_direct(net, daddr, saddr, family, dir);\n\t} while (read_seqcount_retry(&net->xfrm.xfrm_policy_hash_generation, sequence));\n\n\tret = NULL;\n\thlist_for_each_entry_rcu(pol, chain, bydst) {\n\t\terr = xfrm_policy_match(pol, fl, type, family, dir, if_id);\n\t\tif (err) {\n\t\t\tif (err == -ESRCH)\n\t\t\t\tcontinue;\n\t\t\telse {\n\t\t\t\tret = ERR_PTR(err);\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t} else {\n\t\t\tret = pol;\n\t\t\tbreak;\n\t\t}\n\t}\n\tbin = xfrm_policy_inexact_lookup_rcu(net, type, family, dir, if_id);\n\tif (!bin || !xfrm_policy_find_inexact_candidates(&cand, bin, saddr,\n\t\t\t\t\t\t\t daddr))\n\t\tgoto skip_inexact;\n\n\tpol = xfrm_policy_eval_candidates(&cand, ret, fl, type,\n\t\t\t\t\t  family, dir, if_id);\n\tif (pol) {\n\t\tret = pol;\n\t\tif (IS_ERR(pol))\n\t\t\tgoto fail;\n\t}\n\nskip_inexact:\n\tif (read_seqcount_retry(&net->xfrm.xfrm_policy_hash_generation, sequence))\n\t\tgoto retry;\n\n\tif (ret && !xfrm_pol_hold_rcu(ret))\n\t\tgoto retry;\nfail:\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\nstatic struct xfrm_policy *xfrm_policy_lookup(struct net *net,\n\t\t\t\t\t      const struct flowi *fl,\n\t\t\t\t\t      u16 family, u8 dir, u32 if_id)\n{\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tstruct xfrm_policy *pol;\n\n\tpol = xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_SUB, fl, family,\n\t\t\t\t\tdir, if_id);\n\tif (pol != NULL)\n\t\treturn pol;\n#endif\n\treturn xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_MAIN, fl, family,\n\t\t\t\t\t dir, if_id);\n}\n\nstatic struct xfrm_policy *xfrm_sk_policy_lookup(const struct sock *sk, int dir,\n\t\t\t\t\t\t const struct flowi *fl,\n\t\t\t\t\t\t u16 family, u32 if_id)\n{\n\tstruct xfrm_policy *pol;\n\n\trcu_read_lock();\n again:\n\tpol = rcu_dereference(sk->sk_policy[dir]);\n\tif (pol != NULL) {\n\t\tbool match;\n\t\tint err = 0;\n\n\t\tif (pol->family != family) {\n\t\t\tpol = NULL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tmatch = xfrm_selector_match(&pol->selector, fl, family);\n\t\tif (match) {\n\t\t\tif ((sk->sk_mark & pol->mark.m) != pol->mark.v ||\n\t\t\t    pol->if_id != if_id) {\n\t\t\t\tpol = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\terr = security_xfrm_policy_lookup(pol->security,\n\t\t\t\t\t\t      fl->flowi_secid);\n\t\t\tif (!err) {\n\t\t\t\tif (!xfrm_pol_hold_rcu(pol))\n\t\t\t\t\tgoto again;\n\t\t\t} else if (err == -ESRCH) {\n\t\t\t\tpol = NULL;\n\t\t\t} else {\n\t\t\t\tpol = ERR_PTR(err);\n\t\t\t}\n\t\t} else\n\t\t\tpol = NULL;\n\t}\nout:\n\trcu_read_unlock();\n\treturn pol;\n}\n\nstatic void __xfrm_policy_link(struct xfrm_policy *pol, int dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tlist_add(&pol->walk.all, &net->xfrm.policy_all);\n\tnet->xfrm.policy_count[dir]++;\n\txfrm_pol_hold(pol);\n}\n\nstatic struct xfrm_policy *__xfrm_policy_unlink(struct xfrm_policy *pol,\n\t\t\t\t\t\tint dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tif (list_empty(&pol->walk.all))\n\t\treturn NULL;\n\n\t/* Socket policies are not hashed. */\n\tif (!hlist_unhashed(&pol->bydst)) {\n\t\thlist_del_rcu(&pol->bydst);\n\t\thlist_del_init(&pol->bydst_inexact_list);\n\t\thlist_del(&pol->byidx);\n\t}\n\n\tlist_del_init(&pol->walk.all);\n\tnet->xfrm.policy_count[dir]--;\n\n\treturn pol;\n}\n\nstatic void xfrm_sk_policy_link(struct xfrm_policy *pol, int dir)\n{\n\t__xfrm_policy_link(pol, XFRM_POLICY_MAX + dir);\n}\n\nstatic void xfrm_sk_policy_unlink(struct xfrm_policy *pol, int dir)\n{\n\t__xfrm_policy_unlink(pol, XFRM_POLICY_MAX + dir);\n}\n\nint xfrm_policy_delete(struct xfrm_policy *pol, int dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tpol = __xfrm_policy_unlink(pol, dir);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\tif (pol) {\n\t\txfrm_policy_kill(pol);\n\t\treturn 0;\n\t}\n\treturn -ENOENT;\n}\nEXPORT_SYMBOL(xfrm_policy_delete);\n\nint xfrm_sk_policy_insert(struct sock *sk, int dir, struct xfrm_policy *pol)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct xfrm_policy *old_pol;\n\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pol && pol->type != XFRM_POLICY_TYPE_MAIN)\n\t\treturn -EINVAL;\n#endif\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\told_pol = rcu_dereference_protected(sk->sk_policy[dir],\n\t\t\t\tlockdep_is_held(&net->xfrm.xfrm_policy_lock));\n\tif (pol) {\n\t\tpol->curlft.add_time = ktime_get_real_seconds();\n\t\tpol->index = xfrm_gen_index(net, XFRM_POLICY_MAX+dir, 0);\n\t\txfrm_sk_policy_link(pol, dir);\n\t}\n\trcu_assign_pointer(sk->sk_policy[dir], pol);\n\tif (old_pol) {\n\t\tif (pol)\n\t\t\txfrm_policy_requeue(old_pol, pol);\n\n\t\t/* Unlinking succeeds always. This is the only function\n\t\t * allowed to delete or replace socket policy.\n\t\t */\n\t\txfrm_sk_policy_unlink(old_pol, dir);\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (old_pol) {\n\t\txfrm_policy_kill(old_pol);\n\t}\n\treturn 0;\n}\n\nstatic struct xfrm_policy *clone_policy(const struct xfrm_policy *old, int dir)\n{\n\tstruct xfrm_policy *newp = xfrm_policy_alloc(xp_net(old), GFP_ATOMIC);\n\tstruct net *net = xp_net(old);\n\n\tif (newp) {\n\t\tnewp->selector = old->selector;\n\t\tif (security_xfrm_policy_clone(old->security,\n\t\t\t\t\t       &newp->security)) {\n\t\t\tkfree(newp);\n\t\t\treturn NULL;  /* ENOMEM */\n\t\t}\n\t\tnewp->lft = old->lft;\n\t\tnewp->curlft = old->curlft;\n\t\tnewp->mark = old->mark;\n\t\tnewp->if_id = old->if_id;\n\t\tnewp->action = old->action;\n\t\tnewp->flags = old->flags;\n\t\tnewp->xfrm_nr = old->xfrm_nr;\n\t\tnewp->index = old->index;\n\t\tnewp->type = old->type;\n\t\tnewp->family = old->family;\n\t\tmemcpy(newp->xfrm_vec, old->xfrm_vec,\n\t\t       newp->xfrm_nr*sizeof(struct xfrm_tmpl));\n\t\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t\txfrm_sk_policy_link(newp, dir);\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\txfrm_pol_put(newp);\n\t}\n\treturn newp;\n}\n\nint __xfrm_sk_clone_policy(struct sock *sk, const struct sock *osk)\n{\n\tconst struct xfrm_policy *p;\n\tstruct xfrm_policy *np;\n\tint i, ret = 0;\n\n\trcu_read_lock();\n\tfor (i = 0; i < 2; i++) {\n\t\tp = rcu_dereference(osk->sk_policy[i]);\n\t\tif (p) {\n\t\t\tnp = clone_policy(p, i);\n\t\t\tif (unlikely(!np)) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\trcu_assign_pointer(sk->sk_policy[i], np);\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic int\nxfrm_get_saddr(struct net *net, int oif, xfrm_address_t *local,\n\t       xfrm_address_t *remote, unsigned short family, u32 mark)\n{\n\tint err;\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\n\tif (unlikely(afinfo == NULL))\n\t\treturn -EINVAL;\n\terr = afinfo->get_saddr(net, oif, local, remote, mark);\n\trcu_read_unlock();\n\treturn err;\n}\n\n/* Resolve list of templates for the flow, given policy. */\n\nstatic int\nxfrm_tmpl_resolve_one(struct xfrm_policy *policy, const struct flowi *fl,\n\t\t      struct xfrm_state **xfrm, unsigned short family)\n{\n\tstruct net *net = xp_net(policy);\n\tint nx;\n\tint i, error;\n\txfrm_address_t *daddr = xfrm_flowi_daddr(fl, family);\n\txfrm_address_t *saddr = xfrm_flowi_saddr(fl, family);\n\txfrm_address_t tmp;\n\n\tfor (nx = 0, i = 0; i < policy->xfrm_nr; i++) {\n\t\tstruct xfrm_state *x;\n\t\txfrm_address_t *remote = daddr;\n\t\txfrm_address_t *local  = saddr;\n\t\tstruct xfrm_tmpl *tmpl = &policy->xfrm_vec[i];\n\n\t\tif (tmpl->mode == XFRM_MODE_TUNNEL ||\n\t\t    tmpl->mode == XFRM_MODE_BEET) {\n\t\t\tremote = &tmpl->id.daddr;\n\t\t\tlocal = &tmpl->saddr;\n\t\t\tif (xfrm_addr_any(local, tmpl->encap_family)) {\n\t\t\t\terror = xfrm_get_saddr(net, fl->flowi_oif,\n\t\t\t\t\t\t       &tmp, remote,\n\t\t\t\t\t\t       tmpl->encap_family, 0);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto fail;\n\t\t\t\tlocal = &tmp;\n\t\t\t}\n\t\t}\n\n\t\tx = xfrm_state_find(remote, local, fl, tmpl, policy, &error,\n\t\t\t\t    family, policy->if_id);\n\n\t\tif (x && x->km.state == XFRM_STATE_VALID) {\n\t\t\txfrm[nx++] = x;\n\t\t\tdaddr = remote;\n\t\t\tsaddr = local;\n\t\t\tcontinue;\n\t\t}\n\t\tif (x) {\n\t\t\terror = (x->km.state == XFRM_STATE_ERROR ?\n\t\t\t\t -EINVAL : -EAGAIN);\n\t\t\txfrm_state_put(x);\n\t\t} else if (error == -ESRCH) {\n\t\t\terror = -EAGAIN;\n\t\t}\n\n\t\tif (!tmpl->optional)\n\t\t\tgoto fail;\n\t}\n\treturn nx;\n\nfail:\n\tfor (nx--; nx >= 0; nx--)\n\t\txfrm_state_put(xfrm[nx]);\n\treturn error;\n}\n\nstatic int\nxfrm_tmpl_resolve(struct xfrm_policy **pols, int npols, const struct flowi *fl,\n\t\t  struct xfrm_state **xfrm, unsigned short family)\n{\n\tstruct xfrm_state *tp[XFRM_MAX_DEPTH];\n\tstruct xfrm_state **tpp = (npols > 1) ? tp : xfrm;\n\tint cnx = 0;\n\tint error;\n\tint ret;\n\tint i;\n\n\tfor (i = 0; i < npols; i++) {\n\t\tif (cnx + pols[i]->xfrm_nr >= XFRM_MAX_DEPTH) {\n\t\t\terror = -ENOBUFS;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tret = xfrm_tmpl_resolve_one(pols[i], fl, &tpp[cnx], family);\n\t\tif (ret < 0) {\n\t\t\terror = ret;\n\t\t\tgoto fail;\n\t\t} else\n\t\t\tcnx += ret;\n\t}\n\n\t/* found states are sorted for outbound processing */\n\tif (npols > 1)\n\t\txfrm_state_sort(xfrm, tpp, cnx, family);\n\n\treturn cnx;\n\n fail:\n\tfor (cnx--; cnx >= 0; cnx--)\n\t\txfrm_state_put(tpp[cnx]);\n\treturn error;\n\n}\n\nstatic int xfrm_get_tos(const struct flowi *fl, int family)\n{\n\tif (family == AF_INET)\n\t\treturn IPTOS_RT_MASK & fl->u.ip4.flowi4_tos;\n\n\treturn 0;\n}\n\nstatic inline struct xfrm_dst *xfrm_alloc_dst(struct net *net, int family)\n{\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\tstruct dst_ops *dst_ops;\n\tstruct xfrm_dst *xdst;\n\n\tif (!afinfo)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tswitch (family) {\n\tcase AF_INET:\n\t\tdst_ops = &net->xfrm.xfrm4_dst_ops;\n\t\tbreak;\n#if IS_ENABLED(CONFIG_IPV6)\n\tcase AF_INET6:\n\t\tdst_ops = &net->xfrm.xfrm6_dst_ops;\n\t\tbreak;\n#endif\n\tdefault:\n\t\tBUG();\n\t}\n\txdst = dst_alloc(dst_ops, NULL, 1, DST_OBSOLETE_NONE, 0);\n\n\tif (likely(xdst)) {\n\t\tmemset_after(xdst, 0, u.dst);\n\t} else\n\t\txdst = ERR_PTR(-ENOBUFS);\n\n\trcu_read_unlock();\n\n\treturn xdst;\n}\n\nstatic void xfrm_init_path(struct xfrm_dst *path, struct dst_entry *dst,\n\t\t\t   int nfheader_len)\n{\n\tif (dst->ops->family == AF_INET6) {\n\t\tstruct rt6_info *rt = (struct rt6_info *)dst;\n\t\tpath->path_cookie = rt6_get_cookie(rt);\n\t\tpath->u.rt6.rt6i_nfheader_len = nfheader_len;\n\t}\n}\n\nstatic inline int xfrm_fill_dst(struct xfrm_dst *xdst, struct net_device *dev,\n\t\t\t\tconst struct flowi *fl)\n{\n\tconst struct xfrm_policy_afinfo *afinfo =\n\t\txfrm_policy_get_afinfo(xdst->u.dst.ops->family);\n\tint err;\n\n\tif (!afinfo)\n\t\treturn -EINVAL;\n\n\terr = afinfo->fill_dst(xdst, dev, fl);\n\n\trcu_read_unlock();\n\n\treturn err;\n}\n\n\n/* Allocate chain of dst_entry's, attach known xfrm's, calculate\n * all the metrics... Shortly, bundle a bundle.\n */\n\nstatic struct dst_entry *xfrm_bundle_create(struct xfrm_policy *policy,\n\t\t\t\t\t    struct xfrm_state **xfrm,\n\t\t\t\t\t    struct xfrm_dst **bundle,\n\t\t\t\t\t    int nx,\n\t\t\t\t\t    const struct flowi *fl,\n\t\t\t\t\t    struct dst_entry *dst)\n{\n\tconst struct xfrm_state_afinfo *afinfo;\n\tconst struct xfrm_mode *inner_mode;\n\tstruct net *net = xp_net(policy);\n\tunsigned long now = jiffies;\n\tstruct net_device *dev;\n\tstruct xfrm_dst *xdst_prev = NULL;\n\tstruct xfrm_dst *xdst0 = NULL;\n\tint i = 0;\n\tint err;\n\tint header_len = 0;\n\tint nfheader_len = 0;\n\tint trailer_len = 0;\n\tint tos;\n\tint family = policy->selector.family;\n\txfrm_address_t saddr, daddr;\n\n\txfrm_flowi_addr_get(fl, &saddr, &daddr, family);\n\n\ttos = xfrm_get_tos(fl, family);\n\n\tdst_hold(dst);\n\n\tfor (; i < nx; i++) {\n\t\tstruct xfrm_dst *xdst = xfrm_alloc_dst(net, family);\n\t\tstruct dst_entry *dst1 = &xdst->u.dst;\n\n\t\terr = PTR_ERR(xdst);\n\t\tif (IS_ERR(xdst)) {\n\t\t\tdst_release(dst);\n\t\t\tgoto put_states;\n\t\t}\n\n\t\tbundle[i] = xdst;\n\t\tif (!xdst_prev)\n\t\t\txdst0 = xdst;\n\t\telse\n\t\t\t/* Ref count is taken during xfrm_alloc_dst()\n\t\t\t * No need to do dst_clone() on dst1\n\t\t\t */\n\t\t\txfrm_dst_set_child(xdst_prev, &xdst->u.dst);\n\n\t\tif (xfrm[i]->sel.family == AF_UNSPEC) {\n\t\t\tinner_mode = xfrm_ip2inner_mode(xfrm[i],\n\t\t\t\t\t\t\txfrm_af2proto(family));\n\t\t\tif (!inner_mode) {\n\t\t\t\terr = -EAFNOSUPPORT;\n\t\t\t\tdst_release(dst);\n\t\t\t\tgoto put_states;\n\t\t\t}\n\t\t} else\n\t\t\tinner_mode = &xfrm[i]->inner_mode;\n\n\t\txdst->route = dst;\n\t\tdst_copy_metrics(dst1, dst);\n\n\t\tif (xfrm[i]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\t__u32 mark = 0;\n\t\t\tint oif;\n\n\t\t\tif (xfrm[i]->props.smark.v || xfrm[i]->props.smark.m)\n\t\t\t\tmark = xfrm_smark_get(fl->flowi_mark, xfrm[i]);\n\n\t\t\tfamily = xfrm[i]->props.family;\n\t\t\toif = fl->flowi_oif ? : fl->flowi_l3mdev;\n\t\t\tdst = xfrm_dst_lookup(xfrm[i], tos, oif,\n\t\t\t\t\t      &saddr, &daddr, family, mark);\n\t\t\terr = PTR_ERR(dst);\n\t\t\tif (IS_ERR(dst))\n\t\t\t\tgoto put_states;\n\t\t} else\n\t\t\tdst_hold(dst);\n\n\t\tdst1->xfrm = xfrm[i];\n\t\txdst->xfrm_genid = xfrm[i]->genid;\n\n\t\tdst1->obsolete = DST_OBSOLETE_FORCE_CHK;\n\t\tdst1->lastuse = now;\n\n\t\tdst1->input = dst_discard;\n\n\t\trcu_read_lock();\n\t\tafinfo = xfrm_state_afinfo_get_rcu(inner_mode->family);\n\t\tif (likely(afinfo))\n\t\t\tdst1->output = afinfo->output;\n\t\telse\n\t\t\tdst1->output = dst_discard_out;\n\t\trcu_read_unlock();\n\n\t\txdst_prev = xdst;\n\n\t\theader_len += xfrm[i]->props.header_len;\n\t\tif (xfrm[i]->type->flags & XFRM_TYPE_NON_FRAGMENT)\n\t\t\tnfheader_len += xfrm[i]->props.header_len;\n\t\ttrailer_len += xfrm[i]->props.trailer_len;\n\t}\n\n\txfrm_dst_set_child(xdst_prev, dst);\n\txdst0->path = dst;\n\n\terr = -ENODEV;\n\tdev = dst->dev;\n\tif (!dev)\n\t\tgoto free_dst;\n\n\txfrm_init_path(xdst0, dst, nfheader_len);\n\txfrm_init_pmtu(bundle, nx);\n\n\tfor (xdst_prev = xdst0; xdst_prev != (struct xfrm_dst *)dst;\n\t     xdst_prev = (struct xfrm_dst *) xfrm_dst_child(&xdst_prev->u.dst)) {\n\t\terr = xfrm_fill_dst(xdst_prev, dev, fl);\n\t\tif (err)\n\t\t\tgoto free_dst;\n\n\t\txdst_prev->u.dst.header_len = header_len;\n\t\txdst_prev->u.dst.trailer_len = trailer_len;\n\t\theader_len -= xdst_prev->u.dst.xfrm->props.header_len;\n\t\ttrailer_len -= xdst_prev->u.dst.xfrm->props.trailer_len;\n\t}\n\n\treturn &xdst0->u.dst;\n\nput_states:\n\tfor (; i < nx; i++)\n\t\txfrm_state_put(xfrm[i]);\nfree_dst:\n\tif (xdst0)\n\t\tdst_release_immediate(&xdst0->u.dst);\n\n\treturn ERR_PTR(err);\n}\n\nstatic int xfrm_expand_policies(const struct flowi *fl, u16 family,\n\t\t\t\tstruct xfrm_policy **pols,\n\t\t\t\tint *num_pols, int *num_xfrms)\n{\n\tint i;\n\n\tif (*num_pols == 0 || !pols[0]) {\n\t\t*num_pols = 0;\n\t\t*num_xfrms = 0;\n\t\treturn 0;\n\t}\n\tif (IS_ERR(pols[0]))\n\t\treturn PTR_ERR(pols[0]);\n\n\t*num_xfrms = pols[0]->xfrm_nr;\n\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pols[0]->action == XFRM_POLICY_ALLOW &&\n\t    pols[0]->type != XFRM_POLICY_TYPE_MAIN) {\n\t\tpols[1] = xfrm_policy_lookup_bytype(xp_net(pols[0]),\n\t\t\t\t\t\t    XFRM_POLICY_TYPE_MAIN,\n\t\t\t\t\t\t    fl, family,\n\t\t\t\t\t\t    XFRM_POLICY_OUT,\n\t\t\t\t\t\t    pols[0]->if_id);\n\t\tif (pols[1]) {\n\t\t\tif (IS_ERR(pols[1])) {\n\t\t\t\txfrm_pols_put(pols, *num_pols);\n\t\t\t\treturn PTR_ERR(pols[1]);\n\t\t\t}\n\t\t\t(*num_pols)++;\n\t\t\t(*num_xfrms) += pols[1]->xfrm_nr;\n\t\t}\n\t}\n#endif\n\tfor (i = 0; i < *num_pols; i++) {\n\t\tif (pols[i]->action != XFRM_POLICY_ALLOW) {\n\t\t\t*num_xfrms = -1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n\n}\n\nstatic struct xfrm_dst *\nxfrm_resolve_and_create_bundle(struct xfrm_policy **pols, int num_pols,\n\t\t\t       const struct flowi *fl, u16 family,\n\t\t\t       struct dst_entry *dst_orig)\n{\n\tstruct net *net = xp_net(pols[0]);\n\tstruct xfrm_state *xfrm[XFRM_MAX_DEPTH];\n\tstruct xfrm_dst *bundle[XFRM_MAX_DEPTH];\n\tstruct xfrm_dst *xdst;\n\tstruct dst_entry *dst;\n\tint err;\n\n\t/* Try to instantiate a bundle */\n\terr = xfrm_tmpl_resolve(pols, num_pols, fl, xfrm, family);\n\tif (err <= 0) {\n\t\tif (err == 0)\n\t\t\treturn NULL;\n\n\t\tif (err != -EAGAIN)\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLERROR);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tdst = xfrm_bundle_create(pols[0], xfrm, bundle, err, fl, dst_orig);\n\tif (IS_ERR(dst)) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTBUNDLEGENERROR);\n\t\treturn ERR_CAST(dst);\n\t}\n\n\txdst = (struct xfrm_dst *)dst;\n\txdst->num_xfrms = err;\n\txdst->num_pols = num_pols;\n\tmemcpy(xdst->pols, pols, sizeof(struct xfrm_policy *) * num_pols);\n\txdst->policy_genid = atomic_read(&pols[0]->genid);\n\n\treturn xdst;\n}\n\nstatic void xfrm_policy_queue_process(struct timer_list *t)\n{\n\tstruct sk_buff *skb;\n\tstruct sock *sk;\n\tstruct dst_entry *dst;\n\tstruct xfrm_policy *pol = from_timer(pol, t, polq.hold_timer);\n\tstruct net *net = xp_net(pol);\n\tstruct xfrm_policy_queue *pq = &pol->polq;\n\tstruct flowi fl;\n\tstruct sk_buff_head list;\n\t__u32 skb_mark;\n\n\tspin_lock(&pq->hold_queue.lock);\n\tskb = skb_peek(&pq->hold_queue);\n\tif (!skb) {\n\t\tspin_unlock(&pq->hold_queue.lock);\n\t\tgoto out;\n\t}\n\tdst = skb_dst(skb);\n\tsk = skb->sk;\n\n\t/* Fixup the mark to support VTI. */\n\tskb_mark = skb->mark;\n\tskb->mark = pol->mark.v;\n\txfrm_decode_session(skb, &fl, dst->ops->family);\n\tskb->mark = skb_mark;\n\tspin_unlock(&pq->hold_queue.lock);\n\n\tdst_hold(xfrm_dst_path(dst));\n\tdst = xfrm_lookup(net, xfrm_dst_path(dst), &fl, sk, XFRM_LOOKUP_QUEUE);\n\tif (IS_ERR(dst))\n\t\tgoto purge_queue;\n\n\tif (dst->flags & DST_XFRM_QUEUE) {\n\t\tdst_release(dst);\n\n\t\tif (pq->timeout >= XFRM_QUEUE_TMO_MAX)\n\t\t\tgoto purge_queue;\n\n\t\tpq->timeout = pq->timeout << 1;\n\t\tif (!mod_timer(&pq->hold_timer, jiffies + pq->timeout))\n\t\t\txfrm_pol_hold(pol);\n\t\tgoto out;\n\t}\n\n\tdst_release(dst);\n\n\t__skb_queue_head_init(&list);\n\n\tspin_lock(&pq->hold_queue.lock);\n\tpq->timeout = 0;\n\tskb_queue_splice_init(&pq->hold_queue, &list);\n\tspin_unlock(&pq->hold_queue.lock);\n\n\twhile (!skb_queue_empty(&list)) {\n\t\tskb = __skb_dequeue(&list);\n\n\t\t/* Fixup the mark to support VTI. */\n\t\tskb_mark = skb->mark;\n\t\tskb->mark = pol->mark.v;\n\t\txfrm_decode_session(skb, &fl, skb_dst(skb)->ops->family);\n\t\tskb->mark = skb_mark;\n\n\t\tdst_hold(xfrm_dst_path(skb_dst(skb)));\n\t\tdst = xfrm_lookup(net, xfrm_dst_path(skb_dst(skb)), &fl, skb->sk, 0);\n\t\tif (IS_ERR(dst)) {\n\t\t\tkfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tnf_reset_ct(skb);\n\t\tskb_dst_drop(skb);\n\t\tskb_dst_set(skb, dst);\n\n\t\tdst_output(net, skb->sk, skb);\n\t}\n\nout:\n\txfrm_pol_put(pol);\n\treturn;\n\npurge_queue:\n\tpq->timeout = 0;\n\tskb_queue_purge(&pq->hold_queue);\n\txfrm_pol_put(pol);\n}\n\nstatic int xdst_queue_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tunsigned long sched_next;\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct xfrm_dst *xdst = (struct xfrm_dst *) dst;\n\tstruct xfrm_policy *pol = xdst->pols[0];\n\tstruct xfrm_policy_queue *pq = &pol->polq;\n\n\tif (unlikely(skb_fclone_busy(sk, skb))) {\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\n\tif (pq->hold_queue.qlen > XFRM_MAX_QUEUE_LEN) {\n\t\tkfree_skb(skb);\n\t\treturn -EAGAIN;\n\t}\n\n\tskb_dst_force(skb);\n\n\tspin_lock_bh(&pq->hold_queue.lock);\n\n\tif (!pq->timeout)\n\t\tpq->timeout = XFRM_QUEUE_TMO_MIN;\n\n\tsched_next = jiffies + pq->timeout;\n\n\tif (del_timer(&pq->hold_timer)) {\n\t\tif (time_before(pq->hold_timer.expires, sched_next))\n\t\t\tsched_next = pq->hold_timer.expires;\n\t\txfrm_pol_put(pol);\n\t}\n\n\t__skb_queue_tail(&pq->hold_queue, skb);\n\tif (!mod_timer(&pq->hold_timer, sched_next))\n\t\txfrm_pol_hold(pol);\n\n\tspin_unlock_bh(&pq->hold_queue.lock);\n\n\treturn 0;\n}\n\nstatic struct xfrm_dst *xfrm_create_dummy_bundle(struct net *net,\n\t\t\t\t\t\t struct xfrm_flo *xflo,\n\t\t\t\t\t\t const struct flowi *fl,\n\t\t\t\t\t\t int num_xfrms,\n\t\t\t\t\t\t u16 family)\n{\n\tint err;\n\tstruct net_device *dev;\n\tstruct dst_entry *dst;\n\tstruct dst_entry *dst1;\n\tstruct xfrm_dst *xdst;\n\n\txdst = xfrm_alloc_dst(net, family);\n\tif (IS_ERR(xdst))\n\t\treturn xdst;\n\n\tif (!(xflo->flags & XFRM_LOOKUP_QUEUE) ||\n\t    net->xfrm.sysctl_larval_drop ||\n\t    num_xfrms <= 0)\n\t\treturn xdst;\n\n\tdst = xflo->dst_orig;\n\tdst1 = &xdst->u.dst;\n\tdst_hold(dst);\n\txdst->route = dst;\n\n\tdst_copy_metrics(dst1, dst);\n\n\tdst1->obsolete = DST_OBSOLETE_FORCE_CHK;\n\tdst1->flags |= DST_XFRM_QUEUE;\n\tdst1->lastuse = jiffies;\n\n\tdst1->input = dst_discard;\n\tdst1->output = xdst_queue_output;\n\n\tdst_hold(dst);\n\txfrm_dst_set_child(xdst, dst);\n\txdst->path = dst;\n\n\txfrm_init_path((struct xfrm_dst *)dst1, dst, 0);\n\n\terr = -ENODEV;\n\tdev = dst->dev;\n\tif (!dev)\n\t\tgoto free_dst;\n\n\terr = xfrm_fill_dst(xdst, dev, fl);\n\tif (err)\n\t\tgoto free_dst;\n\nout:\n\treturn xdst;\n\nfree_dst:\n\tdst_release(dst1);\n\txdst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic struct xfrm_dst *xfrm_bundle_lookup(struct net *net,\n\t\t\t\t\t   const struct flowi *fl,\n\t\t\t\t\t   u16 family, u8 dir,\n\t\t\t\t\t   struct xfrm_flo *xflo, u32 if_id)\n{\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tint num_pols = 0, num_xfrms = 0, err;\n\tstruct xfrm_dst *xdst;\n\n\t/* Resolve policies to use if we couldn't get them from\n\t * previous cache entry */\n\tnum_pols = 1;\n\tpols[0] = xfrm_policy_lookup(net, fl, family, dir, if_id);\n\terr = xfrm_expand_policies(fl, family, pols,\n\t\t\t\t\t   &num_pols, &num_xfrms);\n\tif (err < 0)\n\t\tgoto inc_error;\n\tif (num_pols == 0)\n\t\treturn NULL;\n\tif (num_xfrms <= 0)\n\t\tgoto make_dummy_bundle;\n\n\txdst = xfrm_resolve_and_create_bundle(pols, num_pols, fl, family,\n\t\t\t\t\t      xflo->dst_orig);\n\tif (IS_ERR(xdst)) {\n\t\terr = PTR_ERR(xdst);\n\t\tif (err == -EREMOTE) {\n\t\t\txfrm_pols_put(pols, num_pols);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (err != -EAGAIN)\n\t\t\tgoto error;\n\t\tgoto make_dummy_bundle;\n\t} else if (xdst == NULL) {\n\t\tnum_xfrms = 0;\n\t\tgoto make_dummy_bundle;\n\t}\n\n\treturn xdst;\n\nmake_dummy_bundle:\n\t/* We found policies, but there's no bundles to instantiate:\n\t * either because the policy blocks, has no transformations or\n\t * we could not build template (no xfrm_states).*/\n\txdst = xfrm_create_dummy_bundle(net, xflo, fl, num_xfrms, family);\n\tif (IS_ERR(xdst)) {\n\t\txfrm_pols_put(pols, num_pols);\n\t\treturn ERR_CAST(xdst);\n\t}\n\txdst->num_pols = num_pols;\n\txdst->num_xfrms = num_xfrms;\n\tmemcpy(xdst->pols, pols, sizeof(struct xfrm_policy *) * num_pols);\n\n\treturn xdst;\n\ninc_error:\n\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLERROR);\nerror:\n\txfrm_pols_put(pols, num_pols);\n\treturn ERR_PTR(err);\n}\n\nstatic struct dst_entry *make_blackhole(struct net *net, u16 family,\n\t\t\t\t\tstruct dst_entry *dst_orig)\n{\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\tstruct dst_entry *ret;\n\n\tif (!afinfo) {\n\t\tdst_release(dst_orig);\n\t\treturn ERR_PTR(-EINVAL);\n\t} else {\n\t\tret = afinfo->blackhole_route(net, dst_orig);\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\n/* Finds/creates a bundle for given flow and if_id\n *\n * At the moment we eat a raw IP route. Mostly to speed up lookups\n * on interfaces with disabled IPsec.\n *\n * xfrm_lookup uses an if_id of 0 by default, and is provided for\n * compatibility\n */\nstruct dst_entry *xfrm_lookup_with_ifid(struct net *net,\n\t\t\t\t\tstruct dst_entry *dst_orig,\n\t\t\t\t\tconst struct flowi *fl,\n\t\t\t\t\tconst struct sock *sk,\n\t\t\t\t\tint flags, u32 if_id)\n{\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tstruct xfrm_dst *xdst;\n\tstruct dst_entry *dst, *route;\n\tu16 family = dst_orig->ops->family;\n\tu8 dir = XFRM_POLICY_OUT;\n\tint i, err, num_pols, num_xfrms = 0, drop_pols = 0;\n\n\tdst = NULL;\n\txdst = NULL;\n\troute = NULL;\n\n\tsk = sk_const_to_full_sk(sk);\n\tif (sk && sk->sk_policy[XFRM_POLICY_OUT]) {\n\t\tnum_pols = 1;\n\t\tpols[0] = xfrm_sk_policy_lookup(sk, XFRM_POLICY_OUT, fl, family,\n\t\t\t\t\t\tif_id);\n\t\terr = xfrm_expand_policies(fl, family, pols,\n\t\t\t\t\t   &num_pols, &num_xfrms);\n\t\tif (err < 0)\n\t\t\tgoto dropdst;\n\n\t\tif (num_pols) {\n\t\t\tif (num_xfrms <= 0) {\n\t\t\t\tdrop_pols = num_pols;\n\t\t\t\tgoto no_transform;\n\t\t\t}\n\n\t\t\txdst = xfrm_resolve_and_create_bundle(\n\t\t\t\t\tpols, num_pols, fl,\n\t\t\t\t\tfamily, dst_orig);\n\n\t\t\tif (IS_ERR(xdst)) {\n\t\t\t\txfrm_pols_put(pols, num_pols);\n\t\t\t\terr = PTR_ERR(xdst);\n\t\t\t\tif (err == -EREMOTE)\n\t\t\t\t\tgoto nopol;\n\n\t\t\t\tgoto dropdst;\n\t\t\t} else if (xdst == NULL) {\n\t\t\t\tnum_xfrms = 0;\n\t\t\t\tdrop_pols = num_pols;\n\t\t\t\tgoto no_transform;\n\t\t\t}\n\n\t\t\troute = xdst->route;\n\t\t}\n\t}\n\n\tif (xdst == NULL) {\n\t\tstruct xfrm_flo xflo;\n\n\t\txflo.dst_orig = dst_orig;\n\t\txflo.flags = flags;\n\n\t\t/* To accelerate a bit...  */\n\t\tif (!if_id && ((dst_orig->flags & DST_NOXFRM) ||\n\t\t\t       !net->xfrm.policy_count[XFRM_POLICY_OUT]))\n\t\t\tgoto nopol;\n\n\t\txdst = xfrm_bundle_lookup(net, fl, family, dir, &xflo, if_id);\n\t\tif (xdst == NULL)\n\t\t\tgoto nopol;\n\t\tif (IS_ERR(xdst)) {\n\t\t\terr = PTR_ERR(xdst);\n\t\t\tgoto dropdst;\n\t\t}\n\n\t\tnum_pols = xdst->num_pols;\n\t\tnum_xfrms = xdst->num_xfrms;\n\t\tmemcpy(pols, xdst->pols, sizeof(struct xfrm_policy *) * num_pols);\n\t\troute = xdst->route;\n\t}\n\n\tdst = &xdst->u.dst;\n\tif (route == NULL && num_xfrms > 0) {\n\t\t/* The only case when xfrm_bundle_lookup() returns a\n\t\t * bundle with null route, is when the template could\n\t\t * not be resolved. It means policies are there, but\n\t\t * bundle could not be created, since we don't yet\n\t\t * have the xfrm_state's. We need to wait for KM to\n\t\t * negotiate new SA's or bail out with error.*/\n\t\tif (net->xfrm.sysctl_larval_drop) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTNOSTATES);\n\t\t\terr = -EREMOTE;\n\t\t\tgoto error;\n\t\t}\n\n\t\terr = -EAGAIN;\n\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTNOSTATES);\n\t\tgoto error;\n\t}\n\nno_transform:\n\tif (num_pols == 0)\n\t\tgoto nopol;\n\n\tif ((flags & XFRM_LOOKUP_ICMP) &&\n\t    !(pols[0]->flags & XFRM_POLICY_ICMP)) {\n\t\terr = -ENOENT;\n\t\tgoto error;\n\t}\n\n\tfor (i = 0; i < num_pols; i++)\n\t\tpols[i]->curlft.use_time = ktime_get_real_seconds();\n\n\tif (num_xfrms < 0) {\n\t\t/* Prohibit the flow */\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLBLOCK);\n\t\terr = -EPERM;\n\t\tgoto error;\n\t} else if (num_xfrms > 0) {\n\t\t/* Flow transformed */\n\t\tdst_release(dst_orig);\n\t} else {\n\t\t/* Flow passes untransformed */\n\t\tdst_release(dst);\n\t\tdst = dst_orig;\n\t}\nok:\n\txfrm_pols_put(pols, drop_pols);\n\tif (dst && dst->xfrm &&\n\t    dst->xfrm->props.mode == XFRM_MODE_TUNNEL)\n\t\tdst->flags |= DST_XFRM_TUNNEL;\n\treturn dst;\n\nnopol:\n\tif (!(dst_orig->dev->flags & IFF_LOOPBACK) &&\n\t    net->xfrm.policy_default[dir] == XFRM_USERPOLICY_BLOCK) {\n\t\terr = -EPERM;\n\t\tgoto error;\n\t}\n\tif (!(flags & XFRM_LOOKUP_ICMP)) {\n\t\tdst = dst_orig;\n\t\tgoto ok;\n\t}\n\terr = -ENOENT;\nerror:\n\tdst_release(dst);\ndropdst:\n\tif (!(flags & XFRM_LOOKUP_KEEP_DST_REF))\n\t\tdst_release(dst_orig);\n\txfrm_pols_put(pols, drop_pols);\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL(xfrm_lookup_with_ifid);\n\n/* Main function: finds/creates a bundle for given flow.\n *\n * At the moment we eat a raw IP route. Mostly to speed up lookups\n * on interfaces with disabled IPsec.\n */\nstruct dst_entry *xfrm_lookup(struct net *net, struct dst_entry *dst_orig,\n\t\t\t      const struct flowi *fl, const struct sock *sk,\n\t\t\t      int flags)\n{\n\treturn xfrm_lookup_with_ifid(net, dst_orig, fl, sk, flags, 0);\n}\nEXPORT_SYMBOL(xfrm_lookup);\n\n/* Callers of xfrm_lookup_route() must ensure a call to dst_output().\n * Otherwise we may send out blackholed packets.\n */\nstruct dst_entry *xfrm_lookup_route(struct net *net, struct dst_entry *dst_orig,\n\t\t\t\t    const struct flowi *fl,\n\t\t\t\t    const struct sock *sk, int flags)\n{\n\tstruct dst_entry *dst = xfrm_lookup(net, dst_orig, fl, sk,\n\t\t\t\t\t    flags | XFRM_LOOKUP_QUEUE |\n\t\t\t\t\t    XFRM_LOOKUP_KEEP_DST_REF);\n\n\tif (PTR_ERR(dst) == -EREMOTE)\n\t\treturn make_blackhole(net, dst_orig->ops->family, dst_orig);\n\n\tif (IS_ERR(dst))\n\t\tdst_release(dst_orig);\n\n\treturn dst;\n}\nEXPORT_SYMBOL(xfrm_lookup_route);\n\nstatic inline int\nxfrm_secpath_reject(int idx, struct sk_buff *skb, const struct flowi *fl)\n{\n\tstruct sec_path *sp = skb_sec_path(skb);\n\tstruct xfrm_state *x;\n\n\tif (!sp || idx < 0 || idx >= sp->len)\n\t\treturn 0;\n\tx = sp->xvec[idx];\n\tif (!x->type->reject)\n\t\treturn 0;\n\treturn x->type->reject(x, skb, fl);\n}\n\n/* When skb is transformed back to its \"native\" form, we have to\n * check policy restrictions. At the moment we make this in maximally\n * stupid way. Shame on me. :-) Of course, connected sockets must\n * have policy cached at them.\n */\n\nstatic inline int\nxfrm_state_ok(const struct xfrm_tmpl *tmpl, const struct xfrm_state *x,\n\t      unsigned short family)\n{\n\tif (xfrm_state_kern(x))\n\t\treturn tmpl->optional && !xfrm_state_addr_cmp(tmpl, x, tmpl->encap_family);\n\treturn\tx->id.proto == tmpl->id.proto &&\n\t\t(x->id.spi == tmpl->id.spi || !tmpl->id.spi) &&\n\t\t(x->props.reqid == tmpl->reqid || !tmpl->reqid) &&\n\t\tx->props.mode == tmpl->mode &&\n\t\t(tmpl->allalgs || (tmpl->aalgos & (1<<x->props.aalgo)) ||\n\t\t !(xfrm_id_proto_match(tmpl->id.proto, IPSEC_PROTO_ANY))) &&\n\t\t!(x->props.mode != XFRM_MODE_TRANSPORT &&\n\t\t  xfrm_state_addr_cmp(tmpl, x, family));\n}\n\n/*\n * 0 or more than 0 is returned when validation is succeeded (either bypass\n * because of optional transport mode, or next index of the matched secpath\n * state with the template.\n * -1 is returned when no matching template is found.\n * Otherwise \"-2 - errored_index\" is returned.\n */\nstatic inline int\nxfrm_policy_ok(const struct xfrm_tmpl *tmpl, const struct sec_path *sp, int start,\n\t       unsigned short family)\n{\n\tint idx = start;\n\n\tif (tmpl->optional) {\n\t\tif (tmpl->mode == XFRM_MODE_TRANSPORT)\n\t\t\treturn start;\n\t} else\n\t\tstart = -1;\n\tfor (; idx < sp->len; idx++) {\n\t\tif (xfrm_state_ok(tmpl, sp->xvec[idx], family))\n\t\t\treturn ++idx;\n\t\tif (sp->xvec[idx]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\tif (start == -1)\n\t\t\t\tstart = -2-idx;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn start;\n}\n\nstatic void\ndecode_session4(struct sk_buff *skb, struct flowi *fl, bool reverse)\n{\n\tconst struct iphdr *iph = ip_hdr(skb);\n\tint ihl = iph->ihl;\n\tu8 *xprth = skb_network_header(skb) + ihl * 4;\n\tstruct flowi4 *fl4 = &fl->u.ip4;\n\tint oif = 0;\n\n\tif (skb_dst(skb) && skb_dst(skb)->dev)\n\t\toif = skb_dst(skb)->dev->ifindex;\n\n\tmemset(fl4, 0, sizeof(struct flowi4));\n\tfl4->flowi4_mark = skb->mark;\n\tfl4->flowi4_oif = reverse ? skb->skb_iif : oif;\n\n\tfl4->flowi4_proto = iph->protocol;\n\tfl4->daddr = reverse ? iph->saddr : iph->daddr;\n\tfl4->saddr = reverse ? iph->daddr : iph->saddr;\n\tfl4->flowi4_tos = iph->tos & ~INET_ECN_MASK;\n\n\tif (!ip_is_fragment(iph)) {\n\t\tswitch (iph->protocol) {\n\t\tcase IPPROTO_UDP:\n\t\tcase IPPROTO_UDPLITE:\n\t\tcase IPPROTO_TCP:\n\t\tcase IPPROTO_SCTP:\n\t\tcase IPPROTO_DCCP:\n\t\t\tif (xprth + 4 < skb->data ||\n\t\t\t    pskb_may_pull(skb, xprth + 4 - skb->data)) {\n\t\t\t\t__be16 *ports;\n\n\t\t\t\txprth = skb_network_header(skb) + ihl * 4;\n\t\t\t\tports = (__be16 *)xprth;\n\n\t\t\t\tfl4->fl4_sport = ports[!!reverse];\n\t\t\t\tfl4->fl4_dport = ports[!reverse];\n\t\t\t}\n\t\t\tbreak;\n\t\tcase IPPROTO_ICMP:\n\t\t\tif (xprth + 2 < skb->data ||\n\t\t\t    pskb_may_pull(skb, xprth + 2 - skb->data)) {\n\t\t\t\tu8 *icmp;\n\n\t\t\t\txprth = skb_network_header(skb) + ihl * 4;\n\t\t\t\ticmp = xprth;\n\n\t\t\t\tfl4->fl4_icmp_type = icmp[0];\n\t\t\t\tfl4->fl4_icmp_code = icmp[1];\n\t\t\t}\n\t\t\tbreak;\n\t\tcase IPPROTO_GRE:\n\t\t\tif (xprth + 12 < skb->data ||\n\t\t\t    pskb_may_pull(skb, xprth + 12 - skb->data)) {\n\t\t\t\t__be16 *greflags;\n\t\t\t\t__be32 *gre_hdr;\n\n\t\t\t\txprth = skb_network_header(skb) + ihl * 4;\n\t\t\t\tgreflags = (__be16 *)xprth;\n\t\t\t\tgre_hdr = (__be32 *)xprth;\n\n\t\t\t\tif (greflags[0] & GRE_KEY) {\n\t\t\t\t\tif (greflags[0] & GRE_CSUM)\n\t\t\t\t\t\tgre_hdr++;\n\t\t\t\t\tfl4->fl4_gre_key = gre_hdr[1];\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\nstatic void\ndecode_session6(struct sk_buff *skb, struct flowi *fl, bool reverse)\n{\n\tstruct flowi6 *fl6 = &fl->u.ip6;\n\tint onlyproto = 0;\n\tconst struct ipv6hdr *hdr = ipv6_hdr(skb);\n\tu32 offset = sizeof(*hdr);\n\tstruct ipv6_opt_hdr *exthdr;\n\tconst unsigned char *nh = skb_network_header(skb);\n\tu16 nhoff = IP6CB(skb)->nhoff;\n\tint oif = 0;\n\tu8 nexthdr;\n\n\tif (!nhoff)\n\t\tnhoff = offsetof(struct ipv6hdr, nexthdr);\n\n\tnexthdr = nh[nhoff];\n\n\tif (skb_dst(skb) && skb_dst(skb)->dev)\n\t\toif = skb_dst(skb)->dev->ifindex;\n\n\tmemset(fl6, 0, sizeof(struct flowi6));\n\tfl6->flowi6_mark = skb->mark;\n\tfl6->flowi6_oif = reverse ? skb->skb_iif : oif;\n\n\tfl6->daddr = reverse ? hdr->saddr : hdr->daddr;\n\tfl6->saddr = reverse ? hdr->daddr : hdr->saddr;\n\n\twhile (nh + offset + sizeof(*exthdr) < skb->data ||\n\t       pskb_may_pull(skb, nh + offset + sizeof(*exthdr) - skb->data)) {\n\t\tnh = skb_network_header(skb);\n\t\texthdr = (struct ipv6_opt_hdr *)(nh + offset);\n\n\t\tswitch (nexthdr) {\n\t\tcase NEXTHDR_FRAGMENT:\n\t\t\tonlyproto = 1;\n\t\t\tfallthrough;\n\t\tcase NEXTHDR_ROUTING:\n\t\tcase NEXTHDR_HOP:\n\t\tcase NEXTHDR_DEST:\n\t\t\toffset += ipv6_optlen(exthdr);\n\t\t\tnexthdr = exthdr->nexthdr;\n\t\t\tbreak;\n\t\tcase IPPROTO_UDP:\n\t\tcase IPPROTO_UDPLITE:\n\t\tcase IPPROTO_TCP:\n\t\tcase IPPROTO_SCTP:\n\t\tcase IPPROTO_DCCP:\n\t\t\tif (!onlyproto && (nh + offset + 4 < skb->data ||\n\t\t\t     pskb_may_pull(skb, nh + offset + 4 - skb->data))) {\n\t\t\t\t__be16 *ports;\n\n\t\t\t\tnh = skb_network_header(skb);\n\t\t\t\tports = (__be16 *)(nh + offset);\n\t\t\t\tfl6->fl6_sport = ports[!!reverse];\n\t\t\t\tfl6->fl6_dport = ports[!reverse];\n\t\t\t}\n\t\t\tfl6->flowi6_proto = nexthdr;\n\t\t\treturn;\n\t\tcase IPPROTO_ICMPV6:\n\t\t\tif (!onlyproto && (nh + offset + 2 < skb->data ||\n\t\t\t    pskb_may_pull(skb, nh + offset + 2 - skb->data))) {\n\t\t\t\tu8 *icmp;\n\n\t\t\t\tnh = skb_network_header(skb);\n\t\t\t\ticmp = (u8 *)(nh + offset);\n\t\t\t\tfl6->fl6_icmp_type = icmp[0];\n\t\t\t\tfl6->fl6_icmp_code = icmp[1];\n\t\t\t}\n\t\t\tfl6->flowi6_proto = nexthdr;\n\t\t\treturn;\n\t\tcase IPPROTO_GRE:\n\t\t\tif (!onlyproto &&\n\t\t\t    (nh + offset + 12 < skb->data ||\n\t\t\t     pskb_may_pull(skb, nh + offset + 12 - skb->data))) {\n\t\t\t\tstruct gre_base_hdr *gre_hdr;\n\t\t\t\t__be32 *gre_key;\n\n\t\t\t\tnh = skb_network_header(skb);\n\t\t\t\tgre_hdr = (struct gre_base_hdr *)(nh + offset);\n\t\t\t\tgre_key = (__be32 *)(gre_hdr + 1);\n\n\t\t\t\tif (gre_hdr->flags & GRE_KEY) {\n\t\t\t\t\tif (gre_hdr->flags & GRE_CSUM)\n\t\t\t\t\t\tgre_key++;\n\t\t\t\t\tfl6->fl6_gre_key = *gre_key;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfl6->flowi6_proto = nexthdr;\n\t\t\treturn;\n\n#if IS_ENABLED(CONFIG_IPV6_MIP6)\n\t\tcase IPPROTO_MH:\n\t\t\toffset += ipv6_optlen(exthdr);\n\t\t\tif (!onlyproto && (nh + offset + 3 < skb->data ||\n\t\t\t    pskb_may_pull(skb, nh + offset + 3 - skb->data))) {\n\t\t\t\tstruct ip6_mh *mh;\n\n\t\t\t\tnh = skb_network_header(skb);\n\t\t\t\tmh = (struct ip6_mh *)(nh + offset);\n\t\t\t\tfl6->fl6_mh_type = mh->ip6mh_type;\n\t\t\t}\n\t\t\tfl6->flowi6_proto = nexthdr;\n\t\t\treturn;\n#endif\n\t\tdefault:\n\t\t\tfl6->flowi6_proto = nexthdr;\n\t\t\treturn;\n\t\t}\n\t}\n}\n#endif\n\nint __xfrm_decode_session(struct sk_buff *skb, struct flowi *fl,\n\t\t\t  unsigned int family, int reverse)\n{\n\tswitch (family) {\n\tcase AF_INET:\n\t\tdecode_session4(skb, fl, reverse);\n\t\tbreak;\n#if IS_ENABLED(CONFIG_IPV6)\n\tcase AF_INET6:\n\t\tdecode_session6(skb, fl, reverse);\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn -EAFNOSUPPORT;\n\t}\n\n\treturn security_xfrm_decode_session(skb, &fl->flowi_secid);\n}\nEXPORT_SYMBOL(__xfrm_decode_session);\n\nstatic inline int secpath_has_nontransport(const struct sec_path *sp, int k, int *idxp)\n{\n\tfor (; k < sp->len; k++) {\n\t\tif (sp->xvec[k]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\t*idxp = k;\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint __xfrm_policy_check(struct sock *sk, int dir, struct sk_buff *skb,\n\t\t\tunsigned short family)\n{\n\tstruct net *net = dev_net(skb->dev);\n\tstruct xfrm_policy *pol;\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tint npols = 0;\n\tint xfrm_nr;\n\tint pi;\n\tint reverse;\n\tstruct flowi fl;\n\tint xerr_idx = -1;\n\tconst struct xfrm_if_cb *ifcb;\n\tstruct sec_path *sp;\n\tstruct xfrm_if *xi;\n\tu32 if_id = 0;\n\n\trcu_read_lock();\n\tifcb = xfrm_if_get_cb();\n\n\tif (ifcb) {\n\t\txi = ifcb->decode_session(skb, family);\n\t\tif (xi) {\n\t\t\tif_id = xi->p.if_id;\n\t\t\tnet = xi->net;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treverse = dir & ~XFRM_POLICY_MASK;\n\tdir &= XFRM_POLICY_MASK;\n\n\tif (__xfrm_decode_session(skb, &fl, family, reverse) < 0) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINHDRERROR);\n\t\treturn 0;\n\t}\n\n\tnf_nat_decode_session(skb, &fl, family);\n\n\t/* First, check used SA against their selectors. */\n\tsp = skb_sec_path(skb);\n\tif (sp) {\n\t\tint i;\n\n\t\tfor (i = sp->len - 1; i >= 0; i--) {\n\t\t\tstruct xfrm_state *x = sp->xvec[i];\n\t\t\tif (!xfrm_selector_match(&x->sel, &fl, family)) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATEMISMATCH);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tpol = NULL;\n\tsk = sk_to_full_sk(sk);\n\tif (sk && sk->sk_policy[dir]) {\n\t\tpol = xfrm_sk_policy_lookup(sk, dir, &fl, family, if_id);\n\t\tif (IS_ERR(pol)) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (!pol)\n\t\tpol = xfrm_policy_lookup(net, &fl, family, dir, if_id);\n\n\tif (IS_ERR(pol)) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\treturn 0;\n\t}\n\n\tif (!pol) {\n\t\tif (net->xfrm.policy_default[dir] == XFRM_USERPOLICY_BLOCK) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINNOPOLS);\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (sp && secpath_has_nontransport(sp, 0, &xerr_idx)) {\n\t\t\txfrm_secpath_reject(xerr_idx, skb, &fl);\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINNOPOLS);\n\t\t\treturn 0;\n\t\t}\n\t\treturn 1;\n\t}\n\n\tpol->curlft.use_time = ktime_get_real_seconds();\n\n\tpols[0] = pol;\n\tnpols++;\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pols[0]->type != XFRM_POLICY_TYPE_MAIN) {\n\t\tpols[1] = xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_MAIN,\n\t\t\t\t\t\t    &fl, family,\n\t\t\t\t\t\t    XFRM_POLICY_IN, if_id);\n\t\tif (pols[1]) {\n\t\t\tif (IS_ERR(pols[1])) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tpols[1]->curlft.use_time = ktime_get_real_seconds();\n\t\t\tnpols++;\n\t\t}\n\t}\n#endif\n\n\tif (pol->action == XFRM_POLICY_ALLOW) {\n\t\tstatic struct sec_path dummy;\n\t\tstruct xfrm_tmpl *tp[XFRM_MAX_DEPTH];\n\t\tstruct xfrm_tmpl *stp[XFRM_MAX_DEPTH];\n\t\tstruct xfrm_tmpl **tpp = tp;\n\t\tint ti = 0;\n\t\tint i, k;\n\n\t\tsp = skb_sec_path(skb);\n\t\tif (!sp)\n\t\t\tsp = &dummy;\n\n\t\tfor (pi = 0; pi < npols; pi++) {\n\t\t\tif (pols[pi] != pol &&\n\t\t\t    pols[pi]->action != XFRM_POLICY_ALLOW) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLBLOCK);\n\t\t\t\tgoto reject;\n\t\t\t}\n\t\t\tif (ti + pols[pi]->xfrm_nr >= XFRM_MAX_DEPTH) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINBUFFERERROR);\n\t\t\t\tgoto reject_error;\n\t\t\t}\n\t\t\tfor (i = 0; i < pols[pi]->xfrm_nr; i++)\n\t\t\t\ttpp[ti++] = &pols[pi]->xfrm_vec[i];\n\t\t}\n\t\txfrm_nr = ti;\n\n\t\tif (net->xfrm.policy_default[dir] == XFRM_USERPOLICY_BLOCK &&\n\t\t    !xfrm_nr) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINNOSTATES);\n\t\t\tgoto reject;\n\t\t}\n\n\t\tif (npols > 1) {\n\t\t\txfrm_tmpl_sort(stp, tpp, xfrm_nr, family);\n\t\t\ttpp = stp;\n\t\t}\n\n\t\t/* For each tunnel xfrm, find the first matching tmpl.\n\t\t * For each tmpl before that, find corresponding xfrm.\n\t\t * Order is _important_. Later we will implement\n\t\t * some barriers, but at the moment barriers\n\t\t * are implied between each two transformations.\n\t\t */\n\t\tfor (i = xfrm_nr-1, k = 0; i >= 0; i--) {\n\t\t\tk = xfrm_policy_ok(tpp[i], sp, k, family);\n\t\t\tif (k < 0) {\n\t\t\t\tif (k < -1)\n\t\t\t\t\t/* \"-2 - errored_index\" returned */\n\t\t\t\t\txerr_idx = -(2+k);\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINTMPLMISMATCH);\n\t\t\t\tgoto reject;\n\t\t\t}\n\t\t}\n\n\t\tif (secpath_has_nontransport(sp, k, &xerr_idx)) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINTMPLMISMATCH);\n\t\t\tgoto reject;\n\t\t}\n\n\t\txfrm_pols_put(pols, npols);\n\t\treturn 1;\n\t}\n\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLBLOCK);\n\nreject:\n\txfrm_secpath_reject(xerr_idx, skb, &fl);\nreject_error:\n\txfrm_pols_put(pols, npols);\n\treturn 0;\n}\nEXPORT_SYMBOL(__xfrm_policy_check);\n\nint __xfrm_route_forward(struct sk_buff *skb, unsigned short family)\n{\n\tstruct net *net = dev_net(skb->dev);\n\tstruct flowi fl;\n\tstruct dst_entry *dst;\n\tint res = 1;\n\n\tif (xfrm_decode_session(skb, &fl, family) < 0) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMFWDHDRERROR);\n\t\treturn 0;\n\t}\n\n\tskb_dst_force(skb);\n\tif (!skb_dst(skb)) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMFWDHDRERROR);\n\t\treturn 0;\n\t}\n\n\tdst = xfrm_lookup(net, skb_dst(skb), &fl, NULL, XFRM_LOOKUP_QUEUE);\n\tif (IS_ERR(dst)) {\n\t\tres = 0;\n\t\tdst = NULL;\n\t}\n\tskb_dst_set(skb, dst);\n\treturn res;\n}\nEXPORT_SYMBOL(__xfrm_route_forward);\n\n/* Optimize later using cookies and generation ids. */\n\nstatic struct dst_entry *xfrm_dst_check(struct dst_entry *dst, u32 cookie)\n{\n\t/* Code (such as __xfrm4_bundle_create()) sets dst->obsolete\n\t * to DST_OBSOLETE_FORCE_CHK to force all XFRM destinations to\n\t * get validated by dst_ops->check on every use.  We do this\n\t * because when a normal route referenced by an XFRM dst is\n\t * obsoleted we do not go looking around for all parent\n\t * referencing XFRM dsts so that we can invalidate them.  It\n\t * is just too much work.  Instead we make the checks here on\n\t * every use.  For example:\n\t *\n\t *\tXFRM dst A --> IPv4 dst X\n\t *\n\t * X is the \"xdst->route\" of A (X is also the \"dst->path\" of A\n\t * in this example).  If X is marked obsolete, \"A\" will not\n\t * notice.  That's what we are validating here via the\n\t * stale_bundle() check.\n\t *\n\t * When a dst is removed from the fib tree, DST_OBSOLETE_DEAD will\n\t * be marked on it.\n\t * This will force stale_bundle() to fail on any xdst bundle with\n\t * this dst linked in it.\n\t */\n\tif (dst->obsolete < 0 && !stale_bundle(dst))\n\t\treturn dst;\n\n\treturn NULL;\n}\n\nstatic int stale_bundle(struct dst_entry *dst)\n{\n\treturn !xfrm_bundle_ok((struct xfrm_dst *)dst);\n}\n\nvoid xfrm_dst_ifdown(struct dst_entry *dst, struct net_device *dev)\n{\n\twhile ((dst = xfrm_dst_child(dst)) && dst->xfrm && dst->dev == dev) {\n\t\tdst->dev = blackhole_netdev;\n\t\tdev_hold(dst->dev);\n\t\tdev_put(dev);\n\t}\n}\nEXPORT_SYMBOL(xfrm_dst_ifdown);\n\nstatic void xfrm_link_failure(struct sk_buff *skb)\n{\n\t/* Impossible. Such dst must be popped before reaches point of failure. */\n}\n\nstatic struct dst_entry *xfrm_negative_advice(struct dst_entry *dst)\n{\n\tif (dst) {\n\t\tif (dst->obsolete) {\n\t\t\tdst_release(dst);\n\t\t\tdst = NULL;\n\t\t}\n\t}\n\treturn dst;\n}\n\nstatic void xfrm_init_pmtu(struct xfrm_dst **bundle, int nr)\n{\n\twhile (nr--) {\n\t\tstruct xfrm_dst *xdst = bundle[nr];\n\t\tu32 pmtu, route_mtu_cached;\n\t\tstruct dst_entry *dst;\n\n\t\tdst = &xdst->u.dst;\n\t\tpmtu = dst_mtu(xfrm_dst_child(dst));\n\t\txdst->child_mtu_cached = pmtu;\n\n\t\tpmtu = xfrm_state_mtu(dst->xfrm, pmtu);\n\n\t\troute_mtu_cached = dst_mtu(xdst->route);\n\t\txdst->route_mtu_cached = route_mtu_cached;\n\n\t\tif (pmtu > route_mtu_cached)\n\t\t\tpmtu = route_mtu_cached;\n\n\t\tdst_metric_set(dst, RTAX_MTU, pmtu);\n\t}\n}\n\n/* Check that the bundle accepts the flow and its components are\n * still valid.\n */\n\nstatic int xfrm_bundle_ok(struct xfrm_dst *first)\n{\n\tstruct xfrm_dst *bundle[XFRM_MAX_DEPTH];\n\tstruct dst_entry *dst = &first->u.dst;\n\tstruct xfrm_dst *xdst;\n\tint start_from, nr;\n\tu32 mtu;\n\n\tif (!dst_check(xfrm_dst_path(dst), ((struct xfrm_dst *)dst)->path_cookie) ||\n\t    (dst->dev && !netif_running(dst->dev)))\n\t\treturn 0;\n\n\tif (dst->flags & DST_XFRM_QUEUE)\n\t\treturn 1;\n\n\tstart_from = nr = 0;\n\tdo {\n\t\tstruct xfrm_dst *xdst = (struct xfrm_dst *)dst;\n\n\t\tif (dst->xfrm->km.state != XFRM_STATE_VALID)\n\t\t\treturn 0;\n\t\tif (xdst->xfrm_genid != dst->xfrm->genid)\n\t\t\treturn 0;\n\t\tif (xdst->num_pols > 0 &&\n\t\t    xdst->policy_genid != atomic_read(&xdst->pols[0]->genid))\n\t\t\treturn 0;\n\n\t\tbundle[nr++] = xdst;\n\n\t\tmtu = dst_mtu(xfrm_dst_child(dst));\n\t\tif (xdst->child_mtu_cached != mtu) {\n\t\t\tstart_from = nr;\n\t\t\txdst->child_mtu_cached = mtu;\n\t\t}\n\n\t\tif (!dst_check(xdst->route, xdst->route_cookie))\n\t\t\treturn 0;\n\t\tmtu = dst_mtu(xdst->route);\n\t\tif (xdst->route_mtu_cached != mtu) {\n\t\t\tstart_from = nr;\n\t\t\txdst->route_mtu_cached = mtu;\n\t\t}\n\n\t\tdst = xfrm_dst_child(dst);\n\t} while (dst->xfrm);\n\n\tif (likely(!start_from))\n\t\treturn 1;\n\n\txdst = bundle[start_from - 1];\n\tmtu = xdst->child_mtu_cached;\n\twhile (start_from--) {\n\t\tdst = &xdst->u.dst;\n\n\t\tmtu = xfrm_state_mtu(dst->xfrm, mtu);\n\t\tif (mtu > xdst->route_mtu_cached)\n\t\t\tmtu = xdst->route_mtu_cached;\n\t\tdst_metric_set(dst, RTAX_MTU, mtu);\n\t\tif (!start_from)\n\t\t\tbreak;\n\n\t\txdst = bundle[start_from - 1];\n\t\txdst->child_mtu_cached = mtu;\n\t}\n\n\treturn 1;\n}\n\nstatic unsigned int xfrm_default_advmss(const struct dst_entry *dst)\n{\n\treturn dst_metric_advmss(xfrm_dst_path(dst));\n}\n\nstatic unsigned int xfrm_mtu(const struct dst_entry *dst)\n{\n\tunsigned int mtu = dst_metric_raw(dst, RTAX_MTU);\n\n\treturn mtu ? : dst_mtu(xfrm_dst_path(dst));\n}\n\nstatic const void *xfrm_get_dst_nexthop(const struct dst_entry *dst,\n\t\t\t\t\tconst void *daddr)\n{\n\twhile (dst->xfrm) {\n\t\tconst struct xfrm_state *xfrm = dst->xfrm;\n\n\t\tdst = xfrm_dst_child(dst);\n\n\t\tif (xfrm->props.mode == XFRM_MODE_TRANSPORT)\n\t\t\tcontinue;\n\t\tif (xfrm->type->flags & XFRM_TYPE_REMOTE_COADDR)\n\t\t\tdaddr = xfrm->coaddr;\n\t\telse if (!(xfrm->type->flags & XFRM_TYPE_LOCAL_COADDR))\n\t\t\tdaddr = &xfrm->id.daddr;\n\t}\n\treturn daddr;\n}\n\nstatic struct neighbour *xfrm_neigh_lookup(const struct dst_entry *dst,\n\t\t\t\t\t   struct sk_buff *skb,\n\t\t\t\t\t   const void *daddr)\n{\n\tconst struct dst_entry *path = xfrm_dst_path(dst);\n\n\tif (!skb)\n\t\tdaddr = xfrm_get_dst_nexthop(dst, daddr);\n\treturn path->ops->neigh_lookup(path, skb, daddr);\n}\n\nstatic void xfrm_confirm_neigh(const struct dst_entry *dst, const void *daddr)\n{\n\tconst struct dst_entry *path = xfrm_dst_path(dst);\n\n\tdaddr = xfrm_get_dst_nexthop(dst, daddr);\n\tpath->ops->confirm_neigh(path, daddr);\n}\n\nint xfrm_policy_register_afinfo(const struct xfrm_policy_afinfo *afinfo, int family)\n{\n\tint err = 0;\n\n\tif (WARN_ON(family >= ARRAY_SIZE(xfrm_policy_afinfo)))\n\t\treturn -EAFNOSUPPORT;\n\n\tspin_lock(&xfrm_policy_afinfo_lock);\n\tif (unlikely(xfrm_policy_afinfo[family] != NULL))\n\t\terr = -EEXIST;\n\telse {\n\t\tstruct dst_ops *dst_ops = afinfo->dst_ops;\n\t\tif (likely(dst_ops->kmem_cachep == NULL))\n\t\t\tdst_ops->kmem_cachep = xfrm_dst_cache;\n\t\tif (likely(dst_ops->check == NULL))\n\t\t\tdst_ops->check = xfrm_dst_check;\n\t\tif (likely(dst_ops->default_advmss == NULL))\n\t\t\tdst_ops->default_advmss = xfrm_default_advmss;\n\t\tif (likely(dst_ops->mtu == NULL))\n\t\t\tdst_ops->mtu = xfrm_mtu;\n\t\tif (likely(dst_ops->negative_advice == NULL))\n\t\t\tdst_ops->negative_advice = xfrm_negative_advice;\n\t\tif (likely(dst_ops->link_failure == NULL))\n\t\t\tdst_ops->link_failure = xfrm_link_failure;\n\t\tif (likely(dst_ops->neigh_lookup == NULL))\n\t\t\tdst_ops->neigh_lookup = xfrm_neigh_lookup;\n\t\tif (likely(!dst_ops->confirm_neigh))\n\t\t\tdst_ops->confirm_neigh = xfrm_confirm_neigh;\n\t\trcu_assign_pointer(xfrm_policy_afinfo[family], afinfo);\n\t}\n\tspin_unlock(&xfrm_policy_afinfo_lock);\n\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_policy_register_afinfo);\n\nvoid xfrm_policy_unregister_afinfo(const struct xfrm_policy_afinfo *afinfo)\n{\n\tstruct dst_ops *dst_ops = afinfo->dst_ops;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(xfrm_policy_afinfo); i++) {\n\t\tif (xfrm_policy_afinfo[i] != afinfo)\n\t\t\tcontinue;\n\t\tRCU_INIT_POINTER(xfrm_policy_afinfo[i], NULL);\n\t\tbreak;\n\t}\n\n\tsynchronize_rcu();\n\n\tdst_ops->kmem_cachep = NULL;\n\tdst_ops->check = NULL;\n\tdst_ops->negative_advice = NULL;\n\tdst_ops->link_failure = NULL;\n}\nEXPORT_SYMBOL(xfrm_policy_unregister_afinfo);\n\nvoid xfrm_if_register_cb(const struct xfrm_if_cb *ifcb)\n{\n\tspin_lock(&xfrm_if_cb_lock);\n\trcu_assign_pointer(xfrm_if_cb, ifcb);\n\tspin_unlock(&xfrm_if_cb_lock);\n}\nEXPORT_SYMBOL(xfrm_if_register_cb);\n\nvoid xfrm_if_unregister_cb(void)\n{\n\tRCU_INIT_POINTER(xfrm_if_cb, NULL);\n\tsynchronize_rcu();\n}\nEXPORT_SYMBOL(xfrm_if_unregister_cb);\n\n#ifdef CONFIG_XFRM_STATISTICS\nstatic int __net_init xfrm_statistics_init(struct net *net)\n{\n\tint rv;\n\tnet->mib.xfrm_statistics = alloc_percpu(struct linux_xfrm_mib);\n\tif (!net->mib.xfrm_statistics)\n\t\treturn -ENOMEM;\n\trv = xfrm_proc_init(net);\n\tif (rv < 0)\n\t\tfree_percpu(net->mib.xfrm_statistics);\n\treturn rv;\n}\n\nstatic void xfrm_statistics_fini(struct net *net)\n{\n\txfrm_proc_fini(net);\n\tfree_percpu(net->mib.xfrm_statistics);\n}\n#else\nstatic int __net_init xfrm_statistics_init(struct net *net)\n{\n\treturn 0;\n}\n\nstatic void xfrm_statistics_fini(struct net *net)\n{\n}\n#endif\n\nstatic int __net_init xfrm_policy_init(struct net *net)\n{\n\tunsigned int hmask, sz;\n\tint dir, err;\n\n\tif (net_eq(net, &init_net)) {\n\t\txfrm_dst_cache = kmem_cache_create(\"xfrm_dst_cache\",\n\t\t\t\t\t   sizeof(struct xfrm_dst),\n\t\t\t\t\t   0, SLAB_HWCACHE_ALIGN|SLAB_PANIC,\n\t\t\t\t\t   NULL);\n\t\terr = rhashtable_init(&xfrm_policy_inexact_table,\n\t\t\t\t      &xfrm_pol_inexact_params);\n\t\tBUG_ON(err);\n\t}\n\n\thmask = 8 - 1;\n\tsz = (hmask+1) * sizeof(struct hlist_head);\n\n\tnet->xfrm.policy_byidx = xfrm_hash_alloc(sz);\n\tif (!net->xfrm.policy_byidx)\n\t\tgoto out_byidx;\n\tnet->xfrm.policy_idx_hmask = hmask;\n\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\tnet->xfrm.policy_count[dir] = 0;\n\t\tnet->xfrm.policy_count[XFRM_POLICY_MAX + dir] = 0;\n\t\tINIT_HLIST_HEAD(&net->xfrm.policy_inexact[dir]);\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\thtab->table = xfrm_hash_alloc(sz);\n\t\tif (!htab->table)\n\t\t\tgoto out_bydst;\n\t\thtab->hmask = hmask;\n\t\thtab->dbits4 = 32;\n\t\thtab->sbits4 = 32;\n\t\thtab->dbits6 = 128;\n\t\thtab->sbits6 = 128;\n\t}\n\tnet->xfrm.policy_hthresh.lbits4 = 32;\n\tnet->xfrm.policy_hthresh.rbits4 = 32;\n\tnet->xfrm.policy_hthresh.lbits6 = 128;\n\tnet->xfrm.policy_hthresh.rbits6 = 128;\n\n\tseqlock_init(&net->xfrm.policy_hthresh.lock);\n\n\tINIT_LIST_HEAD(&net->xfrm.policy_all);\n\tINIT_LIST_HEAD(&net->xfrm.inexact_bins);\n\tINIT_WORK(&net->xfrm.policy_hash_work, xfrm_hash_resize);\n\tINIT_WORK(&net->xfrm.policy_hthresh.work, xfrm_hash_rebuild);\n\treturn 0;\n\nout_bydst:\n\tfor (dir--; dir >= 0; dir--) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\txfrm_hash_free(htab->table, sz);\n\t}\n\txfrm_hash_free(net->xfrm.policy_byidx, sz);\nout_byidx:\n\treturn -ENOMEM;\n}\n\nstatic void xfrm_policy_fini(struct net *net)\n{\n\tstruct xfrm_pol_inexact_bin *b, *t;\n\tunsigned int sz;\n\tint dir;\n\n\tflush_work(&net->xfrm.policy_hash_work);\n#ifdef CONFIG_XFRM_SUB_POLICY\n\txfrm_policy_flush(net, XFRM_POLICY_TYPE_SUB, false);\n#endif\n\txfrm_policy_flush(net, XFRM_POLICY_TYPE_MAIN, false);\n\n\tWARN_ON(!list_empty(&net->xfrm.policy_all));\n\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\tWARN_ON(!hlist_empty(&net->xfrm.policy_inexact[dir]));\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\tsz = (htab->hmask + 1) * sizeof(struct hlist_head);\n\t\tWARN_ON(!hlist_empty(htab->table));\n\t\txfrm_hash_free(htab->table, sz);\n\t}\n\n\tsz = (net->xfrm.policy_idx_hmask + 1) * sizeof(struct hlist_head);\n\tWARN_ON(!hlist_empty(net->xfrm.policy_byidx));\n\txfrm_hash_free(net->xfrm.policy_byidx, sz);\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tlist_for_each_entry_safe(b, t, &net->xfrm.inexact_bins, inexact_bins)\n\t\t__xfrm_policy_inexact_prune_bin(b, true);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n}\n\nstatic int __net_init xfrm_net_init(struct net *net)\n{\n\tint rv;\n\n\t/* Initialize the per-net locks here */\n\tspin_lock_init(&net->xfrm.xfrm_state_lock);\n\tspin_lock_init(&net->xfrm.xfrm_policy_lock);\n\tseqcount_spinlock_init(&net->xfrm.xfrm_policy_hash_generation, &net->xfrm.xfrm_policy_lock);\n\tmutex_init(&net->xfrm.xfrm_cfg_mutex);\n\tnet->xfrm.policy_default[XFRM_POLICY_IN] = XFRM_USERPOLICY_ACCEPT;\n\tnet->xfrm.policy_default[XFRM_POLICY_FWD] = XFRM_USERPOLICY_ACCEPT;\n\tnet->xfrm.policy_default[XFRM_POLICY_OUT] = XFRM_USERPOLICY_ACCEPT;\n\n\trv = xfrm_statistics_init(net);\n\tif (rv < 0)\n\t\tgoto out_statistics;\n\trv = xfrm_state_init(net);\n\tif (rv < 0)\n\t\tgoto out_state;\n\trv = xfrm_policy_init(net);\n\tif (rv < 0)\n\t\tgoto out_policy;\n\trv = xfrm_sysctl_init(net);\n\tif (rv < 0)\n\t\tgoto out_sysctl;\n\n\treturn 0;\n\nout_sysctl:\n\txfrm_policy_fini(net);\nout_policy:\n\txfrm_state_fini(net);\nout_state:\n\txfrm_statistics_fini(net);\nout_statistics:\n\treturn rv;\n}\n\nstatic void __net_exit xfrm_net_exit(struct net *net)\n{\n\txfrm_sysctl_fini(net);\n\txfrm_policy_fini(net);\n\txfrm_state_fini(net);\n\txfrm_statistics_fini(net);\n}\n\nstatic struct pernet_operations __net_initdata xfrm_net_ops = {\n\t.init = xfrm_net_init,\n\t.exit = xfrm_net_exit,\n};\n\nvoid __init xfrm_init(void)\n{\n\tregister_pernet_subsys(&xfrm_net_ops);\n\txfrm_dev_init();\n\txfrm_input_init();\n\n#ifdef CONFIG_XFRM_ESPINTCP\n\tespintcp_init();\n#endif\n}\n\n#ifdef CONFIG_AUDITSYSCALL\nstatic void xfrm_audit_common_policyinfo(struct xfrm_policy *xp,\n\t\t\t\t\t struct audit_buffer *audit_buf)\n{\n\tstruct xfrm_sec_ctx *ctx = xp->security;\n\tstruct xfrm_selector *sel = &xp->selector;\n\n\tif (ctx)\n\t\taudit_log_format(audit_buf, \" sec_alg=%u sec_doi=%u sec_obj=%s\",\n\t\t\t\t ctx->ctx_alg, ctx->ctx_doi, ctx->ctx_str);\n\n\tswitch (sel->family) {\n\tcase AF_INET:\n\t\taudit_log_format(audit_buf, \" src=%pI4\", &sel->saddr.a4);\n\t\tif (sel->prefixlen_s != 32)\n\t\t\taudit_log_format(audit_buf, \" src_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_s);\n\t\taudit_log_format(audit_buf, \" dst=%pI4\", &sel->daddr.a4);\n\t\tif (sel->prefixlen_d != 32)\n\t\t\taudit_log_format(audit_buf, \" dst_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_d);\n\t\tbreak;\n\tcase AF_INET6:\n\t\taudit_log_format(audit_buf, \" src=%pI6\", sel->saddr.a6);\n\t\tif (sel->prefixlen_s != 128)\n\t\t\taudit_log_format(audit_buf, \" src_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_s);\n\t\taudit_log_format(audit_buf, \" dst=%pI6\", sel->daddr.a6);\n\t\tif (sel->prefixlen_d != 128)\n\t\t\taudit_log_format(audit_buf, \" dst_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_d);\n\t\tbreak;\n\t}\n}\n\nvoid xfrm_audit_policy_add(struct xfrm_policy *xp, int result, bool task_valid)\n{\n\tstruct audit_buffer *audit_buf;\n\n\taudit_buf = xfrm_audit_start(\"SPD-add\");\n\tif (audit_buf == NULL)\n\t\treturn;\n\txfrm_audit_helper_usrinfo(task_valid, audit_buf);\n\taudit_log_format(audit_buf, \" res=%u\", result);\n\txfrm_audit_common_policyinfo(xp, audit_buf);\n\taudit_log_end(audit_buf);\n}\nEXPORT_SYMBOL_GPL(xfrm_audit_policy_add);\n\nvoid xfrm_audit_policy_delete(struct xfrm_policy *xp, int result,\n\t\t\t      bool task_valid)\n{\n\tstruct audit_buffer *audit_buf;\n\n\taudit_buf = xfrm_audit_start(\"SPD-delete\");\n\tif (audit_buf == NULL)\n\t\treturn;\n\txfrm_audit_helper_usrinfo(task_valid, audit_buf);\n\taudit_log_format(audit_buf, \" res=%u\", result);\n\txfrm_audit_common_policyinfo(xp, audit_buf);\n\taudit_log_end(audit_buf);\n}\nEXPORT_SYMBOL_GPL(xfrm_audit_policy_delete);\n#endif\n\n#ifdef CONFIG_XFRM_MIGRATE\nstatic bool xfrm_migrate_selector_match(const struct xfrm_selector *sel_cmp,\n\t\t\t\t\tconst struct xfrm_selector *sel_tgt)\n{\n\tif (sel_cmp->proto == IPSEC_ULPROTO_ANY) {\n\t\tif (sel_tgt->family == sel_cmp->family &&\n\t\t    xfrm_addr_equal(&sel_tgt->daddr, &sel_cmp->daddr,\n\t\t\t\t    sel_cmp->family) &&\n\t\t    xfrm_addr_equal(&sel_tgt->saddr, &sel_cmp->saddr,\n\t\t\t\t    sel_cmp->family) &&\n\t\t    sel_tgt->prefixlen_d == sel_cmp->prefixlen_d &&\n\t\t    sel_tgt->prefixlen_s == sel_cmp->prefixlen_s) {\n\t\t\treturn true;\n\t\t}\n\t} else {\n\t\tif (memcmp(sel_tgt, sel_cmp, sizeof(*sel_tgt)) == 0) {\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\nstatic struct xfrm_policy *xfrm_migrate_policy_find(const struct xfrm_selector *sel,\n\t\t\t\t\t\t    u8 dir, u8 type, struct net *net, u32 if_id)\n{\n\tstruct xfrm_policy *pol, *ret = NULL;\n\tstruct hlist_head *chain;\n\tu32 priority = ~0U;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = policy_hash_direct(net, &sel->daddr, &sel->saddr, sel->family, dir);\n\thlist_for_each_entry(pol, chain, bydst) {\n\t\tif ((if_id == 0 || pol->if_id == if_id) &&\n\t\t    xfrm_migrate_selector_match(sel, &pol->selector) &&\n\t\t    pol->type == type) {\n\t\t\tret = pol;\n\t\t\tpriority = ret->priority;\n\t\t\tbreak;\n\t\t}\n\t}\n\tchain = &net->xfrm.policy_inexact[dir];\n\thlist_for_each_entry(pol, chain, bydst_inexact_list) {\n\t\tif ((pol->priority >= priority) && ret)\n\t\t\tbreak;\n\n\t\tif ((if_id == 0 || pol->if_id == if_id) &&\n\t\t    xfrm_migrate_selector_match(sel, &pol->selector) &&\n\t\t    pol->type == type) {\n\t\t\tret = pol;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\txfrm_pol_hold(ret);\n\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\treturn ret;\n}\n\nstatic int migrate_tmpl_match(const struct xfrm_migrate *m, const struct xfrm_tmpl *t)\n{\n\tint match = 0;\n\n\tif (t->mode == m->mode && t->id.proto == m->proto &&\n\t    (m->reqid == 0 || t->reqid == m->reqid)) {\n\t\tswitch (t->mode) {\n\t\tcase XFRM_MODE_TUNNEL:\n\t\tcase XFRM_MODE_BEET:\n\t\t\tif (xfrm_addr_equal(&t->id.daddr, &m->old_daddr,\n\t\t\t\t\t    m->old_family) &&\n\t\t\t    xfrm_addr_equal(&t->saddr, &m->old_saddr,\n\t\t\t\t\t    m->old_family)) {\n\t\t\t\tmatch = 1;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XFRM_MODE_TRANSPORT:\n\t\t\t/* in case of transport mode, template does not store\n\t\t\t   any IP addresses, hence we just compare mode and\n\t\t\t   protocol */\n\t\t\tmatch = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn match;\n}\n\n/* update endpoint address(es) of template(s) */\nstatic int xfrm_policy_migrate(struct xfrm_policy *pol,\n\t\t\t       struct xfrm_migrate *m, int num_migrate)\n{\n\tstruct xfrm_migrate *mp;\n\tint i, j, n = 0;\n\n\twrite_lock_bh(&pol->lock);\n\tif (unlikely(pol->walk.dead)) {\n\t\t/* target policy has been deleted */\n\t\twrite_unlock_bh(&pol->lock);\n\t\treturn -ENOENT;\n\t}\n\n\tfor (i = 0; i < pol->xfrm_nr; i++) {\n\t\tfor (j = 0, mp = m; j < num_migrate; j++, mp++) {\n\t\t\tif (!migrate_tmpl_match(mp, &pol->xfrm_vec[i]))\n\t\t\t\tcontinue;\n\t\t\tn++;\n\t\t\tif (pol->xfrm_vec[i].mode != XFRM_MODE_TUNNEL &&\n\t\t\t    pol->xfrm_vec[i].mode != XFRM_MODE_BEET)\n\t\t\t\tcontinue;\n\t\t\t/* update endpoints */\n\t\t\tmemcpy(&pol->xfrm_vec[i].id.daddr, &mp->new_daddr,\n\t\t\t       sizeof(pol->xfrm_vec[i].id.daddr));\n\t\t\tmemcpy(&pol->xfrm_vec[i].saddr, &mp->new_saddr,\n\t\t\t       sizeof(pol->xfrm_vec[i].saddr));\n\t\t\tpol->xfrm_vec[i].encap_family = mp->new_family;\n\t\t\t/* flush bundles */\n\t\t\tatomic_inc(&pol->genid);\n\t\t}\n\t}\n\n\twrite_unlock_bh(&pol->lock);\n\n\tif (!n)\n\t\treturn -ENODATA;\n\n\treturn 0;\n}\n\nstatic int xfrm_migrate_check(const struct xfrm_migrate *m, int num_migrate)\n{\n\tint i, j;\n\n\tif (num_migrate < 1 || num_migrate > XFRM_MAX_DEPTH)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < num_migrate; i++) {\n\t\tif (xfrm_addr_any(&m[i].new_daddr, m[i].new_family) ||\n\t\t    xfrm_addr_any(&m[i].new_saddr, m[i].new_family))\n\t\t\treturn -EINVAL;\n\n\t\t/* check if there is any duplicated entry */\n\t\tfor (j = i + 1; j < num_migrate; j++) {\n\t\t\tif (!memcmp(&m[i].old_daddr, &m[j].old_daddr,\n\t\t\t\t    sizeof(m[i].old_daddr)) &&\n\t\t\t    !memcmp(&m[i].old_saddr, &m[j].old_saddr,\n\t\t\t\t    sizeof(m[i].old_saddr)) &&\n\t\t\t    m[i].proto == m[j].proto &&\n\t\t\t    m[i].mode == m[j].mode &&\n\t\t\t    m[i].reqid == m[j].reqid &&\n\t\t\t    m[i].old_family == m[j].old_family)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint xfrm_migrate(const struct xfrm_selector *sel, u8 dir, u8 type,\n\t\t struct xfrm_migrate *m, int num_migrate,\n\t\t struct xfrm_kmaddress *k, struct net *net,\n\t\t struct xfrm_encap_tmpl *encap, u32 if_id)\n{\n\tint i, err, nx_cur = 0, nx_new = 0;\n\tstruct xfrm_policy *pol = NULL;\n\tstruct xfrm_state *x, *xc;\n\tstruct xfrm_state *x_cur[XFRM_MAX_DEPTH];\n\tstruct xfrm_state *x_new[XFRM_MAX_DEPTH];\n\tstruct xfrm_migrate *mp;\n\n\t/* Stage 0 - sanity checks */\n\tif ((err = xfrm_migrate_check(m, num_migrate)) < 0)\n\t\tgoto out;\n\n\tif (dir >= XFRM_POLICY_MAX) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Stage 1 - find policy */\n\tif ((pol = xfrm_migrate_policy_find(sel, dir, type, net, if_id)) == NULL) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\t/* Stage 2 - find and update state(s) */\n\tfor (i = 0, mp = m; i < num_migrate; i++, mp++) {\n\t\tif ((x = xfrm_migrate_state_find(mp, net, if_id))) {\n\t\t\tx_cur[nx_cur] = x;\n\t\t\tnx_cur++;\n\t\t\txc = xfrm_state_migrate(x, mp, encap);\n\t\t\tif (xc) {\n\t\t\t\tx_new[nx_new] = xc;\n\t\t\t\tnx_new++;\n\t\t\t} else {\n\t\t\t\terr = -ENODATA;\n\t\t\t\tgoto restore_state;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Stage 3 - update policy */\n\tif ((err = xfrm_policy_migrate(pol, m, num_migrate)) < 0)\n\t\tgoto restore_state;\n\n\t/* Stage 4 - delete old state(s) */\n\tif (nx_cur) {\n\t\txfrm_states_put(x_cur, nx_cur);\n\t\txfrm_states_delete(x_cur, nx_cur);\n\t}\n\n\t/* Stage 5 - announce */\n\tkm_migrate(sel, dir, type, m, num_migrate, k, encap);\n\n\txfrm_pol_put(pol);\n\n\treturn 0;\nout:\n\treturn err;\n\nrestore_state:\n\tif (pol)\n\t\txfrm_pol_put(pol);\n\tif (nx_cur)\n\t\txfrm_states_put(x_cur, nx_cur);\n\tif (nx_new)\n\t\txfrm_states_delete(x_new, nx_new);\n\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_migrate);\n#endif\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0-only\n/*\n * xfrm_policy.c\n *\n * Changes:\n *\tMitsuru KANDA @USAGI\n * \tKazunori MIYAZAWA @USAGI\n * \tKunihiro Ishiguro <kunihiro@ipinfusion.com>\n * \t\tIPv6 support\n * \tKazunori MIYAZAWA @USAGI\n * \tYOSHIFUJI Hideaki\n * \t\tSplit up af-specific portion\n *\tDerek Atkins <derek@ihtfp.com>\t\tAdd the post_input processor\n *\n */\n\n#include <linux/err.h>\n#include <linux/slab.h>\n#include <linux/kmod.h>\n#include <linux/list.h>\n#include <linux/spinlock.h>\n#include <linux/workqueue.h>\n#include <linux/notifier.h>\n#include <linux/netdevice.h>\n#include <linux/netfilter.h>\n#include <linux/module.h>\n#include <linux/cache.h>\n#include <linux/cpu.h>\n#include <linux/audit.h>\n#include <linux/rhashtable.h>\n#include <linux/if_tunnel.h>\n#include <net/dst.h>\n#include <net/flow.h>\n#include <net/inet_ecn.h>\n#include <net/xfrm.h>\n#include <net/ip.h>\n#include <net/gre.h>\n#if IS_ENABLED(CONFIG_IPV6_MIP6)\n#include <net/mip6.h>\n#endif\n#ifdef CONFIG_XFRM_STATISTICS\n#include <net/snmp.h>\n#endif\n#ifdef CONFIG_XFRM_ESPINTCP\n#include <net/espintcp.h>\n#endif\n\n#include \"xfrm_hash.h\"\n\n#define XFRM_QUEUE_TMO_MIN ((unsigned)(HZ/10))\n#define XFRM_QUEUE_TMO_MAX ((unsigned)(60*HZ))\n#define XFRM_MAX_QUEUE_LEN\t100\n\nstruct xfrm_flo {\n\tstruct dst_entry *dst_orig;\n\tu8 flags;\n};\n\n/* prefixes smaller than this are stored in lists, not trees. */\n#define INEXACT_PREFIXLEN_IPV4\t16\n#define INEXACT_PREFIXLEN_IPV6\t48\n\nstruct xfrm_pol_inexact_node {\n\tstruct rb_node node;\n\tunion {\n\t\txfrm_address_t addr;\n\t\tstruct rcu_head rcu;\n\t};\n\tu8 prefixlen;\n\n\tstruct rb_root root;\n\n\t/* the policies matching this node, can be empty list */\n\tstruct hlist_head hhead;\n};\n\n/* xfrm inexact policy search tree:\n * xfrm_pol_inexact_bin = hash(dir,type,family,if_id);\n *  |\n * +---- root_d: sorted by daddr:prefix\n * |                 |\n * |        xfrm_pol_inexact_node\n * |                 |\n * |                 +- root: sorted by saddr/prefix\n * |                 |              |\n * |                 |         xfrm_pol_inexact_node\n * |                 |              |\n * |                 |              + root: unused\n * |                 |              |\n * |                 |              + hhead: saddr:daddr policies\n * |                 |\n * |                 +- coarse policies and all any:daddr policies\n * |\n * +---- root_s: sorted by saddr:prefix\n * |                 |\n * |        xfrm_pol_inexact_node\n * |                 |\n * |                 + root: unused\n * |                 |\n * |                 + hhead: saddr:any policies\n * |\n * +---- coarse policies and all any:any policies\n *\n * Lookups return four candidate lists:\n * 1. any:any list from top-level xfrm_pol_inexact_bin\n * 2. any:daddr list from daddr tree\n * 3. saddr:daddr list from 2nd level daddr tree\n * 4. saddr:any list from saddr tree\n *\n * This result set then needs to be searched for the policy with\n * the lowest priority.  If two results have same prio, youngest one wins.\n */\n\nstruct xfrm_pol_inexact_key {\n\tpossible_net_t net;\n\tu32 if_id;\n\tu16 family;\n\tu8 dir, type;\n};\n\nstruct xfrm_pol_inexact_bin {\n\tstruct xfrm_pol_inexact_key k;\n\tstruct rhash_head head;\n\t/* list containing '*:*' policies */\n\tstruct hlist_head hhead;\n\n\tseqcount_spinlock_t count;\n\t/* tree sorted by daddr/prefix */\n\tstruct rb_root root_d;\n\n\t/* tree sorted by saddr/prefix */\n\tstruct rb_root root_s;\n\n\t/* slow path below */\n\tstruct list_head inexact_bins;\n\tstruct rcu_head rcu;\n};\n\nenum xfrm_pol_inexact_candidate_type {\n\tXFRM_POL_CAND_BOTH,\n\tXFRM_POL_CAND_SADDR,\n\tXFRM_POL_CAND_DADDR,\n\tXFRM_POL_CAND_ANY,\n\n\tXFRM_POL_CAND_MAX,\n};\n\nstruct xfrm_pol_inexact_candidates {\n\tstruct hlist_head *res[XFRM_POL_CAND_MAX];\n};\n\nstatic DEFINE_SPINLOCK(xfrm_if_cb_lock);\nstatic struct xfrm_if_cb const __rcu *xfrm_if_cb __read_mostly;\n\nstatic DEFINE_SPINLOCK(xfrm_policy_afinfo_lock);\nstatic struct xfrm_policy_afinfo const __rcu *xfrm_policy_afinfo[AF_INET6 + 1]\n\t\t\t\t\t\t__read_mostly;\n\nstatic struct kmem_cache *xfrm_dst_cache __ro_after_init;\n\nstatic struct rhashtable xfrm_policy_inexact_table;\nstatic const struct rhashtable_params xfrm_pol_inexact_params;\n\nstatic void xfrm_init_pmtu(struct xfrm_dst **bundle, int nr);\nstatic int stale_bundle(struct dst_entry *dst);\nstatic int xfrm_bundle_ok(struct xfrm_dst *xdst);\nstatic void xfrm_policy_queue_process(struct timer_list *t);\n\nstatic void __xfrm_policy_link(struct xfrm_policy *pol, int dir);\nstatic struct xfrm_policy *__xfrm_policy_unlink(struct xfrm_policy *pol,\n\t\t\t\t\t\tint dir);\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup(struct net *net, u8 type, u16 family, u8 dir,\n\t\t\t   u32 if_id);\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup_rcu(struct net *net,\n\t\t\t       u8 type, u16 family, u8 dir, u32 if_id);\nstatic struct xfrm_policy *\nxfrm_policy_insert_list(struct hlist_head *chain, struct xfrm_policy *policy,\n\t\t\tbool excl);\nstatic void xfrm_policy_insert_inexact_list(struct hlist_head *chain,\n\t\t\t\t\t    struct xfrm_policy *policy);\n\nstatic bool\nxfrm_policy_find_inexact_candidates(struct xfrm_pol_inexact_candidates *cand,\n\t\t\t\t    struct xfrm_pol_inexact_bin *b,\n\t\t\t\t    const xfrm_address_t *saddr,\n\t\t\t\t    const xfrm_address_t *daddr);\n\nstatic inline bool xfrm_pol_hold_rcu(struct xfrm_policy *policy)\n{\n\treturn refcount_inc_not_zero(&policy->refcnt);\n}\n\nstatic inline bool\n__xfrm4_selector_match(const struct xfrm_selector *sel, const struct flowi *fl)\n{\n\tconst struct flowi4 *fl4 = &fl->u.ip4;\n\n\treturn  addr4_match(fl4->daddr, sel->daddr.a4, sel->prefixlen_d) &&\n\t\taddr4_match(fl4->saddr, sel->saddr.a4, sel->prefixlen_s) &&\n\t\t!((xfrm_flowi_dport(fl, &fl4->uli) ^ sel->dport) & sel->dport_mask) &&\n\t\t!((xfrm_flowi_sport(fl, &fl4->uli) ^ sel->sport) & sel->sport_mask) &&\n\t\t(fl4->flowi4_proto == sel->proto || !sel->proto) &&\n\t\t(fl4->flowi4_oif == sel->ifindex || !sel->ifindex);\n}\n\nstatic inline bool\n__xfrm6_selector_match(const struct xfrm_selector *sel, const struct flowi *fl)\n{\n\tconst struct flowi6 *fl6 = &fl->u.ip6;\n\n\treturn  addr_match(&fl6->daddr, &sel->daddr, sel->prefixlen_d) &&\n\t\taddr_match(&fl6->saddr, &sel->saddr, sel->prefixlen_s) &&\n\t\t!((xfrm_flowi_dport(fl, &fl6->uli) ^ sel->dport) & sel->dport_mask) &&\n\t\t!((xfrm_flowi_sport(fl, &fl6->uli) ^ sel->sport) & sel->sport_mask) &&\n\t\t(fl6->flowi6_proto == sel->proto || !sel->proto) &&\n\t\t(fl6->flowi6_oif == sel->ifindex || !sel->ifindex);\n}\n\nbool xfrm_selector_match(const struct xfrm_selector *sel, const struct flowi *fl,\n\t\t\t unsigned short family)\n{\n\tswitch (family) {\n\tcase AF_INET:\n\t\treturn __xfrm4_selector_match(sel, fl);\n\tcase AF_INET6:\n\t\treturn __xfrm6_selector_match(sel, fl);\n\t}\n\treturn false;\n}\n\nstatic const struct xfrm_policy_afinfo *xfrm_policy_get_afinfo(unsigned short family)\n{\n\tconst struct xfrm_policy_afinfo *afinfo;\n\n\tif (unlikely(family >= ARRAY_SIZE(xfrm_policy_afinfo)))\n\t\treturn NULL;\n\trcu_read_lock();\n\tafinfo = rcu_dereference(xfrm_policy_afinfo[family]);\n\tif (unlikely(!afinfo))\n\t\trcu_read_unlock();\n\treturn afinfo;\n}\n\n/* Called with rcu_read_lock(). */\nstatic const struct xfrm_if_cb *xfrm_if_get_cb(void)\n{\n\treturn rcu_dereference(xfrm_if_cb);\n}\n\nstruct dst_entry *__xfrm_dst_lookup(struct net *net, int tos, int oif,\n\t\t\t\t    const xfrm_address_t *saddr,\n\t\t\t\t    const xfrm_address_t *daddr,\n\t\t\t\t    int family, u32 mark)\n{\n\tconst struct xfrm_policy_afinfo *afinfo;\n\tstruct dst_entry *dst;\n\n\tafinfo = xfrm_policy_get_afinfo(family);\n\tif (unlikely(afinfo == NULL))\n\t\treturn ERR_PTR(-EAFNOSUPPORT);\n\n\tdst = afinfo->dst_lookup(net, tos, oif, saddr, daddr, mark);\n\n\trcu_read_unlock();\n\n\treturn dst;\n}\nEXPORT_SYMBOL(__xfrm_dst_lookup);\n\nstatic inline struct dst_entry *xfrm_dst_lookup(struct xfrm_state *x,\n\t\t\t\t\t\tint tos, int oif,\n\t\t\t\t\t\txfrm_address_t *prev_saddr,\n\t\t\t\t\t\txfrm_address_t *prev_daddr,\n\t\t\t\t\t\tint family, u32 mark)\n{\n\tstruct net *net = xs_net(x);\n\txfrm_address_t *saddr = &x->props.saddr;\n\txfrm_address_t *daddr = &x->id.daddr;\n\tstruct dst_entry *dst;\n\n\tif (x->type->flags & XFRM_TYPE_LOCAL_COADDR) {\n\t\tsaddr = x->coaddr;\n\t\tdaddr = prev_daddr;\n\t}\n\tif (x->type->flags & XFRM_TYPE_REMOTE_COADDR) {\n\t\tsaddr = prev_saddr;\n\t\tdaddr = x->coaddr;\n\t}\n\n\tdst = __xfrm_dst_lookup(net, tos, oif, saddr, daddr, family, mark);\n\n\tif (!IS_ERR(dst)) {\n\t\tif (prev_saddr != saddr)\n\t\t\tmemcpy(prev_saddr, saddr,  sizeof(*prev_saddr));\n\t\tif (prev_daddr != daddr)\n\t\t\tmemcpy(prev_daddr, daddr,  sizeof(*prev_daddr));\n\t}\n\n\treturn dst;\n}\n\nstatic inline unsigned long make_jiffies(long secs)\n{\n\tif (secs >= (MAX_SCHEDULE_TIMEOUT-1)/HZ)\n\t\treturn MAX_SCHEDULE_TIMEOUT-1;\n\telse\n\t\treturn secs*HZ;\n}\n\nstatic void xfrm_policy_timer(struct timer_list *t)\n{\n\tstruct xfrm_policy *xp = from_timer(xp, t, timer);\n\ttime64_t now = ktime_get_real_seconds();\n\ttime64_t next = TIME64_MAX;\n\tint warn = 0;\n\tint dir;\n\n\tread_lock(&xp->lock);\n\n\tif (unlikely(xp->walk.dead))\n\t\tgoto out;\n\n\tdir = xfrm_policy_id2dir(xp->index);\n\n\tif (xp->lft.hard_add_expires_seconds) {\n\t\ttime64_t tmo = xp->lft.hard_add_expires_seconds +\n\t\t\txp->curlft.add_time - now;\n\t\tif (tmo <= 0)\n\t\t\tgoto expired;\n\t\tif (tmo < next)\n\t\t\tnext = tmo;\n\t}\n\tif (xp->lft.hard_use_expires_seconds) {\n\t\ttime64_t tmo = xp->lft.hard_use_expires_seconds +\n\t\t\t(xp->curlft.use_time ? : xp->curlft.add_time) - now;\n\t\tif (tmo <= 0)\n\t\t\tgoto expired;\n\t\tif (tmo < next)\n\t\t\tnext = tmo;\n\t}\n\tif (xp->lft.soft_add_expires_seconds) {\n\t\ttime64_t tmo = xp->lft.soft_add_expires_seconds +\n\t\t\txp->curlft.add_time - now;\n\t\tif (tmo <= 0) {\n\t\t\twarn = 1;\n\t\t\ttmo = XFRM_KM_TIMEOUT;\n\t\t}\n\t\tif (tmo < next)\n\t\t\tnext = tmo;\n\t}\n\tif (xp->lft.soft_use_expires_seconds) {\n\t\ttime64_t tmo = xp->lft.soft_use_expires_seconds +\n\t\t\t(xp->curlft.use_time ? : xp->curlft.add_time) - now;\n\t\tif (tmo <= 0) {\n\t\t\twarn = 1;\n\t\t\ttmo = XFRM_KM_TIMEOUT;\n\t\t}\n\t\tif (tmo < next)\n\t\t\tnext = tmo;\n\t}\n\n\tif (warn)\n\t\tkm_policy_expired(xp, dir, 0, 0);\n\tif (next != TIME64_MAX &&\n\t    !mod_timer(&xp->timer, jiffies + make_jiffies(next)))\n\t\txfrm_pol_hold(xp);\n\nout:\n\tread_unlock(&xp->lock);\n\txfrm_pol_put(xp);\n\treturn;\n\nexpired:\n\tread_unlock(&xp->lock);\n\tif (!xfrm_policy_delete(xp, dir))\n\t\tkm_policy_expired(xp, dir, 1, 0);\n\txfrm_pol_put(xp);\n}\n\n/* Allocate xfrm_policy. Not used here, it is supposed to be used by pfkeyv2\n * SPD calls.\n */\n\nstruct xfrm_policy *xfrm_policy_alloc(struct net *net, gfp_t gfp)\n{\n\tstruct xfrm_policy *policy;\n\n\tpolicy = kzalloc(sizeof(struct xfrm_policy), gfp);\n\n\tif (policy) {\n\t\twrite_pnet(&policy->xp_net, net);\n\t\tINIT_LIST_HEAD(&policy->walk.all);\n\t\tINIT_HLIST_NODE(&policy->bydst_inexact_list);\n\t\tINIT_HLIST_NODE(&policy->bydst);\n\t\tINIT_HLIST_NODE(&policy->byidx);\n\t\trwlock_init(&policy->lock);\n\t\trefcount_set(&policy->refcnt, 1);\n\t\tskb_queue_head_init(&policy->polq.hold_queue);\n\t\ttimer_setup(&policy->timer, xfrm_policy_timer, 0);\n\t\ttimer_setup(&policy->polq.hold_timer,\n\t\t\t    xfrm_policy_queue_process, 0);\n\t}\n\treturn policy;\n}\nEXPORT_SYMBOL(xfrm_policy_alloc);\n\nstatic void xfrm_policy_destroy_rcu(struct rcu_head *head)\n{\n\tstruct xfrm_policy *policy = container_of(head, struct xfrm_policy, rcu);\n\n\tsecurity_xfrm_policy_free(policy->security);\n\tkfree(policy);\n}\n\n/* Destroy xfrm_policy: descendant resources must be released to this moment. */\n\nvoid xfrm_policy_destroy(struct xfrm_policy *policy)\n{\n\tBUG_ON(!policy->walk.dead);\n\n\tif (del_timer(&policy->timer) || del_timer(&policy->polq.hold_timer))\n\t\tBUG();\n\n\tcall_rcu(&policy->rcu, xfrm_policy_destroy_rcu);\n}\nEXPORT_SYMBOL(xfrm_policy_destroy);\n\n/* Rule must be locked. Release descendant resources, announce\n * entry dead. The rule must be unlinked from lists to the moment.\n */\n\nstatic void xfrm_policy_kill(struct xfrm_policy *policy)\n{\n\twrite_lock_bh(&policy->lock);\n\tpolicy->walk.dead = 1;\n\twrite_unlock_bh(&policy->lock);\n\n\tatomic_inc(&policy->genid);\n\n\tif (del_timer(&policy->polq.hold_timer))\n\t\txfrm_pol_put(policy);\n\tskb_queue_purge(&policy->polq.hold_queue);\n\n\tif (del_timer(&policy->timer))\n\t\txfrm_pol_put(policy);\n\n\txfrm_pol_put(policy);\n}\n\nstatic unsigned int xfrm_policy_hashmax __read_mostly = 1 * 1024 * 1024;\n\nstatic inline unsigned int idx_hash(struct net *net, u32 index)\n{\n\treturn __idx_hash(index, net->xfrm.policy_idx_hmask);\n}\n\n/* calculate policy hash thresholds */\nstatic void __get_hash_thresh(struct net *net,\n\t\t\t      unsigned short family, int dir,\n\t\t\t      u8 *dbits, u8 *sbits)\n{\n\tswitch (family) {\n\tcase AF_INET:\n\t\t*dbits = net->xfrm.policy_bydst[dir].dbits4;\n\t\t*sbits = net->xfrm.policy_bydst[dir].sbits4;\n\t\tbreak;\n\n\tcase AF_INET6:\n\t\t*dbits = net->xfrm.policy_bydst[dir].dbits6;\n\t\t*sbits = net->xfrm.policy_bydst[dir].sbits6;\n\t\tbreak;\n\n\tdefault:\n\t\t*dbits = 0;\n\t\t*sbits = 0;\n\t}\n}\n\nstatic struct hlist_head *policy_hash_bysel(struct net *net,\n\t\t\t\t\t    const struct xfrm_selector *sel,\n\t\t\t\t\t    unsigned short family, int dir)\n{\n\tunsigned int hmask = net->xfrm.policy_bydst[dir].hmask;\n\tunsigned int hash;\n\tu8 dbits;\n\tu8 sbits;\n\n\t__get_hash_thresh(net, family, dir, &dbits, &sbits);\n\thash = __sel_hash(sel, family, hmask, dbits, sbits);\n\n\tif (hash == hmask + 1)\n\t\treturn NULL;\n\n\treturn rcu_dereference_check(net->xfrm.policy_bydst[dir].table,\n\t\t     lockdep_is_held(&net->xfrm.xfrm_policy_lock)) + hash;\n}\n\nstatic struct hlist_head *policy_hash_direct(struct net *net,\n\t\t\t\t\t     const xfrm_address_t *daddr,\n\t\t\t\t\t     const xfrm_address_t *saddr,\n\t\t\t\t\t     unsigned short family, int dir)\n{\n\tunsigned int hmask = net->xfrm.policy_bydst[dir].hmask;\n\tunsigned int hash;\n\tu8 dbits;\n\tu8 sbits;\n\n\t__get_hash_thresh(net, family, dir, &dbits, &sbits);\n\thash = __addr_hash(daddr, saddr, family, hmask, dbits, sbits);\n\n\treturn rcu_dereference_check(net->xfrm.policy_bydst[dir].table,\n\t\t     lockdep_is_held(&net->xfrm.xfrm_policy_lock)) + hash;\n}\n\nstatic void xfrm_dst_hash_transfer(struct net *net,\n\t\t\t\t   struct hlist_head *list,\n\t\t\t\t   struct hlist_head *ndsttable,\n\t\t\t\t   unsigned int nhashmask,\n\t\t\t\t   int dir)\n{\n\tstruct hlist_node *tmp, *entry0 = NULL;\n\tstruct xfrm_policy *pol;\n\tunsigned int h0 = 0;\n\tu8 dbits;\n\tu8 sbits;\n\nredo:\n\thlist_for_each_entry_safe(pol, tmp, list, bydst) {\n\t\tunsigned int h;\n\n\t\t__get_hash_thresh(net, pol->family, dir, &dbits, &sbits);\n\t\th = __addr_hash(&pol->selector.daddr, &pol->selector.saddr,\n\t\t\t\tpol->family, nhashmask, dbits, sbits);\n\t\tif (!entry0) {\n\t\t\thlist_del_rcu(&pol->bydst);\n\t\t\thlist_add_head_rcu(&pol->bydst, ndsttable + h);\n\t\t\th0 = h;\n\t\t} else {\n\t\t\tif (h != h0)\n\t\t\t\tcontinue;\n\t\t\thlist_del_rcu(&pol->bydst);\n\t\t\thlist_add_behind_rcu(&pol->bydst, entry0);\n\t\t}\n\t\tentry0 = &pol->bydst;\n\t}\n\tif (!hlist_empty(list)) {\n\t\tentry0 = NULL;\n\t\tgoto redo;\n\t}\n}\n\nstatic void xfrm_idx_hash_transfer(struct hlist_head *list,\n\t\t\t\t   struct hlist_head *nidxtable,\n\t\t\t\t   unsigned int nhashmask)\n{\n\tstruct hlist_node *tmp;\n\tstruct xfrm_policy *pol;\n\n\thlist_for_each_entry_safe(pol, tmp, list, byidx) {\n\t\tunsigned int h;\n\n\t\th = __idx_hash(pol->index, nhashmask);\n\t\thlist_add_head(&pol->byidx, nidxtable+h);\n\t}\n}\n\nstatic unsigned long xfrm_new_hash_mask(unsigned int old_hmask)\n{\n\treturn ((old_hmask + 1) << 1) - 1;\n}\n\nstatic void xfrm_bydst_resize(struct net *net, int dir)\n{\n\tunsigned int hmask = net->xfrm.policy_bydst[dir].hmask;\n\tunsigned int nhashmask = xfrm_new_hash_mask(hmask);\n\tunsigned int nsize = (nhashmask + 1) * sizeof(struct hlist_head);\n\tstruct hlist_head *ndst = xfrm_hash_alloc(nsize);\n\tstruct hlist_head *odst;\n\tint i;\n\n\tif (!ndst)\n\t\treturn;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\twrite_seqcount_begin(&net->xfrm.xfrm_policy_hash_generation);\n\n\todst = rcu_dereference_protected(net->xfrm.policy_bydst[dir].table,\n\t\t\t\tlockdep_is_held(&net->xfrm.xfrm_policy_lock));\n\n\tfor (i = hmask; i >= 0; i--)\n\t\txfrm_dst_hash_transfer(net, odst + i, ndst, nhashmask, dir);\n\n\trcu_assign_pointer(net->xfrm.policy_bydst[dir].table, ndst);\n\tnet->xfrm.policy_bydst[dir].hmask = nhashmask;\n\n\twrite_seqcount_end(&net->xfrm.xfrm_policy_hash_generation);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tsynchronize_rcu();\n\n\txfrm_hash_free(odst, (hmask + 1) * sizeof(struct hlist_head));\n}\n\nstatic void xfrm_byidx_resize(struct net *net, int total)\n{\n\tunsigned int hmask = net->xfrm.policy_idx_hmask;\n\tunsigned int nhashmask = xfrm_new_hash_mask(hmask);\n\tunsigned int nsize = (nhashmask + 1) * sizeof(struct hlist_head);\n\tstruct hlist_head *oidx = net->xfrm.policy_byidx;\n\tstruct hlist_head *nidx = xfrm_hash_alloc(nsize);\n\tint i;\n\n\tif (!nidx)\n\t\treturn;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tfor (i = hmask; i >= 0; i--)\n\t\txfrm_idx_hash_transfer(oidx + i, nidx, nhashmask);\n\n\tnet->xfrm.policy_byidx = nidx;\n\tnet->xfrm.policy_idx_hmask = nhashmask;\n\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\txfrm_hash_free(oidx, (hmask + 1) * sizeof(struct hlist_head));\n}\n\nstatic inline int xfrm_bydst_should_resize(struct net *net, int dir, int *total)\n{\n\tunsigned int cnt = net->xfrm.policy_count[dir];\n\tunsigned int hmask = net->xfrm.policy_bydst[dir].hmask;\n\n\tif (total)\n\t\t*total += cnt;\n\n\tif ((hmask + 1) < xfrm_policy_hashmax &&\n\t    cnt > hmask)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic inline int xfrm_byidx_should_resize(struct net *net, int total)\n{\n\tunsigned int hmask = net->xfrm.policy_idx_hmask;\n\n\tif ((hmask + 1) < xfrm_policy_hashmax &&\n\t    total > hmask)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nvoid xfrm_spd_getinfo(struct net *net, struct xfrmk_spdinfo *si)\n{\n\tsi->incnt = net->xfrm.policy_count[XFRM_POLICY_IN];\n\tsi->outcnt = net->xfrm.policy_count[XFRM_POLICY_OUT];\n\tsi->fwdcnt = net->xfrm.policy_count[XFRM_POLICY_FWD];\n\tsi->inscnt = net->xfrm.policy_count[XFRM_POLICY_IN+XFRM_POLICY_MAX];\n\tsi->outscnt = net->xfrm.policy_count[XFRM_POLICY_OUT+XFRM_POLICY_MAX];\n\tsi->fwdscnt = net->xfrm.policy_count[XFRM_POLICY_FWD+XFRM_POLICY_MAX];\n\tsi->spdhcnt = net->xfrm.policy_idx_hmask;\n\tsi->spdhmcnt = xfrm_policy_hashmax;\n}\nEXPORT_SYMBOL(xfrm_spd_getinfo);\n\nstatic DEFINE_MUTEX(hash_resize_mutex);\nstatic void xfrm_hash_resize(struct work_struct *work)\n{\n\tstruct net *net = container_of(work, struct net, xfrm.policy_hash_work);\n\tint dir, total;\n\n\tmutex_lock(&hash_resize_mutex);\n\n\ttotal = 0;\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tif (xfrm_bydst_should_resize(net, dir, &total))\n\t\t\txfrm_bydst_resize(net, dir);\n\t}\n\tif (xfrm_byidx_should_resize(net, total))\n\t\txfrm_byidx_resize(net, total);\n\n\tmutex_unlock(&hash_resize_mutex);\n}\n\n/* Make sure *pol can be inserted into fastbin.\n * Useful to check that later insert requests will be successful\n * (provided xfrm_policy_lock is held throughout).\n */\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_alloc_bin(const struct xfrm_policy *pol, u8 dir)\n{\n\tstruct xfrm_pol_inexact_bin *bin, *prev;\n\tstruct xfrm_pol_inexact_key k = {\n\t\t.family = pol->family,\n\t\t.type = pol->type,\n\t\t.dir = dir,\n\t\t.if_id = pol->if_id,\n\t};\n\tstruct net *net = xp_net(pol);\n\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\twrite_pnet(&k.net, net);\n\tbin = rhashtable_lookup_fast(&xfrm_policy_inexact_table, &k,\n\t\t\t\t     xfrm_pol_inexact_params);\n\tif (bin)\n\t\treturn bin;\n\n\tbin = kzalloc(sizeof(*bin), GFP_ATOMIC);\n\tif (!bin)\n\t\treturn NULL;\n\n\tbin->k = k;\n\tINIT_HLIST_HEAD(&bin->hhead);\n\tbin->root_d = RB_ROOT;\n\tbin->root_s = RB_ROOT;\n\tseqcount_spinlock_init(&bin->count, &net->xfrm.xfrm_policy_lock);\n\n\tprev = rhashtable_lookup_get_insert_key(&xfrm_policy_inexact_table,\n\t\t\t\t\t\t&bin->k, &bin->head,\n\t\t\t\t\t\txfrm_pol_inexact_params);\n\tif (!prev) {\n\t\tlist_add(&bin->inexact_bins, &net->xfrm.inexact_bins);\n\t\treturn bin;\n\t}\n\n\tkfree(bin);\n\n\treturn IS_ERR(prev) ? NULL : prev;\n}\n\nstatic bool xfrm_pol_inexact_addr_use_any_list(const xfrm_address_t *addr,\n\t\t\t\t\t       int family, u8 prefixlen)\n{\n\tif (xfrm_addr_any(addr, family))\n\t\treturn true;\n\n\tif (family == AF_INET6 && prefixlen < INEXACT_PREFIXLEN_IPV6)\n\t\treturn true;\n\n\tif (family == AF_INET && prefixlen < INEXACT_PREFIXLEN_IPV4)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic bool\nxfrm_policy_inexact_insert_use_any_list(const struct xfrm_policy *policy)\n{\n\tconst xfrm_address_t *addr;\n\tbool saddr_any, daddr_any;\n\tu8 prefixlen;\n\n\taddr = &policy->selector.saddr;\n\tprefixlen = policy->selector.prefixlen_s;\n\n\tsaddr_any = xfrm_pol_inexact_addr_use_any_list(addr,\n\t\t\t\t\t\t       policy->family,\n\t\t\t\t\t\t       prefixlen);\n\taddr = &policy->selector.daddr;\n\tprefixlen = policy->selector.prefixlen_d;\n\tdaddr_any = xfrm_pol_inexact_addr_use_any_list(addr,\n\t\t\t\t\t\t       policy->family,\n\t\t\t\t\t\t       prefixlen);\n\treturn saddr_any && daddr_any;\n}\n\nstatic void xfrm_pol_inexact_node_init(struct xfrm_pol_inexact_node *node,\n\t\t\t\t       const xfrm_address_t *addr, u8 prefixlen)\n{\n\tnode->addr = *addr;\n\tnode->prefixlen = prefixlen;\n}\n\nstatic struct xfrm_pol_inexact_node *\nxfrm_pol_inexact_node_alloc(const xfrm_address_t *addr, u8 prefixlen)\n{\n\tstruct xfrm_pol_inexact_node *node;\n\n\tnode = kzalloc(sizeof(*node), GFP_ATOMIC);\n\tif (node)\n\t\txfrm_pol_inexact_node_init(node, addr, prefixlen);\n\n\treturn node;\n}\n\nstatic int xfrm_policy_addr_delta(const xfrm_address_t *a,\n\t\t\t\t  const xfrm_address_t *b,\n\t\t\t\t  u8 prefixlen, u16 family)\n{\n\tu32 ma, mb, mask;\n\tunsigned int pdw, pbi;\n\tint delta = 0;\n\n\tswitch (family) {\n\tcase AF_INET:\n\t\tif (prefixlen == 0)\n\t\t\treturn 0;\n\t\tmask = ~0U << (32 - prefixlen);\n\t\tma = ntohl(a->a4) & mask;\n\t\tmb = ntohl(b->a4) & mask;\n\t\tif (ma < mb)\n\t\t\tdelta = -1;\n\t\telse if (ma > mb)\n\t\t\tdelta = 1;\n\t\tbreak;\n\tcase AF_INET6:\n\t\tpdw = prefixlen >> 5;\n\t\tpbi = prefixlen & 0x1f;\n\n\t\tif (pdw) {\n\t\t\tdelta = memcmp(a->a6, b->a6, pdw << 2);\n\t\t\tif (delta)\n\t\t\t\treturn delta;\n\t\t}\n\t\tif (pbi) {\n\t\t\tmask = ~0U << (32 - pbi);\n\t\t\tma = ntohl(a->a6[pdw]) & mask;\n\t\t\tmb = ntohl(b->a6[pdw]) & mask;\n\t\t\tif (ma < mb)\n\t\t\t\tdelta = -1;\n\t\t\telse if (ma > mb)\n\t\t\t\tdelta = 1;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn delta;\n}\n\nstatic void xfrm_policy_inexact_list_reinsert(struct net *net,\n\t\t\t\t\t      struct xfrm_pol_inexact_node *n,\n\t\t\t\t\t      u16 family)\n{\n\tunsigned int matched_s, matched_d;\n\tstruct xfrm_policy *policy, *p;\n\n\tmatched_s = 0;\n\tmatched_d = 0;\n\n\tlist_for_each_entry_reverse(policy, &net->xfrm.policy_all, walk.all) {\n\t\tstruct hlist_node *newpos = NULL;\n\t\tbool matches_s, matches_d;\n\n\t\tif (!policy->bydst_reinsert)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(policy->family != family);\n\n\t\tpolicy->bydst_reinsert = false;\n\t\thlist_for_each_entry(p, &n->hhead, bydst) {\n\t\t\tif (policy->priority > p->priority)\n\t\t\t\tnewpos = &p->bydst;\n\t\t\telse if (policy->priority == p->priority &&\n\t\t\t\t policy->pos > p->pos)\n\t\t\t\tnewpos = &p->bydst;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (newpos)\n\t\t\thlist_add_behind_rcu(&policy->bydst, newpos);\n\t\telse\n\t\t\thlist_add_head_rcu(&policy->bydst, &n->hhead);\n\n\t\t/* paranoia checks follow.\n\t\t * Check that the reinserted policy matches at least\n\t\t * saddr or daddr for current node prefix.\n\t\t *\n\t\t * Matching both is fine, matching saddr in one policy\n\t\t * (but not daddr) and then matching only daddr in another\n\t\t * is a bug.\n\t\t */\n\t\tmatches_s = xfrm_policy_addr_delta(&policy->selector.saddr,\n\t\t\t\t\t\t   &n->addr,\n\t\t\t\t\t\t   n->prefixlen,\n\t\t\t\t\t\t   family) == 0;\n\t\tmatches_d = xfrm_policy_addr_delta(&policy->selector.daddr,\n\t\t\t\t\t\t   &n->addr,\n\t\t\t\t\t\t   n->prefixlen,\n\t\t\t\t\t\t   family) == 0;\n\t\tif (matches_s && matches_d)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(!matches_s && !matches_d);\n\t\tif (matches_s)\n\t\t\tmatched_s++;\n\t\tif (matches_d)\n\t\t\tmatched_d++;\n\t\tWARN_ON_ONCE(matched_s && matched_d);\n\t}\n}\n\nstatic void xfrm_policy_inexact_node_reinsert(struct net *net,\n\t\t\t\t\t      struct xfrm_pol_inexact_node *n,\n\t\t\t\t\t      struct rb_root *new,\n\t\t\t\t\t      u16 family)\n{\n\tstruct xfrm_pol_inexact_node *node;\n\tstruct rb_node **p, *parent;\n\n\t/* we should not have another subtree here */\n\tWARN_ON_ONCE(!RB_EMPTY_ROOT(&n->root));\nrestart:\n\tparent = NULL;\n\tp = &new->rb_node;\n\twhile (*p) {\n\t\tu8 prefixlen;\n\t\tint delta;\n\n\t\tparent = *p;\n\t\tnode = rb_entry(*p, struct xfrm_pol_inexact_node, node);\n\n\t\tprefixlen = min(node->prefixlen, n->prefixlen);\n\n\t\tdelta = xfrm_policy_addr_delta(&n->addr, &node->addr,\n\t\t\t\t\t       prefixlen, family);\n\t\tif (delta < 0) {\n\t\t\tp = &parent->rb_left;\n\t\t} else if (delta > 0) {\n\t\t\tp = &parent->rb_right;\n\t\t} else {\n\t\t\tbool same_prefixlen = node->prefixlen == n->prefixlen;\n\t\t\tstruct xfrm_policy *tmp;\n\n\t\t\thlist_for_each_entry(tmp, &n->hhead, bydst) {\n\t\t\t\ttmp->bydst_reinsert = true;\n\t\t\t\thlist_del_rcu(&tmp->bydst);\n\t\t\t}\n\n\t\t\tnode->prefixlen = prefixlen;\n\n\t\t\txfrm_policy_inexact_list_reinsert(net, node, family);\n\n\t\t\tif (same_prefixlen) {\n\t\t\t\tkfree_rcu(n, rcu);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\trb_erase(*p, new);\n\t\t\tkfree_rcu(n, rcu);\n\t\t\tn = node;\n\t\t\tgoto restart;\n\t\t}\n\t}\n\n\trb_link_node_rcu(&n->node, parent, p);\n\trb_insert_color(&n->node, new);\n}\n\n/* merge nodes v and n */\nstatic void xfrm_policy_inexact_node_merge(struct net *net,\n\t\t\t\t\t   struct xfrm_pol_inexact_node *v,\n\t\t\t\t\t   struct xfrm_pol_inexact_node *n,\n\t\t\t\t\t   u16 family)\n{\n\tstruct xfrm_pol_inexact_node *node;\n\tstruct xfrm_policy *tmp;\n\tstruct rb_node *rnode;\n\n\t/* To-be-merged node v has a subtree.\n\t *\n\t * Dismantle it and insert its nodes to n->root.\n\t */\n\twhile ((rnode = rb_first(&v->root)) != NULL) {\n\t\tnode = rb_entry(rnode, struct xfrm_pol_inexact_node, node);\n\t\trb_erase(&node->node, &v->root);\n\t\txfrm_policy_inexact_node_reinsert(net, node, &n->root,\n\t\t\t\t\t\t  family);\n\t}\n\n\thlist_for_each_entry(tmp, &v->hhead, bydst) {\n\t\ttmp->bydst_reinsert = true;\n\t\thlist_del_rcu(&tmp->bydst);\n\t}\n\n\txfrm_policy_inexact_list_reinsert(net, n, family);\n}\n\nstatic struct xfrm_pol_inexact_node *\nxfrm_policy_inexact_insert_node(struct net *net,\n\t\t\t\tstruct rb_root *root,\n\t\t\t\txfrm_address_t *addr,\n\t\t\t\tu16 family, u8 prefixlen, u8 dir)\n{\n\tstruct xfrm_pol_inexact_node *cached = NULL;\n\tstruct rb_node **p, *parent = NULL;\n\tstruct xfrm_pol_inexact_node *node;\n\n\tp = &root->rb_node;\n\twhile (*p) {\n\t\tint delta;\n\n\t\tparent = *p;\n\t\tnode = rb_entry(*p, struct xfrm_pol_inexact_node, node);\n\n\t\tdelta = xfrm_policy_addr_delta(addr, &node->addr,\n\t\t\t\t\t       node->prefixlen,\n\t\t\t\t\t       family);\n\t\tif (delta == 0 && prefixlen >= node->prefixlen) {\n\t\t\tWARN_ON_ONCE(cached); /* ipsec policies got lost */\n\t\t\treturn node;\n\t\t}\n\n\t\tif (delta < 0)\n\t\t\tp = &parent->rb_left;\n\t\telse\n\t\t\tp = &parent->rb_right;\n\n\t\tif (prefixlen < node->prefixlen) {\n\t\t\tdelta = xfrm_policy_addr_delta(addr, &node->addr,\n\t\t\t\t\t\t       prefixlen,\n\t\t\t\t\t\t       family);\n\t\t\tif (delta)\n\t\t\t\tcontinue;\n\n\t\t\t/* This node is a subnet of the new prefix. It needs\n\t\t\t * to be removed and re-inserted with the smaller\n\t\t\t * prefix and all nodes that are now also covered\n\t\t\t * by the reduced prefixlen.\n\t\t\t */\n\t\t\trb_erase(&node->node, root);\n\n\t\t\tif (!cached) {\n\t\t\t\txfrm_pol_inexact_node_init(node, addr,\n\t\t\t\t\t\t\t   prefixlen);\n\t\t\t\tcached = node;\n\t\t\t} else {\n\t\t\t\t/* This node also falls within the new\n\t\t\t\t * prefixlen. Merge the to-be-reinserted\n\t\t\t\t * node and this one.\n\t\t\t\t */\n\t\t\t\txfrm_policy_inexact_node_merge(net, node,\n\t\t\t\t\t\t\t       cached, family);\n\t\t\t\tkfree_rcu(node, rcu);\n\t\t\t}\n\n\t\t\t/* restart */\n\t\t\tp = &root->rb_node;\n\t\t\tparent = NULL;\n\t\t}\n\t}\n\n\tnode = cached;\n\tif (!node) {\n\t\tnode = xfrm_pol_inexact_node_alloc(addr, prefixlen);\n\t\tif (!node)\n\t\t\treturn NULL;\n\t}\n\n\trb_link_node_rcu(&node->node, parent, p);\n\trb_insert_color(&node->node, root);\n\n\treturn node;\n}\n\nstatic void xfrm_policy_inexact_gc_tree(struct rb_root *r, bool rm)\n{\n\tstruct xfrm_pol_inexact_node *node;\n\tstruct rb_node *rn = rb_first(r);\n\n\twhile (rn) {\n\t\tnode = rb_entry(rn, struct xfrm_pol_inexact_node, node);\n\n\t\txfrm_policy_inexact_gc_tree(&node->root, rm);\n\t\trn = rb_next(rn);\n\n\t\tif (!hlist_empty(&node->hhead) || !RB_EMPTY_ROOT(&node->root)) {\n\t\t\tWARN_ON_ONCE(rm);\n\t\t\tcontinue;\n\t\t}\n\n\t\trb_erase(&node->node, r);\n\t\tkfree_rcu(node, rcu);\n\t}\n}\n\nstatic void __xfrm_policy_inexact_prune_bin(struct xfrm_pol_inexact_bin *b, bool net_exit)\n{\n\twrite_seqcount_begin(&b->count);\n\txfrm_policy_inexact_gc_tree(&b->root_d, net_exit);\n\txfrm_policy_inexact_gc_tree(&b->root_s, net_exit);\n\twrite_seqcount_end(&b->count);\n\n\tif (!RB_EMPTY_ROOT(&b->root_d) || !RB_EMPTY_ROOT(&b->root_s) ||\n\t    !hlist_empty(&b->hhead)) {\n\t\tWARN_ON_ONCE(net_exit);\n\t\treturn;\n\t}\n\n\tif (rhashtable_remove_fast(&xfrm_policy_inexact_table, &b->head,\n\t\t\t\t   xfrm_pol_inexact_params) == 0) {\n\t\tlist_del(&b->inexact_bins);\n\t\tkfree_rcu(b, rcu);\n\t}\n}\n\nstatic void xfrm_policy_inexact_prune_bin(struct xfrm_pol_inexact_bin *b)\n{\n\tstruct net *net = read_pnet(&b->k.net);\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t__xfrm_policy_inexact_prune_bin(b, false);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n}\n\nstatic void __xfrm_policy_inexact_flush(struct net *net)\n{\n\tstruct xfrm_pol_inexact_bin *bin, *t;\n\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\tlist_for_each_entry_safe(bin, t, &net->xfrm.inexact_bins, inexact_bins)\n\t\t__xfrm_policy_inexact_prune_bin(bin, false);\n}\n\nstatic struct hlist_head *\nxfrm_policy_inexact_alloc_chain(struct xfrm_pol_inexact_bin *bin,\n\t\t\t\tstruct xfrm_policy *policy, u8 dir)\n{\n\tstruct xfrm_pol_inexact_node *n;\n\tstruct net *net;\n\n\tnet = xp_net(policy);\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\tif (xfrm_policy_inexact_insert_use_any_list(policy))\n\t\treturn &bin->hhead;\n\n\tif (xfrm_pol_inexact_addr_use_any_list(&policy->selector.daddr,\n\t\t\t\t\t       policy->family,\n\t\t\t\t\t       policy->selector.prefixlen_d)) {\n\t\twrite_seqcount_begin(&bin->count);\n\t\tn = xfrm_policy_inexact_insert_node(net,\n\t\t\t\t\t\t    &bin->root_s,\n\t\t\t\t\t\t    &policy->selector.saddr,\n\t\t\t\t\t\t    policy->family,\n\t\t\t\t\t\t    policy->selector.prefixlen_s,\n\t\t\t\t\t\t    dir);\n\t\twrite_seqcount_end(&bin->count);\n\t\tif (!n)\n\t\t\treturn NULL;\n\n\t\treturn &n->hhead;\n\t}\n\n\t/* daddr is fixed */\n\twrite_seqcount_begin(&bin->count);\n\tn = xfrm_policy_inexact_insert_node(net,\n\t\t\t\t\t    &bin->root_d,\n\t\t\t\t\t    &policy->selector.daddr,\n\t\t\t\t\t    policy->family,\n\t\t\t\t\t    policy->selector.prefixlen_d, dir);\n\twrite_seqcount_end(&bin->count);\n\tif (!n)\n\t\treturn NULL;\n\n\t/* saddr is wildcard */\n\tif (xfrm_pol_inexact_addr_use_any_list(&policy->selector.saddr,\n\t\t\t\t\t       policy->family,\n\t\t\t\t\t       policy->selector.prefixlen_s))\n\t\treturn &n->hhead;\n\n\twrite_seqcount_begin(&bin->count);\n\tn = xfrm_policy_inexact_insert_node(net,\n\t\t\t\t\t    &n->root,\n\t\t\t\t\t    &policy->selector.saddr,\n\t\t\t\t\t    policy->family,\n\t\t\t\t\t    policy->selector.prefixlen_s, dir);\n\twrite_seqcount_end(&bin->count);\n\tif (!n)\n\t\treturn NULL;\n\n\treturn &n->hhead;\n}\n\nstatic struct xfrm_policy *\nxfrm_policy_inexact_insert(struct xfrm_policy *policy, u8 dir, int excl)\n{\n\tstruct xfrm_pol_inexact_bin *bin;\n\tstruct xfrm_policy *delpol;\n\tstruct hlist_head *chain;\n\tstruct net *net;\n\n\tbin = xfrm_policy_inexact_alloc_bin(policy, dir);\n\tif (!bin)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tnet = xp_net(policy);\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\tchain = xfrm_policy_inexact_alloc_chain(bin, policy, dir);\n\tif (!chain) {\n\t\t__xfrm_policy_inexact_prune_bin(bin, false);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tdelpol = xfrm_policy_insert_list(chain, policy, excl);\n\tif (delpol && excl) {\n\t\t__xfrm_policy_inexact_prune_bin(bin, false);\n\t\treturn ERR_PTR(-EEXIST);\n\t}\n\n\tchain = &net->xfrm.policy_inexact[dir];\n\txfrm_policy_insert_inexact_list(chain, policy);\n\n\tif (delpol)\n\t\t__xfrm_policy_inexact_prune_bin(bin, false);\n\n\treturn delpol;\n}\n\nstatic void xfrm_hash_rebuild(struct work_struct *work)\n{\n\tstruct net *net = container_of(work, struct net,\n\t\t\t\t       xfrm.policy_hthresh.work);\n\tunsigned int hmask;\n\tstruct xfrm_policy *pol;\n\tstruct xfrm_policy *policy;\n\tstruct hlist_head *chain;\n\tstruct hlist_head *odst;\n\tstruct hlist_node *newpos;\n\tint i;\n\tint dir;\n\tunsigned seq;\n\tu8 lbits4, rbits4, lbits6, rbits6;\n\n\tmutex_lock(&hash_resize_mutex);\n\n\t/* read selector prefixlen thresholds */\n\tdo {\n\t\tseq = read_seqbegin(&net->xfrm.policy_hthresh.lock);\n\n\t\tlbits4 = net->xfrm.policy_hthresh.lbits4;\n\t\trbits4 = net->xfrm.policy_hthresh.rbits4;\n\t\tlbits6 = net->xfrm.policy_hthresh.lbits6;\n\t\trbits6 = net->xfrm.policy_hthresh.rbits6;\n\t} while (read_seqretry(&net->xfrm.policy_hthresh.lock, seq));\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\twrite_seqcount_begin(&net->xfrm.xfrm_policy_hash_generation);\n\n\t/* make sure that we can insert the indirect policies again before\n\t * we start with destructive action.\n\t */\n\tlist_for_each_entry(policy, &net->xfrm.policy_all, walk.all) {\n\t\tstruct xfrm_pol_inexact_bin *bin;\n\t\tu8 dbits, sbits;\n\n\t\tdir = xfrm_policy_id2dir(policy->index);\n\t\tif (policy->walk.dead || dir >= XFRM_POLICY_MAX)\n\t\t\tcontinue;\n\n\t\tif ((dir & XFRM_POLICY_MASK) == XFRM_POLICY_OUT) {\n\t\t\tif (policy->family == AF_INET) {\n\t\t\t\tdbits = rbits4;\n\t\t\t\tsbits = lbits4;\n\t\t\t} else {\n\t\t\t\tdbits = rbits6;\n\t\t\t\tsbits = lbits6;\n\t\t\t}\n\t\t} else {\n\t\t\tif (policy->family == AF_INET) {\n\t\t\t\tdbits = lbits4;\n\t\t\t\tsbits = rbits4;\n\t\t\t} else {\n\t\t\t\tdbits = lbits6;\n\t\t\t\tsbits = rbits6;\n\t\t\t}\n\t\t}\n\n\t\tif (policy->selector.prefixlen_d < dbits ||\n\t\t    policy->selector.prefixlen_s < sbits)\n\t\t\tcontinue;\n\n\t\tbin = xfrm_policy_inexact_alloc_bin(policy, dir);\n\t\tif (!bin)\n\t\t\tgoto out_unlock;\n\n\t\tif (!xfrm_policy_inexact_alloc_chain(bin, policy, dir))\n\t\t\tgoto out_unlock;\n\t}\n\n\t/* reset the bydst and inexact table in all directions */\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tstruct hlist_node *n;\n\n\t\thlist_for_each_entry_safe(policy, n,\n\t\t\t\t\t  &net->xfrm.policy_inexact[dir],\n\t\t\t\t\t  bydst_inexact_list) {\n\t\t\thlist_del_rcu(&policy->bydst);\n\t\t\thlist_del_init(&policy->bydst_inexact_list);\n\t\t}\n\n\t\thmask = net->xfrm.policy_bydst[dir].hmask;\n\t\todst = net->xfrm.policy_bydst[dir].table;\n\t\tfor (i = hmask; i >= 0; i--) {\n\t\t\thlist_for_each_entry_safe(policy, n, odst + i, bydst)\n\t\t\t\thlist_del_rcu(&policy->bydst);\n\t\t}\n\t\tif ((dir & XFRM_POLICY_MASK) == XFRM_POLICY_OUT) {\n\t\t\t/* dir out => dst = remote, src = local */\n\t\t\tnet->xfrm.policy_bydst[dir].dbits4 = rbits4;\n\t\t\tnet->xfrm.policy_bydst[dir].sbits4 = lbits4;\n\t\t\tnet->xfrm.policy_bydst[dir].dbits6 = rbits6;\n\t\t\tnet->xfrm.policy_bydst[dir].sbits6 = lbits6;\n\t\t} else {\n\t\t\t/* dir in/fwd => dst = local, src = remote */\n\t\t\tnet->xfrm.policy_bydst[dir].dbits4 = lbits4;\n\t\t\tnet->xfrm.policy_bydst[dir].sbits4 = rbits4;\n\t\t\tnet->xfrm.policy_bydst[dir].dbits6 = lbits6;\n\t\t\tnet->xfrm.policy_bydst[dir].sbits6 = rbits6;\n\t\t}\n\t}\n\n\t/* re-insert all policies by order of creation */\n\tlist_for_each_entry_reverse(policy, &net->xfrm.policy_all, walk.all) {\n\t\tif (policy->walk.dead)\n\t\t\tcontinue;\n\t\tdir = xfrm_policy_id2dir(policy->index);\n\t\tif (dir >= XFRM_POLICY_MAX) {\n\t\t\t/* skip socket policies */\n\t\t\tcontinue;\n\t\t}\n\t\tnewpos = NULL;\n\t\tchain = policy_hash_bysel(net, &policy->selector,\n\t\t\t\t\t  policy->family, dir);\n\n\t\tif (!chain) {\n\t\t\tvoid *p = xfrm_policy_inexact_insert(policy, dir, 0);\n\n\t\t\tWARN_ONCE(IS_ERR(p), \"reinsert: %ld\\n\", PTR_ERR(p));\n\t\t\tcontinue;\n\t\t}\n\n\t\thlist_for_each_entry(pol, chain, bydst) {\n\t\t\tif (policy->priority >= pol->priority)\n\t\t\t\tnewpos = &pol->bydst;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\t\tif (newpos)\n\t\t\thlist_add_behind_rcu(&policy->bydst, newpos);\n\t\telse\n\t\t\thlist_add_head_rcu(&policy->bydst, chain);\n\t}\n\nout_unlock:\n\t__xfrm_policy_inexact_flush(net);\n\twrite_seqcount_end(&net->xfrm.xfrm_policy_hash_generation);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tmutex_unlock(&hash_resize_mutex);\n}\n\nvoid xfrm_policy_hash_rebuild(struct net *net)\n{\n\tschedule_work(&net->xfrm.policy_hthresh.work);\n}\nEXPORT_SYMBOL(xfrm_policy_hash_rebuild);\n\n/* Generate new index... KAME seems to generate them ordered by cost\n * of an absolute inpredictability of ordering of rules. This will not pass. */\nstatic u32 xfrm_gen_index(struct net *net, int dir, u32 index)\n{\n\tstatic u32 idx_generator;\n\n\tfor (;;) {\n\t\tstruct hlist_head *list;\n\t\tstruct xfrm_policy *p;\n\t\tu32 idx;\n\t\tint found;\n\n\t\tif (!index) {\n\t\t\tidx = (idx_generator | dir);\n\t\t\tidx_generator += 8;\n\t\t} else {\n\t\t\tidx = index;\n\t\t\tindex = 0;\n\t\t}\n\n\t\tif (idx == 0)\n\t\t\tidx = 8;\n\t\tlist = net->xfrm.policy_byidx + idx_hash(net, idx);\n\t\tfound = 0;\n\t\thlist_for_each_entry(p, list, byidx) {\n\t\t\tif (p->index == idx) {\n\t\t\t\tfound = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!found)\n\t\t\treturn idx;\n\t}\n}\n\nstatic inline int selector_cmp(struct xfrm_selector *s1, struct xfrm_selector *s2)\n{\n\tu32 *p1 = (u32 *) s1;\n\tu32 *p2 = (u32 *) s2;\n\tint len = sizeof(struct xfrm_selector) / sizeof(u32);\n\tint i;\n\n\tfor (i = 0; i < len; i++) {\n\t\tif (p1[i] != p2[i])\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic void xfrm_policy_requeue(struct xfrm_policy *old,\n\t\t\t\tstruct xfrm_policy *new)\n{\n\tstruct xfrm_policy_queue *pq = &old->polq;\n\tstruct sk_buff_head list;\n\n\tif (skb_queue_empty(&pq->hold_queue))\n\t\treturn;\n\n\t__skb_queue_head_init(&list);\n\n\tspin_lock_bh(&pq->hold_queue.lock);\n\tskb_queue_splice_init(&pq->hold_queue, &list);\n\tif (del_timer(&pq->hold_timer))\n\t\txfrm_pol_put(old);\n\tspin_unlock_bh(&pq->hold_queue.lock);\n\n\tpq = &new->polq;\n\n\tspin_lock_bh(&pq->hold_queue.lock);\n\tskb_queue_splice(&list, &pq->hold_queue);\n\tpq->timeout = XFRM_QUEUE_TMO_MIN;\n\tif (!mod_timer(&pq->hold_timer, jiffies))\n\t\txfrm_pol_hold(new);\n\tspin_unlock_bh(&pq->hold_queue.lock);\n}\n\nstatic inline bool xfrm_policy_mark_match(const struct xfrm_mark *mark,\n\t\t\t\t\t  struct xfrm_policy *pol)\n{\n\treturn mark->v == pol->mark.v && mark->m == pol->mark.m;\n}\n\nstatic u32 xfrm_pol_bin_key(const void *data, u32 len, u32 seed)\n{\n\tconst struct xfrm_pol_inexact_key *k = data;\n\tu32 a = k->type << 24 | k->dir << 16 | k->family;\n\n\treturn jhash_3words(a, k->if_id, net_hash_mix(read_pnet(&k->net)),\n\t\t\t    seed);\n}\n\nstatic u32 xfrm_pol_bin_obj(const void *data, u32 len, u32 seed)\n{\n\tconst struct xfrm_pol_inexact_bin *b = data;\n\n\treturn xfrm_pol_bin_key(&b->k, 0, seed);\n}\n\nstatic int xfrm_pol_bin_cmp(struct rhashtable_compare_arg *arg,\n\t\t\t    const void *ptr)\n{\n\tconst struct xfrm_pol_inexact_key *key = arg->key;\n\tconst struct xfrm_pol_inexact_bin *b = ptr;\n\tint ret;\n\n\tif (!net_eq(read_pnet(&b->k.net), read_pnet(&key->net)))\n\t\treturn -1;\n\n\tret = b->k.dir ^ key->dir;\n\tif (ret)\n\t\treturn ret;\n\n\tret = b->k.type ^ key->type;\n\tif (ret)\n\t\treturn ret;\n\n\tret = b->k.family ^ key->family;\n\tif (ret)\n\t\treturn ret;\n\n\treturn b->k.if_id ^ key->if_id;\n}\n\nstatic const struct rhashtable_params xfrm_pol_inexact_params = {\n\t.head_offset\t\t= offsetof(struct xfrm_pol_inexact_bin, head),\n\t.hashfn\t\t\t= xfrm_pol_bin_key,\n\t.obj_hashfn\t\t= xfrm_pol_bin_obj,\n\t.obj_cmpfn\t\t= xfrm_pol_bin_cmp,\n\t.automatic_shrinking\t= true,\n};\n\nstatic void xfrm_policy_insert_inexact_list(struct hlist_head *chain,\n\t\t\t\t\t    struct xfrm_policy *policy)\n{\n\tstruct xfrm_policy *pol, *delpol = NULL;\n\tstruct hlist_node *newpos = NULL;\n\tint i = 0;\n\n\thlist_for_each_entry(pol, chain, bydst_inexact_list) {\n\t\tif (pol->type == policy->type &&\n\t\t    pol->if_id == policy->if_id &&\n\t\t    !selector_cmp(&pol->selector, &policy->selector) &&\n\t\t    xfrm_policy_mark_match(&policy->mark, pol) &&\n\t\t    xfrm_sec_ctx_match(pol->security, policy->security) &&\n\t\t    !WARN_ON(delpol)) {\n\t\t\tdelpol = pol;\n\t\t\tif (policy->priority > pol->priority)\n\t\t\t\tcontinue;\n\t\t} else if (policy->priority >= pol->priority) {\n\t\t\tnewpos = &pol->bydst_inexact_list;\n\t\t\tcontinue;\n\t\t}\n\t\tif (delpol)\n\t\t\tbreak;\n\t}\n\n\tif (newpos)\n\t\thlist_add_behind_rcu(&policy->bydst_inexact_list, newpos);\n\telse\n\t\thlist_add_head_rcu(&policy->bydst_inexact_list, chain);\n\n\thlist_for_each_entry(pol, chain, bydst_inexact_list) {\n\t\tpol->pos = i;\n\t\ti++;\n\t}\n}\n\nstatic struct xfrm_policy *xfrm_policy_insert_list(struct hlist_head *chain,\n\t\t\t\t\t\t   struct xfrm_policy *policy,\n\t\t\t\t\t\t   bool excl)\n{\n\tstruct xfrm_policy *pol, *newpos = NULL, *delpol = NULL;\n\n\thlist_for_each_entry(pol, chain, bydst) {\n\t\tif (pol->type == policy->type &&\n\t\t    pol->if_id == policy->if_id &&\n\t\t    !selector_cmp(&pol->selector, &policy->selector) &&\n\t\t    xfrm_policy_mark_match(&policy->mark, pol) &&\n\t\t    xfrm_sec_ctx_match(pol->security, policy->security) &&\n\t\t    !WARN_ON(delpol)) {\n\t\t\tif (excl)\n\t\t\t\treturn ERR_PTR(-EEXIST);\n\t\t\tdelpol = pol;\n\t\t\tif (policy->priority > pol->priority)\n\t\t\t\tcontinue;\n\t\t} else if (policy->priority >= pol->priority) {\n\t\t\tnewpos = pol;\n\t\t\tcontinue;\n\t\t}\n\t\tif (delpol)\n\t\t\tbreak;\n\t}\n\n\tif (newpos)\n\t\thlist_add_behind_rcu(&policy->bydst, &newpos->bydst);\n\telse\n\t\thlist_add_head_rcu(&policy->bydst, chain);\n\n\treturn delpol;\n}\n\nint xfrm_policy_insert(int dir, struct xfrm_policy *policy, int excl)\n{\n\tstruct net *net = xp_net(policy);\n\tstruct xfrm_policy *delpol;\n\tstruct hlist_head *chain;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = policy_hash_bysel(net, &policy->selector, policy->family, dir);\n\tif (chain)\n\t\tdelpol = xfrm_policy_insert_list(chain, policy, excl);\n\telse\n\t\tdelpol = xfrm_policy_inexact_insert(policy, dir, excl);\n\n\tif (IS_ERR(delpol)) {\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\treturn PTR_ERR(delpol);\n\t}\n\n\t__xfrm_policy_link(policy, dir);\n\n\t/* After previous checking, family can either be AF_INET or AF_INET6 */\n\tif (policy->family == AF_INET)\n\t\trt_genid_bump_ipv4(net);\n\telse\n\t\trt_genid_bump_ipv6(net);\n\n\tif (delpol) {\n\t\txfrm_policy_requeue(delpol, policy);\n\t\t__xfrm_policy_unlink(delpol, dir);\n\t}\n\tpolicy->index = delpol ? delpol->index : xfrm_gen_index(net, dir, policy->index);\n\thlist_add_head(&policy->byidx, net->xfrm.policy_byidx+idx_hash(net, policy->index));\n\tpolicy->curlft.add_time = ktime_get_real_seconds();\n\tpolicy->curlft.use_time = 0;\n\tif (!mod_timer(&policy->timer, jiffies + HZ))\n\t\txfrm_pol_hold(policy);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (delpol)\n\t\txfrm_policy_kill(delpol);\n\telse if (xfrm_bydst_should_resize(net, dir, NULL))\n\t\tschedule_work(&net->xfrm.policy_hash_work);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(xfrm_policy_insert);\n\nstatic struct xfrm_policy *\n__xfrm_policy_bysel_ctx(struct hlist_head *chain, const struct xfrm_mark *mark,\n\t\t\tu32 if_id, u8 type, int dir, struct xfrm_selector *sel,\n\t\t\tstruct xfrm_sec_ctx *ctx)\n{\n\tstruct xfrm_policy *pol;\n\n\tif (!chain)\n\t\treturn NULL;\n\n\thlist_for_each_entry(pol, chain, bydst) {\n\t\tif (pol->type == type &&\n\t\t    pol->if_id == if_id &&\n\t\t    xfrm_policy_mark_match(mark, pol) &&\n\t\t    !selector_cmp(sel, &pol->selector) &&\n\t\t    xfrm_sec_ctx_match(ctx, pol->security))\n\t\t\treturn pol;\n\t}\n\n\treturn NULL;\n}\n\nstruct xfrm_policy *\nxfrm_policy_bysel_ctx(struct net *net, const struct xfrm_mark *mark, u32 if_id,\n\t\t      u8 type, int dir, struct xfrm_selector *sel,\n\t\t      struct xfrm_sec_ctx *ctx, int delete, int *err)\n{\n\tstruct xfrm_pol_inexact_bin *bin = NULL;\n\tstruct xfrm_policy *pol, *ret = NULL;\n\tstruct hlist_head *chain;\n\n\t*err = 0;\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = policy_hash_bysel(net, sel, sel->family, dir);\n\tif (!chain) {\n\t\tstruct xfrm_pol_inexact_candidates cand;\n\t\tint i;\n\n\t\tbin = xfrm_policy_inexact_lookup(net, type,\n\t\t\t\t\t\t sel->family, dir, if_id);\n\t\tif (!bin) {\n\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (!xfrm_policy_find_inexact_candidates(&cand, bin,\n\t\t\t\t\t\t\t &sel->saddr,\n\t\t\t\t\t\t\t &sel->daddr)) {\n\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tpol = NULL;\n\t\tfor (i = 0; i < ARRAY_SIZE(cand.res); i++) {\n\t\t\tstruct xfrm_policy *tmp;\n\n\t\t\ttmp = __xfrm_policy_bysel_ctx(cand.res[i], mark,\n\t\t\t\t\t\t      if_id, type, dir,\n\t\t\t\t\t\t      sel, ctx);\n\t\t\tif (!tmp)\n\t\t\t\tcontinue;\n\n\t\t\tif (!pol || tmp->pos < pol->pos)\n\t\t\t\tpol = tmp;\n\t\t}\n\t} else {\n\t\tpol = __xfrm_policy_bysel_ctx(chain, mark, if_id, type, dir,\n\t\t\t\t\t      sel, ctx);\n\t}\n\n\tif (pol) {\n\t\txfrm_pol_hold(pol);\n\t\tif (delete) {\n\t\t\t*err = security_xfrm_policy_delete(pol->security);\n\t\t\tif (*err) {\n\t\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\t\treturn pol;\n\t\t\t}\n\t\t\t__xfrm_policy_unlink(pol, dir);\n\t\t}\n\t\tret = pol;\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (ret && delete)\n\t\txfrm_policy_kill(ret);\n\tif (bin && delete)\n\t\txfrm_policy_inexact_prune_bin(bin);\n\treturn ret;\n}\nEXPORT_SYMBOL(xfrm_policy_bysel_ctx);\n\nstruct xfrm_policy *\nxfrm_policy_byid(struct net *net, const struct xfrm_mark *mark, u32 if_id,\n\t\t u8 type, int dir, u32 id, int delete, int *err)\n{\n\tstruct xfrm_policy *pol, *ret;\n\tstruct hlist_head *chain;\n\n\t*err = -ENOENT;\n\tif (xfrm_policy_id2dir(id) != dir)\n\t\treturn NULL;\n\n\t*err = 0;\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = net->xfrm.policy_byidx + idx_hash(net, id);\n\tret = NULL;\n\thlist_for_each_entry(pol, chain, byidx) {\n\t\tif (pol->type == type && pol->index == id &&\n\t\t    pol->if_id == if_id && xfrm_policy_mark_match(mark, pol)) {\n\t\t\txfrm_pol_hold(pol);\n\t\t\tif (delete) {\n\t\t\t\t*err = security_xfrm_policy_delete(\n\t\t\t\t\t\t\t\tpol->security);\n\t\t\t\tif (*err) {\n\t\t\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\t\t\treturn pol;\n\t\t\t\t}\n\t\t\t\t__xfrm_policy_unlink(pol, dir);\n\t\t\t}\n\t\t\tret = pol;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (ret && delete)\n\t\txfrm_policy_kill(ret);\n\treturn ret;\n}\nEXPORT_SYMBOL(xfrm_policy_byid);\n\n#ifdef CONFIG_SECURITY_NETWORK_XFRM\nstatic inline int\nxfrm_policy_flush_secctx_check(struct net *net, u8 type, bool task_valid)\n{\n\tstruct xfrm_policy *pol;\n\tint err = 0;\n\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tif (pol->walk.dead ||\n\t\t    xfrm_policy_id2dir(pol->index) >= XFRM_POLICY_MAX ||\n\t\t    pol->type != type)\n\t\t\tcontinue;\n\n\t\terr = security_xfrm_policy_delete(pol->security);\n\t\tif (err) {\n\t\t\txfrm_audit_policy_delete(pol, 0, task_valid);\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn err;\n}\n#else\nstatic inline int\nxfrm_policy_flush_secctx_check(struct net *net, u8 type, bool task_valid)\n{\n\treturn 0;\n}\n#endif\n\nint xfrm_policy_flush(struct net *net, u8 type, bool task_valid)\n{\n\tint dir, err = 0, cnt = 0;\n\tstruct xfrm_policy *pol;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\n\terr = xfrm_policy_flush_secctx_check(net, type, task_valid);\n\tif (err)\n\t\tgoto out;\n\nagain:\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tdir = xfrm_policy_id2dir(pol->index);\n\t\tif (pol->walk.dead ||\n\t\t    dir >= XFRM_POLICY_MAX ||\n\t\t    pol->type != type)\n\t\t\tcontinue;\n\n\t\t__xfrm_policy_unlink(pol, dir);\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tcnt++;\n\t\txfrm_audit_policy_delete(pol, 1, task_valid);\n\t\txfrm_policy_kill(pol);\n\t\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tgoto again;\n\t}\n\tif (cnt)\n\t\t__xfrm_policy_inexact_flush(net);\n\telse\n\t\terr = -ESRCH;\nout:\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_policy_flush);\n\nint xfrm_policy_walk(struct net *net, struct xfrm_policy_walk *walk,\n\t\t     int (*func)(struct xfrm_policy *, int, int, void*),\n\t\t     void *data)\n{\n\tstruct xfrm_policy *pol;\n\tstruct xfrm_policy_walk_entry *x;\n\tint error = 0;\n\n\tif (walk->type >= XFRM_POLICY_TYPE_MAX &&\n\t    walk->type != XFRM_POLICY_TYPE_ANY)\n\t\treturn -EINVAL;\n\n\tif (list_empty(&walk->walk.all) && walk->seq != 0)\n\t\treturn 0;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tif (list_empty(&walk->walk.all))\n\t\tx = list_first_entry(&net->xfrm.policy_all, struct xfrm_policy_walk_entry, all);\n\telse\n\t\tx = list_first_entry(&walk->walk.all,\n\t\t\t\t     struct xfrm_policy_walk_entry, all);\n\n\tlist_for_each_entry_from(x, &net->xfrm.policy_all, all) {\n\t\tif (x->dead)\n\t\t\tcontinue;\n\t\tpol = container_of(x, struct xfrm_policy, walk);\n\t\tif (walk->type != XFRM_POLICY_TYPE_ANY &&\n\t\t    walk->type != pol->type)\n\t\t\tcontinue;\n\t\terror = func(pol, xfrm_policy_id2dir(pol->index),\n\t\t\t     walk->seq, data);\n\t\tif (error) {\n\t\t\tlist_move_tail(&walk->walk.all, &x->all);\n\t\t\tgoto out;\n\t\t}\n\t\twalk->seq++;\n\t}\n\tif (walk->seq == 0) {\n\t\terror = -ENOENT;\n\t\tgoto out;\n\t}\n\tlist_del_init(&walk->walk.all);\nout:\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\treturn error;\n}\nEXPORT_SYMBOL(xfrm_policy_walk);\n\nvoid xfrm_policy_walk_init(struct xfrm_policy_walk *walk, u8 type)\n{\n\tINIT_LIST_HEAD(&walk->walk.all);\n\twalk->walk.dead = 1;\n\twalk->type = type;\n\twalk->seq = 0;\n}\nEXPORT_SYMBOL(xfrm_policy_walk_init);\n\nvoid xfrm_policy_walk_done(struct xfrm_policy_walk *walk, struct net *net)\n{\n\tif (list_empty(&walk->walk.all))\n\t\treturn;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock); /*FIXME where is net? */\n\tlist_del(&walk->walk.all);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n}\nEXPORT_SYMBOL(xfrm_policy_walk_done);\n\n/*\n * Find policy to apply to this flow.\n *\n * Returns 0 if policy found, else an -errno.\n */\nstatic int xfrm_policy_match(const struct xfrm_policy *pol,\n\t\t\t     const struct flowi *fl,\n\t\t\t     u8 type, u16 family, int dir, u32 if_id)\n{\n\tconst struct xfrm_selector *sel = &pol->selector;\n\tint ret = -ESRCH;\n\tbool match;\n\n\tif (pol->family != family ||\n\t    pol->if_id != if_id ||\n\t    (fl->flowi_mark & pol->mark.m) != pol->mark.v ||\n\t    pol->type != type)\n\t\treturn ret;\n\n\tmatch = xfrm_selector_match(sel, fl, family);\n\tif (match)\n\t\tret = security_xfrm_policy_lookup(pol->security, fl->flowi_secid);\n\treturn ret;\n}\n\nstatic struct xfrm_pol_inexact_node *\nxfrm_policy_lookup_inexact_addr(const struct rb_root *r,\n\t\t\t\tseqcount_spinlock_t *count,\n\t\t\t\tconst xfrm_address_t *addr, u16 family)\n{\n\tconst struct rb_node *parent;\n\tint seq;\n\nagain:\n\tseq = read_seqcount_begin(count);\n\n\tparent = rcu_dereference_raw(r->rb_node);\n\twhile (parent) {\n\t\tstruct xfrm_pol_inexact_node *node;\n\t\tint delta;\n\n\t\tnode = rb_entry(parent, struct xfrm_pol_inexact_node, node);\n\n\t\tdelta = xfrm_policy_addr_delta(addr, &node->addr,\n\t\t\t\t\t       node->prefixlen, family);\n\t\tif (delta < 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_left);\n\t\t\tcontinue;\n\t\t} else if (delta > 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_right);\n\t\t\tcontinue;\n\t\t}\n\n\t\treturn node;\n\t}\n\n\tif (read_seqcount_retry(count, seq))\n\t\tgoto again;\n\n\treturn NULL;\n}\n\nstatic bool\nxfrm_policy_find_inexact_candidates(struct xfrm_pol_inexact_candidates *cand,\n\t\t\t\t    struct xfrm_pol_inexact_bin *b,\n\t\t\t\t    const xfrm_address_t *saddr,\n\t\t\t\t    const xfrm_address_t *daddr)\n{\n\tstruct xfrm_pol_inexact_node *n;\n\tu16 family;\n\n\tif (!b)\n\t\treturn false;\n\n\tfamily = b->k.family;\n\tmemset(cand, 0, sizeof(*cand));\n\tcand->res[XFRM_POL_CAND_ANY] = &b->hhead;\n\n\tn = xfrm_policy_lookup_inexact_addr(&b->root_d, &b->count, daddr,\n\t\t\t\t\t    family);\n\tif (n) {\n\t\tcand->res[XFRM_POL_CAND_DADDR] = &n->hhead;\n\t\tn = xfrm_policy_lookup_inexact_addr(&n->root, &b->count, saddr,\n\t\t\t\t\t\t    family);\n\t\tif (n)\n\t\t\tcand->res[XFRM_POL_CAND_BOTH] = &n->hhead;\n\t}\n\n\tn = xfrm_policy_lookup_inexact_addr(&b->root_s, &b->count, saddr,\n\t\t\t\t\t    family);\n\tif (n)\n\t\tcand->res[XFRM_POL_CAND_SADDR] = &n->hhead;\n\n\treturn true;\n}\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup_rcu(struct net *net, u8 type, u16 family,\n\t\t\t       u8 dir, u32 if_id)\n{\n\tstruct xfrm_pol_inexact_key k = {\n\t\t.family = family,\n\t\t.type = type,\n\t\t.dir = dir,\n\t\t.if_id = if_id,\n\t};\n\n\twrite_pnet(&k.net, net);\n\n\treturn rhashtable_lookup(&xfrm_policy_inexact_table, &k,\n\t\t\t\t xfrm_pol_inexact_params);\n}\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup(struct net *net, u8 type, u16 family,\n\t\t\t   u8 dir, u32 if_id)\n{\n\tstruct xfrm_pol_inexact_bin *bin;\n\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\trcu_read_lock();\n\tbin = xfrm_policy_inexact_lookup_rcu(net, type, family, dir, if_id);\n\trcu_read_unlock();\n\n\treturn bin;\n}\n\nstatic struct xfrm_policy *\n__xfrm_policy_eval_candidates(struct hlist_head *chain,\n\t\t\t      struct xfrm_policy *prefer,\n\t\t\t      const struct flowi *fl,\n\t\t\t      u8 type, u16 family, int dir, u32 if_id)\n{\n\tu32 priority = prefer ? prefer->priority : ~0u;\n\tstruct xfrm_policy *pol;\n\n\tif (!chain)\n\t\treturn NULL;\n\n\thlist_for_each_entry_rcu(pol, chain, bydst) {\n\t\tint err;\n\n\t\tif (pol->priority > priority)\n\t\t\tbreak;\n\n\t\terr = xfrm_policy_match(pol, fl, type, family, dir, if_id);\n\t\tif (err) {\n\t\t\tif (err != -ESRCH)\n\t\t\t\treturn ERR_PTR(err);\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (prefer) {\n\t\t\t/* matches.  Is it older than *prefer? */\n\t\t\tif (pol->priority == priority &&\n\t\t\t    prefer->pos < pol->pos)\n\t\t\t\treturn prefer;\n\t\t}\n\n\t\treturn pol;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct xfrm_policy *\nxfrm_policy_eval_candidates(struct xfrm_pol_inexact_candidates *cand,\n\t\t\t    struct xfrm_policy *prefer,\n\t\t\t    const struct flowi *fl,\n\t\t\t    u8 type, u16 family, int dir, u32 if_id)\n{\n\tstruct xfrm_policy *tmp;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(cand->res); i++) {\n\t\ttmp = __xfrm_policy_eval_candidates(cand->res[i],\n\t\t\t\t\t\t    prefer,\n\t\t\t\t\t\t    fl, type, family, dir,\n\t\t\t\t\t\t    if_id);\n\t\tif (!tmp)\n\t\t\tcontinue;\n\n\t\tif (IS_ERR(tmp))\n\t\t\treturn tmp;\n\t\tprefer = tmp;\n\t}\n\n\treturn prefer;\n}\n\nstatic struct xfrm_policy *xfrm_policy_lookup_bytype(struct net *net, u8 type,\n\t\t\t\t\t\t     const struct flowi *fl,\n\t\t\t\t\t\t     u16 family, u8 dir,\n\t\t\t\t\t\t     u32 if_id)\n{\n\tstruct xfrm_pol_inexact_candidates cand;\n\tconst xfrm_address_t *daddr, *saddr;\n\tstruct xfrm_pol_inexact_bin *bin;\n\tstruct xfrm_policy *pol, *ret;\n\tstruct hlist_head *chain;\n\tunsigned int sequence;\n\tint err;\n\n\tdaddr = xfrm_flowi_daddr(fl, family);\n\tsaddr = xfrm_flowi_saddr(fl, family);\n\tif (unlikely(!daddr || !saddr))\n\t\treturn NULL;\n\n\trcu_read_lock();\n retry:\n\tdo {\n\t\tsequence = read_seqcount_begin(&net->xfrm.xfrm_policy_hash_generation);\n\t\tchain = policy_hash_direct(net, daddr, saddr, family, dir);\n\t} while (read_seqcount_retry(&net->xfrm.xfrm_policy_hash_generation, sequence));\n\n\tret = NULL;\n\thlist_for_each_entry_rcu(pol, chain, bydst) {\n\t\terr = xfrm_policy_match(pol, fl, type, family, dir, if_id);\n\t\tif (err) {\n\t\t\tif (err == -ESRCH)\n\t\t\t\tcontinue;\n\t\t\telse {\n\t\t\t\tret = ERR_PTR(err);\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t} else {\n\t\t\tret = pol;\n\t\t\tbreak;\n\t\t}\n\t}\n\tbin = xfrm_policy_inexact_lookup_rcu(net, type, family, dir, if_id);\n\tif (!bin || !xfrm_policy_find_inexact_candidates(&cand, bin, saddr,\n\t\t\t\t\t\t\t daddr))\n\t\tgoto skip_inexact;\n\n\tpol = xfrm_policy_eval_candidates(&cand, ret, fl, type,\n\t\t\t\t\t  family, dir, if_id);\n\tif (pol) {\n\t\tret = pol;\n\t\tif (IS_ERR(pol))\n\t\t\tgoto fail;\n\t}\n\nskip_inexact:\n\tif (read_seqcount_retry(&net->xfrm.xfrm_policy_hash_generation, sequence))\n\t\tgoto retry;\n\n\tif (ret && !xfrm_pol_hold_rcu(ret))\n\t\tgoto retry;\nfail:\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\nstatic struct xfrm_policy *xfrm_policy_lookup(struct net *net,\n\t\t\t\t\t      const struct flowi *fl,\n\t\t\t\t\t      u16 family, u8 dir, u32 if_id)\n{\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tstruct xfrm_policy *pol;\n\n\tpol = xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_SUB, fl, family,\n\t\t\t\t\tdir, if_id);\n\tif (pol != NULL)\n\t\treturn pol;\n#endif\n\treturn xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_MAIN, fl, family,\n\t\t\t\t\t dir, if_id);\n}\n\nstatic struct xfrm_policy *xfrm_sk_policy_lookup(const struct sock *sk, int dir,\n\t\t\t\t\t\t const struct flowi *fl,\n\t\t\t\t\t\t u16 family, u32 if_id)\n{\n\tstruct xfrm_policy *pol;\n\n\trcu_read_lock();\n again:\n\tpol = rcu_dereference(sk->sk_policy[dir]);\n\tif (pol != NULL) {\n\t\tbool match;\n\t\tint err = 0;\n\n\t\tif (pol->family != family) {\n\t\t\tpol = NULL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tmatch = xfrm_selector_match(&pol->selector, fl, family);\n\t\tif (match) {\n\t\t\tif ((sk->sk_mark & pol->mark.m) != pol->mark.v ||\n\t\t\t    pol->if_id != if_id) {\n\t\t\t\tpol = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\terr = security_xfrm_policy_lookup(pol->security,\n\t\t\t\t\t\t      fl->flowi_secid);\n\t\t\tif (!err) {\n\t\t\t\tif (!xfrm_pol_hold_rcu(pol))\n\t\t\t\t\tgoto again;\n\t\t\t} else if (err == -ESRCH) {\n\t\t\t\tpol = NULL;\n\t\t\t} else {\n\t\t\t\tpol = ERR_PTR(err);\n\t\t\t}\n\t\t} else\n\t\t\tpol = NULL;\n\t}\nout:\n\trcu_read_unlock();\n\treturn pol;\n}\n\nstatic void __xfrm_policy_link(struct xfrm_policy *pol, int dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tlist_add(&pol->walk.all, &net->xfrm.policy_all);\n\tnet->xfrm.policy_count[dir]++;\n\txfrm_pol_hold(pol);\n}\n\nstatic struct xfrm_policy *__xfrm_policy_unlink(struct xfrm_policy *pol,\n\t\t\t\t\t\tint dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tif (list_empty(&pol->walk.all))\n\t\treturn NULL;\n\n\t/* Socket policies are not hashed. */\n\tif (!hlist_unhashed(&pol->bydst)) {\n\t\thlist_del_rcu(&pol->bydst);\n\t\thlist_del_init(&pol->bydst_inexact_list);\n\t\thlist_del(&pol->byidx);\n\t}\n\n\tlist_del_init(&pol->walk.all);\n\tnet->xfrm.policy_count[dir]--;\n\n\treturn pol;\n}\n\nstatic void xfrm_sk_policy_link(struct xfrm_policy *pol, int dir)\n{\n\t__xfrm_policy_link(pol, XFRM_POLICY_MAX + dir);\n}\n\nstatic void xfrm_sk_policy_unlink(struct xfrm_policy *pol, int dir)\n{\n\t__xfrm_policy_unlink(pol, XFRM_POLICY_MAX + dir);\n}\n\nint xfrm_policy_delete(struct xfrm_policy *pol, int dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tpol = __xfrm_policy_unlink(pol, dir);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\tif (pol) {\n\t\txfrm_policy_kill(pol);\n\t\treturn 0;\n\t}\n\treturn -ENOENT;\n}\nEXPORT_SYMBOL(xfrm_policy_delete);\n\nint xfrm_sk_policy_insert(struct sock *sk, int dir, struct xfrm_policy *pol)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct xfrm_policy *old_pol;\n\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pol && pol->type != XFRM_POLICY_TYPE_MAIN)\n\t\treturn -EINVAL;\n#endif\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\told_pol = rcu_dereference_protected(sk->sk_policy[dir],\n\t\t\t\tlockdep_is_held(&net->xfrm.xfrm_policy_lock));\n\tif (pol) {\n\t\tpol->curlft.add_time = ktime_get_real_seconds();\n\t\tpol->index = xfrm_gen_index(net, XFRM_POLICY_MAX+dir, 0);\n\t\txfrm_sk_policy_link(pol, dir);\n\t}\n\trcu_assign_pointer(sk->sk_policy[dir], pol);\n\tif (old_pol) {\n\t\tif (pol)\n\t\t\txfrm_policy_requeue(old_pol, pol);\n\n\t\t/* Unlinking succeeds always. This is the only function\n\t\t * allowed to delete or replace socket policy.\n\t\t */\n\t\txfrm_sk_policy_unlink(old_pol, dir);\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (old_pol) {\n\t\txfrm_policy_kill(old_pol);\n\t}\n\treturn 0;\n}\n\nstatic struct xfrm_policy *clone_policy(const struct xfrm_policy *old, int dir)\n{\n\tstruct xfrm_policy *newp = xfrm_policy_alloc(xp_net(old), GFP_ATOMIC);\n\tstruct net *net = xp_net(old);\n\n\tif (newp) {\n\t\tnewp->selector = old->selector;\n\t\tif (security_xfrm_policy_clone(old->security,\n\t\t\t\t\t       &newp->security)) {\n\t\t\tkfree(newp);\n\t\t\treturn NULL;  /* ENOMEM */\n\t\t}\n\t\tnewp->lft = old->lft;\n\t\tnewp->curlft = old->curlft;\n\t\tnewp->mark = old->mark;\n\t\tnewp->if_id = old->if_id;\n\t\tnewp->action = old->action;\n\t\tnewp->flags = old->flags;\n\t\tnewp->xfrm_nr = old->xfrm_nr;\n\t\tnewp->index = old->index;\n\t\tnewp->type = old->type;\n\t\tnewp->family = old->family;\n\t\tmemcpy(newp->xfrm_vec, old->xfrm_vec,\n\t\t       newp->xfrm_nr*sizeof(struct xfrm_tmpl));\n\t\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t\txfrm_sk_policy_link(newp, dir);\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\txfrm_pol_put(newp);\n\t}\n\treturn newp;\n}\n\nint __xfrm_sk_clone_policy(struct sock *sk, const struct sock *osk)\n{\n\tconst struct xfrm_policy *p;\n\tstruct xfrm_policy *np;\n\tint i, ret = 0;\n\n\trcu_read_lock();\n\tfor (i = 0; i < 2; i++) {\n\t\tp = rcu_dereference(osk->sk_policy[i]);\n\t\tif (p) {\n\t\t\tnp = clone_policy(p, i);\n\t\t\tif (unlikely(!np)) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\trcu_assign_pointer(sk->sk_policy[i], np);\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic int\nxfrm_get_saddr(struct net *net, int oif, xfrm_address_t *local,\n\t       xfrm_address_t *remote, unsigned short family, u32 mark)\n{\n\tint err;\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\n\tif (unlikely(afinfo == NULL))\n\t\treturn -EINVAL;\n\terr = afinfo->get_saddr(net, oif, local, remote, mark);\n\trcu_read_unlock();\n\treturn err;\n}\n\n/* Resolve list of templates for the flow, given policy. */\n\nstatic int\nxfrm_tmpl_resolve_one(struct xfrm_policy *policy, const struct flowi *fl,\n\t\t      struct xfrm_state **xfrm, unsigned short family)\n{\n\tstruct net *net = xp_net(policy);\n\tint nx;\n\tint i, error;\n\txfrm_address_t *daddr = xfrm_flowi_daddr(fl, family);\n\txfrm_address_t *saddr = xfrm_flowi_saddr(fl, family);\n\txfrm_address_t tmp;\n\n\tfor (nx = 0, i = 0; i < policy->xfrm_nr; i++) {\n\t\tstruct xfrm_state *x;\n\t\txfrm_address_t *remote = daddr;\n\t\txfrm_address_t *local  = saddr;\n\t\tstruct xfrm_tmpl *tmpl = &policy->xfrm_vec[i];\n\n\t\tif (tmpl->mode == XFRM_MODE_TUNNEL ||\n\t\t    tmpl->mode == XFRM_MODE_BEET) {\n\t\t\tremote = &tmpl->id.daddr;\n\t\t\tlocal = &tmpl->saddr;\n\t\t\tif (xfrm_addr_any(local, tmpl->encap_family)) {\n\t\t\t\terror = xfrm_get_saddr(net, fl->flowi_oif,\n\t\t\t\t\t\t       &tmp, remote,\n\t\t\t\t\t\t       tmpl->encap_family, 0);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto fail;\n\t\t\t\tlocal = &tmp;\n\t\t\t}\n\t\t}\n\n\t\tx = xfrm_state_find(remote, local, fl, tmpl, policy, &error,\n\t\t\t\t    family, policy->if_id);\n\n\t\tif (x && x->km.state == XFRM_STATE_VALID) {\n\t\t\txfrm[nx++] = x;\n\t\t\tdaddr = remote;\n\t\t\tsaddr = local;\n\t\t\tcontinue;\n\t\t}\n\t\tif (x) {\n\t\t\terror = (x->km.state == XFRM_STATE_ERROR ?\n\t\t\t\t -EINVAL : -EAGAIN);\n\t\t\txfrm_state_put(x);\n\t\t} else if (error == -ESRCH) {\n\t\t\terror = -EAGAIN;\n\t\t}\n\n\t\tif (!tmpl->optional)\n\t\t\tgoto fail;\n\t}\n\treturn nx;\n\nfail:\n\tfor (nx--; nx >= 0; nx--)\n\t\txfrm_state_put(xfrm[nx]);\n\treturn error;\n}\n\nstatic int\nxfrm_tmpl_resolve(struct xfrm_policy **pols, int npols, const struct flowi *fl,\n\t\t  struct xfrm_state **xfrm, unsigned short family)\n{\n\tstruct xfrm_state *tp[XFRM_MAX_DEPTH];\n\tstruct xfrm_state **tpp = (npols > 1) ? tp : xfrm;\n\tint cnx = 0;\n\tint error;\n\tint ret;\n\tint i;\n\n\tfor (i = 0; i < npols; i++) {\n\t\tif (cnx + pols[i]->xfrm_nr >= XFRM_MAX_DEPTH) {\n\t\t\terror = -ENOBUFS;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tret = xfrm_tmpl_resolve_one(pols[i], fl, &tpp[cnx], family);\n\t\tif (ret < 0) {\n\t\t\terror = ret;\n\t\t\tgoto fail;\n\t\t} else\n\t\t\tcnx += ret;\n\t}\n\n\t/* found states are sorted for outbound processing */\n\tif (npols > 1)\n\t\txfrm_state_sort(xfrm, tpp, cnx, family);\n\n\treturn cnx;\n\n fail:\n\tfor (cnx--; cnx >= 0; cnx--)\n\t\txfrm_state_put(tpp[cnx]);\n\treturn error;\n\n}\n\nstatic int xfrm_get_tos(const struct flowi *fl, int family)\n{\n\tif (family == AF_INET)\n\t\treturn IPTOS_RT_MASK & fl->u.ip4.flowi4_tos;\n\n\treturn 0;\n}\n\nstatic inline struct xfrm_dst *xfrm_alloc_dst(struct net *net, int family)\n{\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\tstruct dst_ops *dst_ops;\n\tstruct xfrm_dst *xdst;\n\n\tif (!afinfo)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tswitch (family) {\n\tcase AF_INET:\n\t\tdst_ops = &net->xfrm.xfrm4_dst_ops;\n\t\tbreak;\n#if IS_ENABLED(CONFIG_IPV6)\n\tcase AF_INET6:\n\t\tdst_ops = &net->xfrm.xfrm6_dst_ops;\n\t\tbreak;\n#endif\n\tdefault:\n\t\tBUG();\n\t}\n\txdst = dst_alloc(dst_ops, NULL, 1, DST_OBSOLETE_NONE, 0);\n\n\tif (likely(xdst)) {\n\t\tmemset_after(xdst, 0, u.dst);\n\t} else\n\t\txdst = ERR_PTR(-ENOBUFS);\n\n\trcu_read_unlock();\n\n\treturn xdst;\n}\n\nstatic void xfrm_init_path(struct xfrm_dst *path, struct dst_entry *dst,\n\t\t\t   int nfheader_len)\n{\n\tif (dst->ops->family == AF_INET6) {\n\t\tstruct rt6_info *rt = (struct rt6_info *)dst;\n\t\tpath->path_cookie = rt6_get_cookie(rt);\n\t\tpath->u.rt6.rt6i_nfheader_len = nfheader_len;\n\t}\n}\n\nstatic inline int xfrm_fill_dst(struct xfrm_dst *xdst, struct net_device *dev,\n\t\t\t\tconst struct flowi *fl)\n{\n\tconst struct xfrm_policy_afinfo *afinfo =\n\t\txfrm_policy_get_afinfo(xdst->u.dst.ops->family);\n\tint err;\n\n\tif (!afinfo)\n\t\treturn -EINVAL;\n\n\terr = afinfo->fill_dst(xdst, dev, fl);\n\n\trcu_read_unlock();\n\n\treturn err;\n}\n\n\n/* Allocate chain of dst_entry's, attach known xfrm's, calculate\n * all the metrics... Shortly, bundle a bundle.\n */\n\nstatic struct dst_entry *xfrm_bundle_create(struct xfrm_policy *policy,\n\t\t\t\t\t    struct xfrm_state **xfrm,\n\t\t\t\t\t    struct xfrm_dst **bundle,\n\t\t\t\t\t    int nx,\n\t\t\t\t\t    const struct flowi *fl,\n\t\t\t\t\t    struct dst_entry *dst)\n{\n\tconst struct xfrm_state_afinfo *afinfo;\n\tconst struct xfrm_mode *inner_mode;\n\tstruct net *net = xp_net(policy);\n\tunsigned long now = jiffies;\n\tstruct net_device *dev;\n\tstruct xfrm_dst *xdst_prev = NULL;\n\tstruct xfrm_dst *xdst0 = NULL;\n\tint i = 0;\n\tint err;\n\tint header_len = 0;\n\tint nfheader_len = 0;\n\tint trailer_len = 0;\n\tint tos;\n\tint family = policy->selector.family;\n\txfrm_address_t saddr, daddr;\n\n\txfrm_flowi_addr_get(fl, &saddr, &daddr, family);\n\n\ttos = xfrm_get_tos(fl, family);\n\n\tdst_hold(dst);\n\n\tfor (; i < nx; i++) {\n\t\tstruct xfrm_dst *xdst = xfrm_alloc_dst(net, family);\n\t\tstruct dst_entry *dst1 = &xdst->u.dst;\n\n\t\terr = PTR_ERR(xdst);\n\t\tif (IS_ERR(xdst)) {\n\t\t\tdst_release(dst);\n\t\t\tgoto put_states;\n\t\t}\n\n\t\tbundle[i] = xdst;\n\t\tif (!xdst_prev)\n\t\t\txdst0 = xdst;\n\t\telse\n\t\t\t/* Ref count is taken during xfrm_alloc_dst()\n\t\t\t * No need to do dst_clone() on dst1\n\t\t\t */\n\t\t\txfrm_dst_set_child(xdst_prev, &xdst->u.dst);\n\n\t\tif (xfrm[i]->sel.family == AF_UNSPEC) {\n\t\t\tinner_mode = xfrm_ip2inner_mode(xfrm[i],\n\t\t\t\t\t\t\txfrm_af2proto(family));\n\t\t\tif (!inner_mode) {\n\t\t\t\terr = -EAFNOSUPPORT;\n\t\t\t\tdst_release(dst);\n\t\t\t\tgoto put_states;\n\t\t\t}\n\t\t} else\n\t\t\tinner_mode = &xfrm[i]->inner_mode;\n\n\t\txdst->route = dst;\n\t\tdst_copy_metrics(dst1, dst);\n\n\t\tif (xfrm[i]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\t__u32 mark = 0;\n\t\t\tint oif;\n\n\t\t\tif (xfrm[i]->props.smark.v || xfrm[i]->props.smark.m)\n\t\t\t\tmark = xfrm_smark_get(fl->flowi_mark, xfrm[i]);\n\n\t\t\tfamily = xfrm[i]->props.family;\n\t\t\toif = fl->flowi_oif ? : fl->flowi_l3mdev;\n\t\t\tdst = xfrm_dst_lookup(xfrm[i], tos, oif,\n\t\t\t\t\t      &saddr, &daddr, family, mark);\n\t\t\terr = PTR_ERR(dst);\n\t\t\tif (IS_ERR(dst))\n\t\t\t\tgoto put_states;\n\t\t} else\n\t\t\tdst_hold(dst);\n\n\t\tdst1->xfrm = xfrm[i];\n\t\txdst->xfrm_genid = xfrm[i]->genid;\n\n\t\tdst1->obsolete = DST_OBSOLETE_FORCE_CHK;\n\t\tdst1->lastuse = now;\n\n\t\tdst1->input = dst_discard;\n\n\t\trcu_read_lock();\n\t\tafinfo = xfrm_state_afinfo_get_rcu(inner_mode->family);\n\t\tif (likely(afinfo))\n\t\t\tdst1->output = afinfo->output;\n\t\telse\n\t\t\tdst1->output = dst_discard_out;\n\t\trcu_read_unlock();\n\n\t\txdst_prev = xdst;\n\n\t\theader_len += xfrm[i]->props.header_len;\n\t\tif (xfrm[i]->type->flags & XFRM_TYPE_NON_FRAGMENT)\n\t\t\tnfheader_len += xfrm[i]->props.header_len;\n\t\ttrailer_len += xfrm[i]->props.trailer_len;\n\t}\n\n\txfrm_dst_set_child(xdst_prev, dst);\n\txdst0->path = dst;\n\n\terr = -ENODEV;\n\tdev = dst->dev;\n\tif (!dev)\n\t\tgoto free_dst;\n\n\txfrm_init_path(xdst0, dst, nfheader_len);\n\txfrm_init_pmtu(bundle, nx);\n\n\tfor (xdst_prev = xdst0; xdst_prev != (struct xfrm_dst *)dst;\n\t     xdst_prev = (struct xfrm_dst *) xfrm_dst_child(&xdst_prev->u.dst)) {\n\t\terr = xfrm_fill_dst(xdst_prev, dev, fl);\n\t\tif (err)\n\t\t\tgoto free_dst;\n\n\t\txdst_prev->u.dst.header_len = header_len;\n\t\txdst_prev->u.dst.trailer_len = trailer_len;\n\t\theader_len -= xdst_prev->u.dst.xfrm->props.header_len;\n\t\ttrailer_len -= xdst_prev->u.dst.xfrm->props.trailer_len;\n\t}\n\n\treturn &xdst0->u.dst;\n\nput_states:\n\tfor (; i < nx; i++)\n\t\txfrm_state_put(xfrm[i]);\nfree_dst:\n\tif (xdst0)\n\t\tdst_release_immediate(&xdst0->u.dst);\n\n\treturn ERR_PTR(err);\n}\n\nstatic int xfrm_expand_policies(const struct flowi *fl, u16 family,\n\t\t\t\tstruct xfrm_policy **pols,\n\t\t\t\tint *num_pols, int *num_xfrms)\n{\n\tint i;\n\n\tif (*num_pols == 0 || !pols[0]) {\n\t\t*num_pols = 0;\n\t\t*num_xfrms = 0;\n\t\treturn 0;\n\t}\n\tif (IS_ERR(pols[0])) {\n\t\t*num_pols = 0;\n\t\treturn PTR_ERR(pols[0]);\n\t}\n\n\t*num_xfrms = pols[0]->xfrm_nr;\n\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pols[0]->action == XFRM_POLICY_ALLOW &&\n\t    pols[0]->type != XFRM_POLICY_TYPE_MAIN) {\n\t\tpols[1] = xfrm_policy_lookup_bytype(xp_net(pols[0]),\n\t\t\t\t\t\t    XFRM_POLICY_TYPE_MAIN,\n\t\t\t\t\t\t    fl, family,\n\t\t\t\t\t\t    XFRM_POLICY_OUT,\n\t\t\t\t\t\t    pols[0]->if_id);\n\t\tif (pols[1]) {\n\t\t\tif (IS_ERR(pols[1])) {\n\t\t\t\txfrm_pols_put(pols, *num_pols);\n\t\t\t\t*num_pols = 0;\n\t\t\t\treturn PTR_ERR(pols[1]);\n\t\t\t}\n\t\t\t(*num_pols)++;\n\t\t\t(*num_xfrms) += pols[1]->xfrm_nr;\n\t\t}\n\t}\n#endif\n\tfor (i = 0; i < *num_pols; i++) {\n\t\tif (pols[i]->action != XFRM_POLICY_ALLOW) {\n\t\t\t*num_xfrms = -1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n\n}\n\nstatic struct xfrm_dst *\nxfrm_resolve_and_create_bundle(struct xfrm_policy **pols, int num_pols,\n\t\t\t       const struct flowi *fl, u16 family,\n\t\t\t       struct dst_entry *dst_orig)\n{\n\tstruct net *net = xp_net(pols[0]);\n\tstruct xfrm_state *xfrm[XFRM_MAX_DEPTH];\n\tstruct xfrm_dst *bundle[XFRM_MAX_DEPTH];\n\tstruct xfrm_dst *xdst;\n\tstruct dst_entry *dst;\n\tint err;\n\n\t/* Try to instantiate a bundle */\n\terr = xfrm_tmpl_resolve(pols, num_pols, fl, xfrm, family);\n\tif (err <= 0) {\n\t\tif (err == 0)\n\t\t\treturn NULL;\n\n\t\tif (err != -EAGAIN)\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLERROR);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tdst = xfrm_bundle_create(pols[0], xfrm, bundle, err, fl, dst_orig);\n\tif (IS_ERR(dst)) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTBUNDLEGENERROR);\n\t\treturn ERR_CAST(dst);\n\t}\n\n\txdst = (struct xfrm_dst *)dst;\n\txdst->num_xfrms = err;\n\txdst->num_pols = num_pols;\n\tmemcpy(xdst->pols, pols, sizeof(struct xfrm_policy *) * num_pols);\n\txdst->policy_genid = atomic_read(&pols[0]->genid);\n\n\treturn xdst;\n}\n\nstatic void xfrm_policy_queue_process(struct timer_list *t)\n{\n\tstruct sk_buff *skb;\n\tstruct sock *sk;\n\tstruct dst_entry *dst;\n\tstruct xfrm_policy *pol = from_timer(pol, t, polq.hold_timer);\n\tstruct net *net = xp_net(pol);\n\tstruct xfrm_policy_queue *pq = &pol->polq;\n\tstruct flowi fl;\n\tstruct sk_buff_head list;\n\t__u32 skb_mark;\n\n\tspin_lock(&pq->hold_queue.lock);\n\tskb = skb_peek(&pq->hold_queue);\n\tif (!skb) {\n\t\tspin_unlock(&pq->hold_queue.lock);\n\t\tgoto out;\n\t}\n\tdst = skb_dst(skb);\n\tsk = skb->sk;\n\n\t/* Fixup the mark to support VTI. */\n\tskb_mark = skb->mark;\n\tskb->mark = pol->mark.v;\n\txfrm_decode_session(skb, &fl, dst->ops->family);\n\tskb->mark = skb_mark;\n\tspin_unlock(&pq->hold_queue.lock);\n\n\tdst_hold(xfrm_dst_path(dst));\n\tdst = xfrm_lookup(net, xfrm_dst_path(dst), &fl, sk, XFRM_LOOKUP_QUEUE);\n\tif (IS_ERR(dst))\n\t\tgoto purge_queue;\n\n\tif (dst->flags & DST_XFRM_QUEUE) {\n\t\tdst_release(dst);\n\n\t\tif (pq->timeout >= XFRM_QUEUE_TMO_MAX)\n\t\t\tgoto purge_queue;\n\n\t\tpq->timeout = pq->timeout << 1;\n\t\tif (!mod_timer(&pq->hold_timer, jiffies + pq->timeout))\n\t\t\txfrm_pol_hold(pol);\n\t\tgoto out;\n\t}\n\n\tdst_release(dst);\n\n\t__skb_queue_head_init(&list);\n\n\tspin_lock(&pq->hold_queue.lock);\n\tpq->timeout = 0;\n\tskb_queue_splice_init(&pq->hold_queue, &list);\n\tspin_unlock(&pq->hold_queue.lock);\n\n\twhile (!skb_queue_empty(&list)) {\n\t\tskb = __skb_dequeue(&list);\n\n\t\t/* Fixup the mark to support VTI. */\n\t\tskb_mark = skb->mark;\n\t\tskb->mark = pol->mark.v;\n\t\txfrm_decode_session(skb, &fl, skb_dst(skb)->ops->family);\n\t\tskb->mark = skb_mark;\n\n\t\tdst_hold(xfrm_dst_path(skb_dst(skb)));\n\t\tdst = xfrm_lookup(net, xfrm_dst_path(skb_dst(skb)), &fl, skb->sk, 0);\n\t\tif (IS_ERR(dst)) {\n\t\t\tkfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tnf_reset_ct(skb);\n\t\tskb_dst_drop(skb);\n\t\tskb_dst_set(skb, dst);\n\n\t\tdst_output(net, skb->sk, skb);\n\t}\n\nout:\n\txfrm_pol_put(pol);\n\treturn;\n\npurge_queue:\n\tpq->timeout = 0;\n\tskb_queue_purge(&pq->hold_queue);\n\txfrm_pol_put(pol);\n}\n\nstatic int xdst_queue_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tunsigned long sched_next;\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct xfrm_dst *xdst = (struct xfrm_dst *) dst;\n\tstruct xfrm_policy *pol = xdst->pols[0];\n\tstruct xfrm_policy_queue *pq = &pol->polq;\n\n\tif (unlikely(skb_fclone_busy(sk, skb))) {\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\n\tif (pq->hold_queue.qlen > XFRM_MAX_QUEUE_LEN) {\n\t\tkfree_skb(skb);\n\t\treturn -EAGAIN;\n\t}\n\n\tskb_dst_force(skb);\n\n\tspin_lock_bh(&pq->hold_queue.lock);\n\n\tif (!pq->timeout)\n\t\tpq->timeout = XFRM_QUEUE_TMO_MIN;\n\n\tsched_next = jiffies + pq->timeout;\n\n\tif (del_timer(&pq->hold_timer)) {\n\t\tif (time_before(pq->hold_timer.expires, sched_next))\n\t\t\tsched_next = pq->hold_timer.expires;\n\t\txfrm_pol_put(pol);\n\t}\n\n\t__skb_queue_tail(&pq->hold_queue, skb);\n\tif (!mod_timer(&pq->hold_timer, sched_next))\n\t\txfrm_pol_hold(pol);\n\n\tspin_unlock_bh(&pq->hold_queue.lock);\n\n\treturn 0;\n}\n\nstatic struct xfrm_dst *xfrm_create_dummy_bundle(struct net *net,\n\t\t\t\t\t\t struct xfrm_flo *xflo,\n\t\t\t\t\t\t const struct flowi *fl,\n\t\t\t\t\t\t int num_xfrms,\n\t\t\t\t\t\t u16 family)\n{\n\tint err;\n\tstruct net_device *dev;\n\tstruct dst_entry *dst;\n\tstruct dst_entry *dst1;\n\tstruct xfrm_dst *xdst;\n\n\txdst = xfrm_alloc_dst(net, family);\n\tif (IS_ERR(xdst))\n\t\treturn xdst;\n\n\tif (!(xflo->flags & XFRM_LOOKUP_QUEUE) ||\n\t    net->xfrm.sysctl_larval_drop ||\n\t    num_xfrms <= 0)\n\t\treturn xdst;\n\n\tdst = xflo->dst_orig;\n\tdst1 = &xdst->u.dst;\n\tdst_hold(dst);\n\txdst->route = dst;\n\n\tdst_copy_metrics(dst1, dst);\n\n\tdst1->obsolete = DST_OBSOLETE_FORCE_CHK;\n\tdst1->flags |= DST_XFRM_QUEUE;\n\tdst1->lastuse = jiffies;\n\n\tdst1->input = dst_discard;\n\tdst1->output = xdst_queue_output;\n\n\tdst_hold(dst);\n\txfrm_dst_set_child(xdst, dst);\n\txdst->path = dst;\n\n\txfrm_init_path((struct xfrm_dst *)dst1, dst, 0);\n\n\terr = -ENODEV;\n\tdev = dst->dev;\n\tif (!dev)\n\t\tgoto free_dst;\n\n\terr = xfrm_fill_dst(xdst, dev, fl);\n\tif (err)\n\t\tgoto free_dst;\n\nout:\n\treturn xdst;\n\nfree_dst:\n\tdst_release(dst1);\n\txdst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic struct xfrm_dst *xfrm_bundle_lookup(struct net *net,\n\t\t\t\t\t   const struct flowi *fl,\n\t\t\t\t\t   u16 family, u8 dir,\n\t\t\t\t\t   struct xfrm_flo *xflo, u32 if_id)\n{\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tint num_pols = 0, num_xfrms = 0, err;\n\tstruct xfrm_dst *xdst;\n\n\t/* Resolve policies to use if we couldn't get them from\n\t * previous cache entry */\n\tnum_pols = 1;\n\tpols[0] = xfrm_policy_lookup(net, fl, family, dir, if_id);\n\terr = xfrm_expand_policies(fl, family, pols,\n\t\t\t\t\t   &num_pols, &num_xfrms);\n\tif (err < 0)\n\t\tgoto inc_error;\n\tif (num_pols == 0)\n\t\treturn NULL;\n\tif (num_xfrms <= 0)\n\t\tgoto make_dummy_bundle;\n\n\txdst = xfrm_resolve_and_create_bundle(pols, num_pols, fl, family,\n\t\t\t\t\t      xflo->dst_orig);\n\tif (IS_ERR(xdst)) {\n\t\terr = PTR_ERR(xdst);\n\t\tif (err == -EREMOTE) {\n\t\t\txfrm_pols_put(pols, num_pols);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (err != -EAGAIN)\n\t\t\tgoto error;\n\t\tgoto make_dummy_bundle;\n\t} else if (xdst == NULL) {\n\t\tnum_xfrms = 0;\n\t\tgoto make_dummy_bundle;\n\t}\n\n\treturn xdst;\n\nmake_dummy_bundle:\n\t/* We found policies, but there's no bundles to instantiate:\n\t * either because the policy blocks, has no transformations or\n\t * we could not build template (no xfrm_states).*/\n\txdst = xfrm_create_dummy_bundle(net, xflo, fl, num_xfrms, family);\n\tif (IS_ERR(xdst)) {\n\t\txfrm_pols_put(pols, num_pols);\n\t\treturn ERR_CAST(xdst);\n\t}\n\txdst->num_pols = num_pols;\n\txdst->num_xfrms = num_xfrms;\n\tmemcpy(xdst->pols, pols, sizeof(struct xfrm_policy *) * num_pols);\n\n\treturn xdst;\n\ninc_error:\n\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLERROR);\nerror:\n\txfrm_pols_put(pols, num_pols);\n\treturn ERR_PTR(err);\n}\n\nstatic struct dst_entry *make_blackhole(struct net *net, u16 family,\n\t\t\t\t\tstruct dst_entry *dst_orig)\n{\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\tstruct dst_entry *ret;\n\n\tif (!afinfo) {\n\t\tdst_release(dst_orig);\n\t\treturn ERR_PTR(-EINVAL);\n\t} else {\n\t\tret = afinfo->blackhole_route(net, dst_orig);\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\n/* Finds/creates a bundle for given flow and if_id\n *\n * At the moment we eat a raw IP route. Mostly to speed up lookups\n * on interfaces with disabled IPsec.\n *\n * xfrm_lookup uses an if_id of 0 by default, and is provided for\n * compatibility\n */\nstruct dst_entry *xfrm_lookup_with_ifid(struct net *net,\n\t\t\t\t\tstruct dst_entry *dst_orig,\n\t\t\t\t\tconst struct flowi *fl,\n\t\t\t\t\tconst struct sock *sk,\n\t\t\t\t\tint flags, u32 if_id)\n{\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tstruct xfrm_dst *xdst;\n\tstruct dst_entry *dst, *route;\n\tu16 family = dst_orig->ops->family;\n\tu8 dir = XFRM_POLICY_OUT;\n\tint i, err, num_pols, num_xfrms = 0, drop_pols = 0;\n\n\tdst = NULL;\n\txdst = NULL;\n\troute = NULL;\n\n\tsk = sk_const_to_full_sk(sk);\n\tif (sk && sk->sk_policy[XFRM_POLICY_OUT]) {\n\t\tnum_pols = 1;\n\t\tpols[0] = xfrm_sk_policy_lookup(sk, XFRM_POLICY_OUT, fl, family,\n\t\t\t\t\t\tif_id);\n\t\terr = xfrm_expand_policies(fl, family, pols,\n\t\t\t\t\t   &num_pols, &num_xfrms);\n\t\tif (err < 0)\n\t\t\tgoto dropdst;\n\n\t\tif (num_pols) {\n\t\t\tif (num_xfrms <= 0) {\n\t\t\t\tdrop_pols = num_pols;\n\t\t\t\tgoto no_transform;\n\t\t\t}\n\n\t\t\txdst = xfrm_resolve_and_create_bundle(\n\t\t\t\t\tpols, num_pols, fl,\n\t\t\t\t\tfamily, dst_orig);\n\n\t\t\tif (IS_ERR(xdst)) {\n\t\t\t\txfrm_pols_put(pols, num_pols);\n\t\t\t\terr = PTR_ERR(xdst);\n\t\t\t\tif (err == -EREMOTE)\n\t\t\t\t\tgoto nopol;\n\n\t\t\t\tgoto dropdst;\n\t\t\t} else if (xdst == NULL) {\n\t\t\t\tnum_xfrms = 0;\n\t\t\t\tdrop_pols = num_pols;\n\t\t\t\tgoto no_transform;\n\t\t\t}\n\n\t\t\troute = xdst->route;\n\t\t}\n\t}\n\n\tif (xdst == NULL) {\n\t\tstruct xfrm_flo xflo;\n\n\t\txflo.dst_orig = dst_orig;\n\t\txflo.flags = flags;\n\n\t\t/* To accelerate a bit...  */\n\t\tif (!if_id && ((dst_orig->flags & DST_NOXFRM) ||\n\t\t\t       !net->xfrm.policy_count[XFRM_POLICY_OUT]))\n\t\t\tgoto nopol;\n\n\t\txdst = xfrm_bundle_lookup(net, fl, family, dir, &xflo, if_id);\n\t\tif (xdst == NULL)\n\t\t\tgoto nopol;\n\t\tif (IS_ERR(xdst)) {\n\t\t\terr = PTR_ERR(xdst);\n\t\t\tgoto dropdst;\n\t\t}\n\n\t\tnum_pols = xdst->num_pols;\n\t\tnum_xfrms = xdst->num_xfrms;\n\t\tmemcpy(pols, xdst->pols, sizeof(struct xfrm_policy *) * num_pols);\n\t\troute = xdst->route;\n\t}\n\n\tdst = &xdst->u.dst;\n\tif (route == NULL && num_xfrms > 0) {\n\t\t/* The only case when xfrm_bundle_lookup() returns a\n\t\t * bundle with null route, is when the template could\n\t\t * not be resolved. It means policies are there, but\n\t\t * bundle could not be created, since we don't yet\n\t\t * have the xfrm_state's. We need to wait for KM to\n\t\t * negotiate new SA's or bail out with error.*/\n\t\tif (net->xfrm.sysctl_larval_drop) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTNOSTATES);\n\t\t\terr = -EREMOTE;\n\t\t\tgoto error;\n\t\t}\n\n\t\terr = -EAGAIN;\n\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTNOSTATES);\n\t\tgoto error;\n\t}\n\nno_transform:\n\tif (num_pols == 0)\n\t\tgoto nopol;\n\n\tif ((flags & XFRM_LOOKUP_ICMP) &&\n\t    !(pols[0]->flags & XFRM_POLICY_ICMP)) {\n\t\terr = -ENOENT;\n\t\tgoto error;\n\t}\n\n\tfor (i = 0; i < num_pols; i++)\n\t\tpols[i]->curlft.use_time = ktime_get_real_seconds();\n\n\tif (num_xfrms < 0) {\n\t\t/* Prohibit the flow */\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLBLOCK);\n\t\terr = -EPERM;\n\t\tgoto error;\n\t} else if (num_xfrms > 0) {\n\t\t/* Flow transformed */\n\t\tdst_release(dst_orig);\n\t} else {\n\t\t/* Flow passes untransformed */\n\t\tdst_release(dst);\n\t\tdst = dst_orig;\n\t}\nok:\n\txfrm_pols_put(pols, drop_pols);\n\tif (dst && dst->xfrm &&\n\t    dst->xfrm->props.mode == XFRM_MODE_TUNNEL)\n\t\tdst->flags |= DST_XFRM_TUNNEL;\n\treturn dst;\n\nnopol:\n\tif (!(dst_orig->dev->flags & IFF_LOOPBACK) &&\n\t    net->xfrm.policy_default[dir] == XFRM_USERPOLICY_BLOCK) {\n\t\terr = -EPERM;\n\t\tgoto error;\n\t}\n\tif (!(flags & XFRM_LOOKUP_ICMP)) {\n\t\tdst = dst_orig;\n\t\tgoto ok;\n\t}\n\terr = -ENOENT;\nerror:\n\tdst_release(dst);\ndropdst:\n\tif (!(flags & XFRM_LOOKUP_KEEP_DST_REF))\n\t\tdst_release(dst_orig);\n\txfrm_pols_put(pols, drop_pols);\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL(xfrm_lookup_with_ifid);\n\n/* Main function: finds/creates a bundle for given flow.\n *\n * At the moment we eat a raw IP route. Mostly to speed up lookups\n * on interfaces with disabled IPsec.\n */\nstruct dst_entry *xfrm_lookup(struct net *net, struct dst_entry *dst_orig,\n\t\t\t      const struct flowi *fl, const struct sock *sk,\n\t\t\t      int flags)\n{\n\treturn xfrm_lookup_with_ifid(net, dst_orig, fl, sk, flags, 0);\n}\nEXPORT_SYMBOL(xfrm_lookup);\n\n/* Callers of xfrm_lookup_route() must ensure a call to dst_output().\n * Otherwise we may send out blackholed packets.\n */\nstruct dst_entry *xfrm_lookup_route(struct net *net, struct dst_entry *dst_orig,\n\t\t\t\t    const struct flowi *fl,\n\t\t\t\t    const struct sock *sk, int flags)\n{\n\tstruct dst_entry *dst = xfrm_lookup(net, dst_orig, fl, sk,\n\t\t\t\t\t    flags | XFRM_LOOKUP_QUEUE |\n\t\t\t\t\t    XFRM_LOOKUP_KEEP_DST_REF);\n\n\tif (PTR_ERR(dst) == -EREMOTE)\n\t\treturn make_blackhole(net, dst_orig->ops->family, dst_orig);\n\n\tif (IS_ERR(dst))\n\t\tdst_release(dst_orig);\n\n\treturn dst;\n}\nEXPORT_SYMBOL(xfrm_lookup_route);\n\nstatic inline int\nxfrm_secpath_reject(int idx, struct sk_buff *skb, const struct flowi *fl)\n{\n\tstruct sec_path *sp = skb_sec_path(skb);\n\tstruct xfrm_state *x;\n\n\tif (!sp || idx < 0 || idx >= sp->len)\n\t\treturn 0;\n\tx = sp->xvec[idx];\n\tif (!x->type->reject)\n\t\treturn 0;\n\treturn x->type->reject(x, skb, fl);\n}\n\n/* When skb is transformed back to its \"native\" form, we have to\n * check policy restrictions. At the moment we make this in maximally\n * stupid way. Shame on me. :-) Of course, connected sockets must\n * have policy cached at them.\n */\n\nstatic inline int\nxfrm_state_ok(const struct xfrm_tmpl *tmpl, const struct xfrm_state *x,\n\t      unsigned short family)\n{\n\tif (xfrm_state_kern(x))\n\t\treturn tmpl->optional && !xfrm_state_addr_cmp(tmpl, x, tmpl->encap_family);\n\treturn\tx->id.proto == tmpl->id.proto &&\n\t\t(x->id.spi == tmpl->id.spi || !tmpl->id.spi) &&\n\t\t(x->props.reqid == tmpl->reqid || !tmpl->reqid) &&\n\t\tx->props.mode == tmpl->mode &&\n\t\t(tmpl->allalgs || (tmpl->aalgos & (1<<x->props.aalgo)) ||\n\t\t !(xfrm_id_proto_match(tmpl->id.proto, IPSEC_PROTO_ANY))) &&\n\t\t!(x->props.mode != XFRM_MODE_TRANSPORT &&\n\t\t  xfrm_state_addr_cmp(tmpl, x, family));\n}\n\n/*\n * 0 or more than 0 is returned when validation is succeeded (either bypass\n * because of optional transport mode, or next index of the matched secpath\n * state with the template.\n * -1 is returned when no matching template is found.\n * Otherwise \"-2 - errored_index\" is returned.\n */\nstatic inline int\nxfrm_policy_ok(const struct xfrm_tmpl *tmpl, const struct sec_path *sp, int start,\n\t       unsigned short family)\n{\n\tint idx = start;\n\n\tif (tmpl->optional) {\n\t\tif (tmpl->mode == XFRM_MODE_TRANSPORT)\n\t\t\treturn start;\n\t} else\n\t\tstart = -1;\n\tfor (; idx < sp->len; idx++) {\n\t\tif (xfrm_state_ok(tmpl, sp->xvec[idx], family))\n\t\t\treturn ++idx;\n\t\tif (sp->xvec[idx]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\tif (start == -1)\n\t\t\t\tstart = -2-idx;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn start;\n}\n\nstatic void\ndecode_session4(struct sk_buff *skb, struct flowi *fl, bool reverse)\n{\n\tconst struct iphdr *iph = ip_hdr(skb);\n\tint ihl = iph->ihl;\n\tu8 *xprth = skb_network_header(skb) + ihl * 4;\n\tstruct flowi4 *fl4 = &fl->u.ip4;\n\tint oif = 0;\n\n\tif (skb_dst(skb) && skb_dst(skb)->dev)\n\t\toif = skb_dst(skb)->dev->ifindex;\n\n\tmemset(fl4, 0, sizeof(struct flowi4));\n\tfl4->flowi4_mark = skb->mark;\n\tfl4->flowi4_oif = reverse ? skb->skb_iif : oif;\n\n\tfl4->flowi4_proto = iph->protocol;\n\tfl4->daddr = reverse ? iph->saddr : iph->daddr;\n\tfl4->saddr = reverse ? iph->daddr : iph->saddr;\n\tfl4->flowi4_tos = iph->tos & ~INET_ECN_MASK;\n\n\tif (!ip_is_fragment(iph)) {\n\t\tswitch (iph->protocol) {\n\t\tcase IPPROTO_UDP:\n\t\tcase IPPROTO_UDPLITE:\n\t\tcase IPPROTO_TCP:\n\t\tcase IPPROTO_SCTP:\n\t\tcase IPPROTO_DCCP:\n\t\t\tif (xprth + 4 < skb->data ||\n\t\t\t    pskb_may_pull(skb, xprth + 4 - skb->data)) {\n\t\t\t\t__be16 *ports;\n\n\t\t\t\txprth = skb_network_header(skb) + ihl * 4;\n\t\t\t\tports = (__be16 *)xprth;\n\n\t\t\t\tfl4->fl4_sport = ports[!!reverse];\n\t\t\t\tfl4->fl4_dport = ports[!reverse];\n\t\t\t}\n\t\t\tbreak;\n\t\tcase IPPROTO_ICMP:\n\t\t\tif (xprth + 2 < skb->data ||\n\t\t\t    pskb_may_pull(skb, xprth + 2 - skb->data)) {\n\t\t\t\tu8 *icmp;\n\n\t\t\t\txprth = skb_network_header(skb) + ihl * 4;\n\t\t\t\ticmp = xprth;\n\n\t\t\t\tfl4->fl4_icmp_type = icmp[0];\n\t\t\t\tfl4->fl4_icmp_code = icmp[1];\n\t\t\t}\n\t\t\tbreak;\n\t\tcase IPPROTO_GRE:\n\t\t\tif (xprth + 12 < skb->data ||\n\t\t\t    pskb_may_pull(skb, xprth + 12 - skb->data)) {\n\t\t\t\t__be16 *greflags;\n\t\t\t\t__be32 *gre_hdr;\n\n\t\t\t\txprth = skb_network_header(skb) + ihl * 4;\n\t\t\t\tgreflags = (__be16 *)xprth;\n\t\t\t\tgre_hdr = (__be32 *)xprth;\n\n\t\t\t\tif (greflags[0] & GRE_KEY) {\n\t\t\t\t\tif (greflags[0] & GRE_CSUM)\n\t\t\t\t\t\tgre_hdr++;\n\t\t\t\t\tfl4->fl4_gre_key = gre_hdr[1];\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\nstatic void\ndecode_session6(struct sk_buff *skb, struct flowi *fl, bool reverse)\n{\n\tstruct flowi6 *fl6 = &fl->u.ip6;\n\tint onlyproto = 0;\n\tconst struct ipv6hdr *hdr = ipv6_hdr(skb);\n\tu32 offset = sizeof(*hdr);\n\tstruct ipv6_opt_hdr *exthdr;\n\tconst unsigned char *nh = skb_network_header(skb);\n\tu16 nhoff = IP6CB(skb)->nhoff;\n\tint oif = 0;\n\tu8 nexthdr;\n\n\tif (!nhoff)\n\t\tnhoff = offsetof(struct ipv6hdr, nexthdr);\n\n\tnexthdr = nh[nhoff];\n\n\tif (skb_dst(skb) && skb_dst(skb)->dev)\n\t\toif = skb_dst(skb)->dev->ifindex;\n\n\tmemset(fl6, 0, sizeof(struct flowi6));\n\tfl6->flowi6_mark = skb->mark;\n\tfl6->flowi6_oif = reverse ? skb->skb_iif : oif;\n\n\tfl6->daddr = reverse ? hdr->saddr : hdr->daddr;\n\tfl6->saddr = reverse ? hdr->daddr : hdr->saddr;\n\n\twhile (nh + offset + sizeof(*exthdr) < skb->data ||\n\t       pskb_may_pull(skb, nh + offset + sizeof(*exthdr) - skb->data)) {\n\t\tnh = skb_network_header(skb);\n\t\texthdr = (struct ipv6_opt_hdr *)(nh + offset);\n\n\t\tswitch (nexthdr) {\n\t\tcase NEXTHDR_FRAGMENT:\n\t\t\tonlyproto = 1;\n\t\t\tfallthrough;\n\t\tcase NEXTHDR_ROUTING:\n\t\tcase NEXTHDR_HOP:\n\t\tcase NEXTHDR_DEST:\n\t\t\toffset += ipv6_optlen(exthdr);\n\t\t\tnexthdr = exthdr->nexthdr;\n\t\t\tbreak;\n\t\tcase IPPROTO_UDP:\n\t\tcase IPPROTO_UDPLITE:\n\t\tcase IPPROTO_TCP:\n\t\tcase IPPROTO_SCTP:\n\t\tcase IPPROTO_DCCP:\n\t\t\tif (!onlyproto && (nh + offset + 4 < skb->data ||\n\t\t\t     pskb_may_pull(skb, nh + offset + 4 - skb->data))) {\n\t\t\t\t__be16 *ports;\n\n\t\t\t\tnh = skb_network_header(skb);\n\t\t\t\tports = (__be16 *)(nh + offset);\n\t\t\t\tfl6->fl6_sport = ports[!!reverse];\n\t\t\t\tfl6->fl6_dport = ports[!reverse];\n\t\t\t}\n\t\t\tfl6->flowi6_proto = nexthdr;\n\t\t\treturn;\n\t\tcase IPPROTO_ICMPV6:\n\t\t\tif (!onlyproto && (nh + offset + 2 < skb->data ||\n\t\t\t    pskb_may_pull(skb, nh + offset + 2 - skb->data))) {\n\t\t\t\tu8 *icmp;\n\n\t\t\t\tnh = skb_network_header(skb);\n\t\t\t\ticmp = (u8 *)(nh + offset);\n\t\t\t\tfl6->fl6_icmp_type = icmp[0];\n\t\t\t\tfl6->fl6_icmp_code = icmp[1];\n\t\t\t}\n\t\t\tfl6->flowi6_proto = nexthdr;\n\t\t\treturn;\n\t\tcase IPPROTO_GRE:\n\t\t\tif (!onlyproto &&\n\t\t\t    (nh + offset + 12 < skb->data ||\n\t\t\t     pskb_may_pull(skb, nh + offset + 12 - skb->data))) {\n\t\t\t\tstruct gre_base_hdr *gre_hdr;\n\t\t\t\t__be32 *gre_key;\n\n\t\t\t\tnh = skb_network_header(skb);\n\t\t\t\tgre_hdr = (struct gre_base_hdr *)(nh + offset);\n\t\t\t\tgre_key = (__be32 *)(gre_hdr + 1);\n\n\t\t\t\tif (gre_hdr->flags & GRE_KEY) {\n\t\t\t\t\tif (gre_hdr->flags & GRE_CSUM)\n\t\t\t\t\t\tgre_key++;\n\t\t\t\t\tfl6->fl6_gre_key = *gre_key;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfl6->flowi6_proto = nexthdr;\n\t\t\treturn;\n\n#if IS_ENABLED(CONFIG_IPV6_MIP6)\n\t\tcase IPPROTO_MH:\n\t\t\toffset += ipv6_optlen(exthdr);\n\t\t\tif (!onlyproto && (nh + offset + 3 < skb->data ||\n\t\t\t    pskb_may_pull(skb, nh + offset + 3 - skb->data))) {\n\t\t\t\tstruct ip6_mh *mh;\n\n\t\t\t\tnh = skb_network_header(skb);\n\t\t\t\tmh = (struct ip6_mh *)(nh + offset);\n\t\t\t\tfl6->fl6_mh_type = mh->ip6mh_type;\n\t\t\t}\n\t\t\tfl6->flowi6_proto = nexthdr;\n\t\t\treturn;\n#endif\n\t\tdefault:\n\t\t\tfl6->flowi6_proto = nexthdr;\n\t\t\treturn;\n\t\t}\n\t}\n}\n#endif\n\nint __xfrm_decode_session(struct sk_buff *skb, struct flowi *fl,\n\t\t\t  unsigned int family, int reverse)\n{\n\tswitch (family) {\n\tcase AF_INET:\n\t\tdecode_session4(skb, fl, reverse);\n\t\tbreak;\n#if IS_ENABLED(CONFIG_IPV6)\n\tcase AF_INET6:\n\t\tdecode_session6(skb, fl, reverse);\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn -EAFNOSUPPORT;\n\t}\n\n\treturn security_xfrm_decode_session(skb, &fl->flowi_secid);\n}\nEXPORT_SYMBOL(__xfrm_decode_session);\n\nstatic inline int secpath_has_nontransport(const struct sec_path *sp, int k, int *idxp)\n{\n\tfor (; k < sp->len; k++) {\n\t\tif (sp->xvec[k]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\t*idxp = k;\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint __xfrm_policy_check(struct sock *sk, int dir, struct sk_buff *skb,\n\t\t\tunsigned short family)\n{\n\tstruct net *net = dev_net(skb->dev);\n\tstruct xfrm_policy *pol;\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tint npols = 0;\n\tint xfrm_nr;\n\tint pi;\n\tint reverse;\n\tstruct flowi fl;\n\tint xerr_idx = -1;\n\tconst struct xfrm_if_cb *ifcb;\n\tstruct sec_path *sp;\n\tstruct xfrm_if *xi;\n\tu32 if_id = 0;\n\n\trcu_read_lock();\n\tifcb = xfrm_if_get_cb();\n\n\tif (ifcb) {\n\t\txi = ifcb->decode_session(skb, family);\n\t\tif (xi) {\n\t\t\tif_id = xi->p.if_id;\n\t\t\tnet = xi->net;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treverse = dir & ~XFRM_POLICY_MASK;\n\tdir &= XFRM_POLICY_MASK;\n\n\tif (__xfrm_decode_session(skb, &fl, family, reverse) < 0) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINHDRERROR);\n\t\treturn 0;\n\t}\n\n\tnf_nat_decode_session(skb, &fl, family);\n\n\t/* First, check used SA against their selectors. */\n\tsp = skb_sec_path(skb);\n\tif (sp) {\n\t\tint i;\n\n\t\tfor (i = sp->len - 1; i >= 0; i--) {\n\t\t\tstruct xfrm_state *x = sp->xvec[i];\n\t\t\tif (!xfrm_selector_match(&x->sel, &fl, family)) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATEMISMATCH);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tpol = NULL;\n\tsk = sk_to_full_sk(sk);\n\tif (sk && sk->sk_policy[dir]) {\n\t\tpol = xfrm_sk_policy_lookup(sk, dir, &fl, family, if_id);\n\t\tif (IS_ERR(pol)) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (!pol)\n\t\tpol = xfrm_policy_lookup(net, &fl, family, dir, if_id);\n\n\tif (IS_ERR(pol)) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\treturn 0;\n\t}\n\n\tif (!pol) {\n\t\tif (net->xfrm.policy_default[dir] == XFRM_USERPOLICY_BLOCK) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINNOPOLS);\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (sp && secpath_has_nontransport(sp, 0, &xerr_idx)) {\n\t\t\txfrm_secpath_reject(xerr_idx, skb, &fl);\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINNOPOLS);\n\t\t\treturn 0;\n\t\t}\n\t\treturn 1;\n\t}\n\n\tpol->curlft.use_time = ktime_get_real_seconds();\n\n\tpols[0] = pol;\n\tnpols++;\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pols[0]->type != XFRM_POLICY_TYPE_MAIN) {\n\t\tpols[1] = xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_MAIN,\n\t\t\t\t\t\t    &fl, family,\n\t\t\t\t\t\t    XFRM_POLICY_IN, if_id);\n\t\tif (pols[1]) {\n\t\t\tif (IS_ERR(pols[1])) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tpols[1]->curlft.use_time = ktime_get_real_seconds();\n\t\t\tnpols++;\n\t\t}\n\t}\n#endif\n\n\tif (pol->action == XFRM_POLICY_ALLOW) {\n\t\tstatic struct sec_path dummy;\n\t\tstruct xfrm_tmpl *tp[XFRM_MAX_DEPTH];\n\t\tstruct xfrm_tmpl *stp[XFRM_MAX_DEPTH];\n\t\tstruct xfrm_tmpl **tpp = tp;\n\t\tint ti = 0;\n\t\tint i, k;\n\n\t\tsp = skb_sec_path(skb);\n\t\tif (!sp)\n\t\t\tsp = &dummy;\n\n\t\tfor (pi = 0; pi < npols; pi++) {\n\t\t\tif (pols[pi] != pol &&\n\t\t\t    pols[pi]->action != XFRM_POLICY_ALLOW) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLBLOCK);\n\t\t\t\tgoto reject;\n\t\t\t}\n\t\t\tif (ti + pols[pi]->xfrm_nr >= XFRM_MAX_DEPTH) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINBUFFERERROR);\n\t\t\t\tgoto reject_error;\n\t\t\t}\n\t\t\tfor (i = 0; i < pols[pi]->xfrm_nr; i++)\n\t\t\t\ttpp[ti++] = &pols[pi]->xfrm_vec[i];\n\t\t}\n\t\txfrm_nr = ti;\n\n\t\tif (net->xfrm.policy_default[dir] == XFRM_USERPOLICY_BLOCK &&\n\t\t    !xfrm_nr) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINNOSTATES);\n\t\t\tgoto reject;\n\t\t}\n\n\t\tif (npols > 1) {\n\t\t\txfrm_tmpl_sort(stp, tpp, xfrm_nr, family);\n\t\t\ttpp = stp;\n\t\t}\n\n\t\t/* For each tunnel xfrm, find the first matching tmpl.\n\t\t * For each tmpl before that, find corresponding xfrm.\n\t\t * Order is _important_. Later we will implement\n\t\t * some barriers, but at the moment barriers\n\t\t * are implied between each two transformations.\n\t\t */\n\t\tfor (i = xfrm_nr-1, k = 0; i >= 0; i--) {\n\t\t\tk = xfrm_policy_ok(tpp[i], sp, k, family);\n\t\t\tif (k < 0) {\n\t\t\t\tif (k < -1)\n\t\t\t\t\t/* \"-2 - errored_index\" returned */\n\t\t\t\t\txerr_idx = -(2+k);\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINTMPLMISMATCH);\n\t\t\t\tgoto reject;\n\t\t\t}\n\t\t}\n\n\t\tif (secpath_has_nontransport(sp, k, &xerr_idx)) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINTMPLMISMATCH);\n\t\t\tgoto reject;\n\t\t}\n\n\t\txfrm_pols_put(pols, npols);\n\t\treturn 1;\n\t}\n\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLBLOCK);\n\nreject:\n\txfrm_secpath_reject(xerr_idx, skb, &fl);\nreject_error:\n\txfrm_pols_put(pols, npols);\n\treturn 0;\n}\nEXPORT_SYMBOL(__xfrm_policy_check);\n\nint __xfrm_route_forward(struct sk_buff *skb, unsigned short family)\n{\n\tstruct net *net = dev_net(skb->dev);\n\tstruct flowi fl;\n\tstruct dst_entry *dst;\n\tint res = 1;\n\n\tif (xfrm_decode_session(skb, &fl, family) < 0) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMFWDHDRERROR);\n\t\treturn 0;\n\t}\n\n\tskb_dst_force(skb);\n\tif (!skb_dst(skb)) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMFWDHDRERROR);\n\t\treturn 0;\n\t}\n\n\tdst = xfrm_lookup(net, skb_dst(skb), &fl, NULL, XFRM_LOOKUP_QUEUE);\n\tif (IS_ERR(dst)) {\n\t\tres = 0;\n\t\tdst = NULL;\n\t}\n\tskb_dst_set(skb, dst);\n\treturn res;\n}\nEXPORT_SYMBOL(__xfrm_route_forward);\n\n/* Optimize later using cookies and generation ids. */\n\nstatic struct dst_entry *xfrm_dst_check(struct dst_entry *dst, u32 cookie)\n{\n\t/* Code (such as __xfrm4_bundle_create()) sets dst->obsolete\n\t * to DST_OBSOLETE_FORCE_CHK to force all XFRM destinations to\n\t * get validated by dst_ops->check on every use.  We do this\n\t * because when a normal route referenced by an XFRM dst is\n\t * obsoleted we do not go looking around for all parent\n\t * referencing XFRM dsts so that we can invalidate them.  It\n\t * is just too much work.  Instead we make the checks here on\n\t * every use.  For example:\n\t *\n\t *\tXFRM dst A --> IPv4 dst X\n\t *\n\t * X is the \"xdst->route\" of A (X is also the \"dst->path\" of A\n\t * in this example).  If X is marked obsolete, \"A\" will not\n\t * notice.  That's what we are validating here via the\n\t * stale_bundle() check.\n\t *\n\t * When a dst is removed from the fib tree, DST_OBSOLETE_DEAD will\n\t * be marked on it.\n\t * This will force stale_bundle() to fail on any xdst bundle with\n\t * this dst linked in it.\n\t */\n\tif (dst->obsolete < 0 && !stale_bundle(dst))\n\t\treturn dst;\n\n\treturn NULL;\n}\n\nstatic int stale_bundle(struct dst_entry *dst)\n{\n\treturn !xfrm_bundle_ok((struct xfrm_dst *)dst);\n}\n\nvoid xfrm_dst_ifdown(struct dst_entry *dst, struct net_device *dev)\n{\n\twhile ((dst = xfrm_dst_child(dst)) && dst->xfrm && dst->dev == dev) {\n\t\tdst->dev = blackhole_netdev;\n\t\tdev_hold(dst->dev);\n\t\tdev_put(dev);\n\t}\n}\nEXPORT_SYMBOL(xfrm_dst_ifdown);\n\nstatic void xfrm_link_failure(struct sk_buff *skb)\n{\n\t/* Impossible. Such dst must be popped before reaches point of failure. */\n}\n\nstatic struct dst_entry *xfrm_negative_advice(struct dst_entry *dst)\n{\n\tif (dst) {\n\t\tif (dst->obsolete) {\n\t\t\tdst_release(dst);\n\t\t\tdst = NULL;\n\t\t}\n\t}\n\treturn dst;\n}\n\nstatic void xfrm_init_pmtu(struct xfrm_dst **bundle, int nr)\n{\n\twhile (nr--) {\n\t\tstruct xfrm_dst *xdst = bundle[nr];\n\t\tu32 pmtu, route_mtu_cached;\n\t\tstruct dst_entry *dst;\n\n\t\tdst = &xdst->u.dst;\n\t\tpmtu = dst_mtu(xfrm_dst_child(dst));\n\t\txdst->child_mtu_cached = pmtu;\n\n\t\tpmtu = xfrm_state_mtu(dst->xfrm, pmtu);\n\n\t\troute_mtu_cached = dst_mtu(xdst->route);\n\t\txdst->route_mtu_cached = route_mtu_cached;\n\n\t\tif (pmtu > route_mtu_cached)\n\t\t\tpmtu = route_mtu_cached;\n\n\t\tdst_metric_set(dst, RTAX_MTU, pmtu);\n\t}\n}\n\n/* Check that the bundle accepts the flow and its components are\n * still valid.\n */\n\nstatic int xfrm_bundle_ok(struct xfrm_dst *first)\n{\n\tstruct xfrm_dst *bundle[XFRM_MAX_DEPTH];\n\tstruct dst_entry *dst = &first->u.dst;\n\tstruct xfrm_dst *xdst;\n\tint start_from, nr;\n\tu32 mtu;\n\n\tif (!dst_check(xfrm_dst_path(dst), ((struct xfrm_dst *)dst)->path_cookie) ||\n\t    (dst->dev && !netif_running(dst->dev)))\n\t\treturn 0;\n\n\tif (dst->flags & DST_XFRM_QUEUE)\n\t\treturn 1;\n\n\tstart_from = nr = 0;\n\tdo {\n\t\tstruct xfrm_dst *xdst = (struct xfrm_dst *)dst;\n\n\t\tif (dst->xfrm->km.state != XFRM_STATE_VALID)\n\t\t\treturn 0;\n\t\tif (xdst->xfrm_genid != dst->xfrm->genid)\n\t\t\treturn 0;\n\t\tif (xdst->num_pols > 0 &&\n\t\t    xdst->policy_genid != atomic_read(&xdst->pols[0]->genid))\n\t\t\treturn 0;\n\n\t\tbundle[nr++] = xdst;\n\n\t\tmtu = dst_mtu(xfrm_dst_child(dst));\n\t\tif (xdst->child_mtu_cached != mtu) {\n\t\t\tstart_from = nr;\n\t\t\txdst->child_mtu_cached = mtu;\n\t\t}\n\n\t\tif (!dst_check(xdst->route, xdst->route_cookie))\n\t\t\treturn 0;\n\t\tmtu = dst_mtu(xdst->route);\n\t\tif (xdst->route_mtu_cached != mtu) {\n\t\t\tstart_from = nr;\n\t\t\txdst->route_mtu_cached = mtu;\n\t\t}\n\n\t\tdst = xfrm_dst_child(dst);\n\t} while (dst->xfrm);\n\n\tif (likely(!start_from))\n\t\treturn 1;\n\n\txdst = bundle[start_from - 1];\n\tmtu = xdst->child_mtu_cached;\n\twhile (start_from--) {\n\t\tdst = &xdst->u.dst;\n\n\t\tmtu = xfrm_state_mtu(dst->xfrm, mtu);\n\t\tif (mtu > xdst->route_mtu_cached)\n\t\t\tmtu = xdst->route_mtu_cached;\n\t\tdst_metric_set(dst, RTAX_MTU, mtu);\n\t\tif (!start_from)\n\t\t\tbreak;\n\n\t\txdst = bundle[start_from - 1];\n\t\txdst->child_mtu_cached = mtu;\n\t}\n\n\treturn 1;\n}\n\nstatic unsigned int xfrm_default_advmss(const struct dst_entry *dst)\n{\n\treturn dst_metric_advmss(xfrm_dst_path(dst));\n}\n\nstatic unsigned int xfrm_mtu(const struct dst_entry *dst)\n{\n\tunsigned int mtu = dst_metric_raw(dst, RTAX_MTU);\n\n\treturn mtu ? : dst_mtu(xfrm_dst_path(dst));\n}\n\nstatic const void *xfrm_get_dst_nexthop(const struct dst_entry *dst,\n\t\t\t\t\tconst void *daddr)\n{\n\twhile (dst->xfrm) {\n\t\tconst struct xfrm_state *xfrm = dst->xfrm;\n\n\t\tdst = xfrm_dst_child(dst);\n\n\t\tif (xfrm->props.mode == XFRM_MODE_TRANSPORT)\n\t\t\tcontinue;\n\t\tif (xfrm->type->flags & XFRM_TYPE_REMOTE_COADDR)\n\t\t\tdaddr = xfrm->coaddr;\n\t\telse if (!(xfrm->type->flags & XFRM_TYPE_LOCAL_COADDR))\n\t\t\tdaddr = &xfrm->id.daddr;\n\t}\n\treturn daddr;\n}\n\nstatic struct neighbour *xfrm_neigh_lookup(const struct dst_entry *dst,\n\t\t\t\t\t   struct sk_buff *skb,\n\t\t\t\t\t   const void *daddr)\n{\n\tconst struct dst_entry *path = xfrm_dst_path(dst);\n\n\tif (!skb)\n\t\tdaddr = xfrm_get_dst_nexthop(dst, daddr);\n\treturn path->ops->neigh_lookup(path, skb, daddr);\n}\n\nstatic void xfrm_confirm_neigh(const struct dst_entry *dst, const void *daddr)\n{\n\tconst struct dst_entry *path = xfrm_dst_path(dst);\n\n\tdaddr = xfrm_get_dst_nexthop(dst, daddr);\n\tpath->ops->confirm_neigh(path, daddr);\n}\n\nint xfrm_policy_register_afinfo(const struct xfrm_policy_afinfo *afinfo, int family)\n{\n\tint err = 0;\n\n\tif (WARN_ON(family >= ARRAY_SIZE(xfrm_policy_afinfo)))\n\t\treturn -EAFNOSUPPORT;\n\n\tspin_lock(&xfrm_policy_afinfo_lock);\n\tif (unlikely(xfrm_policy_afinfo[family] != NULL))\n\t\terr = -EEXIST;\n\telse {\n\t\tstruct dst_ops *dst_ops = afinfo->dst_ops;\n\t\tif (likely(dst_ops->kmem_cachep == NULL))\n\t\t\tdst_ops->kmem_cachep = xfrm_dst_cache;\n\t\tif (likely(dst_ops->check == NULL))\n\t\t\tdst_ops->check = xfrm_dst_check;\n\t\tif (likely(dst_ops->default_advmss == NULL))\n\t\t\tdst_ops->default_advmss = xfrm_default_advmss;\n\t\tif (likely(dst_ops->mtu == NULL))\n\t\t\tdst_ops->mtu = xfrm_mtu;\n\t\tif (likely(dst_ops->negative_advice == NULL))\n\t\t\tdst_ops->negative_advice = xfrm_negative_advice;\n\t\tif (likely(dst_ops->link_failure == NULL))\n\t\t\tdst_ops->link_failure = xfrm_link_failure;\n\t\tif (likely(dst_ops->neigh_lookup == NULL))\n\t\t\tdst_ops->neigh_lookup = xfrm_neigh_lookup;\n\t\tif (likely(!dst_ops->confirm_neigh))\n\t\t\tdst_ops->confirm_neigh = xfrm_confirm_neigh;\n\t\trcu_assign_pointer(xfrm_policy_afinfo[family], afinfo);\n\t}\n\tspin_unlock(&xfrm_policy_afinfo_lock);\n\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_policy_register_afinfo);\n\nvoid xfrm_policy_unregister_afinfo(const struct xfrm_policy_afinfo *afinfo)\n{\n\tstruct dst_ops *dst_ops = afinfo->dst_ops;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(xfrm_policy_afinfo); i++) {\n\t\tif (xfrm_policy_afinfo[i] != afinfo)\n\t\t\tcontinue;\n\t\tRCU_INIT_POINTER(xfrm_policy_afinfo[i], NULL);\n\t\tbreak;\n\t}\n\n\tsynchronize_rcu();\n\n\tdst_ops->kmem_cachep = NULL;\n\tdst_ops->check = NULL;\n\tdst_ops->negative_advice = NULL;\n\tdst_ops->link_failure = NULL;\n}\nEXPORT_SYMBOL(xfrm_policy_unregister_afinfo);\n\nvoid xfrm_if_register_cb(const struct xfrm_if_cb *ifcb)\n{\n\tspin_lock(&xfrm_if_cb_lock);\n\trcu_assign_pointer(xfrm_if_cb, ifcb);\n\tspin_unlock(&xfrm_if_cb_lock);\n}\nEXPORT_SYMBOL(xfrm_if_register_cb);\n\nvoid xfrm_if_unregister_cb(void)\n{\n\tRCU_INIT_POINTER(xfrm_if_cb, NULL);\n\tsynchronize_rcu();\n}\nEXPORT_SYMBOL(xfrm_if_unregister_cb);\n\n#ifdef CONFIG_XFRM_STATISTICS\nstatic int __net_init xfrm_statistics_init(struct net *net)\n{\n\tint rv;\n\tnet->mib.xfrm_statistics = alloc_percpu(struct linux_xfrm_mib);\n\tif (!net->mib.xfrm_statistics)\n\t\treturn -ENOMEM;\n\trv = xfrm_proc_init(net);\n\tif (rv < 0)\n\t\tfree_percpu(net->mib.xfrm_statistics);\n\treturn rv;\n}\n\nstatic void xfrm_statistics_fini(struct net *net)\n{\n\txfrm_proc_fini(net);\n\tfree_percpu(net->mib.xfrm_statistics);\n}\n#else\nstatic int __net_init xfrm_statistics_init(struct net *net)\n{\n\treturn 0;\n}\n\nstatic void xfrm_statistics_fini(struct net *net)\n{\n}\n#endif\n\nstatic int __net_init xfrm_policy_init(struct net *net)\n{\n\tunsigned int hmask, sz;\n\tint dir, err;\n\n\tif (net_eq(net, &init_net)) {\n\t\txfrm_dst_cache = kmem_cache_create(\"xfrm_dst_cache\",\n\t\t\t\t\t   sizeof(struct xfrm_dst),\n\t\t\t\t\t   0, SLAB_HWCACHE_ALIGN|SLAB_PANIC,\n\t\t\t\t\t   NULL);\n\t\terr = rhashtable_init(&xfrm_policy_inexact_table,\n\t\t\t\t      &xfrm_pol_inexact_params);\n\t\tBUG_ON(err);\n\t}\n\n\thmask = 8 - 1;\n\tsz = (hmask+1) * sizeof(struct hlist_head);\n\n\tnet->xfrm.policy_byidx = xfrm_hash_alloc(sz);\n\tif (!net->xfrm.policy_byidx)\n\t\tgoto out_byidx;\n\tnet->xfrm.policy_idx_hmask = hmask;\n\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\tnet->xfrm.policy_count[dir] = 0;\n\t\tnet->xfrm.policy_count[XFRM_POLICY_MAX + dir] = 0;\n\t\tINIT_HLIST_HEAD(&net->xfrm.policy_inexact[dir]);\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\thtab->table = xfrm_hash_alloc(sz);\n\t\tif (!htab->table)\n\t\t\tgoto out_bydst;\n\t\thtab->hmask = hmask;\n\t\thtab->dbits4 = 32;\n\t\thtab->sbits4 = 32;\n\t\thtab->dbits6 = 128;\n\t\thtab->sbits6 = 128;\n\t}\n\tnet->xfrm.policy_hthresh.lbits4 = 32;\n\tnet->xfrm.policy_hthresh.rbits4 = 32;\n\tnet->xfrm.policy_hthresh.lbits6 = 128;\n\tnet->xfrm.policy_hthresh.rbits6 = 128;\n\n\tseqlock_init(&net->xfrm.policy_hthresh.lock);\n\n\tINIT_LIST_HEAD(&net->xfrm.policy_all);\n\tINIT_LIST_HEAD(&net->xfrm.inexact_bins);\n\tINIT_WORK(&net->xfrm.policy_hash_work, xfrm_hash_resize);\n\tINIT_WORK(&net->xfrm.policy_hthresh.work, xfrm_hash_rebuild);\n\treturn 0;\n\nout_bydst:\n\tfor (dir--; dir >= 0; dir--) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\txfrm_hash_free(htab->table, sz);\n\t}\n\txfrm_hash_free(net->xfrm.policy_byidx, sz);\nout_byidx:\n\treturn -ENOMEM;\n}\n\nstatic void xfrm_policy_fini(struct net *net)\n{\n\tstruct xfrm_pol_inexact_bin *b, *t;\n\tunsigned int sz;\n\tint dir;\n\n\tflush_work(&net->xfrm.policy_hash_work);\n#ifdef CONFIG_XFRM_SUB_POLICY\n\txfrm_policy_flush(net, XFRM_POLICY_TYPE_SUB, false);\n#endif\n\txfrm_policy_flush(net, XFRM_POLICY_TYPE_MAIN, false);\n\n\tWARN_ON(!list_empty(&net->xfrm.policy_all));\n\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\tWARN_ON(!hlist_empty(&net->xfrm.policy_inexact[dir]));\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\tsz = (htab->hmask + 1) * sizeof(struct hlist_head);\n\t\tWARN_ON(!hlist_empty(htab->table));\n\t\txfrm_hash_free(htab->table, sz);\n\t}\n\n\tsz = (net->xfrm.policy_idx_hmask + 1) * sizeof(struct hlist_head);\n\tWARN_ON(!hlist_empty(net->xfrm.policy_byidx));\n\txfrm_hash_free(net->xfrm.policy_byidx, sz);\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tlist_for_each_entry_safe(b, t, &net->xfrm.inexact_bins, inexact_bins)\n\t\t__xfrm_policy_inexact_prune_bin(b, true);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n}\n\nstatic int __net_init xfrm_net_init(struct net *net)\n{\n\tint rv;\n\n\t/* Initialize the per-net locks here */\n\tspin_lock_init(&net->xfrm.xfrm_state_lock);\n\tspin_lock_init(&net->xfrm.xfrm_policy_lock);\n\tseqcount_spinlock_init(&net->xfrm.xfrm_policy_hash_generation, &net->xfrm.xfrm_policy_lock);\n\tmutex_init(&net->xfrm.xfrm_cfg_mutex);\n\tnet->xfrm.policy_default[XFRM_POLICY_IN] = XFRM_USERPOLICY_ACCEPT;\n\tnet->xfrm.policy_default[XFRM_POLICY_FWD] = XFRM_USERPOLICY_ACCEPT;\n\tnet->xfrm.policy_default[XFRM_POLICY_OUT] = XFRM_USERPOLICY_ACCEPT;\n\n\trv = xfrm_statistics_init(net);\n\tif (rv < 0)\n\t\tgoto out_statistics;\n\trv = xfrm_state_init(net);\n\tif (rv < 0)\n\t\tgoto out_state;\n\trv = xfrm_policy_init(net);\n\tif (rv < 0)\n\t\tgoto out_policy;\n\trv = xfrm_sysctl_init(net);\n\tif (rv < 0)\n\t\tgoto out_sysctl;\n\n\treturn 0;\n\nout_sysctl:\n\txfrm_policy_fini(net);\nout_policy:\n\txfrm_state_fini(net);\nout_state:\n\txfrm_statistics_fini(net);\nout_statistics:\n\treturn rv;\n}\n\nstatic void __net_exit xfrm_net_exit(struct net *net)\n{\n\txfrm_sysctl_fini(net);\n\txfrm_policy_fini(net);\n\txfrm_state_fini(net);\n\txfrm_statistics_fini(net);\n}\n\nstatic struct pernet_operations __net_initdata xfrm_net_ops = {\n\t.init = xfrm_net_init,\n\t.exit = xfrm_net_exit,\n};\n\nvoid __init xfrm_init(void)\n{\n\tregister_pernet_subsys(&xfrm_net_ops);\n\txfrm_dev_init();\n\txfrm_input_init();\n\n#ifdef CONFIG_XFRM_ESPINTCP\n\tespintcp_init();\n#endif\n}\n\n#ifdef CONFIG_AUDITSYSCALL\nstatic void xfrm_audit_common_policyinfo(struct xfrm_policy *xp,\n\t\t\t\t\t struct audit_buffer *audit_buf)\n{\n\tstruct xfrm_sec_ctx *ctx = xp->security;\n\tstruct xfrm_selector *sel = &xp->selector;\n\n\tif (ctx)\n\t\taudit_log_format(audit_buf, \" sec_alg=%u sec_doi=%u sec_obj=%s\",\n\t\t\t\t ctx->ctx_alg, ctx->ctx_doi, ctx->ctx_str);\n\n\tswitch (sel->family) {\n\tcase AF_INET:\n\t\taudit_log_format(audit_buf, \" src=%pI4\", &sel->saddr.a4);\n\t\tif (sel->prefixlen_s != 32)\n\t\t\taudit_log_format(audit_buf, \" src_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_s);\n\t\taudit_log_format(audit_buf, \" dst=%pI4\", &sel->daddr.a4);\n\t\tif (sel->prefixlen_d != 32)\n\t\t\taudit_log_format(audit_buf, \" dst_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_d);\n\t\tbreak;\n\tcase AF_INET6:\n\t\taudit_log_format(audit_buf, \" src=%pI6\", sel->saddr.a6);\n\t\tif (sel->prefixlen_s != 128)\n\t\t\taudit_log_format(audit_buf, \" src_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_s);\n\t\taudit_log_format(audit_buf, \" dst=%pI6\", sel->daddr.a6);\n\t\tif (sel->prefixlen_d != 128)\n\t\t\taudit_log_format(audit_buf, \" dst_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_d);\n\t\tbreak;\n\t}\n}\n\nvoid xfrm_audit_policy_add(struct xfrm_policy *xp, int result, bool task_valid)\n{\n\tstruct audit_buffer *audit_buf;\n\n\taudit_buf = xfrm_audit_start(\"SPD-add\");\n\tif (audit_buf == NULL)\n\t\treturn;\n\txfrm_audit_helper_usrinfo(task_valid, audit_buf);\n\taudit_log_format(audit_buf, \" res=%u\", result);\n\txfrm_audit_common_policyinfo(xp, audit_buf);\n\taudit_log_end(audit_buf);\n}\nEXPORT_SYMBOL_GPL(xfrm_audit_policy_add);\n\nvoid xfrm_audit_policy_delete(struct xfrm_policy *xp, int result,\n\t\t\t      bool task_valid)\n{\n\tstruct audit_buffer *audit_buf;\n\n\taudit_buf = xfrm_audit_start(\"SPD-delete\");\n\tif (audit_buf == NULL)\n\t\treturn;\n\txfrm_audit_helper_usrinfo(task_valid, audit_buf);\n\taudit_log_format(audit_buf, \" res=%u\", result);\n\txfrm_audit_common_policyinfo(xp, audit_buf);\n\taudit_log_end(audit_buf);\n}\nEXPORT_SYMBOL_GPL(xfrm_audit_policy_delete);\n#endif\n\n#ifdef CONFIG_XFRM_MIGRATE\nstatic bool xfrm_migrate_selector_match(const struct xfrm_selector *sel_cmp,\n\t\t\t\t\tconst struct xfrm_selector *sel_tgt)\n{\n\tif (sel_cmp->proto == IPSEC_ULPROTO_ANY) {\n\t\tif (sel_tgt->family == sel_cmp->family &&\n\t\t    xfrm_addr_equal(&sel_tgt->daddr, &sel_cmp->daddr,\n\t\t\t\t    sel_cmp->family) &&\n\t\t    xfrm_addr_equal(&sel_tgt->saddr, &sel_cmp->saddr,\n\t\t\t\t    sel_cmp->family) &&\n\t\t    sel_tgt->prefixlen_d == sel_cmp->prefixlen_d &&\n\t\t    sel_tgt->prefixlen_s == sel_cmp->prefixlen_s) {\n\t\t\treturn true;\n\t\t}\n\t} else {\n\t\tif (memcmp(sel_tgt, sel_cmp, sizeof(*sel_tgt)) == 0) {\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\nstatic struct xfrm_policy *xfrm_migrate_policy_find(const struct xfrm_selector *sel,\n\t\t\t\t\t\t    u8 dir, u8 type, struct net *net, u32 if_id)\n{\n\tstruct xfrm_policy *pol, *ret = NULL;\n\tstruct hlist_head *chain;\n\tu32 priority = ~0U;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = policy_hash_direct(net, &sel->daddr, &sel->saddr, sel->family, dir);\n\thlist_for_each_entry(pol, chain, bydst) {\n\t\tif ((if_id == 0 || pol->if_id == if_id) &&\n\t\t    xfrm_migrate_selector_match(sel, &pol->selector) &&\n\t\t    pol->type == type) {\n\t\t\tret = pol;\n\t\t\tpriority = ret->priority;\n\t\t\tbreak;\n\t\t}\n\t}\n\tchain = &net->xfrm.policy_inexact[dir];\n\thlist_for_each_entry(pol, chain, bydst_inexact_list) {\n\t\tif ((pol->priority >= priority) && ret)\n\t\t\tbreak;\n\n\t\tif ((if_id == 0 || pol->if_id == if_id) &&\n\t\t    xfrm_migrate_selector_match(sel, &pol->selector) &&\n\t\t    pol->type == type) {\n\t\t\tret = pol;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\txfrm_pol_hold(ret);\n\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\treturn ret;\n}\n\nstatic int migrate_tmpl_match(const struct xfrm_migrate *m, const struct xfrm_tmpl *t)\n{\n\tint match = 0;\n\n\tif (t->mode == m->mode && t->id.proto == m->proto &&\n\t    (m->reqid == 0 || t->reqid == m->reqid)) {\n\t\tswitch (t->mode) {\n\t\tcase XFRM_MODE_TUNNEL:\n\t\tcase XFRM_MODE_BEET:\n\t\t\tif (xfrm_addr_equal(&t->id.daddr, &m->old_daddr,\n\t\t\t\t\t    m->old_family) &&\n\t\t\t    xfrm_addr_equal(&t->saddr, &m->old_saddr,\n\t\t\t\t\t    m->old_family)) {\n\t\t\t\tmatch = 1;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XFRM_MODE_TRANSPORT:\n\t\t\t/* in case of transport mode, template does not store\n\t\t\t   any IP addresses, hence we just compare mode and\n\t\t\t   protocol */\n\t\t\tmatch = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn match;\n}\n\n/* update endpoint address(es) of template(s) */\nstatic int xfrm_policy_migrate(struct xfrm_policy *pol,\n\t\t\t       struct xfrm_migrate *m, int num_migrate)\n{\n\tstruct xfrm_migrate *mp;\n\tint i, j, n = 0;\n\n\twrite_lock_bh(&pol->lock);\n\tif (unlikely(pol->walk.dead)) {\n\t\t/* target policy has been deleted */\n\t\twrite_unlock_bh(&pol->lock);\n\t\treturn -ENOENT;\n\t}\n\n\tfor (i = 0; i < pol->xfrm_nr; i++) {\n\t\tfor (j = 0, mp = m; j < num_migrate; j++, mp++) {\n\t\t\tif (!migrate_tmpl_match(mp, &pol->xfrm_vec[i]))\n\t\t\t\tcontinue;\n\t\t\tn++;\n\t\t\tif (pol->xfrm_vec[i].mode != XFRM_MODE_TUNNEL &&\n\t\t\t    pol->xfrm_vec[i].mode != XFRM_MODE_BEET)\n\t\t\t\tcontinue;\n\t\t\t/* update endpoints */\n\t\t\tmemcpy(&pol->xfrm_vec[i].id.daddr, &mp->new_daddr,\n\t\t\t       sizeof(pol->xfrm_vec[i].id.daddr));\n\t\t\tmemcpy(&pol->xfrm_vec[i].saddr, &mp->new_saddr,\n\t\t\t       sizeof(pol->xfrm_vec[i].saddr));\n\t\t\tpol->xfrm_vec[i].encap_family = mp->new_family;\n\t\t\t/* flush bundles */\n\t\t\tatomic_inc(&pol->genid);\n\t\t}\n\t}\n\n\twrite_unlock_bh(&pol->lock);\n\n\tif (!n)\n\t\treturn -ENODATA;\n\n\treturn 0;\n}\n\nstatic int xfrm_migrate_check(const struct xfrm_migrate *m, int num_migrate)\n{\n\tint i, j;\n\n\tif (num_migrate < 1 || num_migrate > XFRM_MAX_DEPTH)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < num_migrate; i++) {\n\t\tif (xfrm_addr_any(&m[i].new_daddr, m[i].new_family) ||\n\t\t    xfrm_addr_any(&m[i].new_saddr, m[i].new_family))\n\t\t\treturn -EINVAL;\n\n\t\t/* check if there is any duplicated entry */\n\t\tfor (j = i + 1; j < num_migrate; j++) {\n\t\t\tif (!memcmp(&m[i].old_daddr, &m[j].old_daddr,\n\t\t\t\t    sizeof(m[i].old_daddr)) &&\n\t\t\t    !memcmp(&m[i].old_saddr, &m[j].old_saddr,\n\t\t\t\t    sizeof(m[i].old_saddr)) &&\n\t\t\t    m[i].proto == m[j].proto &&\n\t\t\t    m[i].mode == m[j].mode &&\n\t\t\t    m[i].reqid == m[j].reqid &&\n\t\t\t    m[i].old_family == m[j].old_family)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint xfrm_migrate(const struct xfrm_selector *sel, u8 dir, u8 type,\n\t\t struct xfrm_migrate *m, int num_migrate,\n\t\t struct xfrm_kmaddress *k, struct net *net,\n\t\t struct xfrm_encap_tmpl *encap, u32 if_id)\n{\n\tint i, err, nx_cur = 0, nx_new = 0;\n\tstruct xfrm_policy *pol = NULL;\n\tstruct xfrm_state *x, *xc;\n\tstruct xfrm_state *x_cur[XFRM_MAX_DEPTH];\n\tstruct xfrm_state *x_new[XFRM_MAX_DEPTH];\n\tstruct xfrm_migrate *mp;\n\n\t/* Stage 0 - sanity checks */\n\tif ((err = xfrm_migrate_check(m, num_migrate)) < 0)\n\t\tgoto out;\n\n\tif (dir >= XFRM_POLICY_MAX) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Stage 1 - find policy */\n\tif ((pol = xfrm_migrate_policy_find(sel, dir, type, net, if_id)) == NULL) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\t/* Stage 2 - find and update state(s) */\n\tfor (i = 0, mp = m; i < num_migrate; i++, mp++) {\n\t\tif ((x = xfrm_migrate_state_find(mp, net, if_id))) {\n\t\t\tx_cur[nx_cur] = x;\n\t\t\tnx_cur++;\n\t\t\txc = xfrm_state_migrate(x, mp, encap);\n\t\t\tif (xc) {\n\t\t\t\tx_new[nx_new] = xc;\n\t\t\t\tnx_new++;\n\t\t\t} else {\n\t\t\t\terr = -ENODATA;\n\t\t\t\tgoto restore_state;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Stage 3 - update policy */\n\tif ((err = xfrm_policy_migrate(pol, m, num_migrate)) < 0)\n\t\tgoto restore_state;\n\n\t/* Stage 4 - delete old state(s) */\n\tif (nx_cur) {\n\t\txfrm_states_put(x_cur, nx_cur);\n\t\txfrm_states_delete(x_cur, nx_cur);\n\t}\n\n\t/* Stage 5 - announce */\n\tkm_migrate(sel, dir, type, m, num_migrate, k, encap);\n\n\txfrm_pol_put(pol);\n\n\treturn 0;\nout:\n\treturn err;\n\nrestore_state:\n\tif (pol)\n\t\txfrm_pol_put(pol);\n\tif (nx_cur)\n\t\txfrm_states_put(x_cur, nx_cur);\n\tif (nx_new)\n\t\txfrm_states_delete(x_new, nx_new);\n\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_migrate);\n#endif\n"], "filenames": ["net/xfrm/xfrm_policy.c"], "buggy_code_start_loc": [2681], "buggy_code_end_loc": [2696], "fixing_code_start_loc": [2681], "fixing_code_end_loc": [2700], "type": "NVD-CWE-Other", "message": "An issue was discovered in the Linux kernel through 5.18.14. xfrm_expand_policies in net/xfrm/xfrm_policy.c can cause a refcount to be dropped twice.", "other": {"cve": {"id": "CVE-2022-36879", "sourceIdentifier": "cve@mitre.org", "published": "2022-07-27T04:15:10.740", "lastModified": "2022-11-04T18:15:44.327", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "An issue was discovered in the Linux kernel through 5.18.14. xfrm_expand_policies in net/xfrm/xfrm_policy.c can cause a refcount to be dropped twice."}, {"lang": "es", "value": "Se ha detectado un problema en el kernel de Linux versiones hasta 5.18.14. la funci\u00f3n xfrm_expand_policies en el archivo net/xfrm/xfrm_policy.c puede causar que un refcount sea descartado dos veces"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-Other"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "5.18.14", "matchCriteriaId": "ABF7248B-E964-4678-9323-06AF633A3E28"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:10.0:*:*:*:*:*:*:*", "matchCriteriaId": "07B237A9-69A3-4A9C-9DA0-4E06BD37AE73"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:11.0:*:*:*:*:*:*:*", "matchCriteriaId": "FA6FEEC2-9F11-4643-8827-749718254FED"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:a700s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "FDD92BFA-9117-4E6E-A13F-ED064B4B7284"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:a700s:-:*:*:*:*:*:*:*", "matchCriteriaId": "4B7DA42F-5D64-4967-A2D4-6210FE507841"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:netapp:active_iq_unified_manager:-:*:*:*:*:vmware_vsphere:*:*", "matchCriteriaId": "3A756737-1CC4-42C2-A4DF-E1C893B4E2D5"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:e-series_santricity_os_controller:*:*:*:*:*:*:*:*", "versionStartIncluding": "11.0", "versionEndIncluding": "11.50.2", "matchCriteriaId": "433D435D-13D0-4EAA-ACD9-DD88DA712D00"}, {"vulnerable": true, "criteria": "cpe:2.3:o:netapp:hci_bootstrap_os:-:*:*:*:*:*:*:*", "matchCriteriaId": "1C767AA1-88B7-48F0-9F31-A89D16DCD52C"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:aff_8300_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "CA79D39A-A5F2-4C44-A805-5113065F8C25"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:aff_8300:-:*:*:*:*:*:*:*", "matchCriteriaId": "4CA55FBD-6EBA-49C8-92BA-2B1BCCB18A3A"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:fas_8300_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "D5CDADAB-72A5-4526-8432-E6C9AC56B29F"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:fas_8300:-:*:*:*:*:*:*:*", "matchCriteriaId": "E64576DE-90F0-4F5E-9C82-AB745CFEDBB7"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:aff_8700_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "70ECC434-DF20-49A6-B4CF-D5CCA480E57D"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:aff_8700:-:*:*:*:*:*:*:*", "matchCriteriaId": "232DC609-8023-41F9-8CE3-1B31CE2F2D93"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:fas_8700_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "EF5AFE69-7990-4F80-9E63-D8AD58AA3A2D"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:fas_8700:-:*:*:*:*:*:*:*", "matchCriteriaId": "6415E28A-4EAC-4F7F-BD81-1A55CE8B6F40"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:aff_a400_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "56FD9B9A-BBE5-4CA5-B9F9-B16E1FE738C8"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:aff_a400:-:*:*:*:*:*:*:*", "matchCriteriaId": "F3E70A56-DBA8-45C7-8C49-1A036501156F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:fas_a400_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "CAA3A789-79F7-4DC8-9722-3958A3162EB4"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:fas_a400:-:*:*:*:*:*:*:*", "matchCriteriaId": "18C138F0-706F-44A8-880E-133F66DE164A"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:aff_a250_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "0D5DE972-F8B8-4964-943A-DA0BD18289D1"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:aff_a250:-:*:*:*:*:*:*:*", "matchCriteriaId": "D4B1F59C-6ADA-4930-834F-2A8A8444F6AE"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:fas_a250_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "3C43BFDA-D643-4619-A34C-9BDDA271F3F2"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:fas_a250:-:*:*:*:*:*:*:*", "matchCriteriaId": "980D02F3-0BC7-4AF1-82B6-4B65D15BEC1D"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:fas_500f_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "86E430A7-F93D-422B-BC9E-99C17CC2BF6F"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:fas_500f:-:*:*:*:*:*:*:*", "matchCriteriaId": "DBC58E3E-C8AA-4400-8A48-733B321CC924"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:aff_500f_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "578BB9A7-BF28-4068-A9A6-1DE19CEEC293"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:aff_500f:-:*:*:*:*:*:*:*", "matchCriteriaId": "2AB58180-E5E0-4056-ABF9-A99E9F6A9E86"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h300s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "6770B6C3-732E-4E22-BF1C-2D2FD610061C"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h300s:-:*:*:*:*:*:*:*", "matchCriteriaId": "9F9C8C20-42EB-4AB5-BD97-212DEB070C43"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h500s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "7FFF7106-ED78-49BA-9EC5-B889E3685D53"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h500s:-:*:*:*:*:*:*:*", "matchCriteriaId": "E63D8B0F-006E-4801-BF9D-1C001BBFB4F9"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h700s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "56409CEC-5A1E-4450-AA42-641E459CC2AF"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h700s:-:*:*:*:*:*:*:*", "matchCriteriaId": "B06F4839-D16A-4A61-9BB5-55B13F41E47F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h410s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "D0B4AD8A-F172-4558-AEC6-FF424BA2D912"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h410s:-:*:*:*:*:*:*:*", "matchCriteriaId": "8497A4C9-8474-4A62-8331-3FE862ED4098"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h410c_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "234DEFE0-5CE5-4B0A-96B8-5D227CB8ED31"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h410c:-:*:*:*:*:*:*:*", "matchCriteriaId": "CDDF61B7-EC5C-467C-B710-B89F502CD04F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h610c_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "89612649-BACF-4FAC-9BA4-324724FD93A6"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h610c:-:*:*:*:*:*:*:*", "matchCriteriaId": "F3D9B255-C1AF-42D1-BF9B-13642FBDC080"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h610s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "FD7CFE0E-9D1E-4495-B302-89C3096FC0DF"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h610s:-:*:*:*:*:*:*:*", "matchCriteriaId": "F63A3FA7-AAED-4A9D-9FDE-6195302DA0F6"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h615c_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "5921A877-18BF-43FE-915C-D226E140ACFC"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h615c:-:*:*:*:*:*:*:*", "matchCriteriaId": "7296A1F2-D315-4FD5-8A73-65C480C855BE"}]}]}], "references": [{"url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit?id=f85daf0e725358be78dfd208dea5fd665d8cb901", "source": "cve@mitre.org", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/f85daf0e725358be78dfd208dea5fd665d8cb901", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2022/09/msg00011.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2022/10/msg00000.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20220901-0007/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.debian.org/security/2022/dsa-5207", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/f85daf0e725358be78dfd208dea5fd665d8cb901"}}
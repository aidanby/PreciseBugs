{"buggy_code": ["/*\n * H.26L/H.264/AVC/JVT/14496-10/... decoder\n * Copyright (c) 2003 Michael Niedermayer <michaelni@gmx.at>\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * H.264 / AVC / MPEG4 part10 codec.\n * @author Michael Niedermayer <michaelni@gmx.at>\n */\n\n#define UNCHECKED_BITSTREAM_READER 1\n\n#include \"libavutil/avassert.h\"\n#include \"libavutil/display.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/stereo3d.h\"\n#include \"libavutil/timer.h\"\n#include \"internal.h\"\n#include \"cabac.h\"\n#include \"cabac_functions.h\"\n#include \"error_resilience.h\"\n#include \"avcodec.h\"\n#include \"h264.h\"\n#include \"h264data.h\"\n#include \"h264chroma.h\"\n#include \"h264_mvpred.h\"\n#include \"golomb.h\"\n#include \"mathops.h\"\n#include \"me_cmp.h\"\n#include \"mpegutils.h\"\n#include \"rectangle.h\"\n#include \"svq3.h\"\n#include \"thread.h\"\n#include \"vdpau_internal.h\"\n\n#include <assert.h>\n\nconst uint16_t ff_h264_mb_sizes[4] = { 256, 384, 512, 768 };\n\nint avpriv_h264_has_num_reorder_frames(AVCodecContext *avctx)\n{\n    H264Context *h = avctx->priv_data;\n    return h ? h->sps.num_reorder_frames : 0;\n}\n\nstatic void h264_er_decode_mb(void *opaque, int ref, int mv_dir, int mv_type,\n                              int (*mv)[2][4][2],\n                              int mb_x, int mb_y, int mb_intra, int mb_skipped)\n{\n    H264Context *h = opaque;\n\n    h->mb_x  = mb_x;\n    h->mb_y  = mb_y;\n    h->mb_xy = mb_x + mb_y * h->mb_stride;\n    memset(h->non_zero_count_cache, 0, sizeof(h->non_zero_count_cache));\n    av_assert1(ref >= 0);\n    /* FIXME: It is possible albeit uncommon that slice references\n     * differ between slices. We take the easy approach and ignore\n     * it for now. If this turns out to have any relevance in\n     * practice then correct remapping should be added. */\n    if (ref >= h->ref_count[0])\n        ref = 0;\n    if (!h->ref_list[0][ref].f.data[0]) {\n        av_log(h->avctx, AV_LOG_DEBUG, \"Reference not available for error concealing\\n\");\n        ref = 0;\n    }\n    if ((h->ref_list[0][ref].reference&3) != 3) {\n        av_log(h->avctx, AV_LOG_DEBUG, \"Reference invalid\\n\");\n        return;\n    }\n    fill_rectangle(&h->cur_pic.ref_index[0][4 * h->mb_xy],\n                   2, 2, 2, ref, 1);\n    fill_rectangle(&h->ref_cache[0][scan8[0]], 4, 4, 8, ref, 1);\n    fill_rectangle(h->mv_cache[0][scan8[0]], 4, 4, 8,\n                   pack16to32((*mv)[0][0][0], (*mv)[0][0][1]), 4);\n    h->mb_mbaff =\n    h->mb_field_decoding_flag = 0;\n    ff_h264_hl_decode_mb(h);\n}\n\nvoid ff_h264_draw_horiz_band(H264Context *h, int y, int height)\n{\n    AVCodecContext *avctx = h->avctx;\n    AVFrame *cur  = &h->cur_pic.f;\n    AVFrame *last = h->ref_list[0][0].f.data[0] ? &h->ref_list[0][0].f : NULL;\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(avctx->pix_fmt);\n    int vshift = desc->log2_chroma_h;\n    const int field_pic = h->picture_structure != PICT_FRAME;\n    if (field_pic) {\n        height <<= 1;\n        y      <<= 1;\n    }\n\n    height = FFMIN(height, avctx->height - y);\n\n    if (field_pic && h->first_field && !(avctx->slice_flags & SLICE_FLAG_ALLOW_FIELD))\n        return;\n\n    if (avctx->draw_horiz_band) {\n        AVFrame *src;\n        int offset[AV_NUM_DATA_POINTERS];\n        int i;\n\n        if (cur->pict_type == AV_PICTURE_TYPE_B || h->low_delay ||\n            (avctx->slice_flags & SLICE_FLAG_CODED_ORDER))\n            src = cur;\n        else if (last)\n            src = last;\n        else\n            return;\n\n        offset[0] = y * src->linesize[0];\n        offset[1] =\n        offset[2] = (y >> vshift) * src->linesize[1];\n        for (i = 3; i < AV_NUM_DATA_POINTERS; i++)\n            offset[i] = 0;\n\n        emms_c();\n\n        avctx->draw_horiz_band(avctx, src, offset,\n                               y, h->picture_structure, height);\n    }\n}\n\n/**\n * Check if the top & left blocks are available if needed and\n * change the dc mode so it only uses the available blocks.\n */\nint ff_h264_check_intra4x4_pred_mode(H264Context *h)\n{\n    static const int8_t top[12] = {\n        -1, 0, LEFT_DC_PRED, -1, -1, -1, -1, -1, 0\n    };\n    static const int8_t left[12] = {\n        0, -1, TOP_DC_PRED, 0, -1, -1, -1, 0, -1, DC_128_PRED\n    };\n    int i;\n\n    if (!(h->top_samples_available & 0x8000)) {\n        for (i = 0; i < 4; i++) {\n            int status = top[h->intra4x4_pred_mode_cache[scan8[0] + i]];\n            if (status < 0) {\n                av_log(h->avctx, AV_LOG_ERROR,\n                       \"top block unavailable for requested intra4x4 mode %d at %d %d\\n\",\n                       status, h->mb_x, h->mb_y);\n                return AVERROR_INVALIDDATA;\n            } else if (status) {\n                h->intra4x4_pred_mode_cache[scan8[0] + i] = status;\n            }\n        }\n    }\n\n    if ((h->left_samples_available & 0x8888) != 0x8888) {\n        static const int mask[4] = { 0x8000, 0x2000, 0x80, 0x20 };\n        for (i = 0; i < 4; i++)\n            if (!(h->left_samples_available & mask[i])) {\n                int status = left[h->intra4x4_pred_mode_cache[scan8[0] + 8 * i]];\n                if (status < 0) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"left block unavailable for requested intra4x4 mode %d at %d %d\\n\",\n                           status, h->mb_x, h->mb_y);\n                    return AVERROR_INVALIDDATA;\n                } else if (status) {\n                    h->intra4x4_pred_mode_cache[scan8[0] + 8 * i] = status;\n                }\n            }\n    }\n\n    return 0;\n} // FIXME cleanup like ff_h264_check_intra_pred_mode\n\n/**\n * Check if the top & left blocks are available if needed and\n * change the dc mode so it only uses the available blocks.\n */\nint ff_h264_check_intra_pred_mode(H264Context *h, int mode, int is_chroma)\n{\n    static const int8_t top[4]  = { LEFT_DC_PRED8x8, 1, -1, -1 };\n    static const int8_t left[5] = { TOP_DC_PRED8x8, -1,  2, -1, DC_128_PRED8x8 };\n\n    if (mode > 3U) {\n        av_log(h->avctx, AV_LOG_ERROR,\n               \"out of range intra chroma pred mode at %d %d\\n\",\n               h->mb_x, h->mb_y);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (!(h->top_samples_available & 0x8000)) {\n        mode = top[mode];\n        if (mode < 0) {\n            av_log(h->avctx, AV_LOG_ERROR,\n                   \"top block unavailable for requested intra mode at %d %d\\n\",\n                   h->mb_x, h->mb_y);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    if ((h->left_samples_available & 0x8080) != 0x8080) {\n        mode = left[mode];\n        if (mode < 0) {\n            av_log(h->avctx, AV_LOG_ERROR,\n                   \"left block unavailable for requested intra mode at %d %d\\n\",\n                   h->mb_x, h->mb_y);\n            return AVERROR_INVALIDDATA;\n        }\n        if (is_chroma && (h->left_samples_available & 0x8080)) {\n            // mad cow disease mode, aka MBAFF + constrained_intra_pred\n            mode = ALZHEIMER_DC_L0T_PRED8x8 +\n                   (!(h->left_samples_available & 0x8000)) +\n                   2 * (mode == DC_128_PRED8x8);\n        }\n    }\n\n    return mode;\n}\n\nconst uint8_t *ff_h264_decode_nal(H264Context *h, const uint8_t *src,\n                                  int *dst_length, int *consumed, int length)\n{\n    int i, si, di;\n    uint8_t *dst;\n    int bufidx;\n\n    // src[0]&0x80; // forbidden bit\n    h->nal_ref_idc   = src[0] >> 5;\n    h->nal_unit_type = src[0] & 0x1F;\n\n    src++;\n    length--;\n\n#define STARTCODE_TEST                                                  \\\n    if (i + 2 < length && src[i + 1] == 0 && src[i + 2] <= 3) {         \\\n        if (src[i + 2] != 3 && src[i + 2] != 0) {                       \\\n            /* startcode, so we must be past the end */                 \\\n            length = i;                                                 \\\n        }                                                               \\\n        break;                                                          \\\n    }\n\n#if HAVE_FAST_UNALIGNED\n#define FIND_FIRST_ZERO                                                 \\\n    if (i > 0 && !src[i])                                               \\\n        i--;                                                            \\\n    while (src[i])                                                      \\\n        i++\n\n#if HAVE_FAST_64BIT\n    for (i = 0; i + 1 < length; i += 9) {\n        if (!((~AV_RN64A(src + i) &\n               (AV_RN64A(src + i) - 0x0100010001000101ULL)) &\n              0x8000800080008080ULL))\n            continue;\n        FIND_FIRST_ZERO;\n        STARTCODE_TEST;\n        i -= 7;\n    }\n#else\n    for (i = 0; i + 1 < length; i += 5) {\n        if (!((~AV_RN32A(src + i) &\n               (AV_RN32A(src + i) - 0x01000101U)) &\n              0x80008080U))\n            continue;\n        FIND_FIRST_ZERO;\n        STARTCODE_TEST;\n        i -= 3;\n    }\n#endif\n#else\n    for (i = 0; i + 1 < length; i += 2) {\n        if (src[i])\n            continue;\n        if (i > 0 && src[i - 1] == 0)\n            i--;\n        STARTCODE_TEST;\n    }\n#endif\n\n    // use second escape buffer for inter data\n    bufidx = h->nal_unit_type == NAL_DPC ? 1 : 0;\n\n    av_fast_padded_malloc(&h->rbsp_buffer[bufidx], &h->rbsp_buffer_size[bufidx], length+MAX_MBPAIR_SIZE);\n    dst = h->rbsp_buffer[bufidx];\n\n    if (!dst)\n        return NULL;\n\n    if(i>=length-1){ //no escaped 0\n        *dst_length= length;\n        *consumed= length+1; //+1 for the header\n        if(h->avctx->flags2 & CODEC_FLAG2_FAST){\n            return src;\n        }else{\n            memcpy(dst, src, length);\n            return dst;\n        }\n    }\n\n    memcpy(dst, src, i);\n    si = di = i;\n    while (si + 2 < length) {\n        // remove escapes (very rare 1:2^22)\n        if (src[si + 2] > 3) {\n            dst[di++] = src[si++];\n            dst[di++] = src[si++];\n        } else if (src[si] == 0 && src[si + 1] == 0 && src[si + 2] != 0) {\n            if (src[si + 2] == 3) { // escape\n                dst[di++]  = 0;\n                dst[di++]  = 0;\n                si        += 3;\n                continue;\n            } else // next start code\n                goto nsc;\n        }\n\n        dst[di++] = src[si++];\n    }\n    while (si < length)\n        dst[di++] = src[si++];\n\nnsc:\n    memset(dst + di, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n    *dst_length = di;\n    *consumed   = si + 1; // +1 for the header\n    /* FIXME store exact number of bits in the getbitcontext\n     * (it is needed for decoding) */\n    return dst;\n}\n\n/**\n * Identify the exact end of the bitstream\n * @return the length of the trailing, or 0 if damaged\n */\nstatic int decode_rbsp_trailing(H264Context *h, const uint8_t *src)\n{\n    int v = *src;\n    int r;\n\n    tprintf(h->avctx, \"rbsp trailing %X\\n\", v);\n\n    for (r = 1; r < 9; r++) {\n        if (v & 1)\n            return r;\n        v >>= 1;\n    }\n    return 0;\n}\n\nvoid ff_h264_free_tables(H264Context *h, int free_rbsp)\n{\n    int i;\n    H264Context *hx;\n\n    av_freep(&h->intra4x4_pred_mode);\n    av_freep(&h->chroma_pred_mode_table);\n    av_freep(&h->cbp_table);\n    av_freep(&h->mvd_table[0]);\n    av_freep(&h->mvd_table[1]);\n    av_freep(&h->direct_table);\n    av_freep(&h->non_zero_count);\n    av_freep(&h->slice_table_base);\n    h->slice_table = NULL;\n    av_freep(&h->list_counts);\n\n    av_freep(&h->mb2b_xy);\n    av_freep(&h->mb2br_xy);\n\n    av_buffer_pool_uninit(&h->qscale_table_pool);\n    av_buffer_pool_uninit(&h->mb_type_pool);\n    av_buffer_pool_uninit(&h->motion_val_pool);\n    av_buffer_pool_uninit(&h->ref_index_pool);\n\n    if (free_rbsp && h->DPB) {\n        for (i = 0; i < H264_MAX_PICTURE_COUNT; i++)\n            ff_h264_unref_picture(h, &h->DPB[i]);\n        av_freep(&h->DPB);\n    } else if (h->DPB) {\n        for (i = 0; i < H264_MAX_PICTURE_COUNT; i++)\n            h->DPB[i].needs_realloc = 1;\n    }\n\n    h->cur_pic_ptr = NULL;\n\n    for (i = 0; i < H264_MAX_THREADS; i++) {\n        hx = h->thread_context[i];\n        if (!hx)\n            continue;\n        av_freep(&hx->top_borders[1]);\n        av_freep(&hx->top_borders[0]);\n        av_freep(&hx->bipred_scratchpad);\n        av_freep(&hx->edge_emu_buffer);\n        av_freep(&hx->dc_val_base);\n        av_freep(&hx->er.mb_index2xy);\n        av_freep(&hx->er.error_status_table);\n        av_freep(&hx->er.er_temp_buffer);\n        av_freep(&hx->er.mbintra_table);\n        av_freep(&hx->er.mbskip_table);\n\n        if (free_rbsp) {\n            av_freep(&hx->rbsp_buffer[1]);\n            av_freep(&hx->rbsp_buffer[0]);\n            hx->rbsp_buffer_size[0] = 0;\n            hx->rbsp_buffer_size[1] = 0;\n        }\n        if (i)\n            av_freep(&h->thread_context[i]);\n    }\n}\n\nint ff_h264_alloc_tables(H264Context *h)\n{\n    const int big_mb_num = h->mb_stride * (h->mb_height + 1);\n    const int row_mb_num = 2*h->mb_stride*FFMAX(h->avctx->thread_count, 1);\n    int x, y, i;\n\n    FF_ALLOCZ_ARRAY_OR_GOTO(h->avctx, h->intra4x4_pred_mode,\n                      row_mb_num, 8 * sizeof(uint8_t), fail)\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->non_zero_count,\n                      big_mb_num * 48 * sizeof(uint8_t), fail)\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->slice_table_base,\n                      (big_mb_num + h->mb_stride) * sizeof(*h->slice_table_base), fail)\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->cbp_table,\n                      big_mb_num * sizeof(uint16_t), fail)\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->chroma_pred_mode_table,\n                      big_mb_num * sizeof(uint8_t), fail)\n    FF_ALLOCZ_ARRAY_OR_GOTO(h->avctx, h->mvd_table[0],\n                      row_mb_num, 16 * sizeof(uint8_t), fail);\n    FF_ALLOCZ_ARRAY_OR_GOTO(h->avctx, h->mvd_table[1],\n                      row_mb_num, 16 * sizeof(uint8_t), fail);\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->direct_table,\n                      4 * big_mb_num * sizeof(uint8_t), fail);\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->list_counts,\n                      big_mb_num * sizeof(uint8_t), fail)\n\n    memset(h->slice_table_base, -1,\n           (big_mb_num + h->mb_stride) * sizeof(*h->slice_table_base));\n    h->slice_table = h->slice_table_base + h->mb_stride * 2 + 1;\n\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->mb2b_xy,\n                      big_mb_num * sizeof(uint32_t), fail);\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->mb2br_xy,\n                      big_mb_num * sizeof(uint32_t), fail);\n    for (y = 0; y < h->mb_height; y++)\n        for (x = 0; x < h->mb_width; x++) {\n            const int mb_xy = x + y * h->mb_stride;\n            const int b_xy  = 4 * x + 4 * y * h->b_stride;\n\n            h->mb2b_xy[mb_xy]  = b_xy;\n            h->mb2br_xy[mb_xy] = 8 * (FMO ? mb_xy : (mb_xy % (2 * h->mb_stride)));\n        }\n\n    if (!h->dequant4_coeff[0])\n        h264_init_dequant_tables(h);\n\n    if (!h->DPB) {\n        h->DPB = av_mallocz_array(H264_MAX_PICTURE_COUNT, sizeof(*h->DPB));\n        if (!h->DPB)\n            goto fail;\n        for (i = 0; i < H264_MAX_PICTURE_COUNT; i++)\n            av_frame_unref(&h->DPB[i].f);\n        av_frame_unref(&h->cur_pic.f);\n    }\n\n    return 0;\n\nfail:\n    ff_h264_free_tables(h, 1);\n    return AVERROR(ENOMEM);\n}\n\n/**\n * Init context\n * Allocate buffers which are not shared amongst multiple threads.\n */\nint ff_h264_context_init(H264Context *h)\n{\n    ERContext *er = &h->er;\n    int mb_array_size = h->mb_height * h->mb_stride;\n    int y_size  = (2 * h->mb_width + 1) * (2 * h->mb_height + 1);\n    int c_size  = h->mb_stride * (h->mb_height + 1);\n    int yc_size = y_size + 2   * c_size;\n    int x, y, i;\n\n    FF_ALLOCZ_ARRAY_OR_GOTO(h->avctx, h->top_borders[0],\n                      h->mb_width, 16 * 3 * sizeof(uint8_t) * 2, fail)\n    FF_ALLOCZ_ARRAY_OR_GOTO(h->avctx, h->top_borders[1],\n                      h->mb_width, 16 * 3 * sizeof(uint8_t) * 2, fail)\n\n    h->ref_cache[0][scan8[5]  + 1] =\n    h->ref_cache[0][scan8[7]  + 1] =\n    h->ref_cache[0][scan8[13] + 1] =\n    h->ref_cache[1][scan8[5]  + 1] =\n    h->ref_cache[1][scan8[7]  + 1] =\n    h->ref_cache[1][scan8[13] + 1] = PART_NOT_AVAILABLE;\n\n    if (CONFIG_ERROR_RESILIENCE) {\n        /* init ER */\n        er->avctx          = h->avctx;\n        er->mecc           = &h->mecc;\n        er->decode_mb      = h264_er_decode_mb;\n        er->opaque         = h;\n        er->quarter_sample = 1;\n\n        er->mb_num      = h->mb_num;\n        er->mb_width    = h->mb_width;\n        er->mb_height   = h->mb_height;\n        er->mb_stride   = h->mb_stride;\n        er->b8_stride   = h->mb_width * 2 + 1;\n\n        // error resilience code looks cleaner with this\n        FF_ALLOCZ_OR_GOTO(h->avctx, er->mb_index2xy,\n                          (h->mb_num + 1) * sizeof(int), fail);\n\n        for (y = 0; y < h->mb_height; y++)\n            for (x = 0; x < h->mb_width; x++)\n                er->mb_index2xy[x + y * h->mb_width] = x + y * h->mb_stride;\n\n        er->mb_index2xy[h->mb_height * h->mb_width] = (h->mb_height - 1) *\n                                                      h->mb_stride + h->mb_width;\n\n        FF_ALLOCZ_OR_GOTO(h->avctx, er->error_status_table,\n                          mb_array_size * sizeof(uint8_t), fail);\n\n        FF_ALLOC_OR_GOTO(h->avctx, er->mbintra_table, mb_array_size, fail);\n        memset(er->mbintra_table, 1, mb_array_size);\n\n        FF_ALLOCZ_OR_GOTO(h->avctx, er->mbskip_table, mb_array_size + 2, fail);\n\n        FF_ALLOC_OR_GOTO(h->avctx, er->er_temp_buffer,\n                         h->mb_height * h->mb_stride, fail);\n\n        FF_ALLOCZ_OR_GOTO(h->avctx, h->dc_val_base,\n                          yc_size * sizeof(int16_t), fail);\n        er->dc_val[0] = h->dc_val_base + h->mb_width * 2 + 2;\n        er->dc_val[1] = h->dc_val_base + y_size + h->mb_stride + 1;\n        er->dc_val[2] = er->dc_val[1] + c_size;\n        for (i = 0; i < yc_size; i++)\n            h->dc_val_base[i] = 1024;\n    }\n\n    return 0;\n\nfail:\n    return AVERROR(ENOMEM); // ff_h264_free_tables will clean up for us\n}\n\nstatic int decode_nal_units(H264Context *h, const uint8_t *buf, int buf_size,\n                            int parse_extradata);\n\nint ff_h264_decode_extradata(H264Context *h, const uint8_t *buf, int size)\n{\n    AVCodecContext *avctx = h->avctx;\n    int ret;\n\n    if (!buf || size <= 0)\n        return -1;\n\n    if (buf[0] == 1) {\n        int i, cnt, nalsize;\n        const unsigned char *p = buf;\n\n        h->is_avc = 1;\n\n        if (size < 7) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"avcC %d too short\\n\", size);\n            return AVERROR_INVALIDDATA;\n        }\n        /* sps and pps in the avcC always have length coded with 2 bytes,\n         * so put a fake nal_length_size = 2 while parsing them */\n        h->nal_length_size = 2;\n        // Decode sps from avcC\n        cnt = *(p + 5) & 0x1f; // Number of sps\n        p  += 6;\n        for (i = 0; i < cnt; i++) {\n            nalsize = AV_RB16(p) + 2;\n            if(nalsize > size - (p-buf))\n                return AVERROR_INVALIDDATA;\n            ret = decode_nal_units(h, p, nalsize, 1);\n            if (ret < 0) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Decoding sps %d from avcC failed\\n\", i);\n                return ret;\n            }\n            p += nalsize;\n        }\n        // Decode pps from avcC\n        cnt = *(p++); // Number of pps\n        for (i = 0; i < cnt; i++) {\n            nalsize = AV_RB16(p) + 2;\n            if(nalsize > size - (p-buf))\n                return AVERROR_INVALIDDATA;\n            ret = decode_nal_units(h, p, nalsize, 1);\n            if (ret < 0) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Decoding pps %d from avcC failed\\n\", i);\n                return ret;\n            }\n            p += nalsize;\n        }\n        // Store right nal length size that will be used to parse all other nals\n        h->nal_length_size = (buf[4] & 0x03) + 1;\n    } else {\n        h->is_avc = 0;\n        ret = decode_nal_units(h, buf, size, 1);\n        if (ret < 0)\n            return ret;\n    }\n    return size;\n}\n\nav_cold int ff_h264_decode_init(AVCodecContext *avctx)\n{\n    H264Context *h = avctx->priv_data;\n    int i;\n    int ret;\n\n    h->avctx = avctx;\n\n    h->bit_depth_luma    = 8;\n    h->chroma_format_idc = 1;\n\n    h->avctx->bits_per_raw_sample = 8;\n    h->cur_chroma_format_idc = 1;\n\n    ff_h264dsp_init(&h->h264dsp, 8, 1);\n    av_assert0(h->sps.bit_depth_chroma == 0);\n    ff_h264chroma_init(&h->h264chroma, h->sps.bit_depth_chroma);\n    ff_h264qpel_init(&h->h264qpel, 8);\n    ff_h264_pred_init(&h->hpc, h->avctx->codec_id, 8, 1);\n\n    h->dequant_coeff_pps = -1;\n    h->current_sps_id = -1;\n\n    /* needed so that IDCT permutation is known early */\n    if (CONFIG_ERROR_RESILIENCE)\n        ff_me_cmp_init(&h->mecc, h->avctx);\n    ff_videodsp_init(&h->vdsp, 8);\n\n    memset(h->pps.scaling_matrix4, 16, 6 * 16 * sizeof(uint8_t));\n    memset(h->pps.scaling_matrix8, 16, 2 * 64 * sizeof(uint8_t));\n\n    h->picture_structure   = PICT_FRAME;\n    h->slice_context_count = 1;\n    h->workaround_bugs     = avctx->workaround_bugs;\n    h->flags               = avctx->flags;\n\n    /* set defaults */\n    // s->decode_mb = ff_h263_decode_mb;\n    if (!avctx->has_b_frames)\n        h->low_delay = 1;\n\n    avctx->chroma_sample_location = AVCHROMA_LOC_LEFT;\n\n    ff_h264_decode_init_vlc();\n\n    ff_init_cabac_states();\n\n    h->pixel_shift        = 0;\n    h->sps.bit_depth_luma = avctx->bits_per_raw_sample = 8;\n\n    h->thread_context[0] = h;\n    h->outputed_poc      = h->next_outputed_poc = INT_MIN;\n    for (i = 0; i < MAX_DELAYED_PIC_COUNT; i++)\n        h->last_pocs[i] = INT_MIN;\n    h->prev_poc_msb = 1 << 16;\n    h->prev_frame_num = -1;\n    h->x264_build   = -1;\n    h->sei_fpa.frame_packing_arrangement_cancel_flag = -1;\n    ff_h264_reset_sei(h);\n    if (avctx->codec_id == AV_CODEC_ID_H264) {\n        if (avctx->ticks_per_frame == 1) {\n            if(h->avctx->time_base.den < INT_MAX/2) {\n                h->avctx->time_base.den *= 2;\n            } else\n                h->avctx->time_base.num /= 2;\n        }\n        avctx->ticks_per_frame = 2;\n    }\n\n    if (avctx->extradata_size > 0 && avctx->extradata) {\n        ret = ff_h264_decode_extradata(h, avctx->extradata, avctx->extradata_size);\n        if (ret < 0) {\n            ff_h264_free_context(h);\n            return ret;\n        }\n    }\n\n    if (h->sps.bitstream_restriction_flag &&\n        h->avctx->has_b_frames < h->sps.num_reorder_frames) {\n        h->avctx->has_b_frames = h->sps.num_reorder_frames;\n        h->low_delay           = 0;\n    }\n\n    avctx->internal->allocate_progress = 1;\n\n    ff_h264_flush_change(h);\n\n    return 0;\n}\n\nstatic int decode_init_thread_copy(AVCodecContext *avctx)\n{\n    H264Context *h = avctx->priv_data;\n\n    if (!avctx->internal->is_copy)\n        return 0;\n    memset(h->sps_buffers, 0, sizeof(h->sps_buffers));\n    memset(h->pps_buffers, 0, sizeof(h->pps_buffers));\n\n    h->rbsp_buffer[0] = NULL;\n    h->rbsp_buffer[1] = NULL;\n    h->rbsp_buffer_size[0] = 0;\n    h->rbsp_buffer_size[1] = 0;\n    h->context_initialized = 0;\n\n    return 0;\n}\n\n/**\n * Run setup operations that must be run after slice header decoding.\n * This includes finding the next displayed frame.\n *\n * @param h h264 master context\n * @param setup_finished enough NALs have been read that we can call\n * ff_thread_finish_setup()\n */\nstatic void decode_postinit(H264Context *h, int setup_finished)\n{\n    H264Picture *out = h->cur_pic_ptr;\n    H264Picture *cur = h->cur_pic_ptr;\n    int i, pics, out_of_order, out_idx;\n\n    h->cur_pic_ptr->f.pict_type = h->pict_type;\n\n    if (h->next_output_pic)\n        return;\n\n    if (cur->field_poc[0] == INT_MAX || cur->field_poc[1] == INT_MAX) {\n        /* FIXME: if we have two PAFF fields in one packet, we can't start\n         * the next thread here. If we have one field per packet, we can.\n         * The check in decode_nal_units() is not good enough to find this\n         * yet, so we assume the worst for now. */\n        // if (setup_finished)\n        //    ff_thread_finish_setup(h->avctx);\n        return;\n    }\n\n    cur->f.interlaced_frame = 0;\n    cur->f.repeat_pict      = 0;\n\n    /* Signal interlacing information externally. */\n    /* Prioritize picture timing SEI information over used\n     * decoding process if it exists. */\n\n    if (h->sps.pic_struct_present_flag) {\n        switch (h->sei_pic_struct) {\n        case SEI_PIC_STRUCT_FRAME:\n            break;\n        case SEI_PIC_STRUCT_TOP_FIELD:\n        case SEI_PIC_STRUCT_BOTTOM_FIELD:\n            cur->f.interlaced_frame = 1;\n            break;\n        case SEI_PIC_STRUCT_TOP_BOTTOM:\n        case SEI_PIC_STRUCT_BOTTOM_TOP:\n            if (FIELD_OR_MBAFF_PICTURE(h))\n                cur->f.interlaced_frame = 1;\n            else\n                // try to flag soft telecine progressive\n                cur->f.interlaced_frame = h->prev_interlaced_frame;\n            break;\n        case SEI_PIC_STRUCT_TOP_BOTTOM_TOP:\n        case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:\n            /* Signal the possibility of telecined film externally\n             * (pic_struct 5,6). From these hints, let the applications\n             * decide if they apply deinterlacing. */\n            cur->f.repeat_pict = 1;\n            break;\n        case SEI_PIC_STRUCT_FRAME_DOUBLING:\n            cur->f.repeat_pict = 2;\n            break;\n        case SEI_PIC_STRUCT_FRAME_TRIPLING:\n            cur->f.repeat_pict = 4;\n            break;\n        }\n\n        if ((h->sei_ct_type & 3) &&\n            h->sei_pic_struct <= SEI_PIC_STRUCT_BOTTOM_TOP)\n            cur->f.interlaced_frame = (h->sei_ct_type & (1 << 1)) != 0;\n    } else {\n        /* Derive interlacing flag from used decoding process. */\n        cur->f.interlaced_frame = FIELD_OR_MBAFF_PICTURE(h);\n    }\n    h->prev_interlaced_frame = cur->f.interlaced_frame;\n\n    if (cur->field_poc[0] != cur->field_poc[1]) {\n        /* Derive top_field_first from field pocs. */\n        cur->f.top_field_first = cur->field_poc[0] < cur->field_poc[1];\n    } else {\n        if (cur->f.interlaced_frame || h->sps.pic_struct_present_flag) {\n            /* Use picture timing SEI information. Even if it is a\n             * information of a past frame, better than nothing. */\n            if (h->sei_pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM ||\n                h->sei_pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM_TOP)\n                cur->f.top_field_first = 1;\n            else\n                cur->f.top_field_first = 0;\n        } else {\n            /* Most likely progressive */\n            cur->f.top_field_first = 0;\n        }\n    }\n\n    if (h->sei_frame_packing_present &&\n        h->frame_packing_arrangement_type >= 0 &&\n        h->frame_packing_arrangement_type <= 6 &&\n        h->content_interpretation_type > 0 &&\n        h->content_interpretation_type < 3) {\n        AVStereo3D *stereo = av_stereo3d_create_side_data(&cur->f);\n        if (stereo) {\n        switch (h->frame_packing_arrangement_type) {\n        case 0:\n            stereo->type = AV_STEREO3D_CHECKERBOARD;\n            break;\n        case 1:\n            stereo->type = AV_STEREO3D_COLUMNS;\n            break;\n        case 2:\n            stereo->type = AV_STEREO3D_LINES;\n            break;\n        case 3:\n            if (h->quincunx_subsampling)\n                stereo->type = AV_STEREO3D_SIDEBYSIDE_QUINCUNX;\n            else\n                stereo->type = AV_STEREO3D_SIDEBYSIDE;\n            break;\n        case 4:\n            stereo->type = AV_STEREO3D_TOPBOTTOM;\n            break;\n        case 5:\n            stereo->type = AV_STEREO3D_FRAMESEQUENCE;\n            break;\n        case 6:\n            stereo->type = AV_STEREO3D_2D;\n            break;\n        }\n\n        if (h->content_interpretation_type == 2)\n            stereo->flags = AV_STEREO3D_FLAG_INVERT;\n        }\n    }\n\n    if (h->sei_display_orientation_present &&\n        (h->sei_anticlockwise_rotation || h->sei_hflip || h->sei_vflip)) {\n        double angle = h->sei_anticlockwise_rotation * 360 / (double) (1 << 16);\n        AVFrameSideData *rotation = av_frame_new_side_data(&cur->f,\n                                                           AV_FRAME_DATA_DISPLAYMATRIX,\n                                                           sizeof(int32_t) * 9);\n        if (rotation) {\n            av_display_rotation_set((int32_t *)rotation->data, angle);\n            av_display_matrix_flip((int32_t *)rotation->data,\n                                   h->sei_hflip, h->sei_vflip);\n        }\n    }\n\n    cur->mmco_reset = h->mmco_reset;\n    h->mmco_reset = 0;\n\n    // FIXME do something with unavailable reference frames\n\n    /* Sort B-frames into display order */\n\n    if (h->sps.bitstream_restriction_flag &&\n        h->avctx->has_b_frames < h->sps.num_reorder_frames) {\n        h->avctx->has_b_frames = h->sps.num_reorder_frames;\n        h->low_delay           = 0;\n    }\n\n    if (h->avctx->strict_std_compliance >= FF_COMPLIANCE_STRICT &&\n        !h->sps.bitstream_restriction_flag) {\n        h->avctx->has_b_frames = MAX_DELAYED_PIC_COUNT - 1;\n        h->low_delay           = 0;\n    }\n\n    for (i = 0; 1; i++) {\n        if(i == MAX_DELAYED_PIC_COUNT || cur->poc < h->last_pocs[i]){\n            if(i)\n                h->last_pocs[i-1] = cur->poc;\n            break;\n        } else if(i) {\n            h->last_pocs[i-1]= h->last_pocs[i];\n        }\n    }\n    out_of_order = MAX_DELAYED_PIC_COUNT - i;\n    if(   cur->f.pict_type == AV_PICTURE_TYPE_B\n       || (h->last_pocs[MAX_DELAYED_PIC_COUNT-2] > INT_MIN && h->last_pocs[MAX_DELAYED_PIC_COUNT-1] - h->last_pocs[MAX_DELAYED_PIC_COUNT-2] > 2))\n        out_of_order = FFMAX(out_of_order, 1);\n    if (out_of_order == MAX_DELAYED_PIC_COUNT) {\n        av_log(h->avctx, AV_LOG_VERBOSE, \"Invalid POC %d<%d\\n\", cur->poc, h->last_pocs[0]);\n        for (i = 1; i < MAX_DELAYED_PIC_COUNT; i++)\n            h->last_pocs[i] = INT_MIN;\n        h->last_pocs[0] = cur->poc;\n        cur->mmco_reset = 1;\n    } else if(h->avctx->has_b_frames < out_of_order && !h->sps.bitstream_restriction_flag){\n        av_log(h->avctx, AV_LOG_VERBOSE, \"Increasing reorder buffer to %d\\n\", out_of_order);\n        h->avctx->has_b_frames = out_of_order;\n        h->low_delay = 0;\n    }\n\n    pics = 0;\n    while (h->delayed_pic[pics])\n        pics++;\n\n    av_assert0(pics <= MAX_DELAYED_PIC_COUNT);\n\n    h->delayed_pic[pics++] = cur;\n    if (cur->reference == 0)\n        cur->reference = DELAYED_PIC_REF;\n\n    out     = h->delayed_pic[0];\n    out_idx = 0;\n    for (i = 1; h->delayed_pic[i] &&\n                !h->delayed_pic[i]->f.key_frame &&\n                !h->delayed_pic[i]->mmco_reset;\n         i++)\n        if (h->delayed_pic[i]->poc < out->poc) {\n            out     = h->delayed_pic[i];\n            out_idx = i;\n        }\n    if (h->avctx->has_b_frames == 0 &&\n        (h->delayed_pic[0]->f.key_frame || h->delayed_pic[0]->mmco_reset))\n        h->next_outputed_poc = INT_MIN;\n    out_of_order = out->poc < h->next_outputed_poc;\n\n    if (out_of_order || pics > h->avctx->has_b_frames) {\n        out->reference &= ~DELAYED_PIC_REF;\n        // for frame threading, the owner must be the second field's thread or\n        // else the first thread can release the picture and reuse it unsafely\n        for (i = out_idx; h->delayed_pic[i]; i++)\n            h->delayed_pic[i] = h->delayed_pic[i + 1];\n    }\n    if (!out_of_order && pics > h->avctx->has_b_frames) {\n        h->next_output_pic = out;\n        if (out_idx == 0 && h->delayed_pic[0] && (h->delayed_pic[0]->f.key_frame || h->delayed_pic[0]->mmco_reset)) {\n            h->next_outputed_poc = INT_MIN;\n        } else\n            h->next_outputed_poc = out->poc;\n    } else {\n        av_log(h->avctx, AV_LOG_DEBUG, \"no picture %s\\n\", out_of_order ? \"ooo\" : \"\");\n    }\n\n    if (h->next_output_pic) {\n        if (h->next_output_pic->recovered) {\n            // We have reached an recovery point and all frames after it in\n            // display order are \"recovered\".\n            h->frame_recovered |= FRAME_RECOVERED_SEI;\n        }\n        h->next_output_pic->recovered |= !!(h->frame_recovered & FRAME_RECOVERED_SEI);\n    }\n\n    if (setup_finished && !h->avctx->hwaccel)\n        ff_thread_finish_setup(h->avctx);\n}\n\nint ff_pred_weight_table(H264Context *h)\n{\n    int list, i;\n    int luma_def, chroma_def;\n\n    h->use_weight             = 0;\n    h->use_weight_chroma      = 0;\n    h->luma_log2_weight_denom = get_ue_golomb(&h->gb);\n    if (h->sps.chroma_format_idc)\n        h->chroma_log2_weight_denom = get_ue_golomb(&h->gb);\n    luma_def   = 1 << h->luma_log2_weight_denom;\n    chroma_def = 1 << h->chroma_log2_weight_denom;\n\n    for (list = 0; list < 2; list++) {\n        h->luma_weight_flag[list]   = 0;\n        h->chroma_weight_flag[list] = 0;\n        for (i = 0; i < h->ref_count[list]; i++) {\n            int luma_weight_flag, chroma_weight_flag;\n\n            luma_weight_flag = get_bits1(&h->gb);\n            if (luma_weight_flag) {\n                h->luma_weight[i][list][0] = get_se_golomb(&h->gb);\n                h->luma_weight[i][list][1] = get_se_golomb(&h->gb);\n                if (h->luma_weight[i][list][0] != luma_def ||\n                    h->luma_weight[i][list][1] != 0) {\n                    h->use_weight             = 1;\n                    h->luma_weight_flag[list] = 1;\n                }\n            } else {\n                h->luma_weight[i][list][0] = luma_def;\n                h->luma_weight[i][list][1] = 0;\n            }\n\n            if (h->sps.chroma_format_idc) {\n                chroma_weight_flag = get_bits1(&h->gb);\n                if (chroma_weight_flag) {\n                    int j;\n                    for (j = 0; j < 2; j++) {\n                        h->chroma_weight[i][list][j][0] = get_se_golomb(&h->gb);\n                        h->chroma_weight[i][list][j][1] = get_se_golomb(&h->gb);\n                        if (h->chroma_weight[i][list][j][0] != chroma_def ||\n                            h->chroma_weight[i][list][j][1] != 0) {\n                            h->use_weight_chroma        = 1;\n                            h->chroma_weight_flag[list] = 1;\n                        }\n                    }\n                } else {\n                    int j;\n                    for (j = 0; j < 2; j++) {\n                        h->chroma_weight[i][list][j][0] = chroma_def;\n                        h->chroma_weight[i][list][j][1] = 0;\n                    }\n                }\n            }\n        }\n        if (h->slice_type_nos != AV_PICTURE_TYPE_B)\n            break;\n    }\n    h->use_weight = h->use_weight || h->use_weight_chroma;\n    return 0;\n}\n\n/**\n * instantaneous decoder refresh.\n */\nstatic void idr(H264Context *h)\n{\n    int i;\n    ff_h264_remove_all_refs(h);\n    h->prev_frame_num        =\n    h->prev_frame_num_offset = 0;\n    h->prev_poc_msb          = 1<<16;\n    h->prev_poc_lsb          = 0;\n    for (i = 0; i < MAX_DELAYED_PIC_COUNT; i++)\n        h->last_pocs[i] = INT_MIN;\n}\n\n/* forget old pics after a seek */\nvoid ff_h264_flush_change(H264Context *h)\n{\n    int i, j;\n\n    h->outputed_poc          = h->next_outputed_poc = INT_MIN;\n    h->prev_interlaced_frame = 1;\n    idr(h);\n\n    h->prev_frame_num = -1;\n    if (h->cur_pic_ptr) {\n        h->cur_pic_ptr->reference = 0;\n        for (j=i=0; h->delayed_pic[i]; i++)\n            if (h->delayed_pic[i] != h->cur_pic_ptr)\n                h->delayed_pic[j++] = h->delayed_pic[i];\n        h->delayed_pic[j] = NULL;\n    }\n    h->first_field = 0;\n    memset(h->ref_list[0], 0, sizeof(h->ref_list[0]));\n    memset(h->ref_list[1], 0, sizeof(h->ref_list[1]));\n    memset(h->default_ref_list[0], 0, sizeof(h->default_ref_list[0]));\n    memset(h->default_ref_list[1], 0, sizeof(h->default_ref_list[1]));\n    ff_h264_reset_sei(h);\n    h->recovery_frame = -1;\n    h->frame_recovered = 0;\n    h->list_count = 0;\n    h->current_slice = 0;\n    h->mmco_reset = 1;\n}\n\n/* forget old pics after a seek */\nstatic void flush_dpb(AVCodecContext *avctx)\n{\n    H264Context *h = avctx->priv_data;\n    int i;\n\n    for (i = 0; i <= MAX_DELAYED_PIC_COUNT; i++) {\n        if (h->delayed_pic[i])\n            h->delayed_pic[i]->reference = 0;\n        h->delayed_pic[i] = NULL;\n    }\n\n    ff_h264_flush_change(h);\n\n    if (h->DPB)\n        for (i = 0; i < H264_MAX_PICTURE_COUNT; i++)\n            ff_h264_unref_picture(h, &h->DPB[i]);\n    h->cur_pic_ptr = NULL;\n    ff_h264_unref_picture(h, &h->cur_pic);\n\n    h->mb_x = h->mb_y = 0;\n\n    h->parse_context.state             = -1;\n    h->parse_context.frame_start_found = 0;\n    h->parse_context.overread          = 0;\n    h->parse_context.overread_index    = 0;\n    h->parse_context.index             = 0;\n    h->parse_context.last_index        = 0;\n\n    ff_h264_free_tables(h, 1);\n    h->context_initialized = 0;\n}\n\nint ff_init_poc(H264Context *h, int pic_field_poc[2], int *pic_poc)\n{\n    const int max_frame_num = 1 << h->sps.log2_max_frame_num;\n    int field_poc[2];\n\n    h->frame_num_offset = h->prev_frame_num_offset;\n    if (h->frame_num < h->prev_frame_num)\n        h->frame_num_offset += max_frame_num;\n\n    if (h->sps.poc_type == 0) {\n        const int max_poc_lsb = 1 << h->sps.log2_max_poc_lsb;\n\n        if (h->poc_lsb < h->prev_poc_lsb &&\n            h->prev_poc_lsb - h->poc_lsb >= max_poc_lsb / 2)\n            h->poc_msb = h->prev_poc_msb + max_poc_lsb;\n        else if (h->poc_lsb > h->prev_poc_lsb &&\n                 h->prev_poc_lsb - h->poc_lsb < -max_poc_lsb / 2)\n            h->poc_msb = h->prev_poc_msb - max_poc_lsb;\n        else\n            h->poc_msb = h->prev_poc_msb;\n        field_poc[0] =\n        field_poc[1] = h->poc_msb + h->poc_lsb;\n        if (h->picture_structure == PICT_FRAME)\n            field_poc[1] += h->delta_poc_bottom;\n    } else if (h->sps.poc_type == 1) {\n        int abs_frame_num, expected_delta_per_poc_cycle, expectedpoc;\n        int i;\n\n        if (h->sps.poc_cycle_length != 0)\n            abs_frame_num = h->frame_num_offset + h->frame_num;\n        else\n            abs_frame_num = 0;\n\n        if (h->nal_ref_idc == 0 && abs_frame_num > 0)\n            abs_frame_num--;\n\n        expected_delta_per_poc_cycle = 0;\n        for (i = 0; i < h->sps.poc_cycle_length; i++)\n            // FIXME integrate during sps parse\n            expected_delta_per_poc_cycle += h->sps.offset_for_ref_frame[i];\n\n        if (abs_frame_num > 0) {\n            int poc_cycle_cnt          = (abs_frame_num - 1) / h->sps.poc_cycle_length;\n            int frame_num_in_poc_cycle = (abs_frame_num - 1) % h->sps.poc_cycle_length;\n\n            expectedpoc = poc_cycle_cnt * expected_delta_per_poc_cycle;\n            for (i = 0; i <= frame_num_in_poc_cycle; i++)\n                expectedpoc = expectedpoc + h->sps.offset_for_ref_frame[i];\n        } else\n            expectedpoc = 0;\n\n        if (h->nal_ref_idc == 0)\n            expectedpoc = expectedpoc + h->sps.offset_for_non_ref_pic;\n\n        field_poc[0] = expectedpoc + h->delta_poc[0];\n        field_poc[1] = field_poc[0] + h->sps.offset_for_top_to_bottom_field;\n\n        if (h->picture_structure == PICT_FRAME)\n            field_poc[1] += h->delta_poc[1];\n    } else {\n        int poc = 2 * (h->frame_num_offset + h->frame_num);\n\n        if (!h->nal_ref_idc)\n            poc--;\n\n        field_poc[0] = poc;\n        field_poc[1] = poc;\n    }\n\n    if (h->picture_structure != PICT_BOTTOM_FIELD)\n        pic_field_poc[0] = field_poc[0];\n    if (h->picture_structure != PICT_TOP_FIELD)\n        pic_field_poc[1] = field_poc[1];\n    *pic_poc = FFMIN(pic_field_poc[0], pic_field_poc[1]);\n\n    return 0;\n}\n\n/**\n * Compute profile from profile_idc and constraint_set?_flags.\n *\n * @param sps SPS\n *\n * @return profile as defined by FF_PROFILE_H264_*\n */\nint ff_h264_get_profile(SPS *sps)\n{\n    int profile = sps->profile_idc;\n\n    switch (sps->profile_idc) {\n    case FF_PROFILE_H264_BASELINE:\n        // constraint_set1_flag set to 1\n        profile |= (sps->constraint_set_flags & 1 << 1) ? FF_PROFILE_H264_CONSTRAINED : 0;\n        break;\n    case FF_PROFILE_H264_HIGH_10:\n    case FF_PROFILE_H264_HIGH_422:\n    case FF_PROFILE_H264_HIGH_444_PREDICTIVE:\n        // constraint_set3_flag set to 1\n        profile |= (sps->constraint_set_flags & 1 << 3) ? FF_PROFILE_H264_INTRA : 0;\n        break;\n    }\n\n    return profile;\n}\n\nint ff_h264_set_parameter_from_sps(H264Context *h)\n{\n    if (h->flags & CODEC_FLAG_LOW_DELAY ||\n        (h->sps.bitstream_restriction_flag &&\n         !h->sps.num_reorder_frames)) {\n        if (h->avctx->has_b_frames > 1 || h->delayed_pic[0])\n            av_log(h->avctx, AV_LOG_WARNING, \"Delayed frames seen. \"\n                   \"Reenabling low delay requires a codec flush.\\n\");\n        else\n            h->low_delay = 1;\n    }\n\n    if (h->avctx->has_b_frames < 2)\n        h->avctx->has_b_frames = !h->low_delay;\n\n    if (h->avctx->bits_per_raw_sample != h->sps.bit_depth_luma ||\n        h->cur_chroma_format_idc      != h->sps.chroma_format_idc) {\n        if (h->avctx->codec &&\n            h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU &&\n            (h->sps.bit_depth_luma != 8 || h->sps.chroma_format_idc > 1)) {\n            av_log(h->avctx, AV_LOG_ERROR,\n                   \"VDPAU decoding does not support video colorspace.\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        if (h->sps.bit_depth_luma >= 8 && h->sps.bit_depth_luma <= 14 &&\n            h->sps.bit_depth_luma != 11 && h->sps.bit_depth_luma != 13) {\n            h->avctx->bits_per_raw_sample = h->sps.bit_depth_luma;\n            h->cur_chroma_format_idc      = h->sps.chroma_format_idc;\n            h->pixel_shift                = h->sps.bit_depth_luma > 8;\n\n            ff_h264dsp_init(&h->h264dsp, h->sps.bit_depth_luma,\n                            h->sps.chroma_format_idc);\n            ff_h264chroma_init(&h->h264chroma, h->sps.bit_depth_chroma);\n            ff_h264qpel_init(&h->h264qpel, h->sps.bit_depth_luma);\n            ff_h264_pred_init(&h->hpc, h->avctx->codec_id, h->sps.bit_depth_luma,\n                              h->sps.chroma_format_idc);\n\n            if (CONFIG_ERROR_RESILIENCE)\n                ff_me_cmp_init(&h->mecc, h->avctx);\n            ff_videodsp_init(&h->vdsp, h->sps.bit_depth_luma);\n        } else {\n            av_log(h->avctx, AV_LOG_ERROR, \"Unsupported bit depth %d\\n\",\n                   h->sps.bit_depth_luma);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n    return 0;\n}\n\nint ff_set_ref_count(H264Context *h)\n{\n    int ref_count[2], list_count;\n    int num_ref_idx_active_override_flag;\n\n    // set defaults, might be overridden a few lines later\n    ref_count[0] = h->pps.ref_count[0];\n    ref_count[1] = h->pps.ref_count[1];\n\n    if (h->slice_type_nos != AV_PICTURE_TYPE_I) {\n        unsigned max[2];\n        max[0] = max[1] = h->picture_structure == PICT_FRAME ? 15 : 31;\n\n        if (h->slice_type_nos == AV_PICTURE_TYPE_B)\n            h->direct_spatial_mv_pred = get_bits1(&h->gb);\n        num_ref_idx_active_override_flag = get_bits1(&h->gb);\n\n        if (num_ref_idx_active_override_flag) {\n            ref_count[0] = get_ue_golomb(&h->gb) + 1;\n            if (h->slice_type_nos == AV_PICTURE_TYPE_B) {\n                ref_count[1] = get_ue_golomb(&h->gb) + 1;\n            } else\n                // full range is spec-ok in this case, even for frames\n                ref_count[1] = 1;\n        }\n\n        if (ref_count[0]-1 > max[0] || ref_count[1]-1 > max[1]){\n            av_log(h->avctx, AV_LOG_ERROR, \"reference overflow %u > %u or %u > %u\\n\", ref_count[0]-1, max[0], ref_count[1]-1, max[1]);\n            h->ref_count[0] = h->ref_count[1] = 0;\n            h->list_count   = 0;\n            return AVERROR_INVALIDDATA;\n        }\n\n        if (h->slice_type_nos == AV_PICTURE_TYPE_B)\n            list_count = 2;\n        else\n            list_count = 1;\n    } else {\n        list_count   = 0;\n        ref_count[0] = ref_count[1] = 0;\n    }\n\n    if (list_count != h->list_count ||\n        ref_count[0] != h->ref_count[0] ||\n        ref_count[1] != h->ref_count[1]) {\n        h->ref_count[0] = ref_count[0];\n        h->ref_count[1] = ref_count[1];\n        h->list_count   = list_count;\n        return 1;\n    }\n\n    return 0;\n}\n\nstatic const uint8_t start_code[] = { 0x00, 0x00, 0x01 };\n\nstatic int get_bit_length(H264Context *h, const uint8_t *buf,\n                          const uint8_t *ptr, int dst_length,\n                          int i, int next_avc)\n{\n    if ((h->workaround_bugs & FF_BUG_AUTODETECT) && i + 3 < next_avc &&\n        buf[i]     == 0x00 && buf[i + 1] == 0x00 &&\n        buf[i + 2] == 0x01 && buf[i + 3] == 0xE0)\n        h->workaround_bugs |= FF_BUG_TRUNCATED;\n\n    if (!(h->workaround_bugs & FF_BUG_TRUNCATED))\n        while (dst_length > 0 && ptr[dst_length - 1] == 0)\n            dst_length--;\n\n    if (!dst_length)\n        return 0;\n\n    return 8 * dst_length - decode_rbsp_trailing(h, ptr + dst_length - 1);\n}\n\nstatic int get_last_needed_nal(H264Context *h, const uint8_t *buf, int buf_size)\n{\n    int next_avc    = h->is_avc ? 0 : buf_size;\n    int nal_index   = 0;\n    int buf_index   = 0;\n    int nals_needed = 0;\n    int first_slice = 0;\n\n    while(1) {\n        int nalsize = 0;\n        int dst_length, bit_length, consumed;\n        const uint8_t *ptr;\n\n        if (buf_index >= next_avc) {\n            nalsize = get_avc_nalsize(h, buf, buf_size, &buf_index);\n            if (nalsize < 0)\n                break;\n            next_avc = buf_index + nalsize;\n        } else {\n            buf_index = find_start_code(buf, buf_size, buf_index, next_avc);\n            if (buf_index >= buf_size)\n                break;\n            if (buf_index >= next_avc)\n                continue;\n        }\n\n        ptr = ff_h264_decode_nal(h, buf + buf_index, &dst_length, &consumed,\n                                 next_avc - buf_index);\n\n        if (!ptr || dst_length < 0)\n            return AVERROR_INVALIDDATA;\n\n        buf_index += consumed;\n\n        bit_length = get_bit_length(h, buf, ptr, dst_length,\n                                    buf_index, next_avc);\n        nal_index++;\n\n        /* packets can sometimes contain multiple PPS/SPS,\n         * e.g. two PAFF field pictures in one packet, or a demuxer\n         * which splits NALs strangely if so, when frame threading we\n         * can't start the next thread until we've read all of them */\n        switch (h->nal_unit_type) {\n        case NAL_SPS:\n        case NAL_PPS:\n            nals_needed = nal_index;\n            break;\n        case NAL_DPA:\n        case NAL_IDR_SLICE:\n        case NAL_SLICE:\n            init_get_bits(&h->gb, ptr, bit_length);\n            if (!get_ue_golomb(&h->gb) ||\n                !first_slice ||\n                first_slice != h->nal_unit_type)\n                nals_needed = nal_index;\n            if (!first_slice)\n                first_slice = h->nal_unit_type;\n        }\n    }\n\n    return nals_needed;\n}\n\nstatic int decode_nal_units(H264Context *h, const uint8_t *buf, int buf_size,\n                            int parse_extradata)\n{\n    AVCodecContext *const avctx = h->avctx;\n    H264Context *hx; ///< thread context\n    int buf_index;\n    unsigned context_count;\n    int next_avc;\n    int nals_needed = 0; ///< number of NALs that need decoding before the next frame thread starts\n    int nal_index;\n    int idr_cleared=0;\n    int ret = 0;\n\n    h->nal_unit_type= 0;\n\n    if(!h->slice_context_count)\n         h->slice_context_count= 1;\n    h->max_contexts = h->slice_context_count;\n    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS)) {\n        h->current_slice = 0;\n        if (!h->first_field)\n            h->cur_pic_ptr = NULL;\n        ff_h264_reset_sei(h);\n    }\n\n    if (h->nal_length_size == 4) {\n        if (buf_size > 8 && AV_RB32(buf) == 1 && AV_RB32(buf+5) > (unsigned)buf_size) {\n            h->is_avc = 0;\n        }else if(buf_size > 3 && AV_RB32(buf) > 1 && AV_RB32(buf) <= (unsigned)buf_size)\n            h->is_avc = 1;\n    }\n\n    if (avctx->active_thread_type & FF_THREAD_FRAME)\n        nals_needed = get_last_needed_nal(h, buf, buf_size);\n\n    {\n        buf_index     = 0;\n        context_count = 0;\n        next_avc      = h->is_avc ? 0 : buf_size;\n        nal_index     = 0;\n        for (;;) {\n            int consumed;\n            int dst_length;\n            int bit_length;\n            const uint8_t *ptr;\n            int nalsize = 0;\n            int err;\n\n            if (buf_index >= next_avc) {\n                nalsize = get_avc_nalsize(h, buf, buf_size, &buf_index);\n                if (nalsize < 0)\n                    break;\n                next_avc = buf_index + nalsize;\n            } else {\n                buf_index = find_start_code(buf, buf_size, buf_index, next_avc);\n                if (buf_index >= buf_size)\n                    break;\n                if (buf_index >= next_avc)\n                    continue;\n            }\n\n            hx = h->thread_context[context_count];\n\n            ptr = ff_h264_decode_nal(hx, buf + buf_index, &dst_length,\n                                     &consumed, next_avc - buf_index);\n            if (!ptr || dst_length < 0) {\n                ret = -1;\n                goto end;\n            }\n\n            bit_length = get_bit_length(h, buf, ptr, dst_length,\n                                        buf_index + consumed, next_avc);\n\n            if (h->avctx->debug & FF_DEBUG_STARTCODE)\n                av_log(h->avctx, AV_LOG_DEBUG,\n                       \"NAL %d/%d at %d/%d length %d\\n\",\n                       hx->nal_unit_type, hx->nal_ref_idc, buf_index, buf_size, dst_length);\n\n            if (h->is_avc && (nalsize != consumed) && nalsize)\n                av_log(h->avctx, AV_LOG_DEBUG,\n                       \"AVC: Consumed only %d bytes instead of %d\\n\",\n                       consumed, nalsize);\n\n            buf_index += consumed;\n            nal_index++;\n\n            if (avctx->skip_frame >= AVDISCARD_NONREF &&\n                h->nal_ref_idc == 0 &&\n                h->nal_unit_type != NAL_SEI)\n                continue;\n\nagain:\n            if (   !(avctx->active_thread_type & FF_THREAD_FRAME)\n                || nals_needed >= nal_index)\n                h->au_pps_id = -1;\n            /* Ignore per frame NAL unit type during extradata\n             * parsing. Decoding slices is not possible in codec init\n             * with frame-mt */\n            if (parse_extradata) {\n                switch (hx->nal_unit_type) {\n                case NAL_IDR_SLICE:\n                case NAL_SLICE:\n                case NAL_DPA:\n                case NAL_DPB:\n                case NAL_DPC:\n                    av_log(h->avctx, AV_LOG_WARNING,\n                           \"Ignoring NAL %d in global header/extradata\\n\",\n                           hx->nal_unit_type);\n                    // fall through to next case\n                case NAL_AUXILIARY_SLICE:\n                    hx->nal_unit_type = NAL_FF_IGNORE;\n                }\n            }\n\n            err = 0;\n\n            switch (hx->nal_unit_type) {\n            case NAL_IDR_SLICE:\n                if ((ptr[0] & 0xFC) == 0x98) {\n                    av_log(h->avctx, AV_LOG_ERROR, \"Invalid inter IDR frame\\n\");\n                    h->next_outputed_poc = INT_MIN;\n                    ret = -1;\n                    goto end;\n                }\n                if (h->nal_unit_type != NAL_IDR_SLICE) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"Invalid mix of idr and non-idr slices\\n\");\n                    ret = -1;\n                    goto end;\n                }\n                if(!idr_cleared)\n                    idr(h); // FIXME ensure we don't lose some frames if there is reordering\n                idr_cleared = 1;\n                h->has_recovery_point = 1;\n            case NAL_SLICE:\n                init_get_bits(&hx->gb, ptr, bit_length);\n                hx->intra_gb_ptr      =\n                hx->inter_gb_ptr      = &hx->gb;\n                hx->data_partitioning = 0;\n\n                if ((err = ff_h264_decode_slice_header(hx, h)))\n                    break;\n\n                if (h->sei_recovery_frame_cnt >= 0) {\n                    if (h->frame_num != h->sei_recovery_frame_cnt || hx->slice_type_nos != AV_PICTURE_TYPE_I)\n                        h->valid_recovery_point = 1;\n\n                    if (   h->recovery_frame < 0\n                        || ((h->recovery_frame - h->frame_num) & ((1 << h->sps.log2_max_frame_num)-1)) > h->sei_recovery_frame_cnt) {\n                        h->recovery_frame = (h->frame_num + h->sei_recovery_frame_cnt) &\n                                            ((1 << h->sps.log2_max_frame_num) - 1);\n\n                        if (!h->valid_recovery_point)\n                            h->recovery_frame = h->frame_num;\n                    }\n                }\n\n                h->cur_pic_ptr->f.key_frame |=\n                    (hx->nal_unit_type == NAL_IDR_SLICE);\n\n                if (hx->nal_unit_type == NAL_IDR_SLICE ||\n                    h->recovery_frame == h->frame_num) {\n                    h->recovery_frame         = -1;\n                    h->cur_pic_ptr->recovered = 1;\n                }\n                // If we have an IDR, all frames after it in decoded order are\n                // \"recovered\".\n                if (hx->nal_unit_type == NAL_IDR_SLICE)\n                    h->frame_recovered |= FRAME_RECOVERED_IDR;\n                h->frame_recovered |= 3*!!(avctx->flags2 & CODEC_FLAG2_SHOW_ALL);\n                h->frame_recovered |= 3*!!(avctx->flags & CODEC_FLAG_OUTPUT_CORRUPT);\n#if 1\n                h->cur_pic_ptr->recovered |= h->frame_recovered;\n#else\n                h->cur_pic_ptr->recovered |= !!(h->frame_recovered & FRAME_RECOVERED_IDR);\n#endif\n\n                if (h->current_slice == 1) {\n                    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS))\n                        decode_postinit(h, nal_index >= nals_needed);\n\n                    if (h->avctx->hwaccel &&\n                        (ret = h->avctx->hwaccel->start_frame(h->avctx, NULL, 0)) < 0)\n                        return ret;\n                    if (CONFIG_H264_VDPAU_DECODER &&\n                        h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)\n                        ff_vdpau_h264_picture_start(h);\n                }\n\n                if (hx->redundant_pic_count == 0) {\n                    if (avctx->hwaccel) {\n                        ret = avctx->hwaccel->decode_slice(avctx,\n                                                           &buf[buf_index - consumed],\n                                                           consumed);\n                        if (ret < 0)\n                            return ret;\n                    } else if (CONFIG_H264_VDPAU_DECODER &&\n                               h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU) {\n                        ff_vdpau_add_data_chunk(h->cur_pic_ptr->f.data[0],\n                                                start_code,\n                                                sizeof(start_code));\n                        ff_vdpau_add_data_chunk(h->cur_pic_ptr->f.data[0],\n                                                &buf[buf_index - consumed],\n                                                consumed);\n                    } else\n                        context_count++;\n                }\n                break;\n            case NAL_DPA:\n                if (h->avctx->flags & CODEC_FLAG2_CHUNKS) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"Decoding in chunks is not supported for \"\n                           \"partitioned slices.\\n\");\n                    return AVERROR(ENOSYS);\n                }\n\n                init_get_bits(&hx->gb, ptr, bit_length);\n                hx->intra_gb_ptr =\n                hx->inter_gb_ptr = NULL;\n\n                if ((err = ff_h264_decode_slice_header(hx, h))) {\n                    /* make sure data_partitioning is cleared if it was set\n                     * before, so we don't try decoding a slice without a valid\n                     * slice header later */\n                    h->data_partitioning = 0;\n                    break;\n                }\n\n                hx->data_partitioning = 1;\n                break;\n            case NAL_DPB:\n                init_get_bits(&hx->intra_gb, ptr, bit_length);\n                hx->intra_gb_ptr = &hx->intra_gb;\n                break;\n            case NAL_DPC:\n                init_get_bits(&hx->inter_gb, ptr, bit_length);\n                hx->inter_gb_ptr = &hx->inter_gb;\n\n                av_log(h->avctx, AV_LOG_ERROR, \"Partitioned H.264 support is incomplete\\n\");\n                break;\n\n                if (hx->redundant_pic_count == 0 &&\n                    hx->intra_gb_ptr &&\n                    hx->data_partitioning &&\n                    h->cur_pic_ptr && h->context_initialized &&\n                    (avctx->skip_frame < AVDISCARD_NONREF || hx->nal_ref_idc) &&\n                    (avctx->skip_frame < AVDISCARD_BIDIR  ||\n                     hx->slice_type_nos != AV_PICTURE_TYPE_B) &&\n                    (avctx->skip_frame < AVDISCARD_NONINTRA ||\n                     hx->slice_type_nos == AV_PICTURE_TYPE_I) &&\n                    avctx->skip_frame < AVDISCARD_ALL)\n                    context_count++;\n                break;\n            case NAL_SEI:\n                init_get_bits(&h->gb, ptr, bit_length);\n                ret = ff_h264_decode_sei(h);\n                if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n                    goto end;\n                break;\n            case NAL_SPS:\n                init_get_bits(&h->gb, ptr, bit_length);\n                if (ff_h264_decode_seq_parameter_set(h) < 0 && (h->is_avc ? nalsize : 1)) {\n                    av_log(h->avctx, AV_LOG_DEBUG,\n                           \"SPS decoding failure, trying again with the complete NAL\\n\");\n                    if (h->is_avc)\n                        av_assert0(next_avc - buf_index + consumed == nalsize);\n                    if ((next_avc - buf_index + consumed - 1) >= INT_MAX/8)\n                        break;\n                    init_get_bits(&h->gb, &buf[buf_index + 1 - consumed],\n                                  8*(next_avc - buf_index + consumed - 1));\n                    ff_h264_decode_seq_parameter_set(h);\n                }\n\n                break;\n            case NAL_PPS:\n                init_get_bits(&h->gb, ptr, bit_length);\n                ret = ff_h264_decode_picture_parameter_set(h, bit_length);\n                if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n                    goto end;\n                break;\n            case NAL_AUD:\n            case NAL_END_SEQUENCE:\n            case NAL_END_STREAM:\n            case NAL_FILLER_DATA:\n            case NAL_SPS_EXT:\n            case NAL_AUXILIARY_SLICE:\n                break;\n            case NAL_FF_IGNORE:\n                break;\n            default:\n                av_log(avctx, AV_LOG_DEBUG, \"Unknown NAL code: %d (%d bits)\\n\",\n                       hx->nal_unit_type, bit_length);\n            }\n\n            if (context_count == h->max_contexts) {\n                ret = ff_h264_execute_decode_slices(h, context_count);\n                if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n                    goto end;\n                context_count = 0;\n            }\n\n            if (err < 0 || err == SLICE_SKIPED) {\n                if (err < 0)\n                    av_log(h->avctx, AV_LOG_ERROR, \"decode_slice_header error\\n\");\n                h->ref_count[0] = h->ref_count[1] = h->list_count = 0;\n            } else if (err == SLICE_SINGLETHREAD) {\n                /* Slice could not be decoded in parallel mode, copy down\n                 * NAL unit stuff to context 0 and restart. Note that\n                 * rbsp_buffer is not transferred, but since we no longer\n                 * run in parallel mode this should not be an issue. */\n                h->nal_unit_type = hx->nal_unit_type;\n                h->nal_ref_idc   = hx->nal_ref_idc;\n                hx               = h;\n                goto again;\n            }\n        }\n    }\n    if (context_count) {\n        ret = ff_h264_execute_decode_slices(h, context_count);\n        if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n            goto end;\n    }\n\n    ret = 0;\nend:\n    /* clean up */\n    if (h->cur_pic_ptr && !h->droppable) {\n        ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n                                  h->picture_structure == PICT_BOTTOM_FIELD);\n    }\n\n    return (ret < 0) ? ret : buf_index;\n}\n\n/**\n * Return the number of bytes consumed for building the current frame.\n */\nstatic int get_consumed_bytes(int pos, int buf_size)\n{\n    if (pos == 0)\n        pos = 1;        // avoid infinite loops (I doubt that is needed but...)\n    if (pos + 10 > buf_size)\n        pos = buf_size; // oops ;)\n\n    return pos;\n}\n\nstatic int output_frame(H264Context *h, AVFrame *dst, H264Picture *srcp)\n{\n    AVFrame *src = &srcp->f;\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(src->format);\n    int i;\n    int ret = av_frame_ref(dst, src);\n    if (ret < 0)\n        return ret;\n\n    av_dict_set(&dst->metadata, \"stereo_mode\", ff_h264_sei_stereo_mode(h), 0);\n\n    if (srcp->sei_recovery_frame_cnt == 0)\n        dst->key_frame = 1;\n    if (!srcp->crop)\n        return 0;\n\n    for (i = 0; i < desc->nb_components; i++) {\n        int hshift = (i > 0) ? desc->log2_chroma_w : 0;\n        int vshift = (i > 0) ? desc->log2_chroma_h : 0;\n        int off    = ((srcp->crop_left >> hshift) << h->pixel_shift) +\n                      (srcp->crop_top  >> vshift) * dst->linesize[i];\n        dst->data[i] += off;\n    }\n    return 0;\n}\n\nstatic int is_extra(const uint8_t *buf, int buf_size)\n{\n    int cnt= buf[5]&0x1f;\n    const uint8_t *p= buf+6;\n    while(cnt--){\n        int nalsize= AV_RB16(p) + 2;\n        if(nalsize > buf_size - (p-buf) || p[2]!=0x67)\n            return 0;\n        p += nalsize;\n    }\n    cnt = *(p++);\n    if(!cnt)\n        return 0;\n    while(cnt--){\n        int nalsize= AV_RB16(p) + 2;\n        if(nalsize > buf_size - (p-buf) || p[2]!=0x68)\n            return 0;\n        p += nalsize;\n    }\n    return 1;\n}\n\nstatic int h264_decode_frame(AVCodecContext *avctx, void *data,\n                             int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size       = avpkt->size;\n    H264Context *h     = avctx->priv_data;\n    AVFrame *pict      = data;\n    int buf_index      = 0;\n    H264Picture *out;\n    int i, out_idx;\n    int ret;\n\n    h->flags = avctx->flags;\n    /* reset data partitioning here, to ensure GetBitContexts from previous\n     * packets do not get used. */\n    h->data_partitioning = 0;\n\n    /* end of stream, output what is still in the buffers */\n    if (buf_size == 0) {\n out:\n\n        h->cur_pic_ptr = NULL;\n        h->first_field = 0;\n\n        // FIXME factorize this with the output code below\n        out     = h->delayed_pic[0];\n        out_idx = 0;\n        for (i = 1;\n             h->delayed_pic[i] &&\n             !h->delayed_pic[i]->f.key_frame &&\n             !h->delayed_pic[i]->mmco_reset;\n             i++)\n            if (h->delayed_pic[i]->poc < out->poc) {\n                out     = h->delayed_pic[i];\n                out_idx = i;\n            }\n\n        for (i = out_idx; h->delayed_pic[i]; i++)\n            h->delayed_pic[i] = h->delayed_pic[i + 1];\n\n        if (out) {\n            out->reference &= ~DELAYED_PIC_REF;\n            ret = output_frame(h, pict, out);\n            if (ret < 0)\n                return ret;\n            *got_frame = 1;\n        }\n\n        return buf_index;\n    }\n    if (h->is_avc && av_packet_get_side_data(avpkt, AV_PKT_DATA_NEW_EXTRADATA, NULL)) {\n        int side_size;\n        uint8_t *side = av_packet_get_side_data(avpkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);\n        if (is_extra(side, side_size))\n            ff_h264_decode_extradata(h, side, side_size);\n    }\n    if(h->is_avc && buf_size >= 9 && buf[0]==1 && buf[2]==0 && (buf[4]&0xFC)==0xFC && (buf[5]&0x1F) && buf[8]==0x67){\n        if (is_extra(buf, buf_size))\n            return ff_h264_decode_extradata(h, buf, buf_size);\n    }\n\n    buf_index = decode_nal_units(h, buf, buf_size, 0);\n    if (buf_index < 0)\n        return AVERROR_INVALIDDATA;\n\n    if (!h->cur_pic_ptr && h->nal_unit_type == NAL_END_SEQUENCE) {\n        av_assert0(buf_index <= buf_size);\n        goto out;\n    }\n\n    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS) && !h->cur_pic_ptr) {\n        if (avctx->skip_frame >= AVDISCARD_NONREF ||\n            buf_size >= 4 && !memcmp(\"Q264\", buf, 4))\n            return buf_size;\n        av_log(avctx, AV_LOG_ERROR, \"no frame!\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS) ||\n        (h->mb_y >= h->mb_height && h->mb_height)) {\n        if (avctx->flags2 & CODEC_FLAG2_CHUNKS)\n            decode_postinit(h, 1);\n\n        ff_h264_field_end(h, 0);\n\n        /* Wait for second field. */\n        *got_frame = 0;\n        if (h->next_output_pic && (\n                                   h->next_output_pic->recovered)) {\n            if (!h->next_output_pic->recovered)\n                h->next_output_pic->f.flags |= AV_FRAME_FLAG_CORRUPT;\n\n            ret = output_frame(h, pict, h->next_output_pic);\n            if (ret < 0)\n                return ret;\n            *got_frame = 1;\n            if (CONFIG_MPEGVIDEO) {\n                ff_print_debug_info2(h->avctx, pict, h->er.mbskip_table,\n                                    h->next_output_pic->mb_type,\n                                    h->next_output_pic->qscale_table,\n                                    h->next_output_pic->motion_val,\n                                    &h->low_delay,\n                                    h->mb_width, h->mb_height, h->mb_stride, 1);\n            }\n        }\n    }\n\n    assert(pict->buf[0] || !*got_frame);\n\n    return get_consumed_bytes(buf_index, buf_size);\n}\n\nav_cold void ff_h264_free_context(H264Context *h)\n{\n    int i;\n\n    ff_h264_free_tables(h, 1); // FIXME cleanup init stuff perhaps\n\n    for (i = 0; i < MAX_SPS_COUNT; i++)\n        av_freep(h->sps_buffers + i);\n\n    for (i = 0; i < MAX_PPS_COUNT; i++)\n        av_freep(h->pps_buffers + i);\n}\n\nstatic av_cold int h264_decode_end(AVCodecContext *avctx)\n{\n    H264Context *h = avctx->priv_data;\n\n    ff_h264_remove_all_refs(h);\n    ff_h264_free_context(h);\n\n    ff_h264_unref_picture(h, &h->cur_pic);\n\n    return 0;\n}\n\nstatic const AVProfile profiles[] = {\n    { FF_PROFILE_H264_BASELINE,             \"Baseline\"              },\n    { FF_PROFILE_H264_CONSTRAINED_BASELINE, \"Constrained Baseline\"  },\n    { FF_PROFILE_H264_MAIN,                 \"Main\"                  },\n    { FF_PROFILE_H264_EXTENDED,             \"Extended\"              },\n    { FF_PROFILE_H264_HIGH,                 \"High\"                  },\n    { FF_PROFILE_H264_HIGH_10,              \"High 10\"               },\n    { FF_PROFILE_H264_HIGH_10_INTRA,        \"High 10 Intra\"         },\n    { FF_PROFILE_H264_HIGH_422,             \"High 4:2:2\"            },\n    { FF_PROFILE_H264_HIGH_422_INTRA,       \"High 4:2:2 Intra\"      },\n    { FF_PROFILE_H264_HIGH_444,             \"High 4:4:4\"            },\n    { FF_PROFILE_H264_HIGH_444_PREDICTIVE,  \"High 4:4:4 Predictive\" },\n    { FF_PROFILE_H264_HIGH_444_INTRA,       \"High 4:4:4 Intra\"      },\n    { FF_PROFILE_H264_CAVLC_444,            \"CAVLC 4:4:4\"           },\n    { FF_PROFILE_UNKNOWN },\n};\n\nstatic const AVOption h264_options[] = {\n    {\"is_avc\", \"is avc\", offsetof(H264Context, is_avc), FF_OPT_TYPE_INT, {.i64 = 0}, 0, 1, 0},\n    {\"nal_length_size\", \"nal_length_size\", offsetof(H264Context, nal_length_size), FF_OPT_TYPE_INT, {.i64 = 0}, 0, 4, 0},\n    {NULL}\n};\n\nstatic const AVClass h264_class = {\n    .class_name = \"H264 Decoder\",\n    .item_name  = av_default_item_name,\n    .option     = h264_options,\n    .version    = LIBAVUTIL_VERSION_INT,\n};\n\nAVCodec ff_h264_decoder = {\n    .name                  = \"h264\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_H264,\n    .priv_data_size        = sizeof(H264Context),\n    .init                  = ff_h264_decode_init,\n    .close                 = h264_decode_end,\n    .decode                = h264_decode_frame,\n    .capabilities          = /*CODEC_CAP_DRAW_HORIZ_BAND |*/ CODEC_CAP_DR1 |\n                             CODEC_CAP_DELAY | CODEC_CAP_SLICE_THREADS |\n                             CODEC_CAP_FRAME_THREADS,\n    .flush                 = flush_dpb,\n    .init_thread_copy      = ONLY_IF_THREADS_ENABLED(decode_init_thread_copy),\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(ff_h264_update_thread_context),\n    .profiles              = NULL_IF_CONFIG_SMALL(profiles),\n    .priv_class            = &h264_class,\n};\n\n#if CONFIG_H264_VDPAU_DECODER\nstatic const AVClass h264_vdpau_class = {\n    .class_name = \"H264 VDPAU Decoder\",\n    .item_name  = av_default_item_name,\n    .option     = h264_options,\n    .version    = LIBAVUTIL_VERSION_INT,\n};\n\nAVCodec ff_h264_vdpau_decoder = {\n    .name           = \"h264_vdpau\",\n    .long_name      = NULL_IF_CONFIG_SMALL(\"H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (VDPAU acceleration)\"),\n    .type           = AVMEDIA_TYPE_VIDEO,\n    .id             = AV_CODEC_ID_H264,\n    .priv_data_size = sizeof(H264Context),\n    .init           = ff_h264_decode_init,\n    .close          = h264_decode_end,\n    .decode         = h264_decode_frame,\n    .capabilities   = CODEC_CAP_DR1 | CODEC_CAP_DELAY | CODEC_CAP_HWACCEL_VDPAU,\n    .flush          = flush_dpb,\n    .pix_fmts       = (const enum AVPixelFormat[]) { AV_PIX_FMT_VDPAU_H264,\n                                                     AV_PIX_FMT_NONE},\n    .profiles       = NULL_IF_CONFIG_SMALL(profiles),\n    .priv_class     = &h264_vdpau_class,\n};\n#endif\n"], "fixing_code": ["/*\n * H.26L/H.264/AVC/JVT/14496-10/... decoder\n * Copyright (c) 2003 Michael Niedermayer <michaelni@gmx.at>\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * H.264 / AVC / MPEG4 part10 codec.\n * @author Michael Niedermayer <michaelni@gmx.at>\n */\n\n#define UNCHECKED_BITSTREAM_READER 1\n\n#include \"libavutil/avassert.h\"\n#include \"libavutil/display.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/stereo3d.h\"\n#include \"libavutil/timer.h\"\n#include \"internal.h\"\n#include \"cabac.h\"\n#include \"cabac_functions.h\"\n#include \"error_resilience.h\"\n#include \"avcodec.h\"\n#include \"h264.h\"\n#include \"h264data.h\"\n#include \"h264chroma.h\"\n#include \"h264_mvpred.h\"\n#include \"golomb.h\"\n#include \"mathops.h\"\n#include \"me_cmp.h\"\n#include \"mpegutils.h\"\n#include \"rectangle.h\"\n#include \"svq3.h\"\n#include \"thread.h\"\n#include \"vdpau_internal.h\"\n\n#include <assert.h>\n\nconst uint16_t ff_h264_mb_sizes[4] = { 256, 384, 512, 768 };\n\nint avpriv_h264_has_num_reorder_frames(AVCodecContext *avctx)\n{\n    H264Context *h = avctx->priv_data;\n    return h ? h->sps.num_reorder_frames : 0;\n}\n\nstatic void h264_er_decode_mb(void *opaque, int ref, int mv_dir, int mv_type,\n                              int (*mv)[2][4][2],\n                              int mb_x, int mb_y, int mb_intra, int mb_skipped)\n{\n    H264Context *h = opaque;\n\n    h->mb_x  = mb_x;\n    h->mb_y  = mb_y;\n    h->mb_xy = mb_x + mb_y * h->mb_stride;\n    memset(h->non_zero_count_cache, 0, sizeof(h->non_zero_count_cache));\n    av_assert1(ref >= 0);\n    /* FIXME: It is possible albeit uncommon that slice references\n     * differ between slices. We take the easy approach and ignore\n     * it for now. If this turns out to have any relevance in\n     * practice then correct remapping should be added. */\n    if (ref >= h->ref_count[0])\n        ref = 0;\n    if (!h->ref_list[0][ref].f.data[0]) {\n        av_log(h->avctx, AV_LOG_DEBUG, \"Reference not available for error concealing\\n\");\n        ref = 0;\n    }\n    if ((h->ref_list[0][ref].reference&3) != 3) {\n        av_log(h->avctx, AV_LOG_DEBUG, \"Reference invalid\\n\");\n        return;\n    }\n    fill_rectangle(&h->cur_pic.ref_index[0][4 * h->mb_xy],\n                   2, 2, 2, ref, 1);\n    fill_rectangle(&h->ref_cache[0][scan8[0]], 4, 4, 8, ref, 1);\n    fill_rectangle(h->mv_cache[0][scan8[0]], 4, 4, 8,\n                   pack16to32((*mv)[0][0][0], (*mv)[0][0][1]), 4);\n    h->mb_mbaff =\n    h->mb_field_decoding_flag = 0;\n    ff_h264_hl_decode_mb(h);\n}\n\nvoid ff_h264_draw_horiz_band(H264Context *h, int y, int height)\n{\n    AVCodecContext *avctx = h->avctx;\n    AVFrame *cur  = &h->cur_pic.f;\n    AVFrame *last = h->ref_list[0][0].f.data[0] ? &h->ref_list[0][0].f : NULL;\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(avctx->pix_fmt);\n    int vshift = desc->log2_chroma_h;\n    const int field_pic = h->picture_structure != PICT_FRAME;\n    if (field_pic) {\n        height <<= 1;\n        y      <<= 1;\n    }\n\n    height = FFMIN(height, avctx->height - y);\n\n    if (field_pic && h->first_field && !(avctx->slice_flags & SLICE_FLAG_ALLOW_FIELD))\n        return;\n\n    if (avctx->draw_horiz_band) {\n        AVFrame *src;\n        int offset[AV_NUM_DATA_POINTERS];\n        int i;\n\n        if (cur->pict_type == AV_PICTURE_TYPE_B || h->low_delay ||\n            (avctx->slice_flags & SLICE_FLAG_CODED_ORDER))\n            src = cur;\n        else if (last)\n            src = last;\n        else\n            return;\n\n        offset[0] = y * src->linesize[0];\n        offset[1] =\n        offset[2] = (y >> vshift) * src->linesize[1];\n        for (i = 3; i < AV_NUM_DATA_POINTERS; i++)\n            offset[i] = 0;\n\n        emms_c();\n\n        avctx->draw_horiz_band(avctx, src, offset,\n                               y, h->picture_structure, height);\n    }\n}\n\n/**\n * Check if the top & left blocks are available if needed and\n * change the dc mode so it only uses the available blocks.\n */\nint ff_h264_check_intra4x4_pred_mode(H264Context *h)\n{\n    static const int8_t top[12] = {\n        -1, 0, LEFT_DC_PRED, -1, -1, -1, -1, -1, 0\n    };\n    static const int8_t left[12] = {\n        0, -1, TOP_DC_PRED, 0, -1, -1, -1, 0, -1, DC_128_PRED\n    };\n    int i;\n\n    if (!(h->top_samples_available & 0x8000)) {\n        for (i = 0; i < 4; i++) {\n            int status = top[h->intra4x4_pred_mode_cache[scan8[0] + i]];\n            if (status < 0) {\n                av_log(h->avctx, AV_LOG_ERROR,\n                       \"top block unavailable for requested intra4x4 mode %d at %d %d\\n\",\n                       status, h->mb_x, h->mb_y);\n                return AVERROR_INVALIDDATA;\n            } else if (status) {\n                h->intra4x4_pred_mode_cache[scan8[0] + i] = status;\n            }\n        }\n    }\n\n    if ((h->left_samples_available & 0x8888) != 0x8888) {\n        static const int mask[4] = { 0x8000, 0x2000, 0x80, 0x20 };\n        for (i = 0; i < 4; i++)\n            if (!(h->left_samples_available & mask[i])) {\n                int status = left[h->intra4x4_pred_mode_cache[scan8[0] + 8 * i]];\n                if (status < 0) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"left block unavailable for requested intra4x4 mode %d at %d %d\\n\",\n                           status, h->mb_x, h->mb_y);\n                    return AVERROR_INVALIDDATA;\n                } else if (status) {\n                    h->intra4x4_pred_mode_cache[scan8[0] + 8 * i] = status;\n                }\n            }\n    }\n\n    return 0;\n} // FIXME cleanup like ff_h264_check_intra_pred_mode\n\n/**\n * Check if the top & left blocks are available if needed and\n * change the dc mode so it only uses the available blocks.\n */\nint ff_h264_check_intra_pred_mode(H264Context *h, int mode, int is_chroma)\n{\n    static const int8_t top[4]  = { LEFT_DC_PRED8x8, 1, -1, -1 };\n    static const int8_t left[5] = { TOP_DC_PRED8x8, -1,  2, -1, DC_128_PRED8x8 };\n\n    if (mode > 3U) {\n        av_log(h->avctx, AV_LOG_ERROR,\n               \"out of range intra chroma pred mode at %d %d\\n\",\n               h->mb_x, h->mb_y);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (!(h->top_samples_available & 0x8000)) {\n        mode = top[mode];\n        if (mode < 0) {\n            av_log(h->avctx, AV_LOG_ERROR,\n                   \"top block unavailable for requested intra mode at %d %d\\n\",\n                   h->mb_x, h->mb_y);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    if ((h->left_samples_available & 0x8080) != 0x8080) {\n        mode = left[mode];\n        if (mode < 0) {\n            av_log(h->avctx, AV_LOG_ERROR,\n                   \"left block unavailable for requested intra mode at %d %d\\n\",\n                   h->mb_x, h->mb_y);\n            return AVERROR_INVALIDDATA;\n        }\n        if (is_chroma && (h->left_samples_available & 0x8080)) {\n            // mad cow disease mode, aka MBAFF + constrained_intra_pred\n            mode = ALZHEIMER_DC_L0T_PRED8x8 +\n                   (!(h->left_samples_available & 0x8000)) +\n                   2 * (mode == DC_128_PRED8x8);\n        }\n    }\n\n    return mode;\n}\n\nconst uint8_t *ff_h264_decode_nal(H264Context *h, const uint8_t *src,\n                                  int *dst_length, int *consumed, int length)\n{\n    int i, si, di;\n    uint8_t *dst;\n    int bufidx;\n\n    // src[0]&0x80; // forbidden bit\n    h->nal_ref_idc   = src[0] >> 5;\n    h->nal_unit_type = src[0] & 0x1F;\n\n    src++;\n    length--;\n\n#define STARTCODE_TEST                                                  \\\n    if (i + 2 < length && src[i + 1] == 0 && src[i + 2] <= 3) {         \\\n        if (src[i + 2] != 3 && src[i + 2] != 0) {                       \\\n            /* startcode, so we must be past the end */                 \\\n            length = i;                                                 \\\n        }                                                               \\\n        break;                                                          \\\n    }\n\n#if HAVE_FAST_UNALIGNED\n#define FIND_FIRST_ZERO                                                 \\\n    if (i > 0 && !src[i])                                               \\\n        i--;                                                            \\\n    while (src[i])                                                      \\\n        i++\n\n#if HAVE_FAST_64BIT\n    for (i = 0; i + 1 < length; i += 9) {\n        if (!((~AV_RN64A(src + i) &\n               (AV_RN64A(src + i) - 0x0100010001000101ULL)) &\n              0x8000800080008080ULL))\n            continue;\n        FIND_FIRST_ZERO;\n        STARTCODE_TEST;\n        i -= 7;\n    }\n#else\n    for (i = 0; i + 1 < length; i += 5) {\n        if (!((~AV_RN32A(src + i) &\n               (AV_RN32A(src + i) - 0x01000101U)) &\n              0x80008080U))\n            continue;\n        FIND_FIRST_ZERO;\n        STARTCODE_TEST;\n        i -= 3;\n    }\n#endif\n#else\n    for (i = 0; i + 1 < length; i += 2) {\n        if (src[i])\n            continue;\n        if (i > 0 && src[i - 1] == 0)\n            i--;\n        STARTCODE_TEST;\n    }\n#endif\n\n    // use second escape buffer for inter data\n    bufidx = h->nal_unit_type == NAL_DPC ? 1 : 0;\n\n    av_fast_padded_malloc(&h->rbsp_buffer[bufidx], &h->rbsp_buffer_size[bufidx], length+MAX_MBPAIR_SIZE);\n    dst = h->rbsp_buffer[bufidx];\n\n    if (!dst)\n        return NULL;\n\n    if(i>=length-1){ //no escaped 0\n        *dst_length= length;\n        *consumed= length+1; //+1 for the header\n        if(h->avctx->flags2 & CODEC_FLAG2_FAST){\n            return src;\n        }else{\n            memcpy(dst, src, length);\n            return dst;\n        }\n    }\n\n    memcpy(dst, src, i);\n    si = di = i;\n    while (si + 2 < length) {\n        // remove escapes (very rare 1:2^22)\n        if (src[si + 2] > 3) {\n            dst[di++] = src[si++];\n            dst[di++] = src[si++];\n        } else if (src[si] == 0 && src[si + 1] == 0 && src[si + 2] != 0) {\n            if (src[si + 2] == 3) { // escape\n                dst[di++]  = 0;\n                dst[di++]  = 0;\n                si        += 3;\n                continue;\n            } else // next start code\n                goto nsc;\n        }\n\n        dst[di++] = src[si++];\n    }\n    while (si < length)\n        dst[di++] = src[si++];\n\nnsc:\n    memset(dst + di, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n    *dst_length = di;\n    *consumed   = si + 1; // +1 for the header\n    /* FIXME store exact number of bits in the getbitcontext\n     * (it is needed for decoding) */\n    return dst;\n}\n\n/**\n * Identify the exact end of the bitstream\n * @return the length of the trailing, or 0 if damaged\n */\nstatic int decode_rbsp_trailing(H264Context *h, const uint8_t *src)\n{\n    int v = *src;\n    int r;\n\n    tprintf(h->avctx, \"rbsp trailing %X\\n\", v);\n\n    for (r = 1; r < 9; r++) {\n        if (v & 1)\n            return r;\n        v >>= 1;\n    }\n    return 0;\n}\n\nvoid ff_h264_free_tables(H264Context *h, int free_rbsp)\n{\n    int i;\n    H264Context *hx;\n\n    av_freep(&h->intra4x4_pred_mode);\n    av_freep(&h->chroma_pred_mode_table);\n    av_freep(&h->cbp_table);\n    av_freep(&h->mvd_table[0]);\n    av_freep(&h->mvd_table[1]);\n    av_freep(&h->direct_table);\n    av_freep(&h->non_zero_count);\n    av_freep(&h->slice_table_base);\n    h->slice_table = NULL;\n    av_freep(&h->list_counts);\n\n    av_freep(&h->mb2b_xy);\n    av_freep(&h->mb2br_xy);\n\n    av_buffer_pool_uninit(&h->qscale_table_pool);\n    av_buffer_pool_uninit(&h->mb_type_pool);\n    av_buffer_pool_uninit(&h->motion_val_pool);\n    av_buffer_pool_uninit(&h->ref_index_pool);\n\n    if (free_rbsp && h->DPB) {\n        for (i = 0; i < H264_MAX_PICTURE_COUNT; i++)\n            ff_h264_unref_picture(h, &h->DPB[i]);\n        memset(h->delayed_pic, 0, sizeof(h->delayed_pic));\n        av_freep(&h->DPB);\n    } else if (h->DPB) {\n        for (i = 0; i < H264_MAX_PICTURE_COUNT; i++)\n            h->DPB[i].needs_realloc = 1;\n    }\n\n    h->cur_pic_ptr = NULL;\n\n    for (i = 0; i < H264_MAX_THREADS; i++) {\n        hx = h->thread_context[i];\n        if (!hx)\n            continue;\n        av_freep(&hx->top_borders[1]);\n        av_freep(&hx->top_borders[0]);\n        av_freep(&hx->bipred_scratchpad);\n        av_freep(&hx->edge_emu_buffer);\n        av_freep(&hx->dc_val_base);\n        av_freep(&hx->er.mb_index2xy);\n        av_freep(&hx->er.error_status_table);\n        av_freep(&hx->er.er_temp_buffer);\n        av_freep(&hx->er.mbintra_table);\n        av_freep(&hx->er.mbskip_table);\n\n        if (free_rbsp) {\n            av_freep(&hx->rbsp_buffer[1]);\n            av_freep(&hx->rbsp_buffer[0]);\n            hx->rbsp_buffer_size[0] = 0;\n            hx->rbsp_buffer_size[1] = 0;\n        }\n        if (i)\n            av_freep(&h->thread_context[i]);\n    }\n}\n\nint ff_h264_alloc_tables(H264Context *h)\n{\n    const int big_mb_num = h->mb_stride * (h->mb_height + 1);\n    const int row_mb_num = 2*h->mb_stride*FFMAX(h->avctx->thread_count, 1);\n    int x, y, i;\n\n    FF_ALLOCZ_ARRAY_OR_GOTO(h->avctx, h->intra4x4_pred_mode,\n                      row_mb_num, 8 * sizeof(uint8_t), fail)\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->non_zero_count,\n                      big_mb_num * 48 * sizeof(uint8_t), fail)\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->slice_table_base,\n                      (big_mb_num + h->mb_stride) * sizeof(*h->slice_table_base), fail)\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->cbp_table,\n                      big_mb_num * sizeof(uint16_t), fail)\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->chroma_pred_mode_table,\n                      big_mb_num * sizeof(uint8_t), fail)\n    FF_ALLOCZ_ARRAY_OR_GOTO(h->avctx, h->mvd_table[0],\n                      row_mb_num, 16 * sizeof(uint8_t), fail);\n    FF_ALLOCZ_ARRAY_OR_GOTO(h->avctx, h->mvd_table[1],\n                      row_mb_num, 16 * sizeof(uint8_t), fail);\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->direct_table,\n                      4 * big_mb_num * sizeof(uint8_t), fail);\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->list_counts,\n                      big_mb_num * sizeof(uint8_t), fail)\n\n    memset(h->slice_table_base, -1,\n           (big_mb_num + h->mb_stride) * sizeof(*h->slice_table_base));\n    h->slice_table = h->slice_table_base + h->mb_stride * 2 + 1;\n\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->mb2b_xy,\n                      big_mb_num * sizeof(uint32_t), fail);\n    FF_ALLOCZ_OR_GOTO(h->avctx, h->mb2br_xy,\n                      big_mb_num * sizeof(uint32_t), fail);\n    for (y = 0; y < h->mb_height; y++)\n        for (x = 0; x < h->mb_width; x++) {\n            const int mb_xy = x + y * h->mb_stride;\n            const int b_xy  = 4 * x + 4 * y * h->b_stride;\n\n            h->mb2b_xy[mb_xy]  = b_xy;\n            h->mb2br_xy[mb_xy] = 8 * (FMO ? mb_xy : (mb_xy % (2 * h->mb_stride)));\n        }\n\n    if (!h->dequant4_coeff[0])\n        h264_init_dequant_tables(h);\n\n    if (!h->DPB) {\n        h->DPB = av_mallocz_array(H264_MAX_PICTURE_COUNT, sizeof(*h->DPB));\n        if (!h->DPB)\n            goto fail;\n        for (i = 0; i < H264_MAX_PICTURE_COUNT; i++)\n            av_frame_unref(&h->DPB[i].f);\n        av_frame_unref(&h->cur_pic.f);\n    }\n\n    return 0;\n\nfail:\n    ff_h264_free_tables(h, 1);\n    return AVERROR(ENOMEM);\n}\n\n/**\n * Init context\n * Allocate buffers which are not shared amongst multiple threads.\n */\nint ff_h264_context_init(H264Context *h)\n{\n    ERContext *er = &h->er;\n    int mb_array_size = h->mb_height * h->mb_stride;\n    int y_size  = (2 * h->mb_width + 1) * (2 * h->mb_height + 1);\n    int c_size  = h->mb_stride * (h->mb_height + 1);\n    int yc_size = y_size + 2   * c_size;\n    int x, y, i;\n\n    FF_ALLOCZ_ARRAY_OR_GOTO(h->avctx, h->top_borders[0],\n                      h->mb_width, 16 * 3 * sizeof(uint8_t) * 2, fail)\n    FF_ALLOCZ_ARRAY_OR_GOTO(h->avctx, h->top_borders[1],\n                      h->mb_width, 16 * 3 * sizeof(uint8_t) * 2, fail)\n\n    h->ref_cache[0][scan8[5]  + 1] =\n    h->ref_cache[0][scan8[7]  + 1] =\n    h->ref_cache[0][scan8[13] + 1] =\n    h->ref_cache[1][scan8[5]  + 1] =\n    h->ref_cache[1][scan8[7]  + 1] =\n    h->ref_cache[1][scan8[13] + 1] = PART_NOT_AVAILABLE;\n\n    if (CONFIG_ERROR_RESILIENCE) {\n        /* init ER */\n        er->avctx          = h->avctx;\n        er->mecc           = &h->mecc;\n        er->decode_mb      = h264_er_decode_mb;\n        er->opaque         = h;\n        er->quarter_sample = 1;\n\n        er->mb_num      = h->mb_num;\n        er->mb_width    = h->mb_width;\n        er->mb_height   = h->mb_height;\n        er->mb_stride   = h->mb_stride;\n        er->b8_stride   = h->mb_width * 2 + 1;\n\n        // error resilience code looks cleaner with this\n        FF_ALLOCZ_OR_GOTO(h->avctx, er->mb_index2xy,\n                          (h->mb_num + 1) * sizeof(int), fail);\n\n        for (y = 0; y < h->mb_height; y++)\n            for (x = 0; x < h->mb_width; x++)\n                er->mb_index2xy[x + y * h->mb_width] = x + y * h->mb_stride;\n\n        er->mb_index2xy[h->mb_height * h->mb_width] = (h->mb_height - 1) *\n                                                      h->mb_stride + h->mb_width;\n\n        FF_ALLOCZ_OR_GOTO(h->avctx, er->error_status_table,\n                          mb_array_size * sizeof(uint8_t), fail);\n\n        FF_ALLOC_OR_GOTO(h->avctx, er->mbintra_table, mb_array_size, fail);\n        memset(er->mbintra_table, 1, mb_array_size);\n\n        FF_ALLOCZ_OR_GOTO(h->avctx, er->mbskip_table, mb_array_size + 2, fail);\n\n        FF_ALLOC_OR_GOTO(h->avctx, er->er_temp_buffer,\n                         h->mb_height * h->mb_stride, fail);\n\n        FF_ALLOCZ_OR_GOTO(h->avctx, h->dc_val_base,\n                          yc_size * sizeof(int16_t), fail);\n        er->dc_val[0] = h->dc_val_base + h->mb_width * 2 + 2;\n        er->dc_val[1] = h->dc_val_base + y_size + h->mb_stride + 1;\n        er->dc_val[2] = er->dc_val[1] + c_size;\n        for (i = 0; i < yc_size; i++)\n            h->dc_val_base[i] = 1024;\n    }\n\n    return 0;\n\nfail:\n    return AVERROR(ENOMEM); // ff_h264_free_tables will clean up for us\n}\n\nstatic int decode_nal_units(H264Context *h, const uint8_t *buf, int buf_size,\n                            int parse_extradata);\n\nint ff_h264_decode_extradata(H264Context *h, const uint8_t *buf, int size)\n{\n    AVCodecContext *avctx = h->avctx;\n    int ret;\n\n    if (!buf || size <= 0)\n        return -1;\n\n    if (buf[0] == 1) {\n        int i, cnt, nalsize;\n        const unsigned char *p = buf;\n\n        h->is_avc = 1;\n\n        if (size < 7) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"avcC %d too short\\n\", size);\n            return AVERROR_INVALIDDATA;\n        }\n        /* sps and pps in the avcC always have length coded with 2 bytes,\n         * so put a fake nal_length_size = 2 while parsing them */\n        h->nal_length_size = 2;\n        // Decode sps from avcC\n        cnt = *(p + 5) & 0x1f; // Number of sps\n        p  += 6;\n        for (i = 0; i < cnt; i++) {\n            nalsize = AV_RB16(p) + 2;\n            if(nalsize > size - (p-buf))\n                return AVERROR_INVALIDDATA;\n            ret = decode_nal_units(h, p, nalsize, 1);\n            if (ret < 0) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Decoding sps %d from avcC failed\\n\", i);\n                return ret;\n            }\n            p += nalsize;\n        }\n        // Decode pps from avcC\n        cnt = *(p++); // Number of pps\n        for (i = 0; i < cnt; i++) {\n            nalsize = AV_RB16(p) + 2;\n            if(nalsize > size - (p-buf))\n                return AVERROR_INVALIDDATA;\n            ret = decode_nal_units(h, p, nalsize, 1);\n            if (ret < 0) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Decoding pps %d from avcC failed\\n\", i);\n                return ret;\n            }\n            p += nalsize;\n        }\n        // Store right nal length size that will be used to parse all other nals\n        h->nal_length_size = (buf[4] & 0x03) + 1;\n    } else {\n        h->is_avc = 0;\n        ret = decode_nal_units(h, buf, size, 1);\n        if (ret < 0)\n            return ret;\n    }\n    return size;\n}\n\nav_cold int ff_h264_decode_init(AVCodecContext *avctx)\n{\n    H264Context *h = avctx->priv_data;\n    int i;\n    int ret;\n\n    h->avctx = avctx;\n\n    h->bit_depth_luma    = 8;\n    h->chroma_format_idc = 1;\n\n    h->avctx->bits_per_raw_sample = 8;\n    h->cur_chroma_format_idc = 1;\n\n    ff_h264dsp_init(&h->h264dsp, 8, 1);\n    av_assert0(h->sps.bit_depth_chroma == 0);\n    ff_h264chroma_init(&h->h264chroma, h->sps.bit_depth_chroma);\n    ff_h264qpel_init(&h->h264qpel, 8);\n    ff_h264_pred_init(&h->hpc, h->avctx->codec_id, 8, 1);\n\n    h->dequant_coeff_pps = -1;\n    h->current_sps_id = -1;\n\n    /* needed so that IDCT permutation is known early */\n    if (CONFIG_ERROR_RESILIENCE)\n        ff_me_cmp_init(&h->mecc, h->avctx);\n    ff_videodsp_init(&h->vdsp, 8);\n\n    memset(h->pps.scaling_matrix4, 16, 6 * 16 * sizeof(uint8_t));\n    memset(h->pps.scaling_matrix8, 16, 2 * 64 * sizeof(uint8_t));\n\n    h->picture_structure   = PICT_FRAME;\n    h->slice_context_count = 1;\n    h->workaround_bugs     = avctx->workaround_bugs;\n    h->flags               = avctx->flags;\n\n    /* set defaults */\n    // s->decode_mb = ff_h263_decode_mb;\n    if (!avctx->has_b_frames)\n        h->low_delay = 1;\n\n    avctx->chroma_sample_location = AVCHROMA_LOC_LEFT;\n\n    ff_h264_decode_init_vlc();\n\n    ff_init_cabac_states();\n\n    h->pixel_shift        = 0;\n    h->sps.bit_depth_luma = avctx->bits_per_raw_sample = 8;\n\n    h->thread_context[0] = h;\n    h->outputed_poc      = h->next_outputed_poc = INT_MIN;\n    for (i = 0; i < MAX_DELAYED_PIC_COUNT; i++)\n        h->last_pocs[i] = INT_MIN;\n    h->prev_poc_msb = 1 << 16;\n    h->prev_frame_num = -1;\n    h->x264_build   = -1;\n    h->sei_fpa.frame_packing_arrangement_cancel_flag = -1;\n    ff_h264_reset_sei(h);\n    if (avctx->codec_id == AV_CODEC_ID_H264) {\n        if (avctx->ticks_per_frame == 1) {\n            if(h->avctx->time_base.den < INT_MAX/2) {\n                h->avctx->time_base.den *= 2;\n            } else\n                h->avctx->time_base.num /= 2;\n        }\n        avctx->ticks_per_frame = 2;\n    }\n\n    if (avctx->extradata_size > 0 && avctx->extradata) {\n        ret = ff_h264_decode_extradata(h, avctx->extradata, avctx->extradata_size);\n        if (ret < 0) {\n            ff_h264_free_context(h);\n            return ret;\n        }\n    }\n\n    if (h->sps.bitstream_restriction_flag &&\n        h->avctx->has_b_frames < h->sps.num_reorder_frames) {\n        h->avctx->has_b_frames = h->sps.num_reorder_frames;\n        h->low_delay           = 0;\n    }\n\n    avctx->internal->allocate_progress = 1;\n\n    ff_h264_flush_change(h);\n\n    return 0;\n}\n\nstatic int decode_init_thread_copy(AVCodecContext *avctx)\n{\n    H264Context *h = avctx->priv_data;\n\n    if (!avctx->internal->is_copy)\n        return 0;\n    memset(h->sps_buffers, 0, sizeof(h->sps_buffers));\n    memset(h->pps_buffers, 0, sizeof(h->pps_buffers));\n\n    h->rbsp_buffer[0] = NULL;\n    h->rbsp_buffer[1] = NULL;\n    h->rbsp_buffer_size[0] = 0;\n    h->rbsp_buffer_size[1] = 0;\n    h->context_initialized = 0;\n\n    return 0;\n}\n\n/**\n * Run setup operations that must be run after slice header decoding.\n * This includes finding the next displayed frame.\n *\n * @param h h264 master context\n * @param setup_finished enough NALs have been read that we can call\n * ff_thread_finish_setup()\n */\nstatic void decode_postinit(H264Context *h, int setup_finished)\n{\n    H264Picture *out = h->cur_pic_ptr;\n    H264Picture *cur = h->cur_pic_ptr;\n    int i, pics, out_of_order, out_idx;\n\n    h->cur_pic_ptr->f.pict_type = h->pict_type;\n\n    if (h->next_output_pic)\n        return;\n\n    if (cur->field_poc[0] == INT_MAX || cur->field_poc[1] == INT_MAX) {\n        /* FIXME: if we have two PAFF fields in one packet, we can't start\n         * the next thread here. If we have one field per packet, we can.\n         * The check in decode_nal_units() is not good enough to find this\n         * yet, so we assume the worst for now. */\n        // if (setup_finished)\n        //    ff_thread_finish_setup(h->avctx);\n        return;\n    }\n\n    cur->f.interlaced_frame = 0;\n    cur->f.repeat_pict      = 0;\n\n    /* Signal interlacing information externally. */\n    /* Prioritize picture timing SEI information over used\n     * decoding process if it exists. */\n\n    if (h->sps.pic_struct_present_flag) {\n        switch (h->sei_pic_struct) {\n        case SEI_PIC_STRUCT_FRAME:\n            break;\n        case SEI_PIC_STRUCT_TOP_FIELD:\n        case SEI_PIC_STRUCT_BOTTOM_FIELD:\n            cur->f.interlaced_frame = 1;\n            break;\n        case SEI_PIC_STRUCT_TOP_BOTTOM:\n        case SEI_PIC_STRUCT_BOTTOM_TOP:\n            if (FIELD_OR_MBAFF_PICTURE(h))\n                cur->f.interlaced_frame = 1;\n            else\n                // try to flag soft telecine progressive\n                cur->f.interlaced_frame = h->prev_interlaced_frame;\n            break;\n        case SEI_PIC_STRUCT_TOP_BOTTOM_TOP:\n        case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:\n            /* Signal the possibility of telecined film externally\n             * (pic_struct 5,6). From these hints, let the applications\n             * decide if they apply deinterlacing. */\n            cur->f.repeat_pict = 1;\n            break;\n        case SEI_PIC_STRUCT_FRAME_DOUBLING:\n            cur->f.repeat_pict = 2;\n            break;\n        case SEI_PIC_STRUCT_FRAME_TRIPLING:\n            cur->f.repeat_pict = 4;\n            break;\n        }\n\n        if ((h->sei_ct_type & 3) &&\n            h->sei_pic_struct <= SEI_PIC_STRUCT_BOTTOM_TOP)\n            cur->f.interlaced_frame = (h->sei_ct_type & (1 << 1)) != 0;\n    } else {\n        /* Derive interlacing flag from used decoding process. */\n        cur->f.interlaced_frame = FIELD_OR_MBAFF_PICTURE(h);\n    }\n    h->prev_interlaced_frame = cur->f.interlaced_frame;\n\n    if (cur->field_poc[0] != cur->field_poc[1]) {\n        /* Derive top_field_first from field pocs. */\n        cur->f.top_field_first = cur->field_poc[0] < cur->field_poc[1];\n    } else {\n        if (cur->f.interlaced_frame || h->sps.pic_struct_present_flag) {\n            /* Use picture timing SEI information. Even if it is a\n             * information of a past frame, better than nothing. */\n            if (h->sei_pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM ||\n                h->sei_pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM_TOP)\n                cur->f.top_field_first = 1;\n            else\n                cur->f.top_field_first = 0;\n        } else {\n            /* Most likely progressive */\n            cur->f.top_field_first = 0;\n        }\n    }\n\n    if (h->sei_frame_packing_present &&\n        h->frame_packing_arrangement_type >= 0 &&\n        h->frame_packing_arrangement_type <= 6 &&\n        h->content_interpretation_type > 0 &&\n        h->content_interpretation_type < 3) {\n        AVStereo3D *stereo = av_stereo3d_create_side_data(&cur->f);\n        if (stereo) {\n        switch (h->frame_packing_arrangement_type) {\n        case 0:\n            stereo->type = AV_STEREO3D_CHECKERBOARD;\n            break;\n        case 1:\n            stereo->type = AV_STEREO3D_COLUMNS;\n            break;\n        case 2:\n            stereo->type = AV_STEREO3D_LINES;\n            break;\n        case 3:\n            if (h->quincunx_subsampling)\n                stereo->type = AV_STEREO3D_SIDEBYSIDE_QUINCUNX;\n            else\n                stereo->type = AV_STEREO3D_SIDEBYSIDE;\n            break;\n        case 4:\n            stereo->type = AV_STEREO3D_TOPBOTTOM;\n            break;\n        case 5:\n            stereo->type = AV_STEREO3D_FRAMESEQUENCE;\n            break;\n        case 6:\n            stereo->type = AV_STEREO3D_2D;\n            break;\n        }\n\n        if (h->content_interpretation_type == 2)\n            stereo->flags = AV_STEREO3D_FLAG_INVERT;\n        }\n    }\n\n    if (h->sei_display_orientation_present &&\n        (h->sei_anticlockwise_rotation || h->sei_hflip || h->sei_vflip)) {\n        double angle = h->sei_anticlockwise_rotation * 360 / (double) (1 << 16);\n        AVFrameSideData *rotation = av_frame_new_side_data(&cur->f,\n                                                           AV_FRAME_DATA_DISPLAYMATRIX,\n                                                           sizeof(int32_t) * 9);\n        if (rotation) {\n            av_display_rotation_set((int32_t *)rotation->data, angle);\n            av_display_matrix_flip((int32_t *)rotation->data,\n                                   h->sei_hflip, h->sei_vflip);\n        }\n    }\n\n    cur->mmco_reset = h->mmco_reset;\n    h->mmco_reset = 0;\n\n    // FIXME do something with unavailable reference frames\n\n    /* Sort B-frames into display order */\n\n    if (h->sps.bitstream_restriction_flag &&\n        h->avctx->has_b_frames < h->sps.num_reorder_frames) {\n        h->avctx->has_b_frames = h->sps.num_reorder_frames;\n        h->low_delay           = 0;\n    }\n\n    if (h->avctx->strict_std_compliance >= FF_COMPLIANCE_STRICT &&\n        !h->sps.bitstream_restriction_flag) {\n        h->avctx->has_b_frames = MAX_DELAYED_PIC_COUNT - 1;\n        h->low_delay           = 0;\n    }\n\n    for (i = 0; 1; i++) {\n        if(i == MAX_DELAYED_PIC_COUNT || cur->poc < h->last_pocs[i]){\n            if(i)\n                h->last_pocs[i-1] = cur->poc;\n            break;\n        } else if(i) {\n            h->last_pocs[i-1]= h->last_pocs[i];\n        }\n    }\n    out_of_order = MAX_DELAYED_PIC_COUNT - i;\n    if(   cur->f.pict_type == AV_PICTURE_TYPE_B\n       || (h->last_pocs[MAX_DELAYED_PIC_COUNT-2] > INT_MIN && h->last_pocs[MAX_DELAYED_PIC_COUNT-1] - h->last_pocs[MAX_DELAYED_PIC_COUNT-2] > 2))\n        out_of_order = FFMAX(out_of_order, 1);\n    if (out_of_order == MAX_DELAYED_PIC_COUNT) {\n        av_log(h->avctx, AV_LOG_VERBOSE, \"Invalid POC %d<%d\\n\", cur->poc, h->last_pocs[0]);\n        for (i = 1; i < MAX_DELAYED_PIC_COUNT; i++)\n            h->last_pocs[i] = INT_MIN;\n        h->last_pocs[0] = cur->poc;\n        cur->mmco_reset = 1;\n    } else if(h->avctx->has_b_frames < out_of_order && !h->sps.bitstream_restriction_flag){\n        av_log(h->avctx, AV_LOG_VERBOSE, \"Increasing reorder buffer to %d\\n\", out_of_order);\n        h->avctx->has_b_frames = out_of_order;\n        h->low_delay = 0;\n    }\n\n    pics = 0;\n    while (h->delayed_pic[pics])\n        pics++;\n\n    av_assert0(pics <= MAX_DELAYED_PIC_COUNT);\n\n    h->delayed_pic[pics++] = cur;\n    if (cur->reference == 0)\n        cur->reference = DELAYED_PIC_REF;\n\n    out     = h->delayed_pic[0];\n    out_idx = 0;\n    for (i = 1; h->delayed_pic[i] &&\n                !h->delayed_pic[i]->f.key_frame &&\n                !h->delayed_pic[i]->mmco_reset;\n         i++)\n        if (h->delayed_pic[i]->poc < out->poc) {\n            out     = h->delayed_pic[i];\n            out_idx = i;\n        }\n    if (h->avctx->has_b_frames == 0 &&\n        (h->delayed_pic[0]->f.key_frame || h->delayed_pic[0]->mmco_reset))\n        h->next_outputed_poc = INT_MIN;\n    out_of_order = out->poc < h->next_outputed_poc;\n\n    if (out_of_order || pics > h->avctx->has_b_frames) {\n        out->reference &= ~DELAYED_PIC_REF;\n        // for frame threading, the owner must be the second field's thread or\n        // else the first thread can release the picture and reuse it unsafely\n        for (i = out_idx; h->delayed_pic[i]; i++)\n            h->delayed_pic[i] = h->delayed_pic[i + 1];\n    }\n    if (!out_of_order && pics > h->avctx->has_b_frames) {\n        h->next_output_pic = out;\n        if (out_idx == 0 && h->delayed_pic[0] && (h->delayed_pic[0]->f.key_frame || h->delayed_pic[0]->mmco_reset)) {\n            h->next_outputed_poc = INT_MIN;\n        } else\n            h->next_outputed_poc = out->poc;\n    } else {\n        av_log(h->avctx, AV_LOG_DEBUG, \"no picture %s\\n\", out_of_order ? \"ooo\" : \"\");\n    }\n\n    if (h->next_output_pic) {\n        if (h->next_output_pic->recovered) {\n            // We have reached an recovery point and all frames after it in\n            // display order are \"recovered\".\n            h->frame_recovered |= FRAME_RECOVERED_SEI;\n        }\n        h->next_output_pic->recovered |= !!(h->frame_recovered & FRAME_RECOVERED_SEI);\n    }\n\n    if (setup_finished && !h->avctx->hwaccel)\n        ff_thread_finish_setup(h->avctx);\n}\n\nint ff_pred_weight_table(H264Context *h)\n{\n    int list, i;\n    int luma_def, chroma_def;\n\n    h->use_weight             = 0;\n    h->use_weight_chroma      = 0;\n    h->luma_log2_weight_denom = get_ue_golomb(&h->gb);\n    if (h->sps.chroma_format_idc)\n        h->chroma_log2_weight_denom = get_ue_golomb(&h->gb);\n    luma_def   = 1 << h->luma_log2_weight_denom;\n    chroma_def = 1 << h->chroma_log2_weight_denom;\n\n    for (list = 0; list < 2; list++) {\n        h->luma_weight_flag[list]   = 0;\n        h->chroma_weight_flag[list] = 0;\n        for (i = 0; i < h->ref_count[list]; i++) {\n            int luma_weight_flag, chroma_weight_flag;\n\n            luma_weight_flag = get_bits1(&h->gb);\n            if (luma_weight_flag) {\n                h->luma_weight[i][list][0] = get_se_golomb(&h->gb);\n                h->luma_weight[i][list][1] = get_se_golomb(&h->gb);\n                if (h->luma_weight[i][list][0] != luma_def ||\n                    h->luma_weight[i][list][1] != 0) {\n                    h->use_weight             = 1;\n                    h->luma_weight_flag[list] = 1;\n                }\n            } else {\n                h->luma_weight[i][list][0] = luma_def;\n                h->luma_weight[i][list][1] = 0;\n            }\n\n            if (h->sps.chroma_format_idc) {\n                chroma_weight_flag = get_bits1(&h->gb);\n                if (chroma_weight_flag) {\n                    int j;\n                    for (j = 0; j < 2; j++) {\n                        h->chroma_weight[i][list][j][0] = get_se_golomb(&h->gb);\n                        h->chroma_weight[i][list][j][1] = get_se_golomb(&h->gb);\n                        if (h->chroma_weight[i][list][j][0] != chroma_def ||\n                            h->chroma_weight[i][list][j][1] != 0) {\n                            h->use_weight_chroma        = 1;\n                            h->chroma_weight_flag[list] = 1;\n                        }\n                    }\n                } else {\n                    int j;\n                    for (j = 0; j < 2; j++) {\n                        h->chroma_weight[i][list][j][0] = chroma_def;\n                        h->chroma_weight[i][list][j][1] = 0;\n                    }\n                }\n            }\n        }\n        if (h->slice_type_nos != AV_PICTURE_TYPE_B)\n            break;\n    }\n    h->use_weight = h->use_weight || h->use_weight_chroma;\n    return 0;\n}\n\n/**\n * instantaneous decoder refresh.\n */\nstatic void idr(H264Context *h)\n{\n    int i;\n    ff_h264_remove_all_refs(h);\n    h->prev_frame_num        =\n    h->prev_frame_num_offset = 0;\n    h->prev_poc_msb          = 1<<16;\n    h->prev_poc_lsb          = 0;\n    for (i = 0; i < MAX_DELAYED_PIC_COUNT; i++)\n        h->last_pocs[i] = INT_MIN;\n}\n\n/* forget old pics after a seek */\nvoid ff_h264_flush_change(H264Context *h)\n{\n    int i, j;\n\n    h->outputed_poc          = h->next_outputed_poc = INT_MIN;\n    h->prev_interlaced_frame = 1;\n    idr(h);\n\n    h->prev_frame_num = -1;\n    if (h->cur_pic_ptr) {\n        h->cur_pic_ptr->reference = 0;\n        for (j=i=0; h->delayed_pic[i]; i++)\n            if (h->delayed_pic[i] != h->cur_pic_ptr)\n                h->delayed_pic[j++] = h->delayed_pic[i];\n        h->delayed_pic[j] = NULL;\n    }\n    h->first_field = 0;\n    memset(h->ref_list[0], 0, sizeof(h->ref_list[0]));\n    memset(h->ref_list[1], 0, sizeof(h->ref_list[1]));\n    memset(h->default_ref_list[0], 0, sizeof(h->default_ref_list[0]));\n    memset(h->default_ref_list[1], 0, sizeof(h->default_ref_list[1]));\n    ff_h264_reset_sei(h);\n    h->recovery_frame = -1;\n    h->frame_recovered = 0;\n    h->list_count = 0;\n    h->current_slice = 0;\n    h->mmco_reset = 1;\n}\n\n/* forget old pics after a seek */\nstatic void flush_dpb(AVCodecContext *avctx)\n{\n    H264Context *h = avctx->priv_data;\n    int i;\n\n    for (i = 0; i <= MAX_DELAYED_PIC_COUNT; i++) {\n        if (h->delayed_pic[i])\n            h->delayed_pic[i]->reference = 0;\n        h->delayed_pic[i] = NULL;\n    }\n\n    ff_h264_flush_change(h);\n\n    if (h->DPB)\n        for (i = 0; i < H264_MAX_PICTURE_COUNT; i++)\n            ff_h264_unref_picture(h, &h->DPB[i]);\n    h->cur_pic_ptr = NULL;\n    ff_h264_unref_picture(h, &h->cur_pic);\n\n    h->mb_x = h->mb_y = 0;\n\n    h->parse_context.state             = -1;\n    h->parse_context.frame_start_found = 0;\n    h->parse_context.overread          = 0;\n    h->parse_context.overread_index    = 0;\n    h->parse_context.index             = 0;\n    h->parse_context.last_index        = 0;\n\n    ff_h264_free_tables(h, 1);\n    h->context_initialized = 0;\n}\n\nint ff_init_poc(H264Context *h, int pic_field_poc[2], int *pic_poc)\n{\n    const int max_frame_num = 1 << h->sps.log2_max_frame_num;\n    int field_poc[2];\n\n    h->frame_num_offset = h->prev_frame_num_offset;\n    if (h->frame_num < h->prev_frame_num)\n        h->frame_num_offset += max_frame_num;\n\n    if (h->sps.poc_type == 0) {\n        const int max_poc_lsb = 1 << h->sps.log2_max_poc_lsb;\n\n        if (h->poc_lsb < h->prev_poc_lsb &&\n            h->prev_poc_lsb - h->poc_lsb >= max_poc_lsb / 2)\n            h->poc_msb = h->prev_poc_msb + max_poc_lsb;\n        else if (h->poc_lsb > h->prev_poc_lsb &&\n                 h->prev_poc_lsb - h->poc_lsb < -max_poc_lsb / 2)\n            h->poc_msb = h->prev_poc_msb - max_poc_lsb;\n        else\n            h->poc_msb = h->prev_poc_msb;\n        field_poc[0] =\n        field_poc[1] = h->poc_msb + h->poc_lsb;\n        if (h->picture_structure == PICT_FRAME)\n            field_poc[1] += h->delta_poc_bottom;\n    } else if (h->sps.poc_type == 1) {\n        int abs_frame_num, expected_delta_per_poc_cycle, expectedpoc;\n        int i;\n\n        if (h->sps.poc_cycle_length != 0)\n            abs_frame_num = h->frame_num_offset + h->frame_num;\n        else\n            abs_frame_num = 0;\n\n        if (h->nal_ref_idc == 0 && abs_frame_num > 0)\n            abs_frame_num--;\n\n        expected_delta_per_poc_cycle = 0;\n        for (i = 0; i < h->sps.poc_cycle_length; i++)\n            // FIXME integrate during sps parse\n            expected_delta_per_poc_cycle += h->sps.offset_for_ref_frame[i];\n\n        if (abs_frame_num > 0) {\n            int poc_cycle_cnt          = (abs_frame_num - 1) / h->sps.poc_cycle_length;\n            int frame_num_in_poc_cycle = (abs_frame_num - 1) % h->sps.poc_cycle_length;\n\n            expectedpoc = poc_cycle_cnt * expected_delta_per_poc_cycle;\n            for (i = 0; i <= frame_num_in_poc_cycle; i++)\n                expectedpoc = expectedpoc + h->sps.offset_for_ref_frame[i];\n        } else\n            expectedpoc = 0;\n\n        if (h->nal_ref_idc == 0)\n            expectedpoc = expectedpoc + h->sps.offset_for_non_ref_pic;\n\n        field_poc[0] = expectedpoc + h->delta_poc[0];\n        field_poc[1] = field_poc[0] + h->sps.offset_for_top_to_bottom_field;\n\n        if (h->picture_structure == PICT_FRAME)\n            field_poc[1] += h->delta_poc[1];\n    } else {\n        int poc = 2 * (h->frame_num_offset + h->frame_num);\n\n        if (!h->nal_ref_idc)\n            poc--;\n\n        field_poc[0] = poc;\n        field_poc[1] = poc;\n    }\n\n    if (h->picture_structure != PICT_BOTTOM_FIELD)\n        pic_field_poc[0] = field_poc[0];\n    if (h->picture_structure != PICT_TOP_FIELD)\n        pic_field_poc[1] = field_poc[1];\n    *pic_poc = FFMIN(pic_field_poc[0], pic_field_poc[1]);\n\n    return 0;\n}\n\n/**\n * Compute profile from profile_idc and constraint_set?_flags.\n *\n * @param sps SPS\n *\n * @return profile as defined by FF_PROFILE_H264_*\n */\nint ff_h264_get_profile(SPS *sps)\n{\n    int profile = sps->profile_idc;\n\n    switch (sps->profile_idc) {\n    case FF_PROFILE_H264_BASELINE:\n        // constraint_set1_flag set to 1\n        profile |= (sps->constraint_set_flags & 1 << 1) ? FF_PROFILE_H264_CONSTRAINED : 0;\n        break;\n    case FF_PROFILE_H264_HIGH_10:\n    case FF_PROFILE_H264_HIGH_422:\n    case FF_PROFILE_H264_HIGH_444_PREDICTIVE:\n        // constraint_set3_flag set to 1\n        profile |= (sps->constraint_set_flags & 1 << 3) ? FF_PROFILE_H264_INTRA : 0;\n        break;\n    }\n\n    return profile;\n}\n\nint ff_h264_set_parameter_from_sps(H264Context *h)\n{\n    if (h->flags & CODEC_FLAG_LOW_DELAY ||\n        (h->sps.bitstream_restriction_flag &&\n         !h->sps.num_reorder_frames)) {\n        if (h->avctx->has_b_frames > 1 || h->delayed_pic[0])\n            av_log(h->avctx, AV_LOG_WARNING, \"Delayed frames seen. \"\n                   \"Reenabling low delay requires a codec flush.\\n\");\n        else\n            h->low_delay = 1;\n    }\n\n    if (h->avctx->has_b_frames < 2)\n        h->avctx->has_b_frames = !h->low_delay;\n\n    if (h->avctx->bits_per_raw_sample != h->sps.bit_depth_luma ||\n        h->cur_chroma_format_idc      != h->sps.chroma_format_idc) {\n        if (h->avctx->codec &&\n            h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU &&\n            (h->sps.bit_depth_luma != 8 || h->sps.chroma_format_idc > 1)) {\n            av_log(h->avctx, AV_LOG_ERROR,\n                   \"VDPAU decoding does not support video colorspace.\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        if (h->sps.bit_depth_luma >= 8 && h->sps.bit_depth_luma <= 14 &&\n            h->sps.bit_depth_luma != 11 && h->sps.bit_depth_luma != 13) {\n            h->avctx->bits_per_raw_sample = h->sps.bit_depth_luma;\n            h->cur_chroma_format_idc      = h->sps.chroma_format_idc;\n            h->pixel_shift                = h->sps.bit_depth_luma > 8;\n\n            ff_h264dsp_init(&h->h264dsp, h->sps.bit_depth_luma,\n                            h->sps.chroma_format_idc);\n            ff_h264chroma_init(&h->h264chroma, h->sps.bit_depth_chroma);\n            ff_h264qpel_init(&h->h264qpel, h->sps.bit_depth_luma);\n            ff_h264_pred_init(&h->hpc, h->avctx->codec_id, h->sps.bit_depth_luma,\n                              h->sps.chroma_format_idc);\n\n            if (CONFIG_ERROR_RESILIENCE)\n                ff_me_cmp_init(&h->mecc, h->avctx);\n            ff_videodsp_init(&h->vdsp, h->sps.bit_depth_luma);\n        } else {\n            av_log(h->avctx, AV_LOG_ERROR, \"Unsupported bit depth %d\\n\",\n                   h->sps.bit_depth_luma);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n    return 0;\n}\n\nint ff_set_ref_count(H264Context *h)\n{\n    int ref_count[2], list_count;\n    int num_ref_idx_active_override_flag;\n\n    // set defaults, might be overridden a few lines later\n    ref_count[0] = h->pps.ref_count[0];\n    ref_count[1] = h->pps.ref_count[1];\n\n    if (h->slice_type_nos != AV_PICTURE_TYPE_I) {\n        unsigned max[2];\n        max[0] = max[1] = h->picture_structure == PICT_FRAME ? 15 : 31;\n\n        if (h->slice_type_nos == AV_PICTURE_TYPE_B)\n            h->direct_spatial_mv_pred = get_bits1(&h->gb);\n        num_ref_idx_active_override_flag = get_bits1(&h->gb);\n\n        if (num_ref_idx_active_override_flag) {\n            ref_count[0] = get_ue_golomb(&h->gb) + 1;\n            if (h->slice_type_nos == AV_PICTURE_TYPE_B) {\n                ref_count[1] = get_ue_golomb(&h->gb) + 1;\n            } else\n                // full range is spec-ok in this case, even for frames\n                ref_count[1] = 1;\n        }\n\n        if (ref_count[0]-1 > max[0] || ref_count[1]-1 > max[1]){\n            av_log(h->avctx, AV_LOG_ERROR, \"reference overflow %u > %u or %u > %u\\n\", ref_count[0]-1, max[0], ref_count[1]-1, max[1]);\n            h->ref_count[0] = h->ref_count[1] = 0;\n            h->list_count   = 0;\n            return AVERROR_INVALIDDATA;\n        }\n\n        if (h->slice_type_nos == AV_PICTURE_TYPE_B)\n            list_count = 2;\n        else\n            list_count = 1;\n    } else {\n        list_count   = 0;\n        ref_count[0] = ref_count[1] = 0;\n    }\n\n    if (list_count != h->list_count ||\n        ref_count[0] != h->ref_count[0] ||\n        ref_count[1] != h->ref_count[1]) {\n        h->ref_count[0] = ref_count[0];\n        h->ref_count[1] = ref_count[1];\n        h->list_count   = list_count;\n        return 1;\n    }\n\n    return 0;\n}\n\nstatic const uint8_t start_code[] = { 0x00, 0x00, 0x01 };\n\nstatic int get_bit_length(H264Context *h, const uint8_t *buf,\n                          const uint8_t *ptr, int dst_length,\n                          int i, int next_avc)\n{\n    if ((h->workaround_bugs & FF_BUG_AUTODETECT) && i + 3 < next_avc &&\n        buf[i]     == 0x00 && buf[i + 1] == 0x00 &&\n        buf[i + 2] == 0x01 && buf[i + 3] == 0xE0)\n        h->workaround_bugs |= FF_BUG_TRUNCATED;\n\n    if (!(h->workaround_bugs & FF_BUG_TRUNCATED))\n        while (dst_length > 0 && ptr[dst_length - 1] == 0)\n            dst_length--;\n\n    if (!dst_length)\n        return 0;\n\n    return 8 * dst_length - decode_rbsp_trailing(h, ptr + dst_length - 1);\n}\n\nstatic int get_last_needed_nal(H264Context *h, const uint8_t *buf, int buf_size)\n{\n    int next_avc    = h->is_avc ? 0 : buf_size;\n    int nal_index   = 0;\n    int buf_index   = 0;\n    int nals_needed = 0;\n    int first_slice = 0;\n\n    while(1) {\n        int nalsize = 0;\n        int dst_length, bit_length, consumed;\n        const uint8_t *ptr;\n\n        if (buf_index >= next_avc) {\n            nalsize = get_avc_nalsize(h, buf, buf_size, &buf_index);\n            if (nalsize < 0)\n                break;\n            next_avc = buf_index + nalsize;\n        } else {\n            buf_index = find_start_code(buf, buf_size, buf_index, next_avc);\n            if (buf_index >= buf_size)\n                break;\n            if (buf_index >= next_avc)\n                continue;\n        }\n\n        ptr = ff_h264_decode_nal(h, buf + buf_index, &dst_length, &consumed,\n                                 next_avc - buf_index);\n\n        if (!ptr || dst_length < 0)\n            return AVERROR_INVALIDDATA;\n\n        buf_index += consumed;\n\n        bit_length = get_bit_length(h, buf, ptr, dst_length,\n                                    buf_index, next_avc);\n        nal_index++;\n\n        /* packets can sometimes contain multiple PPS/SPS,\n         * e.g. two PAFF field pictures in one packet, or a demuxer\n         * which splits NALs strangely if so, when frame threading we\n         * can't start the next thread until we've read all of them */\n        switch (h->nal_unit_type) {\n        case NAL_SPS:\n        case NAL_PPS:\n            nals_needed = nal_index;\n            break;\n        case NAL_DPA:\n        case NAL_IDR_SLICE:\n        case NAL_SLICE:\n            init_get_bits(&h->gb, ptr, bit_length);\n            if (!get_ue_golomb(&h->gb) ||\n                !first_slice ||\n                first_slice != h->nal_unit_type)\n                nals_needed = nal_index;\n            if (!first_slice)\n                first_slice = h->nal_unit_type;\n        }\n    }\n\n    return nals_needed;\n}\n\nstatic int decode_nal_units(H264Context *h, const uint8_t *buf, int buf_size,\n                            int parse_extradata)\n{\n    AVCodecContext *const avctx = h->avctx;\n    H264Context *hx; ///< thread context\n    int buf_index;\n    unsigned context_count;\n    int next_avc;\n    int nals_needed = 0; ///< number of NALs that need decoding before the next frame thread starts\n    int nal_index;\n    int idr_cleared=0;\n    int ret = 0;\n\n    h->nal_unit_type= 0;\n\n    if(!h->slice_context_count)\n         h->slice_context_count= 1;\n    h->max_contexts = h->slice_context_count;\n    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS)) {\n        h->current_slice = 0;\n        if (!h->first_field)\n            h->cur_pic_ptr = NULL;\n        ff_h264_reset_sei(h);\n    }\n\n    if (h->nal_length_size == 4) {\n        if (buf_size > 8 && AV_RB32(buf) == 1 && AV_RB32(buf+5) > (unsigned)buf_size) {\n            h->is_avc = 0;\n        }else if(buf_size > 3 && AV_RB32(buf) > 1 && AV_RB32(buf) <= (unsigned)buf_size)\n            h->is_avc = 1;\n    }\n\n    if (avctx->active_thread_type & FF_THREAD_FRAME)\n        nals_needed = get_last_needed_nal(h, buf, buf_size);\n\n    {\n        buf_index     = 0;\n        context_count = 0;\n        next_avc      = h->is_avc ? 0 : buf_size;\n        nal_index     = 0;\n        for (;;) {\n            int consumed;\n            int dst_length;\n            int bit_length;\n            const uint8_t *ptr;\n            int nalsize = 0;\n            int err;\n\n            if (buf_index >= next_avc) {\n                nalsize = get_avc_nalsize(h, buf, buf_size, &buf_index);\n                if (nalsize < 0)\n                    break;\n                next_avc = buf_index + nalsize;\n            } else {\n                buf_index = find_start_code(buf, buf_size, buf_index, next_avc);\n                if (buf_index >= buf_size)\n                    break;\n                if (buf_index >= next_avc)\n                    continue;\n            }\n\n            hx = h->thread_context[context_count];\n\n            ptr = ff_h264_decode_nal(hx, buf + buf_index, &dst_length,\n                                     &consumed, next_avc - buf_index);\n            if (!ptr || dst_length < 0) {\n                ret = -1;\n                goto end;\n            }\n\n            bit_length = get_bit_length(h, buf, ptr, dst_length,\n                                        buf_index + consumed, next_avc);\n\n            if (h->avctx->debug & FF_DEBUG_STARTCODE)\n                av_log(h->avctx, AV_LOG_DEBUG,\n                       \"NAL %d/%d at %d/%d length %d\\n\",\n                       hx->nal_unit_type, hx->nal_ref_idc, buf_index, buf_size, dst_length);\n\n            if (h->is_avc && (nalsize != consumed) && nalsize)\n                av_log(h->avctx, AV_LOG_DEBUG,\n                       \"AVC: Consumed only %d bytes instead of %d\\n\",\n                       consumed, nalsize);\n\n            buf_index += consumed;\n            nal_index++;\n\n            if (avctx->skip_frame >= AVDISCARD_NONREF &&\n                h->nal_ref_idc == 0 &&\n                h->nal_unit_type != NAL_SEI)\n                continue;\n\nagain:\n            if (   !(avctx->active_thread_type & FF_THREAD_FRAME)\n                || nals_needed >= nal_index)\n                h->au_pps_id = -1;\n            /* Ignore per frame NAL unit type during extradata\n             * parsing. Decoding slices is not possible in codec init\n             * with frame-mt */\n            if (parse_extradata) {\n                switch (hx->nal_unit_type) {\n                case NAL_IDR_SLICE:\n                case NAL_SLICE:\n                case NAL_DPA:\n                case NAL_DPB:\n                case NAL_DPC:\n                    av_log(h->avctx, AV_LOG_WARNING,\n                           \"Ignoring NAL %d in global header/extradata\\n\",\n                           hx->nal_unit_type);\n                    // fall through to next case\n                case NAL_AUXILIARY_SLICE:\n                    hx->nal_unit_type = NAL_FF_IGNORE;\n                }\n            }\n\n            err = 0;\n\n            switch (hx->nal_unit_type) {\n            case NAL_IDR_SLICE:\n                if ((ptr[0] & 0xFC) == 0x98) {\n                    av_log(h->avctx, AV_LOG_ERROR, \"Invalid inter IDR frame\\n\");\n                    h->next_outputed_poc = INT_MIN;\n                    ret = -1;\n                    goto end;\n                }\n                if (h->nal_unit_type != NAL_IDR_SLICE) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"Invalid mix of idr and non-idr slices\\n\");\n                    ret = -1;\n                    goto end;\n                }\n                if(!idr_cleared)\n                    idr(h); // FIXME ensure we don't lose some frames if there is reordering\n                idr_cleared = 1;\n                h->has_recovery_point = 1;\n            case NAL_SLICE:\n                init_get_bits(&hx->gb, ptr, bit_length);\n                hx->intra_gb_ptr      =\n                hx->inter_gb_ptr      = &hx->gb;\n                hx->data_partitioning = 0;\n\n                if ((err = ff_h264_decode_slice_header(hx, h)))\n                    break;\n\n                if (h->sei_recovery_frame_cnt >= 0) {\n                    if (h->frame_num != h->sei_recovery_frame_cnt || hx->slice_type_nos != AV_PICTURE_TYPE_I)\n                        h->valid_recovery_point = 1;\n\n                    if (   h->recovery_frame < 0\n                        || ((h->recovery_frame - h->frame_num) & ((1 << h->sps.log2_max_frame_num)-1)) > h->sei_recovery_frame_cnt) {\n                        h->recovery_frame = (h->frame_num + h->sei_recovery_frame_cnt) &\n                                            ((1 << h->sps.log2_max_frame_num) - 1);\n\n                        if (!h->valid_recovery_point)\n                            h->recovery_frame = h->frame_num;\n                    }\n                }\n\n                h->cur_pic_ptr->f.key_frame |=\n                    (hx->nal_unit_type == NAL_IDR_SLICE);\n\n                if (hx->nal_unit_type == NAL_IDR_SLICE ||\n                    h->recovery_frame == h->frame_num) {\n                    h->recovery_frame         = -1;\n                    h->cur_pic_ptr->recovered = 1;\n                }\n                // If we have an IDR, all frames after it in decoded order are\n                // \"recovered\".\n                if (hx->nal_unit_type == NAL_IDR_SLICE)\n                    h->frame_recovered |= FRAME_RECOVERED_IDR;\n                h->frame_recovered |= 3*!!(avctx->flags2 & CODEC_FLAG2_SHOW_ALL);\n                h->frame_recovered |= 3*!!(avctx->flags & CODEC_FLAG_OUTPUT_CORRUPT);\n#if 1\n                h->cur_pic_ptr->recovered |= h->frame_recovered;\n#else\n                h->cur_pic_ptr->recovered |= !!(h->frame_recovered & FRAME_RECOVERED_IDR);\n#endif\n\n                if (h->current_slice == 1) {\n                    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS))\n                        decode_postinit(h, nal_index >= nals_needed);\n\n                    if (h->avctx->hwaccel &&\n                        (ret = h->avctx->hwaccel->start_frame(h->avctx, NULL, 0)) < 0)\n                        return ret;\n                    if (CONFIG_H264_VDPAU_DECODER &&\n                        h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)\n                        ff_vdpau_h264_picture_start(h);\n                }\n\n                if (hx->redundant_pic_count == 0) {\n                    if (avctx->hwaccel) {\n                        ret = avctx->hwaccel->decode_slice(avctx,\n                                                           &buf[buf_index - consumed],\n                                                           consumed);\n                        if (ret < 0)\n                            return ret;\n                    } else if (CONFIG_H264_VDPAU_DECODER &&\n                               h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU) {\n                        ff_vdpau_add_data_chunk(h->cur_pic_ptr->f.data[0],\n                                                start_code,\n                                                sizeof(start_code));\n                        ff_vdpau_add_data_chunk(h->cur_pic_ptr->f.data[0],\n                                                &buf[buf_index - consumed],\n                                                consumed);\n                    } else\n                        context_count++;\n                }\n                break;\n            case NAL_DPA:\n                if (h->avctx->flags & CODEC_FLAG2_CHUNKS) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"Decoding in chunks is not supported for \"\n                           \"partitioned slices.\\n\");\n                    return AVERROR(ENOSYS);\n                }\n\n                init_get_bits(&hx->gb, ptr, bit_length);\n                hx->intra_gb_ptr =\n                hx->inter_gb_ptr = NULL;\n\n                if ((err = ff_h264_decode_slice_header(hx, h))) {\n                    /* make sure data_partitioning is cleared if it was set\n                     * before, so we don't try decoding a slice without a valid\n                     * slice header later */\n                    h->data_partitioning = 0;\n                    break;\n                }\n\n                hx->data_partitioning = 1;\n                break;\n            case NAL_DPB:\n                init_get_bits(&hx->intra_gb, ptr, bit_length);\n                hx->intra_gb_ptr = &hx->intra_gb;\n                break;\n            case NAL_DPC:\n                init_get_bits(&hx->inter_gb, ptr, bit_length);\n                hx->inter_gb_ptr = &hx->inter_gb;\n\n                av_log(h->avctx, AV_LOG_ERROR, \"Partitioned H.264 support is incomplete\\n\");\n                break;\n\n                if (hx->redundant_pic_count == 0 &&\n                    hx->intra_gb_ptr &&\n                    hx->data_partitioning &&\n                    h->cur_pic_ptr && h->context_initialized &&\n                    (avctx->skip_frame < AVDISCARD_NONREF || hx->nal_ref_idc) &&\n                    (avctx->skip_frame < AVDISCARD_BIDIR  ||\n                     hx->slice_type_nos != AV_PICTURE_TYPE_B) &&\n                    (avctx->skip_frame < AVDISCARD_NONINTRA ||\n                     hx->slice_type_nos == AV_PICTURE_TYPE_I) &&\n                    avctx->skip_frame < AVDISCARD_ALL)\n                    context_count++;\n                break;\n            case NAL_SEI:\n                init_get_bits(&h->gb, ptr, bit_length);\n                ret = ff_h264_decode_sei(h);\n                if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n                    goto end;\n                break;\n            case NAL_SPS:\n                init_get_bits(&h->gb, ptr, bit_length);\n                if (ff_h264_decode_seq_parameter_set(h) < 0 && (h->is_avc ? nalsize : 1)) {\n                    av_log(h->avctx, AV_LOG_DEBUG,\n                           \"SPS decoding failure, trying again with the complete NAL\\n\");\n                    if (h->is_avc)\n                        av_assert0(next_avc - buf_index + consumed == nalsize);\n                    if ((next_avc - buf_index + consumed - 1) >= INT_MAX/8)\n                        break;\n                    init_get_bits(&h->gb, &buf[buf_index + 1 - consumed],\n                                  8*(next_avc - buf_index + consumed - 1));\n                    ff_h264_decode_seq_parameter_set(h);\n                }\n\n                break;\n            case NAL_PPS:\n                init_get_bits(&h->gb, ptr, bit_length);\n                ret = ff_h264_decode_picture_parameter_set(h, bit_length);\n                if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n                    goto end;\n                break;\n            case NAL_AUD:\n            case NAL_END_SEQUENCE:\n            case NAL_END_STREAM:\n            case NAL_FILLER_DATA:\n            case NAL_SPS_EXT:\n            case NAL_AUXILIARY_SLICE:\n                break;\n            case NAL_FF_IGNORE:\n                break;\n            default:\n                av_log(avctx, AV_LOG_DEBUG, \"Unknown NAL code: %d (%d bits)\\n\",\n                       hx->nal_unit_type, bit_length);\n            }\n\n            if (context_count == h->max_contexts) {\n                ret = ff_h264_execute_decode_slices(h, context_count);\n                if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n                    goto end;\n                context_count = 0;\n            }\n\n            if (err < 0 || err == SLICE_SKIPED) {\n                if (err < 0)\n                    av_log(h->avctx, AV_LOG_ERROR, \"decode_slice_header error\\n\");\n                h->ref_count[0] = h->ref_count[1] = h->list_count = 0;\n            } else if (err == SLICE_SINGLETHREAD) {\n                /* Slice could not be decoded in parallel mode, copy down\n                 * NAL unit stuff to context 0 and restart. Note that\n                 * rbsp_buffer is not transferred, but since we no longer\n                 * run in parallel mode this should not be an issue. */\n                h->nal_unit_type = hx->nal_unit_type;\n                h->nal_ref_idc   = hx->nal_ref_idc;\n                hx               = h;\n                goto again;\n            }\n        }\n    }\n    if (context_count) {\n        ret = ff_h264_execute_decode_slices(h, context_count);\n        if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n            goto end;\n    }\n\n    ret = 0;\nend:\n    /* clean up */\n    if (h->cur_pic_ptr && !h->droppable) {\n        ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n                                  h->picture_structure == PICT_BOTTOM_FIELD);\n    }\n\n    return (ret < 0) ? ret : buf_index;\n}\n\n/**\n * Return the number of bytes consumed for building the current frame.\n */\nstatic int get_consumed_bytes(int pos, int buf_size)\n{\n    if (pos == 0)\n        pos = 1;        // avoid infinite loops (I doubt that is needed but...)\n    if (pos + 10 > buf_size)\n        pos = buf_size; // oops ;)\n\n    return pos;\n}\n\nstatic int output_frame(H264Context *h, AVFrame *dst, H264Picture *srcp)\n{\n    AVFrame *src = &srcp->f;\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(src->format);\n    int i;\n    int ret = av_frame_ref(dst, src);\n    if (ret < 0)\n        return ret;\n\n    av_dict_set(&dst->metadata, \"stereo_mode\", ff_h264_sei_stereo_mode(h), 0);\n\n    if (srcp->sei_recovery_frame_cnt == 0)\n        dst->key_frame = 1;\n    if (!srcp->crop)\n        return 0;\n\n    for (i = 0; i < desc->nb_components; i++) {\n        int hshift = (i > 0) ? desc->log2_chroma_w : 0;\n        int vshift = (i > 0) ? desc->log2_chroma_h : 0;\n        int off    = ((srcp->crop_left >> hshift) << h->pixel_shift) +\n                      (srcp->crop_top  >> vshift) * dst->linesize[i];\n        dst->data[i] += off;\n    }\n    return 0;\n}\n\nstatic int is_extra(const uint8_t *buf, int buf_size)\n{\n    int cnt= buf[5]&0x1f;\n    const uint8_t *p= buf+6;\n    while(cnt--){\n        int nalsize= AV_RB16(p) + 2;\n        if(nalsize > buf_size - (p-buf) || p[2]!=0x67)\n            return 0;\n        p += nalsize;\n    }\n    cnt = *(p++);\n    if(!cnt)\n        return 0;\n    while(cnt--){\n        int nalsize= AV_RB16(p) + 2;\n        if(nalsize > buf_size - (p-buf) || p[2]!=0x68)\n            return 0;\n        p += nalsize;\n    }\n    return 1;\n}\n\nstatic int h264_decode_frame(AVCodecContext *avctx, void *data,\n                             int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size       = avpkt->size;\n    H264Context *h     = avctx->priv_data;\n    AVFrame *pict      = data;\n    int buf_index      = 0;\n    H264Picture *out;\n    int i, out_idx;\n    int ret;\n\n    h->flags = avctx->flags;\n    /* reset data partitioning here, to ensure GetBitContexts from previous\n     * packets do not get used. */\n    h->data_partitioning = 0;\n\n    /* end of stream, output what is still in the buffers */\n    if (buf_size == 0) {\n out:\n\n        h->cur_pic_ptr = NULL;\n        h->first_field = 0;\n\n        // FIXME factorize this with the output code below\n        out     = h->delayed_pic[0];\n        out_idx = 0;\n        for (i = 1;\n             h->delayed_pic[i] &&\n             !h->delayed_pic[i]->f.key_frame &&\n             !h->delayed_pic[i]->mmco_reset;\n             i++)\n            if (h->delayed_pic[i]->poc < out->poc) {\n                out     = h->delayed_pic[i];\n                out_idx = i;\n            }\n\n        for (i = out_idx; h->delayed_pic[i]; i++)\n            h->delayed_pic[i] = h->delayed_pic[i + 1];\n\n        if (out) {\n            out->reference &= ~DELAYED_PIC_REF;\n            ret = output_frame(h, pict, out);\n            if (ret < 0)\n                return ret;\n            *got_frame = 1;\n        }\n\n        return buf_index;\n    }\n    if (h->is_avc && av_packet_get_side_data(avpkt, AV_PKT_DATA_NEW_EXTRADATA, NULL)) {\n        int side_size;\n        uint8_t *side = av_packet_get_side_data(avpkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);\n        if (is_extra(side, side_size))\n            ff_h264_decode_extradata(h, side, side_size);\n    }\n    if(h->is_avc && buf_size >= 9 && buf[0]==1 && buf[2]==0 && (buf[4]&0xFC)==0xFC && (buf[5]&0x1F) && buf[8]==0x67){\n        if (is_extra(buf, buf_size))\n            return ff_h264_decode_extradata(h, buf, buf_size);\n    }\n\n    buf_index = decode_nal_units(h, buf, buf_size, 0);\n    if (buf_index < 0)\n        return AVERROR_INVALIDDATA;\n\n    if (!h->cur_pic_ptr && h->nal_unit_type == NAL_END_SEQUENCE) {\n        av_assert0(buf_index <= buf_size);\n        goto out;\n    }\n\n    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS) && !h->cur_pic_ptr) {\n        if (avctx->skip_frame >= AVDISCARD_NONREF ||\n            buf_size >= 4 && !memcmp(\"Q264\", buf, 4))\n            return buf_size;\n        av_log(avctx, AV_LOG_ERROR, \"no frame!\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS) ||\n        (h->mb_y >= h->mb_height && h->mb_height)) {\n        if (avctx->flags2 & CODEC_FLAG2_CHUNKS)\n            decode_postinit(h, 1);\n\n        ff_h264_field_end(h, 0);\n\n        /* Wait for second field. */\n        *got_frame = 0;\n        if (h->next_output_pic && (\n                                   h->next_output_pic->recovered)) {\n            if (!h->next_output_pic->recovered)\n                h->next_output_pic->f.flags |= AV_FRAME_FLAG_CORRUPT;\n\n            ret = output_frame(h, pict, h->next_output_pic);\n            if (ret < 0)\n                return ret;\n            *got_frame = 1;\n            if (CONFIG_MPEGVIDEO) {\n                ff_print_debug_info2(h->avctx, pict, h->er.mbskip_table,\n                                    h->next_output_pic->mb_type,\n                                    h->next_output_pic->qscale_table,\n                                    h->next_output_pic->motion_val,\n                                    &h->low_delay,\n                                    h->mb_width, h->mb_height, h->mb_stride, 1);\n            }\n        }\n    }\n\n    assert(pict->buf[0] || !*got_frame);\n\n    return get_consumed_bytes(buf_index, buf_size);\n}\n\nav_cold void ff_h264_free_context(H264Context *h)\n{\n    int i;\n\n    ff_h264_free_tables(h, 1); // FIXME cleanup init stuff perhaps\n\n    for (i = 0; i < MAX_SPS_COUNT; i++)\n        av_freep(h->sps_buffers + i);\n\n    for (i = 0; i < MAX_PPS_COUNT; i++)\n        av_freep(h->pps_buffers + i);\n}\n\nstatic av_cold int h264_decode_end(AVCodecContext *avctx)\n{\n    H264Context *h = avctx->priv_data;\n\n    ff_h264_remove_all_refs(h);\n    ff_h264_free_context(h);\n\n    ff_h264_unref_picture(h, &h->cur_pic);\n\n    return 0;\n}\n\nstatic const AVProfile profiles[] = {\n    { FF_PROFILE_H264_BASELINE,             \"Baseline\"              },\n    { FF_PROFILE_H264_CONSTRAINED_BASELINE, \"Constrained Baseline\"  },\n    { FF_PROFILE_H264_MAIN,                 \"Main\"                  },\n    { FF_PROFILE_H264_EXTENDED,             \"Extended\"              },\n    { FF_PROFILE_H264_HIGH,                 \"High\"                  },\n    { FF_PROFILE_H264_HIGH_10,              \"High 10\"               },\n    { FF_PROFILE_H264_HIGH_10_INTRA,        \"High 10 Intra\"         },\n    { FF_PROFILE_H264_HIGH_422,             \"High 4:2:2\"            },\n    { FF_PROFILE_H264_HIGH_422_INTRA,       \"High 4:2:2 Intra\"      },\n    { FF_PROFILE_H264_HIGH_444,             \"High 4:4:4\"            },\n    { FF_PROFILE_H264_HIGH_444_PREDICTIVE,  \"High 4:4:4 Predictive\" },\n    { FF_PROFILE_H264_HIGH_444_INTRA,       \"High 4:4:4 Intra\"      },\n    { FF_PROFILE_H264_CAVLC_444,            \"CAVLC 4:4:4\"           },\n    { FF_PROFILE_UNKNOWN },\n};\n\nstatic const AVOption h264_options[] = {\n    {\"is_avc\", \"is avc\", offsetof(H264Context, is_avc), FF_OPT_TYPE_INT, {.i64 = 0}, 0, 1, 0},\n    {\"nal_length_size\", \"nal_length_size\", offsetof(H264Context, nal_length_size), FF_OPT_TYPE_INT, {.i64 = 0}, 0, 4, 0},\n    {NULL}\n};\n\nstatic const AVClass h264_class = {\n    .class_name = \"H264 Decoder\",\n    .item_name  = av_default_item_name,\n    .option     = h264_options,\n    .version    = LIBAVUTIL_VERSION_INT,\n};\n\nAVCodec ff_h264_decoder = {\n    .name                  = \"h264\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_H264,\n    .priv_data_size        = sizeof(H264Context),\n    .init                  = ff_h264_decode_init,\n    .close                 = h264_decode_end,\n    .decode                = h264_decode_frame,\n    .capabilities          = /*CODEC_CAP_DRAW_HORIZ_BAND |*/ CODEC_CAP_DR1 |\n                             CODEC_CAP_DELAY | CODEC_CAP_SLICE_THREADS |\n                             CODEC_CAP_FRAME_THREADS,\n    .flush                 = flush_dpb,\n    .init_thread_copy      = ONLY_IF_THREADS_ENABLED(decode_init_thread_copy),\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(ff_h264_update_thread_context),\n    .profiles              = NULL_IF_CONFIG_SMALL(profiles),\n    .priv_class            = &h264_class,\n};\n\n#if CONFIG_H264_VDPAU_DECODER\nstatic const AVClass h264_vdpau_class = {\n    .class_name = \"H264 VDPAU Decoder\",\n    .item_name  = av_default_item_name,\n    .option     = h264_options,\n    .version    = LIBAVUTIL_VERSION_INT,\n};\n\nAVCodec ff_h264_vdpau_decoder = {\n    .name           = \"h264_vdpau\",\n    .long_name      = NULL_IF_CONFIG_SMALL(\"H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (VDPAU acceleration)\"),\n    .type           = AVMEDIA_TYPE_VIDEO,\n    .id             = AV_CODEC_ID_H264,\n    .priv_data_size = sizeof(H264Context),\n    .init           = ff_h264_decode_init,\n    .close          = h264_decode_end,\n    .decode         = h264_decode_frame,\n    .capabilities   = CODEC_CAP_DR1 | CODEC_CAP_DELAY | CODEC_CAP_HWACCEL_VDPAU,\n    .flush          = flush_dpb,\n    .pix_fmts       = (const enum AVPixelFormat[]) { AV_PIX_FMT_VDPAU_H264,\n                                                     AV_PIX_FMT_NONE},\n    .profiles       = NULL_IF_CONFIG_SMALL(profiles),\n    .priv_class     = &h264_vdpau_class,\n};\n#endif\n"], "filenames": ["libavcodec/h264.c"], "buggy_code_start_loc": [393], "buggy_code_end_loc": [393], "fixing_code_start_loc": [394], "fixing_code_end_loc": [395], "type": "NVD-CWE-Other", "message": "Use-after-free vulnerability in the ff_h264_free_tables function in libavcodec/h264.c in FFmpeg before 2.3.6 allows remote attackers to cause a denial of service or possibly have unspecified other impact via crafted H.264 data in an MP4 file, as demonstrated by an HTML VIDEO element that references H.264 data.", "other": {"cve": {"id": "CVE-2015-3417", "sourceIdentifier": "cve@mitre.org", "published": "2015-04-24T17:59:03.393", "lastModified": "2017-07-01T01:29:16.390", "vulnStatus": "Modified", "evaluatorComment": "<a href=\"http://cwe.mitre.org/data/definitions/416.html\">CWE-416: Use After Free</a>", "descriptions": [{"lang": "en", "value": "Use-after-free vulnerability in the ff_h264_free_tables function in libavcodec/h264.c in FFmpeg before 2.3.6 allows remote attackers to cause a denial of service or possibly have unspecified other impact via crafted H.264 data in an MP4 file, as demonstrated by an HTML VIDEO element that references H.264 data."}, {"lang": "es", "value": "Vulnerabilidad de uso despu\u00e9s de liberaci\u00f3n en la funci\u00f3n ff_h264_free_tables en libavcodec/h264.c en FFmpeg anterior a 2.3.6 permite a atacantes remotos causar una denegaci\u00f3n de servicio o posiblemente tener otro impacto no especificado a trav\u00e9s de datos H.264 manipulados en un fichero MP4, tal y como fue demostrado por un elemento HTML VIDEO que hace referencia a datos H.264."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-Other"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:*:*:*:*:*:*:*:*", "versionEndIncluding": "2.3.5", "matchCriteriaId": "E2A7B6DB-E964-4C0B-BC45-2BA08A4497C2"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}]}]}], "references": [{"url": "http://seclists.org/fulldisclosure/2015/Apr/31", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.debian.org/security/2015/dsa-3288", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/74385", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.securitytracker.com/id/1032198", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://git.libav.org/?p=libav.git;a=blob;f=Changelog;hb=refs/tags/v11.4", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "https://github.com/FFmpeg/FFmpeg/commit/e8714f6f93d1a32f4e4655209960afcf4c185214", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://security.gentoo.org/glsa/201705-08", "source": "cve@mitre.org"}]}, "github_commit_url": "https://github.com/FFmpeg/FFmpeg/commit/e8714f6f93d1a32f4e4655209960afcf4c185214"}}
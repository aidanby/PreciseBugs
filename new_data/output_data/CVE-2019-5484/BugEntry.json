{"buggy_code": ["var path = require('path');\nvar fs = require('./fs');\nvar zlib = require('zlib');\nvar DecompressZip = require('decompress-zip');\nvar tar = require('tar-fs');\nvar Q = require('q');\nvar mout = require('mout');\nvar junk = require('junk');\nvar createError = require('./createError');\nvar createWriteStream = require('fs-write-stream-atomic');\nvar destroy = require('destroy');\nvar tmp = require('tmp');\n\n// This forces the default chunk size to something small in an attempt\n// to avoid issue #314\nzlib.Z_DEFAULT_CHUNK = 1024 * 8;\n\nvar extractors;\nvar extractorTypes;\n\nextractors = {\n    '.zip': extractZip,\n    '.tar': extractTar,\n    '.tar.gz': extractTarGz,\n    '.tgz': extractTarGz,\n    '.gz': extractGz,\n    'application/zip': extractZip,\n    'application/x-zip': extractZip,\n    'application/x-zip-compressed': extractZip,\n    'application/x-tar': extractTar,\n    'application/x-tgz': extractTarGz,\n    'application/x-gzip': extractGz\n};\n\nextractorTypes = Object.keys(extractors);\n\nfunction extractZip(archive, dst) {\n    var deferred = Q.defer();\n\n    new DecompressZip(archive)\n        .on('error', deferred.reject)\n        .on('extract', deferred.resolve.bind(deferred, dst))\n        .extract({\n            path: dst,\n            follow: false, // Do not follow symlinks (#699)\n            filter: filterSymlinks // Filter symlink files\n        });\n\n    return deferred.promise;\n}\n\nfunction extractTar(archive, dst) {\n    var deferred = Q.defer();\n\n    var stream = fs.createReadStream(archive);\n\n    var reject = function(error) {\n        destroy(stream);\n        deferred.reject(error);\n    };\n\n    stream\n        .on('error', reject)\n        .pipe(\n            tar.extract(dst, {\n                ignore: isSymlink, // Filter symlink files\n                dmode: 0555, // Ensure dirs are readable\n                fmode: 0444 // Ensure files are readable\n            })\n        )\n        .on('error', reject)\n        .on('finish', function(result) {\n            destroy(stream);\n            deferred.resolve(dst);\n        });\n\n    return deferred.promise;\n}\n\nfunction extractTarGz(archive, dst) {\n    var deferred = Q.defer();\n\n    var stream = fs.createReadStream(archive);\n\n    var reject = function(error) {\n        destroy(stream);\n        deferred.reject(error);\n    };\n\n    stream\n        .on('error', reject)\n        .pipe(zlib.createGunzip())\n        .on('error', reject)\n        .pipe(\n            tar.extract(dst, {\n                ignore: isSymlink, // Filter symlink files\n                dmode: 0555, // Ensure dirs are readable\n                fmode: 0444 // Ensure files are readable\n            })\n        )\n        .on('error', reject)\n        .on('finish', function(result) {\n            destroy(stream);\n            deferred.resolve(dst);\n        });\n\n    return deferred.promise;\n}\n\nfunction extractGz(archive, dst) {\n    var deferred = Q.defer();\n\n    var stream = fs.createReadStream(archive);\n\n    var reject = function(error) {\n        destroy(stream);\n        deferred.reject(error);\n    };\n    stream\n        .on('error', reject)\n        .pipe(zlib.createGunzip())\n        .on('error', reject)\n        .pipe(createWriteStream(dst))\n        .on('error', reject)\n        .on('finish', function(result) {\n            destroy(stream);\n            deferred.resolve(dst);\n        });\n\n    return deferred.promise;\n}\n\nfunction isSymlink(entry) {\n    return entry.type === 'SymbolicLink';\n}\n\nfunction filterSymlinks(entry) {\n    return entry.type !== 'SymbolicLink';\n}\n\nfunction getExtractor(archive) {\n    // Make the archive lower case to match against the types\n    // This ensures that upper-cased extensions work\n    archive = archive.toLowerCase();\n\n    var type = mout.array.find(extractorTypes, function(type) {\n        return mout.string.endsWith(archive, type);\n    });\n\n    return type ? extractors[type] : null;\n}\n\nfunction isSingleDir(dir) {\n    return Q.nfcall(fs.readdir, dir).then(function(files) {\n        var singleDir;\n\n        // Remove any OS specific files from the files array\n        // before checking its length\n        files = files.filter(junk.isnt);\n\n        if (files.length !== 1) {\n            return false;\n        }\n\n        singleDir = path.join(dir, files[0]);\n\n        return Q.nfcall(fs.stat, singleDir).then(function(stat) {\n            return stat.isDirectory() ? singleDir : false;\n        });\n    });\n}\n\nfunction moveDirectory(srcDir, destDir) {\n    return Q.nfcall(fs.readdir, srcDir)\n        .then(function(files) {\n            var promises = files.map(function(file) {\n                var src = path.join(srcDir, file);\n                var dst = path.join(destDir, file);\n\n                return Q.nfcall(fs.rename, src, dst);\n            });\n\n            return Q.all(promises);\n        })\n        .then(function() {\n            return Q.nfcall(fs.rmdir, srcDir);\n        });\n}\n\n// -----------------------------\n\nfunction canExtract(src, mimeType) {\n    if (mimeType && mimeType !== 'application/octet-stream') {\n        return !!getExtractor(mimeType);\n    }\n\n    return !!getExtractor(src);\n}\n\n// Available options:\n// - keepArchive: true to keep the archive afterwards (defaults to false)\n// - keepStructure: true to keep the extracted structure unchanged (defaults to false)\nfunction extract(src, dst, opts) {\n    var extractor;\n    var promise;\n\n    opts = opts || {};\n    extractor = getExtractor(src);\n\n    // Try to get extractor from mime type\n    if (!extractor && opts.mimeType) {\n        extractor = getExtractor(opts.mimeType);\n    }\n\n    // If extractor is null, then the archive type is unknown\n    if (!extractor) {\n        return Q.reject(\n            createError(\n                'File ' + src + ' is not a known archive',\n                'ENOTARCHIVE'\n            )\n        );\n    }\n\n    // Extract to a temporary directory in case of file name clashes\n    return Q.nfcall(tmp.dir, {\n        template: dst + '-XXXXXX',\n        mode: 0777 & ~process.umask()\n    })\n        .then(function(tempDir) {\n            // nfcall may return multiple callback arguments as an array\n            return Array.isArray(tempDir) ? tempDir[0] : tempDir;\n        })\n        .then(function(tempDir) {\n            // Check archive file size\n            promise = Q.nfcall(fs.stat, src).then(function(stat) {\n                if (stat.size <= 8) {\n                    throw createError(\n                        'File ' + src + ' is an invalid archive',\n                        'ENOTARCHIVE'\n                    );\n                }\n\n                // Extract archive\n                return extractor(src, tempDir);\n            });\n\n            // Remove archive\n            if (!opts.keepArchive) {\n                promise = promise.then(function() {\n                    return Q.nfcall(fs.unlink, src);\n                });\n            }\n\n            // Move contents from the temporary directory\n            // If the contents are a single directory (and we're not preserving structure),\n            // move its contents directly instead.\n            promise = promise\n                .then(function() {\n                    return isSingleDir(tempDir);\n                })\n                .then(function(singleDir) {\n                    if (singleDir && !opts.keepStructure) {\n                        return moveDirectory(singleDir, dst);\n                    } else {\n                        return moveDirectory(tempDir, dst);\n                    }\n                });\n\n            // Resolve promise to the dst dir\n            return promise.then(function() {\n                return dst;\n            });\n        });\n}\n\nmodule.exports = extract;\nmodule.exports.canExtract = canExtract;\n", "{\n  \"name\": \"bower\",\n  \"version\": \"1.8.7\",\n  \"description\": \"The browser package manager\",\n  \"author\": \"Twitter\",\n  \"license\": \"MIT\",\n  \"repository\": \"bower/bower\",\n  \"main\": \"lib\",\n  \"bin\": \"bin/bower\",\n  \"homepage\": \"http://bower.io\",\n  \"engines\": {\n    \"node\": \">=0.10.0\"\n  },\n  \"keywords\": [\n    \"bower\"\n  ],\n  \"dependencies\": {\n    \"abbrev\": \"^1.0.5\",\n    \"archy\": \"1.0.0\",\n    \"bower-config\": \"^1.4.1\",\n    \"bower-endpoint-parser\": \"^0.2.2\",\n    \"bower-json\": \"^0.8.1\",\n    \"bower-logger\": \"^0.2.2\",\n    \"bower-registry-client\": \"^1.0.0\",\n    \"cardinal\": \"0.4.4\",\n    \"chalk\": \"^1.0.0\",\n    \"chmodr\": \"^1.0.2\",\n    \"configstore\": \"^2.0.0\",\n    \"decompress-zip\": \"^0.2.2\",\n    \"destroy\": \"^1.0.3\",\n    \"findup-sync\": \"^0.3.0\",\n    \"fs-write-stream-atomic\": \"1.0.8\",\n    \"fstream\": \"^1.0.3\",\n    \"fstream-ignore\": \"^1.0.2\",\n    \"github\": \"^0.2.3\",\n    \"glob\": \"^4.3.2\",\n    \"graceful-fs\": \"^4.1.3\",\n    \"handlebars\": \"^4.0.5\",\n    \"inquirer\": \"0.10.0\",\n    \"is-root\": \"^1.0.0\",\n    \"junk\": \"^1.0.0\",\n    \"lockfile\": \"^1.0.0\",\n    \"lru-cache\": \"^2.5.0\",\n    \"md5-hex\": \"^1.0.2\",\n    \"mkdirp\": \"0.5.0\",\n    \"mout\": \"^0.11.0\",\n    \"nopt\": \"^3.0.1\",\n    \"opn\": \"^4.0.0\",\n    \"p-throttler\": \"0.1.1\",\n    \"promptly\": \"0.2.0\",\n    \"q\": \"^1.1.2\",\n    \"request\": \"2.67.0\",\n    \"request-progress\": \"0.3.1\",\n    \"requireg\": \"^0.1.5\",\n    \"resolve\": \"^1.1.7\",\n    \"retry\": \"0.6.1\",\n    \"rimraf\": \"^2.2.8\",\n    \"semver\": \"^2.3.0\",\n    \"semver-utils\": \"^1.1.1\",\n    \"shell-quote\": \"^1.4.2\",\n    \"stringify-object\": \"^1.0.0\",\n    \"tar-fs\": \"^1.4.1\",\n    \"tmp\": \"0.0.28\",\n    \"update-notifier\": \"^0.6.0\",\n    \"user-home\": \"^1.1.0\",\n    \"which\": \"^1.0.8\"\n  },\n  \"devDependencies\": {\n    \"arr-diff\": \"^2.0.0\",\n    \"chai\": \"^3.5.0\",\n    \"coveralls\": \"^2.11.9\",\n    \"expect.js\": \"^0.3.1\",\n    \"grunt\": \"^1.0.1\",\n    \"grunt-cli\": \"^1.1.0\",\n    \"grunt-contrib-watch\": \"^1.0.0\",\n    \"grunt-eslint\": \"^18.1.0\",\n    \"grunt-exec\": \"^0.4.7\",\n    \"grunt-simple-mocha\": \"^0.4.1\",\n    \"husky\": \"^0.14.3\",\n    \"in-publish\": \"^2.0.0\",\n    \"istanbul\": \"^0.4.3\",\n    \"lint-staged\": \"^7.0.0\",\n    \"load-grunt-tasks\": \"^3.5.0\",\n    \"mocha\": \"^2.5.3\",\n    \"multiline\": \"^1.0.2\",\n    \"nock\": \"^9.2.3\",\n    \"node-uuid\": \"^1.4.7\",\n    \"prettier\": \"^1.11.1\",\n    \"proxyquire\": \"^1.7.9\",\n    \"spawn-sync\": \"1.0.15\",\n    \"wrench\": \"^1.5.8\"\n  },\n  \"scripts\": {\n    \"test\": \"grunt test\",\n    \"ci\": \"grunt travis\",\n    \"coveralls\": \"coveralls\",\n    \"prepublish\": \"in-publish && echo 'You need to use \\\"grunt publish\\\" to publish bower' && false || not-in-publish\",\n    \"format\": \"prettier --write --single-quote --tab-width 4 '**/*.js'\",\n    \"precommit\": \"lint-staged\"\n  },\n  \"lint-staged\": {\n    \"*.js\": [\n      \"prettier --single-quote --tab-width 4\",\n      \"git add\"\n    ]\n  },\n  \"files\": [\n    \"bin\",\n    \"lib\"\n  ]\n}\n"], "fixing_code": ["var path = require('path');\nvar fs = require('./fs');\nvar zlib = require('zlib');\nvar DecompressZip = require('decompress-zip');\nvar tar = require('tar-fs');\nvar Q = require('q');\nvar mout = require('mout');\nvar junk = require('junk');\nvar createError = require('./createError');\nvar createWriteStream = require('fs-write-stream-atomic');\nvar destroy = require('destroy');\nvar tmp = require('tmp');\n\n// This forces the default chunk size to something small in an attempt\n// to avoid issue #314\nzlib.Z_DEFAULT_CHUNK = 1024 * 8;\n\nvar extractors;\nvar extractorTypes;\n\nextractors = {\n    '.zip': extractZip,\n    '.tar': extractTar,\n    '.tar.gz': extractTarGz,\n    '.tgz': extractTarGz,\n    '.gz': extractGz,\n    'application/zip': extractZip,\n    'application/x-zip': extractZip,\n    'application/x-zip-compressed': extractZip,\n    'application/x-tar': extractTar,\n    'application/x-tgz': extractTarGz,\n    'application/x-gzip': extractGz\n};\n\nextractorTypes = Object.keys(extractors);\n\nfunction extractZip(archive, dst) {\n    var deferred = Q.defer();\n\n    new DecompressZip(archive)\n        .on('error', deferred.reject)\n        .on('extract', deferred.resolve.bind(deferred, dst))\n        .extract({\n            path: dst,\n            follow: false, // Do not follow symlinks (#699)\n            filter: filterSymlinks // Filter symlink files\n        });\n\n    return deferred.promise;\n}\n\nfunction extractTar(archive, dst) {\n    var deferred = Q.defer();\n\n    var stream = fs.createReadStream(archive);\n\n    var reject = function(error) {\n        destroy(stream);\n        deferred.reject(error);\n    };\n\n    stream\n        .on('error', reject)\n        .pipe(\n            tar.extract(dst, {\n                ignore: isSymlink, // Filter symlink files\n                dmode: 0555, // Ensure dirs are readable\n                fmode: 0444 // Ensure files are readable\n            })\n        )\n        .on('error', reject)\n        .on('finish', function(result) {\n            destroy(stream);\n            deferred.resolve(dst);\n        });\n\n    return deferred.promise;\n}\n\nfunction extractTarGz(archive, dst) {\n    var deferred = Q.defer();\n\n    var stream = fs.createReadStream(archive);\n\n    var reject = function(error) {\n        destroy(stream);\n        deferred.reject(error);\n    };\n\n    stream\n        .on('error', reject)\n        .pipe(zlib.createGunzip())\n        .on('error', reject)\n        .pipe(\n            tar.extract(dst, {\n                ignore: isSymlink, // Filter symlink files\n                dmode: 0555, // Ensure dirs are readable\n                fmode: 0444 // Ensure files are readable\n            })\n        )\n        .on('error', reject)\n        .on('finish', function(result) {\n            destroy(stream);\n            deferred.resolve(dst);\n        });\n\n    return deferred.promise;\n}\n\nfunction extractGz(archive, dst) {\n    var deferred = Q.defer();\n\n    var stream = fs.createReadStream(archive);\n\n    var reject = function(error) {\n        destroy(stream);\n        deferred.reject(error);\n    };\n    stream\n        .on('error', reject)\n        .pipe(zlib.createGunzip())\n        .on('error', reject)\n        .pipe(createWriteStream(dst))\n        .on('error', reject)\n        .on('finish', function(result) {\n            destroy(stream);\n            deferred.resolve(dst);\n        });\n\n    return deferred.promise;\n}\n\nfunction isSymlink(_, entry) {\n    return entry.type === 'symlink';\n}\n\nfunction filterSymlinks(entry) {\n    return entry.type !== 'SymbolicLink';\n}\n\nfunction getExtractor(archive) {\n    // Make the archive lower case to match against the types\n    // This ensures that upper-cased extensions work\n    archive = archive.toLowerCase();\n\n    var type = mout.array.find(extractorTypes, function(type) {\n        return mout.string.endsWith(archive, type);\n    });\n\n    return type ? extractors[type] : null;\n}\n\nfunction isSingleDir(dir) {\n    return Q.nfcall(fs.readdir, dir).then(function(files) {\n        var singleDir;\n\n        // Remove any OS specific files from the files array\n        // before checking its length\n        files = files.filter(junk.isnt);\n\n        if (files.length !== 1) {\n            return false;\n        }\n\n        singleDir = path.join(dir, files[0]);\n\n        return Q.nfcall(fs.stat, singleDir).then(function(stat) {\n            return stat.isDirectory() ? singleDir : false;\n        });\n    });\n}\n\nfunction moveDirectory(srcDir, destDir) {\n    return Q.nfcall(fs.readdir, srcDir)\n        .then(function(files) {\n            var promises = files.map(function(file) {\n                var src = path.join(srcDir, file);\n                var dst = path.join(destDir, file);\n\n                return Q.nfcall(fs.rename, src, dst);\n            });\n\n            return Q.all(promises);\n        })\n        .then(function() {\n            return Q.nfcall(fs.rmdir, srcDir);\n        });\n}\n\n// -----------------------------\n\nfunction canExtract(src, mimeType) {\n    if (mimeType && mimeType !== 'application/octet-stream') {\n        return !!getExtractor(mimeType);\n    }\n\n    return !!getExtractor(src);\n}\n\n// Available options:\n// - keepArchive: true to keep the archive afterwards (defaults to false)\n// - keepStructure: true to keep the extracted structure unchanged (defaults to false)\nfunction extract(src, dst, opts) {\n    var extractor;\n    var promise;\n\n    opts = opts || {};\n    extractor = getExtractor(src);\n\n    // Try to get extractor from mime type\n    if (!extractor && opts.mimeType) {\n        extractor = getExtractor(opts.mimeType);\n    }\n\n    // If extractor is null, then the archive type is unknown\n    if (!extractor) {\n        return Q.reject(\n            createError(\n                'File ' + src + ' is not a known archive',\n                'ENOTARCHIVE'\n            )\n        );\n    }\n\n    // Extract to a temporary directory in case of file name clashes\n    return Q.nfcall(tmp.dir, {\n        template: dst + '-XXXXXX',\n        mode: 0777 & ~process.umask()\n    })\n        .then(function(tempDir) {\n            // nfcall may return multiple callback arguments as an array\n            return Array.isArray(tempDir) ? tempDir[0] : tempDir;\n        })\n        .then(function(tempDir) {\n            // Check archive file size\n            promise = Q.nfcall(fs.stat, src).then(function(stat) {\n                if (stat.size <= 8) {\n                    throw createError(\n                        'File ' + src + ' is an invalid archive',\n                        'ENOTARCHIVE'\n                    );\n                }\n\n                // Extract archive\n                return extractor(src, tempDir);\n            });\n\n            // Remove archive\n            if (!opts.keepArchive) {\n                promise = promise.then(function() {\n                    return Q.nfcall(fs.unlink, src);\n                });\n            }\n\n            // Move contents from the temporary directory\n            // If the contents are a single directory (and we're not preserving structure),\n            // move its contents directly instead.\n            promise = promise\n                .then(function() {\n                    return isSingleDir(tempDir);\n                })\n                .then(function(singleDir) {\n                    if (singleDir && !opts.keepStructure) {\n                        return moveDirectory(singleDir, dst);\n                    } else {\n                        return moveDirectory(tempDir, dst);\n                    }\n                });\n\n            // Resolve promise to the dst dir\n            return promise.then(function() {\n                return dst;\n            });\n        });\n}\n\nmodule.exports = extract;\nmodule.exports.canExtract = canExtract;\n", "{\n  \"name\": \"bower\",\n  \"version\": \"1.8.7\",\n  \"description\": \"The browser package manager\",\n  \"author\": \"Twitter\",\n  \"license\": \"MIT\",\n  \"repository\": \"bower/bower\",\n  \"main\": \"lib\",\n  \"bin\": \"bin/bower\",\n  \"homepage\": \"http://bower.io\",\n  \"engines\": {\n    \"node\": \">=0.10.0\"\n  },\n  \"keywords\": [\n    \"bower\"\n  ],\n  \"dependencies\": {\n    \"abbrev\": \"^1.0.5\",\n    \"archy\": \"1.0.0\",\n    \"bower-config\": \"^1.4.1\",\n    \"bower-endpoint-parser\": \"^0.2.2\",\n    \"bower-json\": \"^0.8.1\",\n    \"bower-logger\": \"^0.2.2\",\n    \"bower-registry-client\": \"^1.0.0\",\n    \"cardinal\": \"0.4.4\",\n    \"chalk\": \"^1.0.0\",\n    \"chmodr\": \"^1.0.2\",\n    \"configstore\": \"^2.0.0\",\n    \"decompress-zip\": \"^0.2.2\",\n    \"destroy\": \"^1.0.3\",\n    \"findup-sync\": \"^0.3.0\",\n    \"fs-write-stream-atomic\": \"1.0.8\",\n    \"fstream\": \"^1.0.3\",\n    \"fstream-ignore\": \"^1.0.2\",\n    \"github\": \"^0.2.3\",\n    \"glob\": \"^4.3.2\",\n    \"graceful-fs\": \"^4.1.3\",\n    \"handlebars\": \"^4.0.5\",\n    \"inquirer\": \"0.10.0\",\n    \"is-root\": \"^1.0.0\",\n    \"junk\": \"^1.0.0\",\n    \"lockfile\": \"^1.0.0\",\n    \"lru-cache\": \"^2.5.0\",\n    \"md5-hex\": \"^1.0.2\",\n    \"mkdirp\": \"0.5.0\",\n    \"mout\": \"^0.11.0\",\n    \"nopt\": \"^3.0.1\",\n    \"opn\": \"^4.0.0\",\n    \"p-throttler\": \"0.1.1\",\n    \"promptly\": \"0.2.0\",\n    \"q\": \"^1.1.2\",\n    \"request\": \"2.67.0\",\n    \"request-progress\": \"0.3.1\",\n    \"requireg\": \"^0.1.5\",\n    \"resolve\": \"^1.1.7\",\n    \"retry\": \"0.6.1\",\n    \"rimraf\": \"^2.2.8\",\n    \"semver\": \"^2.3.0\",\n    \"semver-utils\": \"^1.1.1\",\n    \"shell-quote\": \"^1.4.2\",\n    \"stringify-object\": \"^1.0.0\",\n    \"tar-fs\": \"^1.4.1\",\n    \"tmp\": \"0.0.28\",\n    \"update-notifier\": \"^0.6.0\",\n    \"user-home\": \"^1.1.0\",\n    \"which\": \"^1.0.8\"\n  },\n  \"devDependencies\": {\n    \"arr-diff\": \"^2.0.0\",\n    \"chai\": \"^3.5.0\",\n    \"coveralls\": \"^2.11.9\",\n    \"expect.js\": \"^0.3.1\",\n    \"grunt\": \"^1.0.1\",\n    \"grunt-cli\": \"^1.1.0\",\n    \"grunt-contrib-watch\": \"^1.0.0\",\n    \"grunt-eslint\": \"^18.1.0\",\n    \"grunt-exec\": \"^0.4.7\",\n    \"grunt-simple-mocha\": \"^0.4.1\",\n    \"husky\": \"^0.14.3\",\n    \"in-publish\": \"^2.0.0\",\n    \"istanbul\": \"^0.4.3\",\n    \"lint-staged\": \"^7.0.0\",\n    \"load-grunt-tasks\": \"^3.5.0\",\n    \"mocha\": \"^2.5.3\",\n    \"multiline\": \"^1.0.2\",\n    \"nock\": \"^9.2.3\",\n    \"node-uuid\": \"^1.4.7\",\n    \"prettier\": \"^1.11.1\",\n    \"proxyquire\": \"^1.7.9\",\n    \"spawn-sync\": \"1.0.15\",\n    \"wrench\": \"^1.5.8\"\n  },\n  \"scripts\": {\n    \"test\": \"grunt test\",\n    \"ci\": \"grunt travis\",\n    \"coveralls\": \"coveralls\",\n    \"prepublishOnly\": \"in-publish && echo 'You need to use \\\"grunt publish\\\" to publish bower' && false || not-in-publish\",\n    \"format\": \"prettier --write --single-quote --tab-width 4 '**/*.js'\",\n    \"precommit\": \"lint-staged\"\n  },\n  \"lint-staged\": {\n    \"*.js\": [\n      \"prettier --single-quote --tab-width 4\",\n      \"git add\"\n    ]\n  },\n  \"files\": [\n    \"bin\",\n    \"lib\"\n  ]\n}\n"], "filenames": ["lib/util/extract.js", "package.json"], "buggy_code_start_loc": [133, 97], "buggy_code_end_loc": [135, 98], "fixing_code_start_loc": [133, 97], "fixing_code_end_loc": [135, 98], "type": "CWE-22", "message": "Bower before 1.8.8 has a path traversal vulnerability permitting file write in arbitrary locations via install command, which allows attackers to write arbitrary files when a malicious package is extracted.", "other": {"cve": {"id": "CVE-2019-5484", "sourceIdentifier": "support@hackerone.com", "published": "2019-09-13T18:15:11.063", "lastModified": "2023-02-28T19:36:17.647", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Bower before 1.8.8 has a path traversal vulnerability permitting file write in arbitrary locations via install command, which allows attackers to write arbitrary files when a malicious package is extracted."}, {"lang": "es", "value": "Bower versiones anteriores a 1.8.8, presenta una vulnerabilidad de salto de directorio que permite la escritura de archivos en ubicaciones arbitrarias por medio del comando de instalaci\u00f3n, lo que habilita a atacantes para escribir archivos arbitrarios cuando se extrae un paquete malicioso."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-22"}]}, {"source": "support@hackerone.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-22"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:bower:bower:*:*:*:*:*:node.js:*:*", "versionEndExcluding": "1.8.8", "matchCriteriaId": "C64C8F00-EC75-447E-8076-CE5BC5AB42D8"}]}]}], "references": [{"url": "https://github.com/bower/bower/commit/45c6bfa86f6e57731b153baca9e0b41a1cc699e3", "source": "support@hackerone.com", "tags": ["Patch"]}, {"url": "https://hackerone.com/reports/473811", "source": "support@hackerone.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}, {"url": "https://lists.apache.org/thread.html/r8ba4c628fba7181af58817d452119481adce4ba92e889c643e4c7dd3@%3Ccommits.netbeans.apache.org%3E", "source": "support@hackerone.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.apache.org/thread.html/rb5ac16fad337d1f3bb7079549f97d8166d0ef3082629417c39f12d63@%3Cnotifications.netbeans.apache.org%3E", "source": "support@hackerone.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://snyk.io/blog/severe-security-vulnerability-in-bowers-zip-archive-extraction", "source": "support@hackerone.com", "tags": ["Exploit", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/bower/bower/commit/45c6bfa86f6e57731b153baca9e0b41a1cc699e3"}}
{"buggy_code": ["# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals, absolute_import\nfrom collections import OrderedDict\nimport re\n\nfrom io import StringIO\n\nfrom configparser import ConfigParser, NoOptionError\n\n\nfrom .regex import URL_REGEX, HASH_REGEX\n\nfrom .dependencies import DependencyFile, Dependency\nfrom packaging.requirements import Requirement as PackagingRequirement, InvalidRequirement\nfrom . import filetypes\nimport toml\nfrom packaging.specifiers import SpecifierSet\nimport json\n\n\n# this is a backport from setuptools 26.1\ndef setuptools_parse_requirements_backport(strs):  # pragma: no cover\n    # Copyright (C) 2016 Jason R Coombs <jaraco@jaraco.com>\n    #\n    # Permission is hereby granted, free of charge, to any person obtaining a copy of\n    # this software and associated documentation files (the \"Software\"), to deal in\n    # the Software without restriction, including without limitation the rights to\n    # use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n    # of the Software, and to permit persons to whom the Software is furnished to do\n    # so, subject to the following conditions:\n    #\n    # The above copyright notice and this permission notice shall be included in all\n    # copies or substantial portions of the Software.\n    #\n    # THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    # SOFTWARE.\n    \"\"\"Yield ``Requirement`` objects for each specification in `strs`\n\n    `strs` must be a string, or a (possibly-nested) iterable thereof.\n    \"\"\"\n    # create a steppable iterator, so we can handle \\-continuations\n    def yield_lines(strs):\n        \"\"\"Yield non-empty/non-comment lines of a string or sequence\"\"\"\n        if isinstance(strs, str):\n            for s in strs.splitlines():\n                s = s.strip()\n                # skip blank lines/comments\n                if s and not s.startswith('#'):\n                    yield s\n        else:\n            for ss in strs:\n                for s in yield_lines(ss):\n                    yield s\n    lines = iter(yield_lines(strs))\n\n    for line in lines:\n        # Drop comments -- a hash without a space may be in a URL.\n        if ' #' in line:\n            line = line[:line.find(' #')]\n        # If there is a line continuation, drop it, and append the next line.\n        if line.endswith('\\\\'):\n            line = line[:-2].strip()\n            line += next(lines)\n        yield PackagingRequirement(line)\n\n\nclass RequirementsTXTLineParser(object):\n    \"\"\"\n\n    \"\"\"\n\n    @classmethod\n    def parse(cls, line):\n        \"\"\"\n\n        :param line:\n        :return:\n        \"\"\"\n        try:\n            # setuptools requires a space before the comment. If this isn't the case, add it.\n            if \"\\t#\" in line:\n                parsed, = setuptools_parse_requirements_backport(line.replace(\"\\t#\", \"\\t #\"))\n            else:\n                parsed, = setuptools_parse_requirements_backport(line)\n        except InvalidRequirement:\n            return None\n        dep = Dependency(\n            name=parsed.name,\n            specs=parsed.specifier,\n            line=line,\n            extras=parsed.extras,\n            dependency_type=filetypes.requirements_txt\n        )\n        return dep\n\n\nclass Parser(object):\n    \"\"\"\n\n    \"\"\"\n\n    def __init__(self, obj):\n        \"\"\"\n\n        :param obj:\n        \"\"\"\n        self.obj = obj\n        self._lines = None\n\n    def iter_lines(self, lineno=0):\n        \"\"\"\n\n        :param lineno:\n        :return:\n        \"\"\"\n        for line in self.lines[lineno:]:\n            yield line\n\n    @property\n    def lines(self):\n        \"\"\"\n\n        :return:\n        \"\"\"\n        if self._lines is None:\n            self._lines = self.obj.content.splitlines()\n        return self._lines\n\n    @property\n    def is_marked_file(self):\n        \"\"\"\n\n        :return:\n        \"\"\"\n        for n, line in enumerate(self.iter_lines()):\n            for marker in self.obj.file_marker:\n                if marker in line:\n                    return True\n            if n >= 2:\n                break\n        return False\n\n    def is_marked_line(self, line):\n        \"\"\"\n\n        :param line:\n        :return:\n        \"\"\"\n        for marker in self.obj.line_marker:\n            if marker in line:\n                return True\n        return False\n\n    @classmethod\n    def parse_hashes(cls, line):\n        \"\"\"\n\n        :param line:\n        :return:\n        \"\"\"\n        hashes = []\n        for match in re.finditer(HASH_REGEX, line):\n            hashes.append(line[match.start():match.end()])\n        return re.sub(HASH_REGEX, \"\", line).strip(), hashes\n\n    @classmethod\n    def parse_index_server(cls, line):\n        \"\"\"\n\n        :param line:\n        :return:\n        \"\"\"\n        matches = URL_REGEX.findall(line)\n        if matches:\n            url = matches[0]\n            return url if url.endswith(\"/\") else url + \"/\"\n        return None\n\n    @classmethod\n    def resolve_file(cls, file_path, line):\n        \"\"\"\n\n        :param file_path:\n        :param line:\n        :return:\n        \"\"\"\n        line = line.replace(\"-r \", \"\").replace(\"--requirement \", \"\")\n        parts = file_path.split(\"/\")\n        if \" #\" in line:\n            line = line.split(\"#\")[0].strip()\n        if len(parts) == 1:\n            return line\n        return \"/\".join(parts[:-1]) + \"/\" + line\n\n\nclass RequirementsTXTParser(Parser):\n    \"\"\"\n\n    \"\"\"\n\n    def parse(self):\n        \"\"\"\n        Parses a requirements.txt-like file\n        \"\"\"\n        index_server = None\n        for num, line in enumerate(self.iter_lines()):\n            line = line.rstrip()\n            if not line:\n                continue\n            if line.startswith('#'):\n                # comments are lines that start with # only\n                continue\n            if line.startswith('-i') or \\\n                line.startswith('--index-url') or \\\n                line.startswith('--extra-index-url'):\n                # this file is using a private index server, try to parse it\n                index_server = self.parse_index_server(line)\n                continue\n            elif self.obj.path and (line.startswith('-r') or line.startswith('--requirement')):\n                self.obj.resolved_files.append(self.resolve_file(self.obj.path, line))\n            elif line.startswith('-f') or line.startswith('--find-links') or \\\n                line.startswith('--no-index') or line.startswith('--allow-external') or \\\n                line.startswith('--allow-unverified') or line.startswith('-Z') or \\\n                line.startswith('--always-unzip'):\n                continue\n            elif self.is_marked_line(line):\n                continue\n            else:\n                try:\n\n                    parseable_line = line\n\n                    # multiline requirements are not parseable\n                    if \"\\\\\" in line:\n                        parseable_line = line.replace(\"\\\\\", \"\")\n                        for next_line in self.iter_lines(num + 1):\n                            parseable_line += next_line.strip().replace(\"\\\\\", \"\")\n                            line += \"\\n\" + next_line\n                            if \"\\\\\" in next_line:\n                                continue\n                            break\n                        # ignore multiline requirements if they are marked\n                        if self.is_marked_line(parseable_line):\n                            continue\n\n                    hashes = []\n                    if \"--hash\" in parseable_line:\n                        parseable_line, hashes = Parser.parse_hashes(parseable_line)\n\n                    req = RequirementsTXTLineParser.parse(parseable_line)\n                    if req:\n                        req.hashes = hashes\n                        req.index_server = index_server\n                        # replace the requirements line with the 'real' line\n                        req.line = line\n                        self.obj.dependencies.append(req)\n                except ValueError:\n                    continue\n\n\nclass ToxINIParser(Parser):\n    \"\"\"\n\n    \"\"\"\n\n    def parse(self):\n        \"\"\"\n\n        :return:\n        \"\"\"\n        parser = ConfigParser()\n        parser.readfp(StringIO(self.obj.content))\n        for section in parser.sections():\n            try:\n                content = parser.get(section=section, option=\"deps\")\n                for n, line in enumerate(content.splitlines()):\n                    if self.is_marked_line(line):\n                        continue\n                    if line:\n                        req = RequirementsTXTLineParser.parse(line)\n                        if req:\n                            req.dependency_type = self.obj.file_type\n                            self.obj.dependencies.append(req)\n            except NoOptionError:\n                pass\n\n\nclass CondaYMLParser(Parser):\n    \"\"\"\n\n    \"\"\"\n\n    def parse(self):\n        \"\"\"\n\n        :return:\n        \"\"\"\n        import yaml\n        try:\n            data = yaml.safe_load(self.obj.content)\n            if data and 'dependencies' in data and isinstance(data['dependencies'], list):\n                for dep in data['dependencies']:\n                    if isinstance(dep, dict) and 'pip' in dep:\n                        for n, line in enumerate(dep['pip']):\n                            if self.is_marked_line(line):\n                                continue\n                            req = RequirementsTXTLineParser.parse(line)\n                            if req:\n                                req.dependency_type = self.obj.file_type\n                                self.obj.dependencies.append(req)\n        except yaml.YAMLError:\n            pass\n\n\nclass PipfileParser(Parser):\n\n    def parse(self):\n        \"\"\"\n        Parse a Pipfile (as seen in pipenv)\n        :return:\n        \"\"\"\n        try:\n            data = toml.loads(self.obj.content, _dict=OrderedDict)\n            if data:\n                for package_type in ['packages', 'dev-packages']:\n                    if package_type in data:\n                        for name, specs in data[package_type].items():\n                            # skip on VCS dependencies\n                            if not isinstance(specs, str):\n                                continue\n                            if specs == '*':\n                                specs = ''\n                            self.obj.dependencies.append(\n                                Dependency(\n                                    name=name, specs=SpecifierSet(specs),\n                                    dependency_type=filetypes.pipfile,\n                                    line=''.join([name, specs]),\n                                    section=package_type\n                                )\n                            )\n        except (toml.TomlDecodeError, IndexError) as e:\n            pass\n\nclass PipfileLockParser(Parser):\n\n    def parse(self):\n        \"\"\"\n        Parse a Pipfile.lock (as seen in pipenv)\n        :return:\n        \"\"\"\n        try:\n            data = json.loads(self.obj.content, object_pairs_hook=OrderedDict)\n            if data:\n                for package_type in ['default', 'develop']:\n                    if package_type in data:\n                        for name, meta in data[package_type].items():\n                            # skip VCS dependencies\n                            if 'version' not in meta:\n                                continue\n                            specs = meta['version']\n                            hashes = meta['hashes']\n                            self.obj.dependencies.append(\n                                Dependency(\n                                    name=name, specs=SpecifierSet(specs),\n                                    dependency_type=filetypes.pipfile_lock,\n                                    hashes=hashes,\n                                    line=''.join([name, specs]),\n                                    section=package_type\n                                )\n                            )\n        except ValueError:\n            pass\n\n\nclass SetupCfgParser(Parser):\n    def parse(self):\n        parser = ConfigParser()\n        parser.readfp(StringIO(self.obj.content))\n        for section in parser.values():\n            if section.name == 'options':\n                options = 'install_requires', 'setup_requires', 'test_require'\n                for name in options:\n                    content = section.get(name)\n                    if not content:\n                        continue\n                    self._parse_content(content)\n            elif section.name == 'options.extras_require':\n                for content in section.values():\n                    self._parse_content(content)\n\n    def _parse_content(self, content):\n        for n, line in enumerate(content.splitlines()):\n            if self.is_marked_line(line):\n                continue\n            if line:\n                req = RequirementsTXTLineParser.parse(line)\n                if req:\n                    req.dependency_type = self.obj.file_type\n                    self.obj.dependencies.append(req)\n\n\ndef parse(content, file_type=None, path=None, sha=None, marker=((), ()), parser=None):\n    \"\"\"\n\n    :param content:\n    :param file_type:\n    :param path:\n    :param sha:\n    :param marker:\n    :param parser:\n    :return:\n    \"\"\"\n    dep_file = DependencyFile(\n        content=content,\n        path=path,\n        sha=sha,\n        marker=marker,\n        file_type=file_type,\n        parser=parser\n    )\n\n    return dep_file.parse()\n", "# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import, print_function, unicode_literals\n\nimport re\n# see https://gist.github.com/dperini/729294\nURL_REGEX = re.compile(\n    # protocol identifier\n    \"(?:(?:https?|ftp)://)\"\n    # user:pass authentication\n    \"(?:\\S+(?::\\S*)?@)?\"\n    \"(?:\"\n    # IP address exclusion\n    # private & local networks\n    \"(?!(?:10|127)(?:\\.\\d{1,3}){3})\"\n    \"(?!(?:169\\.254|192\\.168)(?:\\.\\d{1,3}){2})\"\n    \"(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})\"\n    # IP address dotted notation octets\n    # excludes loopback network 0.0.0.0\n    # excludes reserved space >= 224.0.0.0\n    # excludes network & broadcast addresses\n    # (first & last IP address of each class)\n    \"(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])\"\n    \"(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}\"\n    \"(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))\"\n    \"|\"\n    # host name\n    \"(?:(?:[a-z\\u00a1-\\uffff0-9]-?)*[a-z\\u00a1-\\uffff0-9]+)\"\n    # domain name\n    \"(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-?)*[a-z\\u00a1-\\uffff0-9]+)*\"\n    # TLD identifier\n    \"(?:\\.(?:[a-z\\u00a1-\\uffff]{2,}))\"\n    \")\"\n    # port number\n    \"(?::\\d{2,5})?\"\n    # resource path\n    \"(?:/\\S*)?\",\n    re.UNICODE)\n\nHASH_REGEX = r\"--hash[=| ][\\w]+:[\\w]+\"\n"], "fixing_code": ["# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals, absolute_import\nfrom collections import OrderedDict\nimport re\n\nfrom io import StringIO\n\nfrom configparser import ConfigParser, NoOptionError\n\n\nfrom .regex import HASH_REGEX\n\nfrom .dependencies import DependencyFile, Dependency\nfrom packaging.requirements import Requirement as PackagingRequirement, InvalidRequirement\nfrom . import filetypes\nimport toml\nfrom packaging.specifiers import SpecifierSet\nimport json\n\n\n# this is a backport from setuptools 26.1\ndef setuptools_parse_requirements_backport(strs):  # pragma: no cover\n    # Copyright (C) 2016 Jason R Coombs <jaraco@jaraco.com>\n    #\n    # Permission is hereby granted, free of charge, to any person obtaining a copy of\n    # this software and associated documentation files (the \"Software\"), to deal in\n    # the Software without restriction, including without limitation the rights to\n    # use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n    # of the Software, and to permit persons to whom the Software is furnished to do\n    # so, subject to the following conditions:\n    #\n    # The above copyright notice and this permission notice shall be included in all\n    # copies or substantial portions of the Software.\n    #\n    # THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    # SOFTWARE.\n    \"\"\"Yield ``Requirement`` objects for each specification in `strs`\n\n    `strs` must be a string, or a (possibly-nested) iterable thereof.\n    \"\"\"\n    # create a steppable iterator, so we can handle \\-continuations\n    def yield_lines(strs):\n        \"\"\"Yield non-empty/non-comment lines of a string or sequence\"\"\"\n        if isinstance(strs, str):\n            for s in strs.splitlines():\n                s = s.strip()\n                # skip blank lines/comments\n                if s and not s.startswith('#'):\n                    yield s\n        else:\n            for ss in strs:\n                for s in yield_lines(ss):\n                    yield s\n    lines = iter(yield_lines(strs))\n\n    for line in lines:\n        # Drop comments -- a hash without a space may be in a URL.\n        if ' #' in line:\n            line = line[:line.find(' #')]\n        # If there is a line continuation, drop it, and append the next line.\n        if line.endswith('\\\\'):\n            line = line[:-2].strip()\n            line += next(lines)\n        yield PackagingRequirement(line)\n\n\nclass RequirementsTXTLineParser(object):\n    \"\"\"\n\n    \"\"\"\n\n    @classmethod\n    def parse(cls, line):\n        \"\"\"\n\n        :param line:\n        :return:\n        \"\"\"\n        try:\n            # setuptools requires a space before the comment. If this isn't the case, add it.\n            if \"\\t#\" in line:\n                parsed, = setuptools_parse_requirements_backport(line.replace(\"\\t#\", \"\\t #\"))\n            else:\n                parsed, = setuptools_parse_requirements_backport(line)\n        except InvalidRequirement:\n            return None\n        dep = Dependency(\n            name=parsed.name,\n            specs=parsed.specifier,\n            line=line,\n            extras=parsed.extras,\n            dependency_type=filetypes.requirements_txt\n        )\n        return dep\n\n\nclass Parser(object):\n    \"\"\"\n\n    \"\"\"\n\n    def __init__(self, obj):\n        \"\"\"\n\n        :param obj:\n        \"\"\"\n        self.obj = obj\n        self._lines = None\n\n    def iter_lines(self, lineno=0):\n        \"\"\"\n\n        :param lineno:\n        :return:\n        \"\"\"\n        for line in self.lines[lineno:]:\n            yield line\n\n    @property\n    def lines(self):\n        \"\"\"\n\n        :return:\n        \"\"\"\n        if self._lines is None:\n            self._lines = self.obj.content.splitlines()\n        return self._lines\n\n    @property\n    def is_marked_file(self):\n        \"\"\"\n\n        :return:\n        \"\"\"\n        for n, line in enumerate(self.iter_lines()):\n            for marker in self.obj.file_marker:\n                if marker in line:\n                    return True\n            if n >= 2:\n                break\n        return False\n\n    def is_marked_line(self, line):\n        \"\"\"\n\n        :param line:\n        :return:\n        \"\"\"\n        for marker in self.obj.line_marker:\n            if marker in line:\n                return True\n        return False\n\n    @classmethod\n    def parse_hashes(cls, line):\n        \"\"\"\n\n        :param line:\n        :return:\n        \"\"\"\n        hashes = []\n        for match in re.finditer(HASH_REGEX, line):\n            hashes.append(line[match.start():match.end()])\n        return re.sub(HASH_REGEX, \"\", line).strip(), hashes\n\n    @classmethod\n    def parse_index_server(cls, line):\n        \"\"\"\n\n        :param line:\n        :return:\n        \"\"\"\n        groups = re.split(pattern=\"[=\\s]+\", string=line.strip(), maxsplit=100)\n\n        if len(groups) >= 2:\n            return groups[1] if groups[1].endswith(\"/\") else groups[1] + \"/\"\n\n        return None\n\n    @classmethod\n    def resolve_file(cls, file_path, line):\n        \"\"\"\n\n        :param file_path:\n        :param line:\n        :return:\n        \"\"\"\n        line = line.replace(\"-r \", \"\").replace(\"--requirement \", \"\")\n        parts = file_path.split(\"/\")\n        if \" #\" in line:\n            line = line.split(\"#\")[0].strip()\n        if len(parts) == 1:\n            return line\n        return \"/\".join(parts[:-1]) + \"/\" + line\n\n\nclass RequirementsTXTParser(Parser):\n    \"\"\"\n\n    \"\"\"\n\n    def parse(self):\n        \"\"\"\n        Parses a requirements.txt-like file\n        \"\"\"\n        index_server = None\n        for num, line in enumerate(self.iter_lines()):\n            line = line.rstrip()\n            if not line:\n                continue\n            if line.startswith('#'):\n                # comments are lines that start with # only\n                continue\n            if line.startswith('-i') or \\\n                line.startswith('--index-url') or \\\n                line.startswith('--extra-index-url'):\n                # this file is using a private index server, try to parse it\n                index_server = self.parse_index_server(line)\n                continue\n            elif self.obj.path and (line.startswith('-r') or line.startswith('--requirement')):\n                self.obj.resolved_files.append(self.resolve_file(self.obj.path, line))\n            elif line.startswith('-f') or line.startswith('--find-links') or \\\n                line.startswith('--no-index') or line.startswith('--allow-external') or \\\n                line.startswith('--allow-unverified') or line.startswith('-Z') or \\\n                line.startswith('--always-unzip'):\n                continue\n            elif self.is_marked_line(line):\n                continue\n            else:\n                try:\n\n                    parseable_line = line\n\n                    # multiline requirements are not parseable\n                    if \"\\\\\" in line:\n                        parseable_line = line.replace(\"\\\\\", \"\")\n                        for next_line in self.iter_lines(num + 1):\n                            parseable_line += next_line.strip().replace(\"\\\\\", \"\")\n                            line += \"\\n\" + next_line\n                            if \"\\\\\" in next_line:\n                                continue\n                            break\n                        # ignore multiline requirements if they are marked\n                        if self.is_marked_line(parseable_line):\n                            continue\n\n                    hashes = []\n                    if \"--hash\" in parseable_line:\n                        parseable_line, hashes = Parser.parse_hashes(parseable_line)\n\n                    req = RequirementsTXTLineParser.parse(parseable_line)\n                    if req:\n                        req.hashes = hashes\n                        req.index_server = index_server\n                        # replace the requirements line with the 'real' line\n                        req.line = line\n                        self.obj.dependencies.append(req)\n                except ValueError:\n                    continue\n\n\nclass ToxINIParser(Parser):\n    \"\"\"\n\n    \"\"\"\n\n    def parse(self):\n        \"\"\"\n\n        :return:\n        \"\"\"\n        parser = ConfigParser()\n        parser.readfp(StringIO(self.obj.content))\n        for section in parser.sections():\n            try:\n                content = parser.get(section=section, option=\"deps\")\n                for n, line in enumerate(content.splitlines()):\n                    if self.is_marked_line(line):\n                        continue\n                    if line:\n                        req = RequirementsTXTLineParser.parse(line)\n                        if req:\n                            req.dependency_type = self.obj.file_type\n                            self.obj.dependencies.append(req)\n            except NoOptionError:\n                pass\n\n\nclass CondaYMLParser(Parser):\n    \"\"\"\n\n    \"\"\"\n\n    def parse(self):\n        \"\"\"\n\n        :return:\n        \"\"\"\n        import yaml\n        try:\n            data = yaml.safe_load(self.obj.content)\n            if data and 'dependencies' in data and isinstance(data['dependencies'], list):\n                for dep in data['dependencies']:\n                    if isinstance(dep, dict) and 'pip' in dep:\n                        for n, line in enumerate(dep['pip']):\n                            if self.is_marked_line(line):\n                                continue\n                            req = RequirementsTXTLineParser.parse(line)\n                            if req:\n                                req.dependency_type = self.obj.file_type\n                                self.obj.dependencies.append(req)\n        except yaml.YAMLError:\n            pass\n\n\nclass PipfileParser(Parser):\n\n    def parse(self):\n        \"\"\"\n        Parse a Pipfile (as seen in pipenv)\n        :return:\n        \"\"\"\n        try:\n            data = toml.loads(self.obj.content, _dict=OrderedDict)\n            if data:\n                for package_type in ['packages', 'dev-packages']:\n                    if package_type in data:\n                        for name, specs in data[package_type].items():\n                            # skip on VCS dependencies\n                            if not isinstance(specs, str):\n                                continue\n                            if specs == '*':\n                                specs = ''\n                            self.obj.dependencies.append(\n                                Dependency(\n                                    name=name, specs=SpecifierSet(specs),\n                                    dependency_type=filetypes.pipfile,\n                                    line=''.join([name, specs]),\n                                    section=package_type\n                                )\n                            )\n        except (toml.TomlDecodeError, IndexError) as e:\n            pass\n\n\nclass PipfileLockParser(Parser):\n\n    def parse(self):\n        \"\"\"\n        Parse a Pipfile.lock (as seen in pipenv)\n        :return:\n        \"\"\"\n        try:\n            data = json.loads(self.obj.content, object_pairs_hook=OrderedDict)\n            if data:\n                for package_type in ['default', 'develop']:\n                    if package_type in data:\n                        for name, meta in data[package_type].items():\n                            # skip VCS dependencies\n                            if 'version' not in meta:\n                                continue\n                            specs = meta['version']\n                            hashes = meta['hashes']\n                            self.obj.dependencies.append(\n                                Dependency(\n                                    name=name, specs=SpecifierSet(specs),\n                                    dependency_type=filetypes.pipfile_lock,\n                                    hashes=hashes,\n                                    line=''.join([name, specs]),\n                                    section=package_type\n                                )\n                            )\n        except ValueError:\n            pass\n\n\nclass SetupCfgParser(Parser):\n    def parse(self):\n        parser = ConfigParser()\n        parser.readfp(StringIO(self.obj.content))\n        for section in parser.values():\n            if section.name == 'options':\n                options = 'install_requires', 'setup_requires', 'test_require'\n                for name in options:\n                    content = section.get(name)\n                    if not content:\n                        continue\n                    self._parse_content(content)\n            elif section.name == 'options.extras_require':\n                for content in section.values():\n                    self._parse_content(content)\n\n    def _parse_content(self, content):\n        for n, line in enumerate(content.splitlines()):\n            if self.is_marked_line(line):\n                continue\n            if line:\n                req = RequirementsTXTLineParser.parse(line)\n                if req:\n                    req.dependency_type = self.obj.file_type\n                    self.obj.dependencies.append(req)\n\n\ndef parse(content, file_type=None, path=None, sha=None, marker=((), ()), parser=None):\n    \"\"\"\n\n    :param content:\n    :param file_type:\n    :param path:\n    :param sha:\n    :param marker:\n    :param parser:\n    :return:\n    \"\"\"\n    dep_file = DependencyFile(\n        content=content,\n        path=path,\n        sha=sha,\n        marker=marker,\n        file_type=file_type,\n        parser=parser\n    )\n\n    return dep_file.parse()\n", "# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import, print_function, unicode_literals\n\nHASH_REGEX = r\"--hash[=| ]\\w+:\\w+\"\n"], "filenames": ["dparse/parser.py", "dparse/regex.py"], "buggy_code_start_loc": [11, 4], "buggy_code_end_loc": [347, 40], "fixing_code_start_loc": [11, 4], "fixing_code_end_loc": [350, 5], "type": "CWE-400", "message": "dparse is a parser for Python dependency files. dparse in versions before 0.5.2 contain a regular expression that is vulnerable to a Regular Expression Denial of Service. All the users parsing index server URLs with dparse are impacted by this vulnerability. A patch has been applied in version `0.5.2`, all the users are advised to upgrade to `0.5.2` as soon as possible. Users unable to upgrade should avoid passing index server URLs in the source file to be parsed.", "other": {"cve": {"id": "CVE-2022-39280", "sourceIdentifier": "security-advisories@github.com", "published": "2022-10-06T18:16:18.007", "lastModified": "2022-11-10T04:26:56.237", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "dparse is a parser for Python dependency files. dparse in versions before 0.5.2 contain a regular expression that is vulnerable to a Regular Expression Denial of Service. All the users parsing index server URLs with dparse are impacted by this vulnerability. A patch has been applied in version `0.5.2`, all the users are advised to upgrade to `0.5.2` as soon as possible. Users unable to upgrade should avoid passing index server URLs in the source file to be parsed."}, {"lang": "es", "value": "dparse es un analizador de archivos de dependencia de Python. dparse en versiones anteriores a 0.5.2, contiene una expresi\u00f3n regular que es vulnerable a una Denegaci\u00f3n de Servicio por Expresi\u00f3n Regular. Todos los usuarios que parseen URLs de servidores de \u00edndices con dparse est\u00e1n impactados por esta vulnerabilidad. Ha sido aplicado un parche en versi\u00f3n \"0.5.2\", Es recomendado a todos los usuarios actualizar a \"0.5.2\" lo antes posible. Los usuarios que no puedan actualizar deber\u00edan evitar pasar las URLs del servidor de \u00edndices en el archivo fuente a analizar"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-400"}]}, {"source": "nvd@nist.gov", "type": "Secondary", "description": [{"lang": "en", "value": "NVD-CWE-Other"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:pyup:dependency_parser:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.5.1", "matchCriteriaId": "E9AC6716-0EE7-4CB2-9787-BB97BDD6F1EA"}]}]}], "references": [{"url": "https://github.com/pyupio/dparse/commit/8c990170bbd6c0cf212f1151e9025486556062d5", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/pyupio/dparse/commit/d87364f9db9ab916451b1b036cfeb039e726e614", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/pyupio/dparse/security/advisories/GHSA-8fg9-p83m-x5pq", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS", "source": "security-advisories@github.com", "tags": ["Technical Description", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/pyupio/dparse/commit/8c990170bbd6c0cf212f1151e9025486556062d5"}}
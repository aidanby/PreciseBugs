{"buggy_code": ["package client\n\nimport (\n\t\"bytes\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"io/ioutil\"\n\n\t\"github.com/theupdateframework/go-tuf/data\"\n\t\"github.com/theupdateframework/go-tuf/util\"\n\t\"github.com/theupdateframework/go-tuf/verify\"\n)\n\nconst (\n\t// This is the upper limit in bytes we will use to limit the download\n\t// size of the root/timestamp roles, since we might not don't know how\n\t// big it is.\n\tdefaultRootDownloadLimit      = 512000\n\tdefaultTimestampDownloadLimit = 16384\n\tdefaultMaxDelegations         = 32\n\tdefaultMaxRootRotations       = 1e3\n)\n\n// LocalStore is local storage for downloaded top-level metadata.\ntype LocalStore interface {\n\tio.Closer\n\n\t// GetMeta returns top-level metadata from local storage. The keys are\n\t// in the form `ROLE.json`, with ROLE being a valid top-level role.\n\tGetMeta() (map[string]json.RawMessage, error)\n\n\t// SetMeta persists the given top-level metadata in local storage, the\n\t// name taking the same format as the keys returned by GetMeta.\n\tSetMeta(name string, meta json.RawMessage) error\n\n\t// DeleteMeta deletes a given metadata.\n\tDeleteMeta(name string) error\n}\n\n// RemoteStore downloads top-level metadata and target files from a remote\n// repository.\ntype RemoteStore interface {\n\t// GetMeta downloads the given metadata from remote storage.\n\t//\n\t// `name` is the filename of the metadata (e.g. \"root.json\")\n\t//\n\t// `err` is ErrNotFound if the given file does not exist.\n\t//\n\t// `size` is the size of the stream, -1 indicating an unknown length.\n\tGetMeta(name string) (stream io.ReadCloser, size int64, err error)\n\n\t// GetTarget downloads the given target file from remote storage.\n\t//\n\t// `path` is the path of the file relative to the root of the remote\n\t//        targets directory (e.g. \"/path/to/file.txt\").\n\t//\n\t// `err` is ErrNotFound if the given file does not exist.\n\t//\n\t// `size` is the size of the stream, -1 indicating an unknown length.\n\tGetTarget(path string) (stream io.ReadCloser, size int64, err error)\n}\n\n// Client provides methods for fetching updates from a remote repository and\n// downloading remote target files.\ntype Client struct {\n\tlocal  LocalStore\n\tremote RemoteStore\n\n\t// The following four fields represent the versions of metatdata either\n\t// from local storage or from recently downloaded metadata\n\trootVer      int64\n\ttargetsVer   int64\n\tsnapshotVer  int64\n\ttimestampVer int64\n\n\t// targets is the list of available targets, either from local storage\n\t// or from recently downloaded targets metadata\n\ttargets data.TargetFiles\n\n\t// localMeta is the raw metadata from local storage and is used to\n\t// check whether remote metadata is present locally\n\tlocalMeta map[string]json.RawMessage\n\n\t// db is a key DB used for verifying metadata\n\tdb *verify.DB\n\n\t// consistentSnapshot indicates whether the remote storage is using\n\t// consistent snapshots (as specified in root.json)\n\tconsistentSnapshot bool\n\n\t// MaxDelegations limits by default the number of delegations visited for any\n\t// target\n\tMaxDelegations int\n\n\t// MaxRootRotations limits the number of downloaded roots in 1.0.19 root updater\n\tMaxRootRotations int\n}\n\nfunc NewClient(local LocalStore, remote RemoteStore) *Client {\n\treturn &Client{\n\t\tlocal:            local,\n\t\tremote:           remote,\n\t\tMaxDelegations:   defaultMaxDelegations,\n\t\tMaxRootRotations: defaultMaxRootRotations,\n\t}\n}\n\n// Init initializes a local repository.\n//\n// The latest root.json is fetched from remote storage, verified using rootKeys\n// and threshold, and then saved in local storage. It is expected that rootKeys\n// were securely distributed with the software being updated.\n//\n// Deprecated: Use c.InitLocal and c.Update to initialize a local repository.\nfunc (c *Client) Init(rootKeys []*data.PublicKey, threshold int) error {\n\tif len(rootKeys) < threshold {\n\t\treturn ErrInsufficientKeys\n\t}\n\trootJSON, err := c.downloadMetaUnsafe(\"root.json\", defaultRootDownloadLimit)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// create a new key database, and add all the public `rootKeys` to it.\n\tc.db = verify.NewDB()\n\trootKeyIDs := make([]string, 0, len(rootKeys))\n\tfor _, key := range rootKeys {\n\t\tfor _, id := range key.IDs() {\n\t\t\trootKeyIDs = append(rootKeyIDs, id)\n\t\t\tif err := c.db.AddKey(id, key); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\t// add a mock \"root\" role that trusts the passed in key ids. These keys\n\t// will be used to verify the `root.json` we just fetched.\n\trole := &data.Role{Threshold: threshold, KeyIDs: rootKeyIDs}\n\tif err := c.db.AddRole(\"root\", role); err != nil {\n\t\treturn err\n\t}\n\n\t// verify that the new root is valid.\n\tif err := c.decodeRoot(rootJSON); err != nil {\n\t\treturn err\n\t}\n\n\treturn c.local.SetMeta(\"root.json\", rootJSON)\n}\n\n// InitLocal initializes a local repository from root metadata.\n//\n// The root's keys are extracted from the root and saved in local storage.\n// Root expiration is not checked.\n// It is expected that rootJSON was securely distributed with the software\n// being updated.\nfunc (c *Client) InitLocal(rootJSON []byte) error {\n\terr := c.loadAndVerifyRootMeta(rootJSON, true /*ignoreExpiredCheck*/)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn c.local.SetMeta(\"root.json\", rootJSON)\n}\n\n// Update downloads and verifies remote metadata and returns updated targets.\n// It always performs root update (5.2 and 5.3) section of the v1.0.19 spec.\n//\n// https://theupdateframework.github.io/specification/v1.0.19/index.html#load-trusted-root\nfunc (c *Client) Update() (data.TargetFiles, error) {\n\tif err := c.UpdateRoots(); err != nil {\n\t\tif _, ok := err.(verify.ErrExpired); ok {\n\t\t\t// For backward compatibility, we wrap the ErrExpired inside\n\t\t\t// ErrDecodeFailed.\n\t\t\treturn nil, ErrDecodeFailed{\"root.json\", err}\n\t\t}\n\t\treturn nil, err\n\t}\n\n\t// Get timestamp.json, extract snapshot.json file meta and save the\n\t// timestamp.json locally\n\ttimestampJSON, err := c.downloadMetaUnsafe(\"timestamp.json\", defaultTimestampDownloadLimit)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsnapshotMeta, err := c.decodeTimestamp(timestampJSON)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := c.local.SetMeta(\"timestamp.json\", timestampJSON); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Get snapshot.json, then extract file metas.\n\t// root.json meta should not be stored in the snapshot, if it is,\n\t// the root will be checked, re-downloaded\n\tsnapshotJSON, err := c.downloadMetaFromTimestamp(\"snapshot.json\", snapshotMeta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsnapshotMetas, err := c.decodeSnapshot(snapshotJSON)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Save the snapshot.json\n\tif err := c.local.SetMeta(\"snapshot.json\", snapshotJSON); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// If we don't have the targets.json, download it, determine updated\n\t// targets and save targets.json in local storage\n\tvar updatedTargets data.TargetFiles\n\ttargetsMeta := snapshotMetas[\"targets.json\"]\n\tif !c.hasMetaFromSnapshot(\"targets.json\", targetsMeta) {\n\t\ttargetsJSON, err := c.downloadMetaFromSnapshot(\"targets.json\", targetsMeta)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tupdatedTargets, err = c.decodeTargets(targetsJSON)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif err := c.local.SetMeta(\"targets.json\", targetsJSON); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn updatedTargets, nil\n}\n\nfunc (c *Client) UpdateRoots() error {\n\t// https://theupdateframework.github.io/specification/v1.0.19/index.html#load-trusted-root\n\t// 5.2 Load the trusted root metadata file. We assume that a good,\n\t// trusted copy of this file was shipped with the package manager\n\t// or software updater using an out-of-band process.\n\tif err := c.loadAndVerifyLocalRootMeta( /*ignoreExpiredCheck=*/ true); err != nil {\n\t\treturn err\n\t}\n\tm, err := c.local.GetMeta()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\ttype KeyInfo struct {\n\t\tKeyIDs    map[string]bool\n\t\tThreshold int\n\t}\n\n\t// Prepare for 5.3.11: If the timestamp and / or snapshot keys have been rotated,\n\t// then delete the trusted timestamp and snapshot metadata files.\n\tgetKeyInfo := func(role string) KeyInfo {\n\t\tkeyIDs := make(map[string]bool)\n\t\tfor k := range c.db.GetRole(role).KeyIDs {\n\t\t\tkeyIDs[k] = true\n\t\t}\n\t\treturn KeyInfo{keyIDs, c.db.GetRole(role).Threshold}\n\t}\n\n\t// The nonRootKeyInfo looks like this:\n\t// {\n\t//\t\"timestamp\": {KeyIDs={\"KEYID1\": true, \"KEYID2\": true}, Threshold=2},\n\t//\t\"snapshot\": {KeyIDs={\"KEYID3\": true}, Threshold=1},\n\t//\t\"targets\": {KeyIDs={\"KEYID4\": true, \"KEYID5\": true, \"KEYID6\": true}, Threshold=1}\n\t// }\n\n\tnonRootKeyInfo := map[string]KeyInfo{\"timestamp\": {}, \"snapshot\": {}, \"targets\": {}}\n\tfor k := range nonRootKeyInfo {\n\t\tnonRootKeyInfo[k] = getKeyInfo(k)\n\t}\n\n\t// 5.3.1 Temorarily turn on the consistent snapshots in order to download\n\t// versioned root metadata files as described next.\n\tconsistentSnapshot := c.consistentSnapshot\n\tc.consistentSnapshot = true\n\n\tnRootMetadata := m[\"root.json\"]\n\n\t// https://theupdateframework.github.io/specification/v1.0.19/index.html#update-root\n\n\t// 5.3.1 Since it may now be signed using entirely different keys,\n\t// the client MUST somehow be able to establish a trusted line of\n\t// continuity to the latest set of keys (see \u00a7\u202f6.1 Key\n\t// management and migration). To do so, the client MUST\n\t// download intermediate root metadata files, until the\n\t// latest available one is reached. Therefore, it MUST\n\t// temporarily turn on consistent snapshots in order to\n\t// download versioned root metadata files as described next.\n\n\t// This loop returns on error or breaks after downloading the lastest root metadata.\n\t// 5.3.2 Let N denote the version number of the trusted root metadata file.\n\tfor i := 0; i < c.MaxRootRotations; i++ {\n\t\t// 5.3.3 Try downloading version nPlusOne of the root metadata file.\n\t\t// NOTE: as a side effect, we do update c.rootVer to nPlusOne between iterations.\n\t\tnPlusOne := c.rootVer + 1\n\t\tnPlusOneRootPath := util.VersionedPath(\"root.json\", nPlusOne)\n\t\tnPlusOneRootMetadata, err := c.downloadMetaUnsafe(nPlusOneRootPath, defaultRootDownloadLimit)\n\n\t\tif err != nil {\n\t\t\tif _, ok := err.(ErrMissingRemoteMetadata); ok {\n\t\t\t\t// stop when the next root can't be downloaded\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\n\t\t// 5.3.4 Check for an arbitrary software attack.\n\t\t// 5.3.4.1 Check that N signed N+1\n\t\tnPlusOneRootMetadataSigned, err := c.verifyRoot(nRootMetadata, nPlusOneRootMetadata)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// 5.3.4.2 check that N+1 signed itself.\n\t\tif _, err := c.verifyRoot(nPlusOneRootMetadata, nPlusOneRootMetadata); err != nil {\n\t\t\t// 5.3.6 Note that the expiration of the new (intermediate) root\n\t\t\t// metadata file does not matter yet, because we will check for\n\t\t\t// it in step 5.3.10.\n\t\t\treturn err\n\t\t}\n\n\t\t// 5.3.5 Check for a rollback attack. Here, we check that nPlusOneRootMetadataSigned.version == nPlusOne.\n\t\tif nPlusOneRootMetadataSigned.Version != nPlusOne {\n\t\t\treturn verify.ErrWrongVersion{\n\t\t\t\tGiven:    nPlusOneRootMetadataSigned.Version,\n\t\t\t\tExpected: nPlusOne,\n\t\t\t}\n\t\t}\n\n\t\t// 5.3.7 Set the trusted root metadata file to the new root metadata file.\n\t\tc.rootVer = nPlusOneRootMetadataSigned.Version\n\t\t// NOTE: following up on 5.3.1, we want to always have consistent snapshots on for the duration\n\t\t// of root rotation. AFTER the rotation is over, we will set it to the value of the last root.\n\t\tconsistentSnapshot = nPlusOneRootMetadataSigned.ConsistentSnapshot\n\t\t// 5.3.8 Persist root metadata. The client MUST write the file to non-volatile storage as FILENAME.EXT (e.g. root.json).\n\t\t// NOTE: Internally, setMeta stores metadata in LevelDB in a persistent manner.\n\t\tif err := c.local.SetMeta(\"root.json\", nPlusOneRootMetadata); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tnRootMetadata = nPlusOneRootMetadata\n\t\t// 5.3.9 Repeat steps 5.3.2 to 5.3.9\n\n\t} // End of the for loop.\n\n\t// 5.3.10 Check for a freeze attack.\n\t// NOTE: This will check for any, including freeze, attack.\n\tif err := c.loadAndVerifyLocalRootMeta( /*ignoreExpiredCheck=*/ false); err != nil {\n\t\treturn err\n\t}\n\n\tcountDeleted := func(s1 map[string]bool, s2 map[string]bool) int {\n\t\tc := 0\n\t\tfor k := range s1 {\n\t\t\tif _, ok := s2[k]; !ok {\n\t\t\t\tc++\n\t\t\t}\n\t\t}\n\t\treturn c\n\t}\n\n\t// 5.3.11 To recover from fast-forward attack, certain metadata files need\n\t// to be deleted if a threshold of keys are revoked.\n\t// List of metadata that should be deleted per role if a threshold of keys\n\t// are revoked:\n\t// (based on the ongoing PR: https://github.com/mnm678/specification/tree/e50151d9df632299ddea364c4f44fe8ca9c10184)\n\t// timestamp -> delete timestamp.json\n\t// snapshot ->  delete timestamp.json and snapshot.json\n\t// targets ->   delete snapshot.json and targets.json\n\t//\n\t// nonRootKeyInfo contains the keys and thresholds from root.json\n\t// that were on disk before the root update process begins.\n\tfor topLevelRolename := range nonRootKeyInfo {\n\t\t// ki contains the keys and thresholds from the latest downloaded root.json.\n\t\tki := getKeyInfo(topLevelRolename)\n\t\tif countDeleted(nonRootKeyInfo[topLevelRolename].KeyIDs, ki.KeyIDs) >= nonRootKeyInfo[topLevelRolename].Threshold {\n\t\t\tdeleteMeta := map[string][]string{\n\t\t\t\t\"timestamp\": {\"timestamp.json\"},\n\t\t\t\t\"snapshot\":  {\"timestamp.json\", \"snapshot.json\"},\n\t\t\t\t\"targets\":   {\"snapshot.json\", \"targets.json\"},\n\t\t\t}\n\n\t\t\tfor _, r := range deleteMeta[topLevelRolename] {\n\t\t\t\tc.local.DeleteMeta(r)\n\t\t\t}\n\t\t}\n\t}\n\n\t// 5.3.12 Set whether consistent snapshots are used as per the trusted root metadata file.\n\tc.consistentSnapshot = consistentSnapshot\n\treturn nil\n}\n\n// getLocalMeta decodes and verifies metadata from local storage.\n// The verification of local files is purely for consistency, if an attacker\n// has compromised the local storage, there is no guarantee it can be trusted.\nfunc (c *Client) getLocalMeta() error {\n\tif err := c.loadAndVerifyLocalRootMeta( /*ignoreExpiredCheck=*/ false); err != nil {\n\t\treturn err\n\t}\n\n\tmeta, err := c.local.GetMeta()\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\tif timestampJSON, ok := meta[\"timestamp.json\"]; ok {\n\t\ttimestamp := &data.Timestamp{}\n\t\tif err := c.db.UnmarshalTrusted(timestampJSON, timestamp, \"timestamp\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tc.timestampVer = timestamp.Version\n\t}\n\n\tif snapshotJSON, ok := meta[\"snapshot.json\"]; ok {\n\t\tsnapshot := &data.Snapshot{}\n\t\tif err := c.db.UnmarshalTrusted(snapshotJSON, snapshot, \"snapshot\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tc.snapshotVer = snapshot.Version\n\t}\n\n\tif targetsJSON, ok := meta[\"targets.json\"]; ok {\n\t\ttargets := &data.Targets{}\n\t\tif err := c.db.UnmarshalTrusted(targetsJSON, targets, \"targets\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tc.targetsVer = targets.Version\n\t\t// FIXME(TUF-0.9) temporarily support files with leading path separators.\n\t\t// c.targets = targets.Targets\n\t\tc.loadTargets(targets.Targets)\n\t}\n\n\tc.localMeta = meta\n\treturn nil\n}\n\n// loadAndVerifyLocalRootMeta decodes and verifies root metadata from\n// local storage and loads the top-level keys. This method first clears\n// the DB for top-level keys and then loads the new keys.\nfunc (c *Client) loadAndVerifyLocalRootMeta(ignoreExpiredCheck bool) error {\n\tmeta, err := c.local.GetMeta()\n\tif err != nil {\n\t\treturn err\n\t}\n\trootJSON, ok := meta[\"root.json\"]\n\tif !ok {\n\t\treturn ErrNoRootKeys\n\t}\n\treturn c.loadAndVerifyRootMeta(rootJSON, ignoreExpiredCheck)\n}\n\n// loadAndVerifyRootMeta decodes and verifies root metadata and loads the top-level keys.\n// This method first clears the DB for top-level keys and then loads the new keys.\nfunc (c *Client) loadAndVerifyRootMeta(rootJSON []byte, ignoreExpiredCheck bool) error {\n\t// unmarshal root.json without verifying as we need the root\n\t// keys first\n\ts := &data.Signed{}\n\tif err := json.Unmarshal(rootJSON, s); err != nil {\n\t\treturn err\n\t}\n\troot := &data.Root{}\n\tif err := json.Unmarshal(s.Signed, root); err != nil {\n\t\treturn err\n\t}\n\tndb := verify.NewDB()\n\tfor id, k := range root.Keys {\n\t\tif err := ndb.AddKey(id, k); err != nil {\n\t\t\t// TUF is considering in TAP-12 removing the\n\t\t\t// requirement that the keyid hash algorithm be derived\n\t\t\t// from the public key. So to be forwards compatible,\n\t\t\t// we ignore `ErrWrongID` errors.\n\t\t\t//\n\t\t\t// TAP-12: https://github.com/theupdateframework/taps/blob/master/tap12.md\n\t\t\tif _, ok := err.(verify.ErrWrongID); !ok {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\tfor name, role := range root.Roles {\n\t\tif err := ndb.AddRole(name, role); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t// Any trusted local root metadata version must be greater than 0.\n\tif ignoreExpiredCheck {\n\t\tif err := ndb.VerifyIgnoreExpiredCheck(s, \"root\", 0); err != nil {\n\t\t\treturn err\n\t\t}\n\t} else {\n\t\tif err := ndb.Verify(s, \"root\", 0); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tc.consistentSnapshot = root.ConsistentSnapshot\n\tc.rootVer = root.Version\n\tc.db = ndb\n\treturn nil\n}\n\n// verifyRoot verifies Signed section of the bJSON\n// using verification keys in aJSON.\nfunc (c *Client) verifyRoot(aJSON []byte, bJSON []byte) (*data.Root, error) {\n\taSigned := &data.Signed{}\n\tif err := json.Unmarshal(aJSON, aSigned); err != nil {\n\t\treturn nil, err\n\t}\n\taRoot := &data.Root{}\n\tif err := json.Unmarshal(aSigned.Signed, aRoot); err != nil {\n\t\treturn nil, err\n\t}\n\n\tbSigned := &data.Signed{}\n\tif err := json.Unmarshal(bJSON, bSigned); err != nil {\n\t\treturn nil, err\n\t}\n\tbRoot := &data.Root{}\n\tif err := json.Unmarshal(bSigned.Signed, bRoot); err != nil {\n\t\treturn nil, err\n\t}\n\n\tndb := verify.NewDB()\n\tfor id, k := range aRoot.Keys {\n\t\tif err := ndb.AddKey(id, k); err != nil {\n\t\t\t// TUF is considering in TAP-12 removing the\n\t\t\t// requirement that the keyid hash algorithm be derived\n\t\t\t// from the public key. So to be forwards compatible,\n\t\t\t// we ignore `ErrWrongID` errors.\n\t\t\t//\n\t\t\t// TAP-12: https://github.com/theupdateframework/taps/blob/master/tap12.md\n\t\t\tif _, ok := err.(verify.ErrWrongID); !ok {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\tfor name, role := range aRoot.Roles {\n\t\tif err := ndb.AddRole(name, role); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif err := ndb.VerifySignatures(bSigned, \"root\"); err != nil {\n\t\treturn nil, err\n\t}\n\treturn bRoot, nil\n}\n\n// FIXME(TUF-0.9) TUF is considering removing support for target files starting\n// with a leading path separator. In order to be backwards compatible, we'll\n// just remove leading separators for now.\nfunc (c *Client) loadTargets(targets data.TargetFiles) {\n\tc.targets = make(data.TargetFiles)\n\tfor name, meta := range targets {\n\t\tc.targets[name] = meta\n\t\tc.targets[util.NormalizeTarget(name)] = meta\n\t}\n}\n\n// downloadMetaUnsafe downloads top-level metadata from remote storage without\n// verifying it's length and hashes (used for example to download timestamp.json\n// which has unknown size). It will download at most maxMetaSize bytes.\nfunc (c *Client) downloadMetaUnsafe(name string, maxMetaSize int64) ([]byte, error) {\n\tr, size, err := c.remote.GetMeta(name)\n\tif err != nil {\n\t\tif IsNotFound(err) {\n\t\t\treturn nil, ErrMissingRemoteMetadata{name}\n\t\t}\n\t\treturn nil, ErrDownloadFailed{name, err}\n\t}\n\tdefer r.Close()\n\n\t// return ErrMetaTooLarge if the reported size is greater than maxMetaSize\n\tif size > maxMetaSize {\n\t\treturn nil, ErrMetaTooLarge{name, size, maxMetaSize}\n\t}\n\n\t// although the size has been checked above, use a LimitReader in case\n\t// the reported size is inaccurate, or size is -1 which indicates an\n\t// unknown length\n\treturn ioutil.ReadAll(io.LimitReader(r, maxMetaSize))\n}\n\n// remoteGetFunc is the type of function the download method uses to download\n// remote files\ntype remoteGetFunc func(string) (io.ReadCloser, int64, error)\n\n// downloadHashed tries to download the hashed prefixed version of the file.\nfunc (c *Client) downloadHashed(file string, get remoteGetFunc, hashes data.Hashes) (io.ReadCloser, int64, error) {\n\t// try each hashed path in turn, and either return the contents,\n\t// try the next one if a 404 is returned, or return an error\n\tfor _, path := range util.HashedPaths(file, hashes) {\n\t\tr, size, err := get(path)\n\t\tif err != nil {\n\t\t\tif IsNotFound(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn nil, 0, err\n\t\t}\n\t\treturn r, size, nil\n\t}\n\treturn nil, 0, ErrNotFound{file}\n}\n\n// download downloads the given target file from remote storage using the get\n// function, adding hashes to the path if consistent snapshots are in use\nfunc (c *Client) downloadTarget(file string, get remoteGetFunc, hashes data.Hashes) (io.ReadCloser, int64, error) {\n\tif c.consistentSnapshot {\n\t\treturn c.downloadHashed(file, get, hashes)\n\t} else {\n\t\treturn get(file)\n\t}\n}\n\n// downloadVersionedMeta downloads top-level metadata from remote storage and\n// verifies it using the given file metadata.\nfunc (c *Client) downloadMeta(name string, version int64, m data.FileMeta) ([]byte, error) {\n\tr, size, err := func() (io.ReadCloser, int64, error) {\n\t\tif c.consistentSnapshot {\n\t\t\tpath := util.VersionedPath(name, version)\n\t\t\tr, size, err := c.remote.GetMeta(path)\n\t\t\tif err == nil {\n\t\t\t\treturn r, size, nil\n\t\t\t}\n\n\t\t\treturn nil, 0, err\n\t\t} else {\n\t\t\treturn c.remote.GetMeta(name)\n\t\t}\n\t}()\n\tif err != nil {\n\t\tif IsNotFound(err) {\n\t\t\treturn nil, ErrMissingRemoteMetadata{name}\n\t\t}\n\t\treturn nil, err\n\t}\n\tdefer r.Close()\n\n\t// return ErrWrongSize if the reported size is known and incorrect\n\tvar stream io.Reader\n\tif m.Length != 0 {\n\t\tif size >= 0 && size != m.Length {\n\t\t\treturn nil, ErrWrongSize{name, size, m.Length}\n\t\t}\n\n\t\t// wrap the data in a LimitReader so we download at most m.Length bytes\n\t\tstream = io.LimitReader(r, m.Length)\n\t} else {\n\t\tstream = r\n\t}\n\n\treturn ioutil.ReadAll(stream)\n}\n\nfunc (c *Client) downloadMetaFromSnapshot(name string, m data.SnapshotFileMeta) ([]byte, error) {\n\tb, err := c.downloadMeta(name, m.Version, m.FileMeta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmeta, err := util.GenerateSnapshotFileMeta(bytes.NewReader(b), m.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := util.SnapshotFileMetaEqual(meta, m); err != nil {\n\t\treturn nil, ErrDownloadFailed{name, err}\n\t}\n\treturn b, nil\n}\n\nfunc (c *Client) downloadMetaFromTimestamp(name string, m data.TimestampFileMeta) ([]byte, error) {\n\tb, err := c.downloadMeta(name, m.Version, m.FileMeta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmeta, err := util.GenerateTimestampFileMeta(bytes.NewReader(b), m.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := util.TimestampFileMetaEqual(meta, m); err != nil {\n\t\treturn nil, ErrDownloadFailed{name, err}\n\t}\n\treturn b, nil\n}\n\n// decodeRoot decodes and verifies root metadata.\nfunc (c *Client) decodeRoot(b json.RawMessage) error {\n\troot := &data.Root{}\n\tif err := c.db.Unmarshal(b, root, \"root\", c.rootVer); err != nil {\n\t\treturn ErrDecodeFailed{\"root.json\", err}\n\t}\n\tc.rootVer = root.Version\n\tc.consistentSnapshot = root.ConsistentSnapshot\n\treturn nil\n}\n\n// decodeSnapshot decodes and verifies snapshot metadata, and returns the new\n// root and targets file meta.\nfunc (c *Client) decodeSnapshot(b json.RawMessage) (data.SnapshotFiles, error) {\n\tsnapshot := &data.Snapshot{}\n\tif err := c.db.Unmarshal(b, snapshot, \"snapshot\", c.snapshotVer); err != nil {\n\t\treturn data.SnapshotFiles{}, ErrDecodeFailed{\"snapshot.json\", err}\n\t}\n\tc.snapshotVer = snapshot.Version\n\treturn snapshot.Meta, nil\n}\n\n// decodeTargets decodes and verifies targets metadata, sets c.targets and\n// returns updated targets.\nfunc (c *Client) decodeTargets(b json.RawMessage) (data.TargetFiles, error) {\n\ttargets := &data.Targets{}\n\tif err := c.db.Unmarshal(b, targets, \"targets\", c.targetsVer); err != nil {\n\t\treturn nil, ErrDecodeFailed{\"targets.json\", err}\n\t}\n\tupdatedTargets := make(data.TargetFiles)\n\tfor path, meta := range targets.Targets {\n\t\tif local, ok := c.targets[path]; ok {\n\t\t\tif err := util.TargetFileMetaEqual(local, meta); err == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tupdatedTargets[path] = meta\n\t}\n\tc.targetsVer = targets.Version\n\t// FIXME(TUF-0.9) temporarily support files with leading path separators.\n\t// c.targets = targets.Targets\n\tc.loadTargets(targets.Targets)\n\treturn updatedTargets, nil\n}\n\n// decodeTimestamp decodes and verifies timestamp metadata, and returns the\n// new snapshot file meta.\nfunc (c *Client) decodeTimestamp(b json.RawMessage) (data.TimestampFileMeta, error) {\n\ttimestamp := &data.Timestamp{}\n\tif err := c.db.Unmarshal(b, timestamp, \"timestamp\", c.timestampVer); err != nil {\n\t\treturn data.TimestampFileMeta{}, ErrDecodeFailed{\"timestamp.json\", err}\n\t}\n\tc.timestampVer = timestamp.Version\n\treturn timestamp.Meta[\"snapshot.json\"], nil\n}\n\n// hasMetaFromSnapshot checks whether local metadata has the given meta\nfunc (c *Client) hasMetaFromSnapshot(name string, m data.SnapshotFileMeta) bool {\n\t_, ok := c.localMetaFromSnapshot(name, m)\n\treturn ok\n}\n\n// localMetaFromSnapshot returns localmetadata if it matches the snapshot\nfunc (c *Client) localMetaFromSnapshot(name string, m data.SnapshotFileMeta) (json.RawMessage, bool) {\n\tb, ok := c.localMeta[name]\n\tif !ok {\n\t\treturn nil, false\n\t}\n\tmeta, err := util.GenerateSnapshotFileMeta(bytes.NewReader(b), m.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn nil, false\n\t}\n\terr = util.SnapshotFileMetaEqual(meta, m)\n\treturn b, err == nil\n}\n\n// hasTargetsMeta checks whether local metadata has the given snapshot meta\n//lint:ignore U1000 unused\nfunc (c *Client) hasTargetsMeta(m data.SnapshotFileMeta) bool {\n\tb, ok := c.localMeta[\"targets.json\"]\n\tif !ok {\n\t\treturn false\n\t}\n\tmeta, err := util.GenerateSnapshotFileMeta(bytes.NewReader(b), m.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn false\n\t}\n\terr = util.SnapshotFileMetaEqual(meta, m)\n\treturn err == nil\n}\n\n// hasSnapshotMeta checks whether local metadata has the given meta\n//lint:ignore U1000 unused\nfunc (c *Client) hasMetaFromTimestamp(name string, m data.TimestampFileMeta) bool {\n\tb, ok := c.localMeta[name]\n\tif !ok {\n\t\treturn false\n\t}\n\tmeta, err := util.GenerateTimestampFileMeta(bytes.NewReader(b), m.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn false\n\t}\n\terr = util.TimestampFileMetaEqual(meta, m)\n\treturn err == nil\n}\n\ntype Destination interface {\n\tio.Writer\n\tDelete() error\n}\n\n// Download downloads the given target file from remote storage into dest.\n//\n// dest will be deleted and an error returned in the following situations:\n//\n//   * The target does not exist in the local targets.json\n//   * Failed to fetch the chain of delegations accessible from local snapshot.json\n//   * The target does not exist in any targets\n//   * Metadata cannot be generated for the downloaded data\n//   * Generated metadata does not match local metadata for the given file\nfunc (c *Client) Download(name string, dest Destination) (err error) {\n\t// delete dest if there is an error\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tdest.Delete()\n\t\t}\n\t}()\n\n\t// populate c.targets from local storage if not set\n\tif c.targets == nil {\n\t\tif err := c.getLocalMeta(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tnormalizedName := util.NormalizeTarget(name)\n\tlocalMeta, ok := c.targets[normalizedName]\n\tif !ok {\n\t\t// search in delegations\n\t\tlocalMeta, err = c.getTargetFileMeta(normalizedName)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// get the data from remote storage\n\tr, size, err := c.downloadTarget(normalizedName, c.remote.GetTarget, localMeta.Hashes)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer r.Close()\n\n\t// return ErrWrongSize if the reported size is known and incorrect\n\tif size >= 0 && size != localMeta.Length {\n\t\treturn ErrWrongSize{name, size, localMeta.Length}\n\t}\n\n\t// wrap the data in a LimitReader so we download at most localMeta.Length bytes\n\tstream := io.LimitReader(r, localMeta.Length)\n\n\t// read the data, simultaneously writing it to dest and generating metadata\n\tactual, err := util.GenerateTargetFileMeta(io.TeeReader(stream, dest), localMeta.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn ErrDownloadFailed{name, err}\n\t}\n\n\t// check the data has the correct length and hashes\n\tif err := util.TargetFileMetaEqual(actual, localMeta); err != nil {\n\t\tif e, ok := err.(util.ErrWrongLength); ok {\n\t\t\treturn ErrWrongSize{name, e.Actual, e.Expected}\n\t\t}\n\t\treturn ErrDownloadFailed{name, err}\n\t}\n\n\treturn nil\n}\n\nfunc (c *Client) VerifyDigest(digest string, digestAlg string, length int64, path string) error {\n\tlocalMeta, ok := c.targets[path]\n\tif !ok {\n\t\treturn ErrUnknownTarget{Name: path, SnapshotVersion: c.snapshotVer}\n\t}\n\n\tactual := data.FileMeta{Length: length, Hashes: make(data.Hashes, 1)}\n\tvar err error\n\tactual.Hashes[digestAlg], err = hex.DecodeString(digest)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := util.TargetFileMetaEqual(data.TargetFileMeta{FileMeta: actual}, localMeta); err != nil {\n\t\tif e, ok := err.(util.ErrWrongLength); ok {\n\t\t\treturn ErrWrongSize{path, e.Actual, e.Expected}\n\t\t}\n\t\treturn ErrDownloadFailed{path, err}\n\t}\n\n\treturn nil\n}\n\n// Target returns the target metadata for a specific target if it\n// exists, searching from top-level level targets then through\n// all delegations. If it does not, ErrNotFound will be returned.\nfunc (c *Client) Target(name string) (data.TargetFileMeta, error) {\n\ttarget, err := c.getTargetFileMeta(util.NormalizeTarget(name))\n\tif err == nil {\n\t\treturn target, nil\n\t}\n\n\tif _, ok := err.(ErrUnknownTarget); ok {\n\t\treturn data.TargetFileMeta{}, ErrNotFound{name}\n\t}\n\n\treturn data.TargetFileMeta{}, err\n}\n\n// Targets returns the complete list of available top-level targets.\nfunc (c *Client) Targets() (data.TargetFiles, error) {\n\t// populate c.targets from local storage if not set\n\tif c.targets == nil {\n\t\tif err := c.getLocalMeta(); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn c.targets, nil\n}\n", "package client\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\tErrNoRootKeys       = errors.New(\"tuf: no root keys found in local meta store\")\n\tErrInsufficientKeys = errors.New(\"tuf: insufficient keys to meet threshold\")\n\tErrNoLocalSnapshot  = errors.New(\"tuf: no snapshot stored locally\")\n)\n\ntype ErrMissingRemoteMetadata struct {\n\tName string\n}\n\nfunc (e ErrMissingRemoteMetadata) Error() string {\n\treturn fmt.Sprintf(\"tuf: missing remote metadata %s\", e.Name)\n}\n\ntype ErrDownloadFailed struct {\n\tFile string\n\tErr  error\n}\n\nfunc (e ErrDownloadFailed) Error() string {\n\treturn fmt.Sprintf(\"tuf: failed to download %s: %s\", e.File, e.Err)\n}\n\ntype ErrDecodeFailed struct {\n\tFile string\n\tErr  error\n}\n\nfunc (e ErrDecodeFailed) Error() string {\n\treturn fmt.Sprintf(\"tuf: failed to decode %s: %s\", e.File, e.Err)\n}\n\ntype ErrMaxDelegations struct {\n\tTarget          string\n\tMaxDelegations  int\n\tSnapshotVersion int64\n}\n\nfunc (e ErrMaxDelegations) Error() string {\n\treturn fmt.Sprintf(\"tuf: max delegation of %d reached searching for %s with snapshot version %d\", e.MaxDelegations, e.Target, e.SnapshotVersion)\n}\n\ntype ErrNotFound struct {\n\tFile string\n}\n\nfunc (e ErrNotFound) Error() string {\n\treturn fmt.Sprintf(\"tuf: file not found: %s\", e.File)\n}\n\nfunc IsNotFound(err error) bool {\n\t_, ok := err.(ErrNotFound)\n\treturn ok\n}\n\ntype ErrWrongSize struct {\n\tFile     string\n\tActual   int64\n\tExpected int64\n}\n\nfunc (e ErrWrongSize) Error() string {\n\treturn fmt.Sprintf(\"tuf: unexpected file size: %s (expected %d bytes, got %d bytes)\", e.File, e.Expected, e.Actual)\n}\n\ntype ErrLatestSnapshot struct {\n\tVersion int64\n}\n\nfunc (e ErrLatestSnapshot) Error() string {\n\treturn fmt.Sprintf(\"tuf: the local snapshot version (%d) is the latest\", e.Version)\n}\n\nfunc IsLatestSnapshot(err error) bool {\n\t_, ok := err.(ErrLatestSnapshot)\n\treturn ok\n}\n\ntype ErrUnknownTarget struct {\n\tName            string\n\tSnapshotVersion int64\n}\n\nfunc (e ErrUnknownTarget) Error() string {\n\treturn fmt.Sprintf(\"tuf: unknown target file: %s with snapshot version %d\", e.Name, e.SnapshotVersion)\n}\n\ntype ErrMetaTooLarge struct {\n\tName    string\n\tSize    int64\n\tMaxSize int64\n}\n\nfunc (e ErrMetaTooLarge) Error() string {\n\treturn fmt.Sprintf(\"tuf: %s size %d bytes greater than maximum %d bytes\", e.Name, e.Size, e.MaxSize)\n}\n\ntype ErrInvalidURL struct {\n\tURL string\n}\n\nfunc (e ErrInvalidURL) Error() string {\n\treturn fmt.Sprintf(\"tuf: invalid repository URL %s\", e.URL)\n}\n\ntype ErrRoleNotInSnapshot struct {\n\tRole            string\n\tSnapshotVersion int64\n}\n\nfunc (e ErrRoleNotInSnapshot) Error() string {\n\treturn fmt.Sprintf(\"tuf: role %s not in snapshot version %d\", e.Role, e.SnapshotVersion)\n}\n", "package client\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\n\t\"github.com/theupdateframework/go-tuf/util\"\n\t. \"gopkg.in/check.v1\"\n\n\tgoTufGenerator \"github.com/theupdateframework/go-tuf/client/testdata/go-tuf/generator\"\n)\n\ntype InteropSuite struct{}\n\nvar _ = Suite(&InteropSuite{})\n\nfunc (InteropSuite) TestGoClientIdentityConsistentSnapshotFalse(c *C) {\n\tcheckGoIdentity(c, false)\n}\n\nfunc (InteropSuite) TestGoClientIdentityConsistentSnapshotTrue(c *C) {\n\tcheckGoIdentity(c, true)\n}\n\nfunc checkGoIdentity(c *C, consistentSnapshot bool) {\n\tcwd, err := os.Getwd()\n\tc.Assert(err, IsNil)\n\ttestDataDir := filepath.Join(cwd, \"testdata\")\n\n\ttempDir, err := ioutil.TempDir(\"\", \"\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(tempDir)\n\n\t// Generate the metadata and compute hashes for all the files.\n\tgoTufGenerator.Generate(tempDir, filepath.Join(testDataDir, \"keys.json\"), consistentSnapshot)\n\thashes := computeHashes(c, tempDir)\n\n\tsnapshotDir := filepath.Join(testDataDir, \"go-tuf\", fmt.Sprintf(\"consistent-snapshot-%t\", consistentSnapshot))\n\tsnapshotHashes := computeHashes(c, snapshotDir)\n\n\tc.Assert(hashes, DeepEquals, snapshotHashes, Commentf(\"metadata out of date, regenerate by running client/testdata/go-tuf/regenerate-metadata.sh\"))\n}\n\nfunc computeHashes(c *C, dir string) map[string]string {\n\thashes := make(map[string]string)\n\n\terr := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif info.IsDir() {\n\t\t\treturn nil\n\t\t}\n\n\t\tbytes, err := ioutil.ReadFile(path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpath, err = filepath.Rel(dir, path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\thashes[path] = string(bytes)\n\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\n\treturn hashes\n}\n\nfunc (InteropSuite) TestGoClientCompatibility(c *C) {\n\tnames := []string{\n\t\t\"go-tuf\",\n\t\t\"go-tuf-transition-M3\",\n\t\t\"go-tuf-transition-M4\",\n\t}\n\toptions := &HTTPRemoteOptions{MetadataPath: \"\", TargetsPath: \"targets\"}\n\n\tfor _, name := range names {\n\t\tfor _, consistentSnapshot := range []bool{false, true} {\n\t\t\tt := newTestCase(c, name, consistentSnapshot, options)\n\t\t\tt.run(c)\n\t\t}\n\t}\n}\n\ntype testCase struct {\n\tname               string\n\tconsistentSnapshot bool\n\toptions            *HTTPRemoteOptions\n\tlocal              LocalStore\n\ttargets            map[string][]byte\n\ttestDir            string\n\ttestSteps          []string\n}\n\nfunc newTestCase(c *C, name string, consistentSnapshot bool, options *HTTPRemoteOptions) testCase {\n\tcwd, err := os.Getwd()\n\tc.Assert(err, IsNil)\n\ttestDir := filepath.Join(cwd, \"testdata\", name, fmt.Sprintf(\"consistent-snapshot-%t\", consistentSnapshot))\n\n\tdirEntries, err := ioutil.ReadDir(testDir)\n\tc.Assert(err, IsNil)\n\tc.Assert(dirEntries, Not(HasLen), 0)\n\n\ttestSteps := []string{}\n\tfor _, dirEntry := range dirEntries {\n\t\tif dirEntry.IsDir() {\n\t\t\ttestSteps = append(testSteps, dirEntry.Name())\n\t\t}\n\t}\n\n\treturn testCase{\n\t\tname:               name,\n\t\tconsistentSnapshot: consistentSnapshot,\n\t\toptions:            options,\n\t\tlocal:              MemoryLocalStore(),\n\t\ttargets:            make(map[string][]byte),\n\t\ttestDir:            testDir,\n\t\ttestSteps:          testSteps,\n\t}\n}\n\nfunc (t *testCase) run(c *C) {\n\tc.Logf(\"test case: %s consistent-snapshot: %t\", t.name, t.consistentSnapshot)\n\n\tfor _, stepName := range t.testSteps {\n\t\tt.runStep(c, stepName)\n\t}\n}\n\nfunc (t *testCase) runStep(c *C, stepName string) {\n\tc.Logf(\"step: %s\", stepName)\n\n\taddr, cleanup := startFileServer(c, t.testDir)\n\tdefer cleanup()\n\n\tremote, err := HTTPRemoteStore(fmt.Sprintf(\"http://%s/%s/repository\", addr, stepName), t.options, nil)\n\tc.Assert(err, IsNil)\n\n\tclient := NewClient(t.local, remote)\n\t// initiate a client with the root metadata\n\tioReader, _, err := remote.GetMeta(\"root.json\")\n\tc.Assert(err, IsNil)\n\trootJsonBytes, err := io.ReadAll(ioReader)\n\tc.Assert(err, IsNil)\n\tc.Assert(client.InitLocal(rootJsonBytes), IsNil)\n\n\t// check update returns the correct updated targets\n\tfiles, err := client.Update()\n\tc.Assert(err, IsNil)\n\tl, _ := strconv.Atoi(stepName)\n\tc.Assert(files, HasLen, l+1)\n\n\ttargetName := stepName\n\tt.targets[targetName] = []byte(targetName)\n\n\tfile, ok := files[targetName]\n\tif !ok {\n\t\tc.Fatalf(\"expected updated targets to contain %s\", targetName)\n\t}\n\n\tdata := t.targets[targetName]\n\tmeta, err := util.GenerateTargetFileMeta(bytes.NewReader(data), file.HashAlgorithms()...)\n\tc.Assert(err, IsNil)\n\tc.Assert(util.TargetFileMetaEqual(file, meta), IsNil)\n\n\t// download the files and check they have the correct content\n\tfor name, data := range t.targets {\n\t\tfor _, prefix := range []string{\"\", \"/\"} {\n\t\t\tvar dest testDestination\n\t\t\tc.Assert(client.Download(prefix+name, &dest), IsNil)\n\t\t\tc.Assert(dest.deleted, Equals, false)\n\t\t\tc.Assert(dest.String(), Equals, string(data))\n\t\t}\n\t}\n}\n\nfunc startFileServer(c *C, dir string) (string, func() error) {\n\tl, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n\tc.Assert(err, IsNil)\n\taddr := l.Addr().String()\n\tgo http.Serve(l, http.FileServer(http.Dir(dir)))\n\treturn addr, l.Close\n}\n", "package main\n\nimport (\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\n\t\"github.com/flynn/go-docopt\"\n\ttuf \"github.com/theupdateframework/go-tuf/client\"\n\t\"github.com/theupdateframework/go-tuf/util\"\n)\n\nfunc init() {\n\tregister(\"get\", cmdGet, `\nusage: tuf-client get [-s|--store=<path>] <url> <target>\n\nOptions:\n  -s <path>    The path to the local file store [default: tuf.db]\n\nGet a target from the repository.\n  `)\n}\n\ntype tmpFile struct {\n\t*os.File\n}\n\nfunc (t *tmpFile) Delete() error {\n\tt.Close()\n\treturn os.Remove(t.Name())\n}\n\nfunc cmdGet(args *docopt.Args, client *tuf.Client) error {\n\tif _, err := client.Update(); err != nil && !tuf.IsLatestSnapshot(err) {\n\t\treturn err\n\t}\n\ttarget := util.NormalizeTarget(args.String[\"<target>\"])\n\tfile, err := ioutil.TempFile(\"\", \"go-tuf\")\n\tif err != nil {\n\t\treturn err\n\t}\n\ttmp := tmpFile{file}\n\tif err := client.Download(target, &tmp); err != nil {\n\t\treturn err\n\t}\n\tdefer tmp.Delete()\n\tif _, err := tmp.Seek(0, io.SeekStart); err != nil {\n\t\treturn err\n\t}\n\t_, err = io.Copy(os.Stdout, file)\n\treturn err\n}\n", "package main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"text/tabwriter\"\n\n\t\"github.com/dustin/go-humanize\"\n\t\"github.com/flynn/go-docopt\"\n\ttuf \"github.com/theupdateframework/go-tuf/client\"\n)\n\nfunc init() {\n\tregister(\"list\", cmdList, `\nusage: tuf-client list [-s|--store=<path>] <url>\n\nOptions:\n  -s <path>    The path to the local file store [default: tuf.db]\n\nList available target files.\n  `)\n}\n\nfunc cmdList(args *docopt.Args, client *tuf.Client) error {\n\tif _, err := client.Update(); err != nil && !tuf.IsLatestSnapshot(err) {\n\t\treturn err\n\t}\n\ttargets, err := client.Targets()\n\tif err != nil {\n\t\treturn err\n\t}\n\tw := tabwriter.NewWriter(os.Stdout, 1, 2, 2, ' ', 0)\n\tdefer w.Flush()\n\tfmt.Fprintln(w, \"PATH\\tSIZE\")\n\tfor path, meta := range targets {\n\t\tfmt.Fprintf(w, \"%s\\t%s\\n\", path, humanize.Bytes(uint64(meta.Length)))\n\t}\n\treturn nil\n}\n", "package util\n\nimport (\n\t\"bytes\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"hash\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/theupdateframework/go-tuf/data\"\n)\n\ntype ErrWrongLength struct {\n\tExpected int64\n\tActual   int64\n}\n\nfunc (e ErrWrongLength) Error() string {\n\treturn fmt.Sprintf(\"wrong length, expected %d got %d\", e.Expected, e.Actual)\n}\n\ntype ErrWrongVersion struct {\n\tExpected int64\n\tActual   int64\n}\n\nfunc (e ErrWrongVersion) Error() string {\n\treturn fmt.Sprintf(\"wrong version, expected %d got %d\", e.Expected, e.Actual)\n}\n\ntype ErrWrongHash struct {\n\tType     string\n\tExpected data.HexBytes\n\tActual   data.HexBytes\n}\n\nfunc (e ErrWrongHash) Error() string {\n\treturn fmt.Sprintf(\"wrong %s hash, expected %s got %s\", e.Type, hex.EncodeToString(e.Expected), hex.EncodeToString(e.Actual))\n}\n\ntype ErrNoCommonHash struct {\n\tExpected data.Hashes\n\tActual   data.Hashes\n}\n\nfunc (e ErrNoCommonHash) Error() string {\n\ttypes := func(a data.Hashes) []string {\n\t\tt := make([]string, 0, len(a))\n\t\tfor typ := range a {\n\t\t\tt = append(t, typ)\n\t\t}\n\t\treturn t\n\t}\n\treturn fmt.Sprintf(\"no common hash function, expected one of %s, got %s\", types(e.Expected), types(e.Actual))\n}\n\ntype ErrUnknownHashAlgorithm struct {\n\tName string\n}\n\nfunc (e ErrUnknownHashAlgorithm) Error() string {\n\treturn fmt.Sprintf(\"unknown hash algorithm: %s\", e.Name)\n}\n\ntype PassphraseFunc func(role string, confirm bool, change bool) ([]byte, error)\n\nfunc FileMetaEqual(actual data.FileMeta, expected data.FileMeta) error {\n\tif actual.Length != expected.Length {\n\t\treturn ErrWrongLength{expected.Length, actual.Length}\n\t}\n\n\tif err := hashEqual(actual.Hashes, expected.Hashes); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc hashEqual(actual data.Hashes, expected data.Hashes) error {\n\thashChecked := false\n\tfor typ, hash := range expected {\n\t\tif h, ok := actual[typ]; ok {\n\t\t\thashChecked = true\n\t\t\tif !hmac.Equal(h, hash) {\n\t\t\t\treturn ErrWrongHash{typ, hash, h}\n\t\t\t}\n\t\t}\n\t}\n\tif !hashChecked {\n\t\treturn ErrNoCommonHash{expected, actual}\n\t}\n\treturn nil\n}\n\nfunc versionEqual(actual int64, expected int64) error {\n\tif actual != expected {\n\t\treturn ErrWrongVersion{expected, actual}\n\t}\n\treturn nil\n}\n\nfunc SnapshotFileMetaEqual(actual data.SnapshotFileMeta, expected data.SnapshotFileMeta) error {\n\t// TUF-1.0 no longer considers the length and hashes to be a required\n\t// member of snapshots. However they are considering requiring hashes\n\t// for delegated roles to avoid an attack described in Section 5.6 of\n\t// the Mercury paper:\n\t// https://github.com/theupdateframework/specification/pull/40\n\tif expected.Length != 0 && actual.Length != expected.Length {\n\t\treturn ErrWrongLength{expected.Length, actual.Length}\n\t}\n\n\tif len(expected.Hashes) != 0 {\n\t\tif err := hashEqual(actual.Hashes, expected.Hashes); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := versionEqual(actual.Version, expected.Version); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc TargetFileMetaEqual(actual data.TargetFileMeta, expected data.TargetFileMeta) error {\n\treturn FileMetaEqual(actual.FileMeta, expected.FileMeta)\n}\n\nfunc TimestampFileMetaEqual(actual data.TimestampFileMeta, expected data.TimestampFileMeta) error {\n\t// As opposed to snapshots, the length and hashes are still required in\n\t// TUF-1.0. See:\n\t// https://github.com/theupdateframework/specification/issues/38\n\tif err := FileMetaEqual(actual.FileMeta, expected.FileMeta); err != nil {\n\t\treturn err\n\t}\n\n\tif err := versionEqual(actual.Version, expected.Version); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nconst defaultHashAlgorithm = \"sha512\"\n\nfunc GenerateFileMeta(r io.Reader, hashAlgorithms ...string) (data.FileMeta, error) {\n\tif len(hashAlgorithms) == 0 {\n\t\thashAlgorithms = []string{defaultHashAlgorithm}\n\t}\n\thashes := make(map[string]hash.Hash, len(hashAlgorithms))\n\tfor _, hashAlgorithm := range hashAlgorithms {\n\t\tvar h hash.Hash\n\t\tswitch hashAlgorithm {\n\t\tcase \"sha256\":\n\t\t\th = sha256.New()\n\t\tcase \"sha512\":\n\t\t\th = sha512.New()\n\t\tdefault:\n\t\t\treturn data.FileMeta{}, ErrUnknownHashAlgorithm{hashAlgorithm}\n\t\t}\n\t\thashes[hashAlgorithm] = h\n\t\tr = io.TeeReader(r, h)\n\t}\n\tn, err := io.Copy(ioutil.Discard, r)\n\tif err != nil {\n\t\treturn data.FileMeta{}, err\n\t}\n\tm := data.FileMeta{Length: n, Hashes: make(data.Hashes, len(hashes))}\n\tfor hashAlgorithm, h := range hashes {\n\t\tm.Hashes[hashAlgorithm] = h.Sum(nil)\n\t}\n\treturn m, nil\n}\n\ntype versionedMeta struct {\n\tVersion int64 `json:\"version\"`\n}\n\nfunc generateVersionedFileMeta(r io.Reader, hashAlgorithms ...string) (data.FileMeta, int64, error) {\n\tb, err := ioutil.ReadAll(r)\n\tif err != nil {\n\t\treturn data.FileMeta{}, 0, err\n\t}\n\n\tm, err := GenerateFileMeta(bytes.NewReader(b), hashAlgorithms...)\n\tif err != nil {\n\t\treturn data.FileMeta{}, 0, err\n\t}\n\n\ts := data.Signed{}\n\tif err := json.Unmarshal(b, &s); err != nil {\n\t\treturn data.FileMeta{}, 0, err\n\t}\n\n\tvm := versionedMeta{}\n\tif err := json.Unmarshal(s.Signed, &vm); err != nil {\n\t\treturn data.FileMeta{}, 0, err\n\t}\n\n\treturn m, vm.Version, nil\n}\n\nfunc GenerateSnapshotFileMeta(r io.Reader, hashAlgorithms ...string) (data.SnapshotFileMeta, error) {\n\tm, v, err := generateVersionedFileMeta(r, hashAlgorithms...)\n\tif err != nil {\n\t\treturn data.SnapshotFileMeta{}, err\n\t}\n\treturn data.SnapshotFileMeta{\n\t\tFileMeta: m,\n\t\tVersion:  v,\n\t}, nil\n}\n\nfunc GenerateTargetFileMeta(r io.Reader, hashAlgorithms ...string) (data.TargetFileMeta, error) {\n\tm, err := GenerateFileMeta(r, hashAlgorithms...)\n\tif err != nil {\n\t\treturn data.TargetFileMeta{}, err\n\t}\n\treturn data.TargetFileMeta{\n\t\tFileMeta: m,\n\t}, nil\n}\n\nfunc GenerateTimestampFileMeta(r io.Reader, hashAlgorithms ...string) (data.TimestampFileMeta, error) {\n\tm, v, err := generateVersionedFileMeta(r, hashAlgorithms...)\n\tif err != nil {\n\t\treturn data.TimestampFileMeta{}, err\n\t}\n\treturn data.TimestampFileMeta{\n\t\tFileMeta: m,\n\t\tVersion:  v,\n\t}, nil\n}\n\nfunc NormalizeTarget(p string) string {\n\t// FIXME(TUF-0.9) TUF-1.0 is considering banning paths that begin with\n\t// a leading path separator, to avoid surprising behavior when joining\n\t// target and delgated paths. python-tuf raises an exception if any\n\t// path starts with '/', but since we need to be cross compatible with\n\t// TUF-0.9 we still need to support leading slashes. For now, we will\n\t// just strip them out, but eventually we should also consider turning\n\t// them into an error.\n\treturn strings.TrimPrefix(path.Join(\"/\", p), \"/\")\n}\n\nfunc VersionedPath(p string, version int64) string {\n\treturn path.Join(path.Dir(p), strconv.FormatInt(version, 10)+\".\"+path.Base(p))\n}\n\nfunc HashedPaths(p string, hashes data.Hashes) []string {\n\tpaths := make([]string, 0, len(hashes))\n\tfor _, hash := range hashes {\n\t\thashedPath := path.Join(path.Dir(p), hash.String()+\".\"+path.Base(p))\n\t\tpaths = append(paths, hashedPath)\n\t}\n\treturn paths\n}\n\nfunc AtomicallyWriteFile(filename string, data []byte, perm os.FileMode) error {\n\tdir, name := filepath.Split(filename)\n\tf, err := ioutil.TempFile(dir, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = f.Write(data)\n\tif err != nil {\n\t\tf.Close()\n\t\tos.Remove(f.Name())\n\t\treturn err\n\t}\n\n\tif err = f.Chmod(perm); err != nil {\n\t\tf.Close()\n\t\tos.Remove(f.Name())\n\t\treturn err\n\t}\n\n\tif err := f.Close(); err != nil {\n\t\tos.Remove(f.Name())\n\t\treturn err\n\t}\n\n\tif err := os.Rename(f.Name(), filename); err != nil {\n\t\tos.Remove(f.Name())\n\t\treturn err\n\t}\n\n\treturn nil\n}\n", "package verify\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"time\"\n)\n\nvar (\n\tErrMissingKey           = errors.New(\"tuf: missing key\")\n\tErrNoSignatures         = errors.New(\"tuf: data has no signatures\")\n\tErrInvalid              = errors.New(\"tuf: signature verification failed\")\n\tErrWrongMethod          = errors.New(\"tuf: invalid signature type\")\n\tErrWrongMetaType        = errors.New(\"tuf: meta file has wrong type\")\n\tErrExists               = errors.New(\"tuf: key already in db\")\n\tErrInvalidKey           = errors.New(\"tuf: invalid key\")\n\tErrInvalidRole          = errors.New(\"tuf: invalid role\")\n\tErrInvalidDelegatedRole = errors.New(\"tuf: invalid delegated role\")\n\tErrInvalidKeyID         = errors.New(\"tuf: invalid key id\")\n\tErrInvalidThreshold     = errors.New(\"tuf: invalid role threshold\")\n)\n\ntype ErrWrongID struct{}\n\nfunc (ErrWrongID) Error() string {\n\treturn \"tuf: key id mismatch\"\n}\n\ntype ErrUnknownRole struct {\n\tRole string\n}\n\nfunc (e ErrUnknownRole) Error() string {\n\treturn fmt.Sprintf(\"tuf: unknown role %q\", e.Role)\n}\n\ntype ErrExpired struct {\n\tExpired time.Time\n}\n\nfunc (e ErrExpired) Error() string {\n\treturn fmt.Sprintf(\"expired at %s\", e.Expired)\n}\n\ntype ErrLowVersion struct {\n\tActual  int64\n\tCurrent int64\n}\n\nfunc (e ErrLowVersion) Error() string {\n\treturn fmt.Sprintf(\"version %d is lower than current version %d\", e.Actual, e.Current)\n}\n\ntype ErrWrongVersion struct {\n\tGiven    int64\n\tExpected int64\n}\n\nfunc (e ErrWrongVersion) Error() string {\n\treturn fmt.Sprintf(\"version %d does not match the expected version %d\", e.Given, e.Expected)\n}\n\ntype ErrRoleThreshold struct {\n\tExpected int\n\tActual   int\n}\n\nfunc (e ErrRoleThreshold) Error() string {\n\treturn \"tuf: valid signatures did not meet threshold\"\n}\n", "package verify\n\nimport (\n\t\"encoding/json\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/secure-systems-lab/go-securesystemslib/cjson\"\n\t\"github.com/theupdateframework/go-tuf/data\"\n\t\"github.com/theupdateframework/go-tuf/internal/roles\"\n)\n\ntype signedMeta struct {\n\tType    string    `json:\"_type\"`\n\tExpires time.Time `json:\"expires\"`\n\tVersion int64     `json:\"version\"`\n}\n\nfunc (db *DB) VerifyIgnoreExpiredCheck(s *data.Signed, role string, minVersion int64) error {\n\tif err := db.VerifySignatures(s, role); err != nil {\n\t\treturn err\n\t}\n\n\tsm := &signedMeta{}\n\tif err := json.Unmarshal(s.Signed, sm); err != nil {\n\t\treturn err\n\t}\n\n\tif roles.IsTopLevelRole(role) {\n\t\t// Top-level roles can only sign metadata of the same type (e.g. snapshot\n\t\t// metadata must be signed by the snapshot role).\n\t\tif !strings.EqualFold(sm.Type, role) {\n\t\t\treturn ErrWrongMetaType\n\t\t}\n\t} else {\n\t\t// Delegated (non-top-level) roles may only sign targets metadata.\n\t\tif strings.ToLower(sm.Type) != \"targets\" {\n\t\t\treturn ErrWrongMetaType\n\t\t}\n\t}\n\n\tif sm.Version < minVersion {\n\t\treturn ErrLowVersion{sm.Version, minVersion}\n\t}\n\n\treturn nil\n}\n\nfunc (db *DB) Verify(s *data.Signed, role string, minVersion int64) error {\n\n\terr := db.VerifyIgnoreExpiredCheck(s, role, minVersion)\n\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsm := &signedMeta{}\n\tif err := json.Unmarshal(s.Signed, sm); err != nil {\n\t\treturn err\n\t}\n\n\tif IsExpired(sm.Expires) {\n\t\treturn ErrExpired{sm.Expires}\n\t}\n\n\treturn nil\n}\n\nvar IsExpired = func(t time.Time) bool {\n\treturn time.Until(t) <= 0\n}\n\nfunc (db *DB) VerifySignatures(s *data.Signed, role string) error {\n\tif len(s.Signatures) == 0 {\n\t\treturn ErrNoSignatures\n\t}\n\n\troleData := db.GetRole(role)\n\tif roleData == nil {\n\t\treturn ErrUnknownRole{role}\n\t}\n\n\tvar decoded map[string]interface{}\n\tif err := json.Unmarshal(s.Signed, &decoded); err != nil {\n\t\treturn err\n\t}\n\tmsg, err := cjson.EncodeCanonical(decoded)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Verify that a threshold of keys signed the data. Since keys can have\n\t// multiple key ids, we need to protect against multiple attached\n\t// signatures that just differ on the key id.\n\tseen := make(map[string]struct{})\n\tvalid := 0\n\tfor _, sig := range s.Signatures {\n\t\tif !roleData.ValidKey(sig.KeyID) {\n\t\t\tcontinue\n\t\t}\n\t\tverifier, err := db.GetVerifier(sig.KeyID)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tif err := verifier.Verify(msg, sig.Signature); err != nil {\n\t\t\treturn ErrInvalid\n\t\t}\n\n\t\t// Only consider this key valid if we haven't seen any of it's\n\t\t// key ids before.\n\t\tif _, ok := seen[sig.KeyID]; !ok {\n\t\t\tfor _, id := range verifier.MarshalPublicKey().IDs() {\n\t\t\t\tseen[id] = struct{}{}\n\t\t\t}\n\n\t\t\tvalid++\n\t\t}\n\t}\n\tif valid < roleData.Threshold {\n\t\treturn ErrRoleThreshold{roleData.Threshold, valid}\n\t}\n\n\treturn nil\n}\n\nfunc (db *DB) Unmarshal(b []byte, v interface{}, role string, minVersion int64) error {\n\ts := &data.Signed{}\n\tif err := json.Unmarshal(b, s); err != nil {\n\t\treturn err\n\t}\n\tif err := db.Verify(s, role, minVersion); err != nil {\n\t\treturn err\n\t}\n\treturn json.Unmarshal(s.Signed, v)\n}\n\n// UnmarshalExpired is exactly like Unmarshal except ignores expired timestamp error.\nfunc (db *DB) UnmarshalIgnoreExpired(b []byte, v interface{}, role string, minVersion int64) error {\n\ts := &data.Signed{}\n\tif err := json.Unmarshal(b, s); err != nil {\n\t\treturn err\n\t}\n\t// Note: If verification fails, then we wont attempt to unmarshal\n\t// unless when verification error is errExpired.\n\tverifyErr := db.Verify(s, role, minVersion)\n\tif verifyErr != nil {\n\t\tif _, ok := verifyErr.(ErrExpired); !ok {\n\t\t\treturn verifyErr\n\t\t}\n\t}\n\treturn json.Unmarshal(s.Signed, v)\n}\n\nfunc (db *DB) UnmarshalTrusted(b []byte, v interface{}, role string) error {\n\ts := &data.Signed{}\n\tif err := json.Unmarshal(b, s); err != nil {\n\t\treturn err\n\t}\n\tif err := db.VerifySignatures(s, role); err != nil {\n\t\treturn err\n\t}\n\treturn json.Unmarshal(s.Signed, v)\n}\n"], "fixing_code": ["package client\n\nimport (\n\t\"bytes\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"io/ioutil\"\n\n\t\"github.com/theupdateframework/go-tuf/data\"\n\t\"github.com/theupdateframework/go-tuf/util\"\n\t\"github.com/theupdateframework/go-tuf/verify\"\n)\n\nconst (\n\t// This is the upper limit in bytes we will use to limit the download\n\t// size of the root/timestamp roles, since we might not don't know how\n\t// big it is.\n\tdefaultRootDownloadLimit      = 512000\n\tdefaultTimestampDownloadLimit = 16384\n\tdefaultMaxDelegations         = 32\n\tdefaultMaxRootRotations       = 1e3\n)\n\n// LocalStore is local storage for downloaded top-level metadata.\ntype LocalStore interface {\n\tio.Closer\n\n\t// GetMeta returns top-level metadata from local storage. The keys are\n\t// in the form `ROLE.json`, with ROLE being a valid top-level role.\n\tGetMeta() (map[string]json.RawMessage, error)\n\n\t// SetMeta persists the given top-level metadata in local storage, the\n\t// name taking the same format as the keys returned by GetMeta.\n\tSetMeta(name string, meta json.RawMessage) error\n\n\t// DeleteMeta deletes a given metadata.\n\tDeleteMeta(name string) error\n}\n\n// RemoteStore downloads top-level metadata and target files from a remote\n// repository.\ntype RemoteStore interface {\n\t// GetMeta downloads the given metadata from remote storage.\n\t//\n\t// `name` is the filename of the metadata (e.g. \"root.json\")\n\t//\n\t// `err` is ErrNotFound if the given file does not exist.\n\t//\n\t// `size` is the size of the stream, -1 indicating an unknown length.\n\tGetMeta(name string) (stream io.ReadCloser, size int64, err error)\n\n\t// GetTarget downloads the given target file from remote storage.\n\t//\n\t// `path` is the path of the file relative to the root of the remote\n\t//        targets directory (e.g. \"/path/to/file.txt\").\n\t//\n\t// `err` is ErrNotFound if the given file does not exist.\n\t//\n\t// `size` is the size of the stream, -1 indicating an unknown length.\n\tGetTarget(path string) (stream io.ReadCloser, size int64, err error)\n}\n\n// Client provides methods for fetching updates from a remote repository and\n// downloading remote target files.\ntype Client struct {\n\tlocal  LocalStore\n\tremote RemoteStore\n\n\t// The following four fields represent the versions of metatdata either\n\t// from local storage or from recently downloaded metadata\n\trootVer      int64\n\ttargetsVer   int64\n\tsnapshotVer  int64\n\ttimestampVer int64\n\n\t// targets is the list of available targets, either from local storage\n\t// or from recently downloaded targets metadata\n\ttargets data.TargetFiles\n\n\t// localMeta is the raw metadata from local storage and is used to\n\t// check whether remote metadata is present locally\n\tlocalMeta map[string]json.RawMessage\n\n\t// db is a key DB used for verifying metadata\n\tdb *verify.DB\n\n\t// consistentSnapshot indicates whether the remote storage is using\n\t// consistent snapshots (as specified in root.json)\n\tconsistentSnapshot bool\n\n\t// MaxDelegations limits by default the number of delegations visited for any\n\t// target\n\tMaxDelegations int\n\n\t// MaxRootRotations limits the number of downloaded roots in 1.0.19 root updater\n\tMaxRootRotations int\n}\n\nfunc NewClient(local LocalStore, remote RemoteStore) *Client {\n\treturn &Client{\n\t\tlocal:            local,\n\t\tremote:           remote,\n\t\tMaxDelegations:   defaultMaxDelegations,\n\t\tMaxRootRotations: defaultMaxRootRotations,\n\t}\n}\n\n// Init initializes a local repository.\n//\n// The latest root.json is fetched from remote storage, verified using rootKeys\n// and threshold, and then saved in local storage. It is expected that rootKeys\n// were securely distributed with the software being updated.\n//\n// Deprecated: Use c.InitLocal and c.Update to initialize a local repository.\nfunc (c *Client) Init(rootKeys []*data.PublicKey, threshold int) error {\n\tif len(rootKeys) < threshold {\n\t\treturn ErrInsufficientKeys\n\t}\n\trootJSON, err := c.downloadMetaUnsafe(\"root.json\", defaultRootDownloadLimit)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// create a new key database, and add all the public `rootKeys` to it.\n\tc.db = verify.NewDB()\n\trootKeyIDs := make([]string, 0, len(rootKeys))\n\tfor _, key := range rootKeys {\n\t\tfor _, id := range key.IDs() {\n\t\t\trootKeyIDs = append(rootKeyIDs, id)\n\t\t\tif err := c.db.AddKey(id, key); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\t// add a mock \"root\" role that trusts the passed in key ids. These keys\n\t// will be used to verify the `root.json` we just fetched.\n\trole := &data.Role{Threshold: threshold, KeyIDs: rootKeyIDs}\n\tif err := c.db.AddRole(\"root\", role); err != nil {\n\t\treturn err\n\t}\n\n\t// verify that the new root is valid.\n\tif err := c.decodeRoot(rootJSON); err != nil {\n\t\treturn err\n\t}\n\n\treturn c.local.SetMeta(\"root.json\", rootJSON)\n}\n\n// InitLocal initializes a local repository from root metadata.\n//\n// The root's keys are extracted from the root and saved in local storage.\n// Root expiration is not checked.\n// It is expected that rootJSON was securely distributed with the software\n// being updated.\nfunc (c *Client) InitLocal(rootJSON []byte) error {\n\terr := c.loadAndVerifyRootMeta(rootJSON, true /*ignoreExpiredCheck*/)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn c.local.SetMeta(\"root.json\", rootJSON)\n}\n\n// Update downloads and verifies remote metadata and returns updated targets.\n// It always performs root update (5.2 and 5.3) section of the v1.0.19 spec.\n//\n// https://theupdateframework.github.io/specification/v1.0.19/index.html#load-trusted-root\nfunc (c *Client) Update() (data.TargetFiles, error) {\n\tif err := c.UpdateRoots(); err != nil {\n\t\tif _, ok := err.(verify.ErrExpired); ok {\n\t\t\t// For backward compatibility, we wrap the ErrExpired inside\n\t\t\t// ErrDecodeFailed.\n\t\t\treturn nil, ErrDecodeFailed{\"root.json\", err}\n\t\t}\n\t\treturn nil, err\n\t}\n\n\t// Load trusted metadata files, if any, and verify them against the latest root\n\tc.getLocalMeta()\n\n\t// 5.4.1 - Download the timestamp metadata\n\ttimestampJSON, err := c.downloadMetaUnsafe(\"timestamp.json\", defaultTimestampDownloadLimit)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// 5.4.(2,3 and 4) - Verify timestamp against various attacks\n\t// Returns the extracted snapshot metadata\n\tsnapshotMeta, err := c.decodeTimestamp(timestampJSON)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// 5.4.5 - Persist the timestamp metadata\n\tif err := c.local.SetMeta(\"timestamp.json\", timestampJSON); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// 5.5.1 - Download snapshot metadata\n\t// 5.5.2 and 5.5.4 - Check against timestamp role's snapshot hash and version\n\tsnapshotJSON, err := c.downloadMetaFromTimestamp(\"snapshot.json\", snapshotMeta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// 5.5.(3,5 and 6) - Verify snapshot against various attacks\n\t// Returns the extracted metadata files\n\tsnapshotMetas, err := c.decodeSnapshot(snapshotJSON)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// 5.5.7 - Persist snapshot metadata\n\tif err := c.local.SetMeta(\"snapshot.json\", snapshotJSON); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// If we don't have the targets.json, download it, determine updated\n\t// targets and save targets.json in local storage\n\tvar updatedTargets data.TargetFiles\n\ttargetsMeta := snapshotMetas[\"targets.json\"]\n\tif !c.hasMetaFromSnapshot(\"targets.json\", targetsMeta) {\n\t\t// 5.6.1 - Download the top-level targets metadata file\n\t\t// 5.6.2 and 5.6.4 - Check against snapshot role's targets hash and version\n\t\ttargetsJSON, err := c.downloadMetaFromSnapshot(\"targets.json\", targetsMeta)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// 5.6.(3 and 5) - Verify signatures and check against freeze attack\n\t\tupdatedTargets, err = c.decodeTargets(targetsJSON)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// 5.6.6 - Persist targets metadata\n\t\tif err := c.local.SetMeta(\"targets.json\", targetsJSON); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn updatedTargets, nil\n}\n\nfunc (c *Client) UpdateRoots() error {\n\t// https://theupdateframework.github.io/specification/v1.0.19/index.html#load-trusted-root\n\t// 5.2 Load the trusted root metadata file. We assume that a good,\n\t// trusted copy of this file was shipped with the package manager\n\t// or software updater using an out-of-band process.\n\tif err := c.loadAndVerifyLocalRootMeta( /*ignoreExpiredCheck=*/ true); err != nil {\n\t\treturn err\n\t}\n\tm, err := c.local.GetMeta()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\ttype KeyInfo struct {\n\t\tKeyIDs    map[string]bool\n\t\tThreshold int\n\t}\n\n\t// Prepare for 5.3.11: If the timestamp and / or snapshot keys have been rotated,\n\t// then delete the trusted timestamp and snapshot metadata files.\n\tgetKeyInfo := func(role string) KeyInfo {\n\t\tkeyIDs := make(map[string]bool)\n\t\tfor k := range c.db.GetRole(role).KeyIDs {\n\t\t\tkeyIDs[k] = true\n\t\t}\n\t\treturn KeyInfo{keyIDs, c.db.GetRole(role).Threshold}\n\t}\n\n\t// The nonRootKeyInfo looks like this:\n\t// {\n\t//\t\"timestamp\": {KeyIDs={\"KEYID1\": true, \"KEYID2\": true}, Threshold=2},\n\t//\t\"snapshot\": {KeyIDs={\"KEYID3\": true}, Threshold=1},\n\t//\t\"targets\": {KeyIDs={\"KEYID4\": true, \"KEYID5\": true, \"KEYID6\": true}, Threshold=1}\n\t// }\n\n\tnonRootKeyInfo := map[string]KeyInfo{\"timestamp\": {}, \"snapshot\": {}, \"targets\": {}}\n\tfor k := range nonRootKeyInfo {\n\t\tnonRootKeyInfo[k] = getKeyInfo(k)\n\t}\n\n\t// 5.3.1 Temorarily turn on the consistent snapshots in order to download\n\t// versioned root metadata files as described next.\n\tconsistentSnapshot := c.consistentSnapshot\n\tc.consistentSnapshot = true\n\n\tnRootMetadata := m[\"root.json\"]\n\n\t// https://theupdateframework.github.io/specification/v1.0.19/index.html#update-root\n\n\t// 5.3.1 Since it may now be signed using entirely different keys,\n\t// the client MUST somehow be able to establish a trusted line of\n\t// continuity to the latest set of keys (see \u00a7\u202f6.1 Key\n\t// management and migration). To do so, the client MUST\n\t// download intermediate root metadata files, until the\n\t// latest available one is reached. Therefore, it MUST\n\t// temporarily turn on consistent snapshots in order to\n\t// download versioned root metadata files as described next.\n\n\t// This loop returns on error or breaks after downloading the lastest root metadata.\n\t// 5.3.2 Let N denote the version number of the trusted root metadata file.\n\tfor i := 0; i < c.MaxRootRotations; i++ {\n\t\t// 5.3.3 Try downloading version nPlusOne of the root metadata file.\n\t\t// NOTE: as a side effect, we do update c.rootVer to nPlusOne between iterations.\n\t\tnPlusOne := c.rootVer + 1\n\t\tnPlusOneRootPath := util.VersionedPath(\"root.json\", nPlusOne)\n\t\tnPlusOneRootMetadata, err := c.downloadMetaUnsafe(nPlusOneRootPath, defaultRootDownloadLimit)\n\n\t\tif err != nil {\n\t\t\tif _, ok := err.(ErrMissingRemoteMetadata); ok {\n\t\t\t\t// stop when the next root can't be downloaded\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\n\t\t// 5.3.4 Check for an arbitrary software attack.\n\t\t// 5.3.4.1 Check that N signed N+1\n\t\tnPlusOneRootMetadataSigned, err := c.verifyRoot(nRootMetadata, nPlusOneRootMetadata)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// 5.3.4.2 check that N+1 signed itself.\n\t\tif _, err := c.verifyRoot(nPlusOneRootMetadata, nPlusOneRootMetadata); err != nil {\n\t\t\t// 5.3.6 Note that the expiration of the new (intermediate) root\n\t\t\t// metadata file does not matter yet, because we will check for\n\t\t\t// it in step 5.3.10.\n\t\t\treturn err\n\t\t}\n\n\t\t// 5.3.5 Check for a rollback attack. Here, we check that nPlusOneRootMetadataSigned.version == nPlusOne.\n\t\tif nPlusOneRootMetadataSigned.Version != nPlusOne {\n\t\t\treturn verify.ErrWrongVersion{\n\t\t\t\tGiven:    nPlusOneRootMetadataSigned.Version,\n\t\t\t\tExpected: nPlusOne,\n\t\t\t}\n\t\t}\n\n\t\t// 5.3.7 Set the trusted root metadata file to the new root metadata file.\n\t\tc.rootVer = nPlusOneRootMetadataSigned.Version\n\t\t// NOTE: following up on 5.3.1, we want to always have consistent snapshots on for the duration\n\t\t// of root rotation. AFTER the rotation is over, we will set it to the value of the last root.\n\t\tconsistentSnapshot = nPlusOneRootMetadataSigned.ConsistentSnapshot\n\t\t// 5.3.8 Persist root metadata. The client MUST write the file to non-volatile storage as FILENAME.EXT (e.g. root.json).\n\t\t// NOTE: Internally, setMeta stores metadata in LevelDB in a persistent manner.\n\t\tif err := c.local.SetMeta(\"root.json\", nPlusOneRootMetadata); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tnRootMetadata = nPlusOneRootMetadata\n\t\t// 5.3.9 Repeat steps 5.3.2 to 5.3.9\n\n\t} // End of the for loop.\n\n\t// 5.3.10 Check for a freeze attack.\n\t// NOTE: This will check for any, including freeze, attack.\n\tif err := c.loadAndVerifyLocalRootMeta( /*ignoreExpiredCheck=*/ false); err != nil {\n\t\treturn err\n\t}\n\n\tcountDeleted := func(s1 map[string]bool, s2 map[string]bool) int {\n\t\tc := 0\n\t\tfor k := range s1 {\n\t\t\tif _, ok := s2[k]; !ok {\n\t\t\t\tc++\n\t\t\t}\n\t\t}\n\t\treturn c\n\t}\n\n\t// 5.3.11 To recover from fast-forward attack, certain metadata files need\n\t// to be deleted if a threshold of keys are revoked.\n\t// List of metadata that should be deleted per role if a threshold of keys\n\t// are revoked:\n\t// (based on the ongoing PR: https://github.com/mnm678/specification/tree/e50151d9df632299ddea364c4f44fe8ca9c10184)\n\t// timestamp -> delete timestamp.json\n\t// snapshot ->  delete timestamp.json and snapshot.json\n\t// targets ->   delete snapshot.json and targets.json\n\t//\n\t// nonRootKeyInfo contains the keys and thresholds from root.json\n\t// that were on disk before the root update process begins.\n\tfor topLevelRolename := range nonRootKeyInfo {\n\t\t// ki contains the keys and thresholds from the latest downloaded root.json.\n\t\tki := getKeyInfo(topLevelRolename)\n\t\tif countDeleted(nonRootKeyInfo[topLevelRolename].KeyIDs, ki.KeyIDs) >= nonRootKeyInfo[topLevelRolename].Threshold {\n\t\t\tdeleteMeta := map[string][]string{\n\t\t\t\t\"timestamp\": {\"timestamp.json\"},\n\t\t\t\t\"snapshot\":  {\"timestamp.json\", \"snapshot.json\"},\n\t\t\t\t\"targets\":   {\"snapshot.json\", \"targets.json\"},\n\t\t\t}\n\n\t\t\tfor _, r := range deleteMeta[topLevelRolename] {\n\t\t\t\tc.local.DeleteMeta(r)\n\t\t\t}\n\t\t}\n\t}\n\n\t// 5.3.12 Set whether consistent snapshots are used as per the trusted root metadata file.\n\tc.consistentSnapshot = consistentSnapshot\n\treturn nil\n}\n\n// getLocalMeta decodes and verifies metadata from local storage.\n// The verification of local files is purely for consistency, if an attacker\n// has compromised the local storage, there is no guarantee it can be trusted.\n// Before trying to load the metadata files, it clears the in-memory copy of the local metadata.\n// This is to insure that all of the loaded metadata files at the end are indeed verified by the latest root.\n// If some of the metadata files fail to load it will proceed with trying to load the rest,\n// but still return an error at the end, if such occurred. Otherwise returns nil.\nfunc (c *Client) getLocalMeta() error {\n\tvar retErr error\n\tloadFailed := false\n\t// Clear the in-memory copy of the local metadata. The goal is to reload and take into account\n\t// only the metadata files that are verified by the latest root. Otherwise, their content should\n\t// be ignored.\n\tc.localMeta = make(map[string]json.RawMessage)\n\n\t// Load the latest root meta\n\tif err := c.loadAndVerifyLocalRootMeta( /*ignoreExpiredCheck=*/ false); err != nil {\n\t\treturn err\n\t}\n\n\t// Load into memory the existing meta, if any, from the local storage\n\tmeta, err := c.local.GetMeta()\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\t// Verify the top-level metadata (timestamp, snapshot and targets) against the latest root and load it, if okay\n\tif timestampJSON, ok := meta[\"timestamp.json\"]; ok {\n\t\ttimestamp := &data.Timestamp{}\n\t\tif err := c.db.UnmarshalTrusted(timestampJSON, timestamp, \"timestamp\"); err != nil {\n\t\t\tloadFailed = true\n\t\t\tretErr = err\n\t\t} else {\n\t\t\tc.localMeta[\"timestamp.json\"] = meta[\"timestamp.json\"]\n\t\t\tc.timestampVer = timestamp.Version\n\t\t}\n\t}\n\n\tif snapshotJSON, ok := meta[\"snapshot.json\"]; ok {\n\t\tsnapshot := &data.Snapshot{}\n\t\tif err := c.db.UnmarshalTrusted(snapshotJSON, snapshot, \"snapshot\"); err != nil {\n\t\t\tloadFailed = true\n\t\t\tretErr = err\n\t\t} else {\n\t\t\tc.localMeta[\"snapshot.json\"] = meta[\"snapshot.json\"]\n\t\t\tc.snapshotVer = snapshot.Version\n\t\t}\n\t}\n\n\tif targetsJSON, ok := meta[\"targets.json\"]; ok {\n\t\ttargets := &data.Targets{}\n\t\tif err := c.db.UnmarshalTrusted(targetsJSON, targets, \"targets\"); err != nil {\n\t\t\tloadFailed = true\n\t\t\tretErr = err\n\t\t} else {\n\t\t\tc.localMeta[\"targets.json\"] = meta[\"targets.json\"]\n\t\t\tc.targetsVer = targets.Version\n\t\t\t// FIXME(TUF-0.9) temporarily support files with leading path separators.\n\t\t\t// c.targets = targets.Targets\n\t\t\tc.loadTargets(targets.Targets)\n\t\t}\n\t}\n\tif loadFailed {\n\t\t// If any of the metadata failed to be verified, return the reason for that failure\n\t\treturn retErr\n\t}\n\treturn nil\n}\n\n// loadAndVerifyLocalRootMeta decodes and verifies root metadata from\n// local storage and loads the top-level keys. This method first clears\n// the DB for top-level keys and then loads the new keys.\nfunc (c *Client) loadAndVerifyLocalRootMeta(ignoreExpiredCheck bool) error {\n\tmeta, err := c.local.GetMeta()\n\tif err != nil {\n\t\treturn err\n\t}\n\trootJSON, ok := meta[\"root.json\"]\n\tif !ok {\n\t\treturn ErrNoRootKeys\n\t}\n\treturn c.loadAndVerifyRootMeta(rootJSON, ignoreExpiredCheck)\n}\n\n// loadAndVerifyRootMeta decodes and verifies root metadata and loads the top-level keys.\n// This method first clears the DB for top-level keys and then loads the new keys.\nfunc (c *Client) loadAndVerifyRootMeta(rootJSON []byte, ignoreExpiredCheck bool) error {\n\t// unmarshal root.json without verifying as we need the root\n\t// keys first\n\ts := &data.Signed{}\n\tif err := json.Unmarshal(rootJSON, s); err != nil {\n\t\treturn err\n\t}\n\troot := &data.Root{}\n\tif err := json.Unmarshal(s.Signed, root); err != nil {\n\t\treturn err\n\t}\n\tndb := verify.NewDB()\n\tfor id, k := range root.Keys {\n\t\tif err := ndb.AddKey(id, k); err != nil {\n\t\t\t// TUF is considering in TAP-12 removing the\n\t\t\t// requirement that the keyid hash algorithm be derived\n\t\t\t// from the public key. So to be forwards compatible,\n\t\t\t// we ignore `ErrWrongID` errors.\n\t\t\t//\n\t\t\t// TAP-12: https://github.com/theupdateframework/taps/blob/master/tap12.md\n\t\t\tif _, ok := err.(verify.ErrWrongID); !ok {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\tfor name, role := range root.Roles {\n\t\tif err := ndb.AddRole(name, role); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t// Any trusted local root metadata version must be greater than 0.\n\tif ignoreExpiredCheck {\n\t\tif err := ndb.VerifyIgnoreExpiredCheck(s, \"root\", 0); err != nil {\n\t\t\treturn err\n\t\t}\n\t} else {\n\t\tif err := ndb.Verify(s, \"root\", 0); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tc.consistentSnapshot = root.ConsistentSnapshot\n\tc.rootVer = root.Version\n\tc.db = ndb\n\treturn nil\n}\n\n// verifyRoot verifies Signed section of the bJSON\n// using verification keys in aJSON.\nfunc (c *Client) verifyRoot(aJSON []byte, bJSON []byte) (*data.Root, error) {\n\taSigned := &data.Signed{}\n\tif err := json.Unmarshal(aJSON, aSigned); err != nil {\n\t\treturn nil, err\n\t}\n\taRoot := &data.Root{}\n\tif err := json.Unmarshal(aSigned.Signed, aRoot); err != nil {\n\t\treturn nil, err\n\t}\n\n\tbSigned := &data.Signed{}\n\tif err := json.Unmarshal(bJSON, bSigned); err != nil {\n\t\treturn nil, err\n\t}\n\tbRoot := &data.Root{}\n\tif err := json.Unmarshal(bSigned.Signed, bRoot); err != nil {\n\t\treturn nil, err\n\t}\n\n\tndb := verify.NewDB()\n\tfor id, k := range aRoot.Keys {\n\t\tif err := ndb.AddKey(id, k); err != nil {\n\t\t\t// TUF is considering in TAP-12 removing the\n\t\t\t// requirement that the keyid hash algorithm be derived\n\t\t\t// from the public key. So to be forwards compatible,\n\t\t\t// we ignore `ErrWrongID` errors.\n\t\t\t//\n\t\t\t// TAP-12: https://github.com/theupdateframework/taps/blob/master/tap12.md\n\t\t\tif _, ok := err.(verify.ErrWrongID); !ok {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\tfor name, role := range aRoot.Roles {\n\t\tif err := ndb.AddRole(name, role); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif err := ndb.VerifySignatures(bSigned, \"root\"); err != nil {\n\t\treturn nil, err\n\t}\n\treturn bRoot, nil\n}\n\n// FIXME(TUF-0.9) TUF is considering removing support for target files starting\n// with a leading path separator. In order to be backwards compatible, we'll\n// just remove leading separators for now.\nfunc (c *Client) loadTargets(targets data.TargetFiles) {\n\tc.targets = make(data.TargetFiles)\n\tfor name, meta := range targets {\n\t\tc.targets[name] = meta\n\t\tc.targets[util.NormalizeTarget(name)] = meta\n\t}\n}\n\n// downloadMetaUnsafe downloads top-level metadata from remote storage without\n// verifying it's length and hashes (used for example to download timestamp.json\n// which has unknown size). It will download at most maxMetaSize bytes.\nfunc (c *Client) downloadMetaUnsafe(name string, maxMetaSize int64) ([]byte, error) {\n\tr, size, err := c.remote.GetMeta(name)\n\tif err != nil {\n\t\tif IsNotFound(err) {\n\t\t\treturn nil, ErrMissingRemoteMetadata{name}\n\t\t}\n\t\treturn nil, ErrDownloadFailed{name, err}\n\t}\n\tdefer r.Close()\n\n\t// return ErrMetaTooLarge if the reported size is greater than maxMetaSize\n\tif size > maxMetaSize {\n\t\treturn nil, ErrMetaTooLarge{name, size, maxMetaSize}\n\t}\n\n\t// although the size has been checked above, use a LimitReader in case\n\t// the reported size is inaccurate, or size is -1 which indicates an\n\t// unknown length\n\treturn ioutil.ReadAll(io.LimitReader(r, maxMetaSize))\n}\n\n// remoteGetFunc is the type of function the download method uses to download\n// remote files\ntype remoteGetFunc func(string) (io.ReadCloser, int64, error)\n\n// downloadHashed tries to download the hashed prefixed version of the file.\nfunc (c *Client) downloadHashed(file string, get remoteGetFunc, hashes data.Hashes) (io.ReadCloser, int64, error) {\n\t// try each hashed path in turn, and either return the contents,\n\t// try the next one if a 404 is returned, or return an error\n\tfor _, path := range util.HashedPaths(file, hashes) {\n\t\tr, size, err := get(path)\n\t\tif err != nil {\n\t\t\tif IsNotFound(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn nil, 0, err\n\t\t}\n\t\treturn r, size, nil\n\t}\n\treturn nil, 0, ErrNotFound{file}\n}\n\n// download downloads the given target file from remote storage using the get\n// function, adding hashes to the path if consistent snapshots are in use\nfunc (c *Client) downloadTarget(file string, get remoteGetFunc, hashes data.Hashes) (io.ReadCloser, int64, error) {\n\tif c.consistentSnapshot {\n\t\treturn c.downloadHashed(file, get, hashes)\n\t} else {\n\t\treturn get(file)\n\t}\n}\n\n// downloadVersionedMeta downloads top-level metadata from remote storage and\n// verifies it using the given file metadata.\nfunc (c *Client) downloadMeta(name string, version int64, m data.FileMeta) ([]byte, error) {\n\tr, size, err := func() (io.ReadCloser, int64, error) {\n\t\tif c.consistentSnapshot {\n\t\t\tpath := util.VersionedPath(name, version)\n\t\t\tr, size, err := c.remote.GetMeta(path)\n\t\t\tif err == nil {\n\t\t\t\treturn r, size, nil\n\t\t\t}\n\n\t\t\treturn nil, 0, err\n\t\t} else {\n\t\t\treturn c.remote.GetMeta(name)\n\t\t}\n\t}()\n\tif err != nil {\n\t\tif IsNotFound(err) {\n\t\t\treturn nil, ErrMissingRemoteMetadata{name}\n\t\t}\n\t\treturn nil, err\n\t}\n\tdefer r.Close()\n\n\t// return ErrWrongSize if the reported size is known and incorrect\n\tvar stream io.Reader\n\tif m.Length != 0 {\n\t\tif size >= 0 && size != m.Length {\n\t\t\treturn nil, ErrWrongSize{name, size, m.Length}\n\t\t}\n\n\t\t// wrap the data in a LimitReader so we download at most m.Length bytes\n\t\tstream = io.LimitReader(r, m.Length)\n\t} else {\n\t\tstream = r\n\t}\n\n\treturn ioutil.ReadAll(stream)\n}\n\nfunc (c *Client) downloadMetaFromSnapshot(name string, m data.SnapshotFileMeta) ([]byte, error) {\n\tb, err := c.downloadMeta(name, m.Version, m.FileMeta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmeta, err := util.GenerateSnapshotFileMeta(bytes.NewReader(b), m.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// 5.6.2 and 5.6.4 - Check against snapshot role's targets hash and version\n\tif err := util.SnapshotFileMetaEqual(meta, m); err != nil {\n\t\treturn nil, ErrDownloadFailed{name, err}\n\t}\n\treturn b, nil\n}\n\nfunc (c *Client) downloadMetaFromTimestamp(name string, m data.TimestampFileMeta) ([]byte, error) {\n\tb, err := c.downloadMeta(name, m.Version, m.FileMeta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmeta, err := util.GenerateTimestampFileMeta(bytes.NewReader(b), m.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// 5.5.2 and 5.5.4 - Check against timestamp role's snapshot hash and version\n\tif err := util.TimestampFileMetaEqual(meta, m); err != nil {\n\t\treturn nil, ErrDownloadFailed{name, err}\n\t}\n\treturn b, nil\n}\n\n// decodeRoot decodes and verifies root metadata.\nfunc (c *Client) decodeRoot(b json.RawMessage) error {\n\troot := &data.Root{}\n\tif err := c.db.Unmarshal(b, root, \"root\", c.rootVer); err != nil {\n\t\treturn ErrDecodeFailed{\"root.json\", err}\n\t}\n\tc.rootVer = root.Version\n\tc.consistentSnapshot = root.ConsistentSnapshot\n\treturn nil\n}\n\n// decodeSnapshot decodes and verifies snapshot metadata, and returns the new\n// root and targets file meta.\nfunc (c *Client) decodeSnapshot(b json.RawMessage) (data.SnapshotFiles, error) {\n\tsnapshot := &data.Snapshot{}\n\t// 5.5.(3 and 6) - Verify it's signed correctly and it's not expired\n\tif err := c.db.Unmarshal(b, snapshot, \"snapshot\", c.snapshotVer); err != nil {\n\t\treturn data.SnapshotFiles{}, ErrDecodeFailed{\"snapshot.json\", err}\n\t}\n\t// 5.5.5 - Check for top-level targets rollback attack\n\t// Verify explicitly that current targets meta version is less than or equal to the new one\n\tif snapshot.Meta[\"targets.json\"].Version < c.targetsVer {\n\t\treturn data.SnapshotFiles{}, verify.ErrLowVersion{Actual: snapshot.Meta[\"targets.json\"].Version, Current: c.targetsVer}\n\t}\n\n\t// 5.5.5 - Get the local/trusted snapshot metadata, if any, and check all target metafiles against rollback attack\n\t// In case the local snapshot metadata was not verified by the keys in the latest root during getLocalMeta(),\n\t// snapshot.json won't be present in c.localMeta and thus this check will not be processed.\n\tif snapshotJSON, ok := c.localMeta[\"snapshot.json\"]; ok {\n\t\tcurrentSnapshot := &data.Snapshot{}\n\t\tif err := c.db.UnmarshalTrusted(snapshotJSON, currentSnapshot, \"snapshot\"); err != nil {\n\t\t\treturn data.SnapshotFiles{}, err\n\t\t}\n\t\t// 5.5.5 - Check for rollback attacks in both top-level and delegated targets roles (note that the Meta object includes both)\n\t\tfor path, local := range currentSnapshot.Meta {\n\t\t\tif newMeta, ok := snapshot.Meta[path]; ok {\n\t\t\t\t// 5.5.5 - Check for rollback attack\n\t\t\t\tif newMeta.Version < local.Version {\n\t\t\t\t\treturn data.SnapshotFiles{}, verify.ErrLowVersion{Actual: newMeta.Version, Current: local.Version}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// 5.5.5 - Abort the update if a target file has been removed from the new snapshot file\n\t\t\t\treturn data.SnapshotFiles{}, verify.ErrMissingTargetFile\n\t\t\t}\n\t\t}\n\t}\n\t// At this point we can trust the new snapshot, the top-level targets, and any delegated targets versions it refers to\n\t// so we can update the client's trusted versions and proceed with persisting the new snapshot metadata\n\t// c.snapshotVer was already set when we verified the timestamp metadata\n\tc.targetsVer = snapshot.Meta[\"targets.json\"].Version\n\treturn snapshot.Meta, nil\n}\n\n// decodeTargets decodes and verifies targets metadata, sets c.targets and\n// returns updated targets.\nfunc (c *Client) decodeTargets(b json.RawMessage) (data.TargetFiles, error) {\n\ttargets := &data.Targets{}\n\t// 5.6.(3 and 5) - Verify signatures and check against freeze attack\n\tif err := c.db.Unmarshal(b, targets, \"targets\", c.targetsVer); err != nil {\n\t\treturn nil, ErrDecodeFailed{\"targets.json\", err}\n\t}\n\t// Generate a list with the updated targets\n\tupdatedTargets := make(data.TargetFiles)\n\tfor path, meta := range targets.Targets {\n\t\tif local, ok := c.targets[path]; ok {\n\t\t\tif err := util.TargetFileMetaEqual(local, meta); err == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tupdatedTargets[path] = meta\n\t}\n\t// c.targetsVer was already updated when we verified the snapshot metadata\n\t// FIXME(TUF-0.9) temporarily support files with leading path separators.\n\t// c.targets = targets.Targets\n\tc.loadTargets(targets.Targets)\n\treturn updatedTargets, nil\n}\n\n// decodeTimestamp decodes and verifies timestamp metadata, and returns the\n// new snapshot file meta.\nfunc (c *Client) decodeTimestamp(b json.RawMessage) (data.TimestampFileMeta, error) {\n\ttimestamp := &data.Timestamp{}\n\tif err := c.db.Unmarshal(b, timestamp, \"timestamp\", c.timestampVer); err != nil {\n\t\treturn data.TimestampFileMeta{}, ErrDecodeFailed{\"timestamp.json\", err}\n\t}\n\t// 5.4.3.2 - Check for snapshot rollback attack\n\t// Verify that the current snapshot meta version is less than or equal to the new one\n\tif timestamp.Meta[\"snapshot.json\"].Version < c.snapshotVer {\n\t\treturn data.TimestampFileMeta{}, verify.ErrLowVersion{Actual: timestamp.Meta[\"snapshot.json\"].Version, Current: c.snapshotVer}\n\t}\n\t// At this point we can trust the new timestamp and the snaphost version it refers to\n\t// so we can update the client's trusted versions and proceed with persisting the new timestamp\n\tc.timestampVer = timestamp.Version\n\tc.snapshotVer = timestamp.Meta[\"snapshot.json\"].Version\n\treturn timestamp.Meta[\"snapshot.json\"], nil\n}\n\n// hasMetaFromSnapshot checks whether local metadata has the given meta\nfunc (c *Client) hasMetaFromSnapshot(name string, m data.SnapshotFileMeta) bool {\n\t_, ok := c.localMetaFromSnapshot(name, m)\n\treturn ok\n}\n\n// localMetaFromSnapshot returns localmetadata if it matches the snapshot\nfunc (c *Client) localMetaFromSnapshot(name string, m data.SnapshotFileMeta) (json.RawMessage, bool) {\n\tb, ok := c.localMeta[name]\n\tif !ok {\n\t\treturn nil, false\n\t}\n\tmeta, err := util.GenerateSnapshotFileMeta(bytes.NewReader(b), m.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn nil, false\n\t}\n\terr = util.SnapshotFileMetaEqual(meta, m)\n\treturn b, err == nil\n}\n\n// hasTargetsMeta checks whether local metadata has the given snapshot meta\n//lint:ignore U1000 unused\nfunc (c *Client) hasTargetsMeta(m data.SnapshotFileMeta) bool {\n\tb, ok := c.localMeta[\"targets.json\"]\n\tif !ok {\n\t\treturn false\n\t}\n\tmeta, err := util.GenerateSnapshotFileMeta(bytes.NewReader(b), m.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn false\n\t}\n\terr = util.SnapshotFileMetaEqual(meta, m)\n\treturn err == nil\n}\n\n// hasSnapshotMeta checks whether local metadata has the given meta\n//lint:ignore U1000 unused\nfunc (c *Client) hasMetaFromTimestamp(name string, m data.TimestampFileMeta) bool {\n\tb, ok := c.localMeta[name]\n\tif !ok {\n\t\treturn false\n\t}\n\tmeta, err := util.GenerateTimestampFileMeta(bytes.NewReader(b), m.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn false\n\t}\n\terr = util.TimestampFileMetaEqual(meta, m)\n\treturn err == nil\n}\n\ntype Destination interface {\n\tio.Writer\n\tDelete() error\n}\n\n// Download downloads the given target file from remote storage into dest.\n//\n// dest will be deleted and an error returned in the following situations:\n//\n//   * The target does not exist in the local targets.json\n//   * Failed to fetch the chain of delegations accessible from local snapshot.json\n//   * The target does not exist in any targets\n//   * Metadata cannot be generated for the downloaded data\n//   * Generated metadata does not match local metadata for the given file\nfunc (c *Client) Download(name string, dest Destination) (err error) {\n\t// delete dest if there is an error\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tdest.Delete()\n\t\t}\n\t}()\n\n\t// populate c.targets from local storage if not set\n\tif c.targets == nil {\n\t\tif err := c.getLocalMeta(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tnormalizedName := util.NormalizeTarget(name)\n\tlocalMeta, ok := c.targets[normalizedName]\n\tif !ok {\n\t\t// search in delegations\n\t\tlocalMeta, err = c.getTargetFileMeta(normalizedName)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// get the data from remote storage\n\tr, size, err := c.downloadTarget(normalizedName, c.remote.GetTarget, localMeta.Hashes)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer r.Close()\n\n\t// return ErrWrongSize if the reported size is known and incorrect\n\tif size >= 0 && size != localMeta.Length {\n\t\treturn ErrWrongSize{name, size, localMeta.Length}\n\t}\n\n\t// wrap the data in a LimitReader so we download at most localMeta.Length bytes\n\tstream := io.LimitReader(r, localMeta.Length)\n\n\t// read the data, simultaneously writing it to dest and generating metadata\n\tactual, err := util.GenerateTargetFileMeta(io.TeeReader(stream, dest), localMeta.HashAlgorithms()...)\n\tif err != nil {\n\t\treturn ErrDownloadFailed{name, err}\n\t}\n\n\t// check the data has the correct length and hashes\n\tif err := util.TargetFileMetaEqual(actual, localMeta); err != nil {\n\t\tif e, ok := err.(util.ErrWrongLength); ok {\n\t\t\treturn ErrWrongSize{name, e.Actual, e.Expected}\n\t\t}\n\t\treturn ErrDownloadFailed{name, err}\n\t}\n\n\treturn nil\n}\n\nfunc (c *Client) VerifyDigest(digest string, digestAlg string, length int64, path string) error {\n\tlocalMeta, ok := c.targets[path]\n\tif !ok {\n\t\treturn ErrUnknownTarget{Name: path, SnapshotVersion: c.snapshotVer}\n\t}\n\n\tactual := data.FileMeta{Length: length, Hashes: make(data.Hashes, 1)}\n\tvar err error\n\tactual.Hashes[digestAlg], err = hex.DecodeString(digest)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := util.TargetFileMetaEqual(data.TargetFileMeta{FileMeta: actual}, localMeta); err != nil {\n\t\tif e, ok := err.(util.ErrWrongLength); ok {\n\t\t\treturn ErrWrongSize{path, e.Actual, e.Expected}\n\t\t}\n\t\treturn ErrDownloadFailed{path, err}\n\t}\n\n\treturn nil\n}\n\n// Target returns the target metadata for a specific target if it\n// exists, searching from top-level level targets then through\n// all delegations. If it does not, ErrNotFound will be returned.\nfunc (c *Client) Target(name string) (data.TargetFileMeta, error) {\n\ttarget, err := c.getTargetFileMeta(util.NormalizeTarget(name))\n\tif err == nil {\n\t\treturn target, nil\n\t}\n\n\tif _, ok := err.(ErrUnknownTarget); ok {\n\t\treturn data.TargetFileMeta{}, ErrNotFound{name}\n\t}\n\n\treturn data.TargetFileMeta{}, err\n}\n\n// Targets returns the complete list of available top-level targets.\nfunc (c *Client) Targets() (data.TargetFiles, error) {\n\t// populate c.targets from local storage if not set\n\tif c.targets == nil {\n\t\tif err := c.getLocalMeta(); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn c.targets, nil\n}\n", "package client\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\nvar (\n\tErrNoRootKeys       = errors.New(\"tuf: no root keys found in local meta store\")\n\tErrInsufficientKeys = errors.New(\"tuf: insufficient keys to meet threshold\")\n\tErrNoLocalSnapshot  = errors.New(\"tuf: no snapshot stored locally\")\n)\n\ntype ErrMissingRemoteMetadata struct {\n\tName string\n}\n\nfunc (e ErrMissingRemoteMetadata) Error() string {\n\treturn fmt.Sprintf(\"tuf: missing remote metadata %s\", e.Name)\n}\n\ntype ErrDownloadFailed struct {\n\tFile string\n\tErr  error\n}\n\nfunc (e ErrDownloadFailed) Error() string {\n\treturn fmt.Sprintf(\"tuf: failed to download %s: %s\", e.File, e.Err)\n}\n\ntype ErrDecodeFailed struct {\n\tFile string\n\tErr  error\n}\n\nfunc (e ErrDecodeFailed) Error() string {\n\treturn fmt.Sprintf(\"tuf: failed to decode %s: %s\", e.File, e.Err)\n}\n\ntype ErrMaxDelegations struct {\n\tTarget          string\n\tMaxDelegations  int\n\tSnapshotVersion int64\n}\n\nfunc (e ErrMaxDelegations) Error() string {\n\treturn fmt.Sprintf(\"tuf: max delegation of %d reached searching for %s with snapshot version %d\", e.MaxDelegations, e.Target, e.SnapshotVersion)\n}\n\ntype ErrNotFound struct {\n\tFile string\n}\n\nfunc (e ErrNotFound) Error() string {\n\treturn fmt.Sprintf(\"tuf: file not found: %s\", e.File)\n}\n\nfunc IsNotFound(err error) bool {\n\t_, ok := err.(ErrNotFound)\n\treturn ok\n}\n\ntype ErrWrongSize struct {\n\tFile     string\n\tActual   int64\n\tExpected int64\n}\n\nfunc (e ErrWrongSize) Error() string {\n\treturn fmt.Sprintf(\"tuf: unexpected file size: %s (expected %d bytes, got %d bytes)\", e.File, e.Expected, e.Actual)\n}\n\ntype ErrUnknownTarget struct {\n\tName            string\n\tSnapshotVersion int64\n}\n\nfunc (e ErrUnknownTarget) Error() string {\n\treturn fmt.Sprintf(\"tuf: unknown target file: %s with snapshot version %d\", e.Name, e.SnapshotVersion)\n}\n\ntype ErrMetaTooLarge struct {\n\tName    string\n\tSize    int64\n\tMaxSize int64\n}\n\nfunc (e ErrMetaTooLarge) Error() string {\n\treturn fmt.Sprintf(\"tuf: %s size %d bytes greater than maximum %d bytes\", e.Name, e.Size, e.MaxSize)\n}\n\ntype ErrInvalidURL struct {\n\tURL string\n}\n\nfunc (e ErrInvalidURL) Error() string {\n\treturn fmt.Sprintf(\"tuf: invalid repository URL %s\", e.URL)\n}\n\ntype ErrRoleNotInSnapshot struct {\n\tRole            string\n\tSnapshotVersion int64\n}\n\nfunc (e ErrRoleNotInSnapshot) Error() string {\n\treturn fmt.Sprintf(\"tuf: role %s not in snapshot version %d\", e.Role, e.SnapshotVersion)\n}\n", "package client\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"path/filepath\"\n\n\t\"github.com/theupdateframework/go-tuf/util\"\n\t. \"gopkg.in/check.v1\"\n\n\tgoTufGenerator \"github.com/theupdateframework/go-tuf/client/testdata/go-tuf/generator\"\n)\n\ntype InteropSuite struct{}\n\nvar _ = Suite(&InteropSuite{})\n\nfunc (InteropSuite) TestGoClientIdentityConsistentSnapshotFalse(c *C) {\n\tcheckGoIdentity(c, false)\n}\n\nfunc (InteropSuite) TestGoClientIdentityConsistentSnapshotTrue(c *C) {\n\tcheckGoIdentity(c, true)\n}\n\nfunc checkGoIdentity(c *C, consistentSnapshot bool) {\n\tcwd, err := os.Getwd()\n\tc.Assert(err, IsNil)\n\ttestDataDir := filepath.Join(cwd, \"testdata\")\n\n\ttempDir, err := ioutil.TempDir(\"\", \"\")\n\tc.Assert(err, IsNil)\n\tdefer os.RemoveAll(tempDir)\n\n\t// Generate the metadata and compute hashes for all the files.\n\tgoTufGenerator.Generate(tempDir, filepath.Join(testDataDir, \"keys.json\"), consistentSnapshot)\n\thashes := computeHashes(c, tempDir)\n\n\tsnapshotDir := filepath.Join(testDataDir, \"go-tuf\", fmt.Sprintf(\"consistent-snapshot-%t\", consistentSnapshot))\n\tsnapshotHashes := computeHashes(c, snapshotDir)\n\n\tc.Assert(hashes, DeepEquals, snapshotHashes, Commentf(\"metadata out of date, regenerate by running client/testdata/go-tuf/regenerate-metadata.sh\"))\n}\n\nfunc computeHashes(c *C, dir string) map[string]string {\n\thashes := make(map[string]string)\n\n\terr := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif info.IsDir() {\n\t\t\treturn nil\n\t\t}\n\n\t\tbytes, err := ioutil.ReadFile(path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpath, err = filepath.Rel(dir, path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\thashes[path] = string(bytes)\n\n\t\treturn nil\n\t})\n\tc.Assert(err, IsNil)\n\n\treturn hashes\n}\n\nfunc (InteropSuite) TestGoClientCompatibility(c *C) {\n\tnames := []string{\n\t\t\"go-tuf\",\n\t\t\"go-tuf-transition-M3\",\n\t\t\"go-tuf-transition-M4\",\n\t}\n\toptions := &HTTPRemoteOptions{MetadataPath: \"\", TargetsPath: \"targets\"}\n\n\tfor _, name := range names {\n\t\tfor _, consistentSnapshot := range []bool{false, true} {\n\t\t\tt := newTestCase(c, name, consistentSnapshot, options)\n\t\t\tt.run(c)\n\t\t}\n\t}\n}\n\ntype testCase struct {\n\tname               string\n\tconsistentSnapshot bool\n\toptions            *HTTPRemoteOptions\n\tlocal              LocalStore\n\ttargets            map[string][]byte\n\ttestDir            string\n\ttestSteps          []string\n}\n\nfunc newTestCase(c *C, name string, consistentSnapshot bool, options *HTTPRemoteOptions) testCase {\n\tcwd, err := os.Getwd()\n\tc.Assert(err, IsNil)\n\ttestDir := filepath.Join(cwd, \"testdata\", name, fmt.Sprintf(\"consistent-snapshot-%t\", consistentSnapshot))\n\n\tdirEntries, err := ioutil.ReadDir(testDir)\n\tc.Assert(err, IsNil)\n\tc.Assert(dirEntries, Not(HasLen), 0)\n\n\ttestSteps := []string{}\n\tfor _, dirEntry := range dirEntries {\n\t\tif dirEntry.IsDir() {\n\t\t\ttestSteps = append(testSteps, dirEntry.Name())\n\t\t}\n\t}\n\n\treturn testCase{\n\t\tname:               name,\n\t\tconsistentSnapshot: consistentSnapshot,\n\t\toptions:            options,\n\t\tlocal:              MemoryLocalStore(),\n\t\ttargets:            make(map[string][]byte),\n\t\ttestDir:            testDir,\n\t\ttestSteps:          testSteps,\n\t}\n}\n\nfunc (t *testCase) run(c *C) {\n\tc.Logf(\"test case: %s consistent-snapshot: %t\", t.name, t.consistentSnapshot)\n\n\tfor _, stepName := range t.testSteps {\n\t\tt.runStep(c, stepName)\n\t}\n}\n\nfunc (t *testCase) runStep(c *C, stepName string) {\n\tc.Logf(\"step: %s\", stepName)\n\n\taddr, cleanup := startFileServer(c, t.testDir)\n\tdefer cleanup()\n\n\tremote, err := HTTPRemoteStore(fmt.Sprintf(\"http://%s/%s/repository\", addr, stepName), t.options, nil)\n\tc.Assert(err, IsNil)\n\n\tclient := NewClient(t.local, remote)\n\t// initiate a client with the root metadata\n\tioReader, _, err := remote.GetMeta(\"root.json\")\n\tc.Assert(err, IsNil)\n\trootJsonBytes, err := io.ReadAll(ioReader)\n\tc.Assert(err, IsNil)\n\tc.Assert(client.InitLocal(rootJsonBytes), IsNil)\n\n\t// check update returns the correct updated targets\n\tfiles, err := client.Update()\n\tc.Assert(err, IsNil)\n\tif stepName != \"2\" {\n\t\t// The rest of the test cases add one target file at a time for each cycle, so this is why we expect that\n\t\t// the number of updated targets returned by Update() should equals to 1\n\t\tc.Assert(files, HasLen, 1)\n\t} else {\n\t\t// The following test case (#2) verifies that when a targets key has been rotated in the latest 3.root.json,\n\t\t// the local targets.json meta is indeed ignored since it's signed with a key that has been now changed.\n\t\t// The reason we check for 3 here is that the updated targets corresponds to all target files listed in the\n\t\t// targets.json for test case #2\n\t\tc.Assert(files, HasLen, 3)\n\t}\n\ttargetName := stepName\n\tt.targets[targetName] = []byte(targetName)\n\n\tfile, ok := files[targetName]\n\tif !ok {\n\t\tc.Fatalf(\"expected updated targets to contain %s\", targetName)\n\t}\n\n\tdata := t.targets[targetName]\n\tmeta, err := util.GenerateTargetFileMeta(bytes.NewReader(data), file.HashAlgorithms()...)\n\tc.Assert(err, IsNil)\n\tc.Assert(util.TargetFileMetaEqual(file, meta), IsNil)\n\n\t// download the files and check they have the correct content\n\tfor name, data := range t.targets {\n\t\tfor _, prefix := range []string{\"\", \"/\"} {\n\t\t\tvar dest testDestination\n\t\t\tc.Assert(client.Download(prefix+name, &dest), IsNil)\n\t\t\tc.Assert(dest.deleted, Equals, false)\n\t\t\tc.Assert(dest.String(), Equals, string(data))\n\t\t}\n\t}\n}\n\nfunc startFileServer(c *C, dir string) (string, func() error) {\n\tl, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n\tc.Assert(err, IsNil)\n\taddr := l.Addr().String()\n\tgo http.Serve(l, http.FileServer(http.Dir(dir)))\n\treturn addr, l.Close\n}\n", "package main\n\nimport (\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\n\t\"github.com/flynn/go-docopt\"\n\ttuf \"github.com/theupdateframework/go-tuf/client\"\n\t\"github.com/theupdateframework/go-tuf/util\"\n)\n\nfunc init() {\n\tregister(\"get\", cmdGet, `\nusage: tuf-client get [-s|--store=<path>] <url> <target>\n\nOptions:\n  -s <path>    The path to the local file store [default: tuf.db]\n\nGet a target from the repository.\n  `)\n}\n\ntype tmpFile struct {\n\t*os.File\n}\n\nfunc (t *tmpFile) Delete() error {\n\tt.Close()\n\treturn os.Remove(t.Name())\n}\n\nfunc cmdGet(args *docopt.Args, client *tuf.Client) error {\n\tif _, err := client.Update(); err != nil {\n\t\treturn err\n\t}\n\ttarget := util.NormalizeTarget(args.String[\"<target>\"])\n\tfile, err := ioutil.TempFile(\"\", \"go-tuf\")\n\tif err != nil {\n\t\treturn err\n\t}\n\ttmp := tmpFile{file}\n\tif err := client.Download(target, &tmp); err != nil {\n\t\treturn err\n\t}\n\tdefer tmp.Delete()\n\tif _, err := tmp.Seek(0, io.SeekStart); err != nil {\n\t\treturn err\n\t}\n\t_, err = io.Copy(os.Stdout, file)\n\treturn err\n}\n", "package main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"text/tabwriter\"\n\n\t\"github.com/dustin/go-humanize\"\n\t\"github.com/flynn/go-docopt\"\n\ttuf \"github.com/theupdateframework/go-tuf/client\"\n)\n\nfunc init() {\n\tregister(\"list\", cmdList, `\nusage: tuf-client list [-s|--store=<path>] <url>\n\nOptions:\n  -s <path>    The path to the local file store [default: tuf.db]\n\nList available target files.\n  `)\n}\n\nfunc cmdList(args *docopt.Args, client *tuf.Client) error {\n\tif _, err := client.Update(); err != nil {\n\t\treturn err\n\t}\n\ttargets, err := client.Targets()\n\tif err != nil {\n\t\treturn err\n\t}\n\tw := tabwriter.NewWriter(os.Stdout, 1, 2, 2, ' ', 0)\n\tdefer w.Flush()\n\tfmt.Fprintln(w, \"PATH\\tSIZE\")\n\tfor path, meta := range targets {\n\t\tfmt.Fprintf(w, \"%s\\t%s\\n\", path, humanize.Bytes(uint64(meta.Length)))\n\t}\n\treturn nil\n}\n", "package util\n\nimport (\n\t\"bytes\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"hash\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/theupdateframework/go-tuf/data\"\n)\n\ntype ErrWrongLength struct {\n\tExpected int64\n\tActual   int64\n}\n\nfunc (e ErrWrongLength) Error() string {\n\treturn fmt.Sprintf(\"wrong length, expected %d got %d\", e.Expected, e.Actual)\n}\n\ntype ErrWrongVersion struct {\n\tExpected int64\n\tActual   int64\n}\n\nfunc (e ErrWrongVersion) Error() string {\n\treturn fmt.Sprintf(\"wrong version, expected %d got %d\", e.Expected, e.Actual)\n}\n\ntype ErrWrongHash struct {\n\tType     string\n\tExpected data.HexBytes\n\tActual   data.HexBytes\n}\n\nfunc (e ErrWrongHash) Error() string {\n\treturn fmt.Sprintf(\"wrong %s hash, expected %s got %s\", e.Type, hex.EncodeToString(e.Expected), hex.EncodeToString(e.Actual))\n}\n\ntype ErrNoCommonHash struct {\n\tExpected data.Hashes\n\tActual   data.Hashes\n}\n\nfunc (e ErrNoCommonHash) Error() string {\n\ttypes := func(a data.Hashes) []string {\n\t\tt := make([]string, 0, len(a))\n\t\tfor typ := range a {\n\t\t\tt = append(t, typ)\n\t\t}\n\t\treturn t\n\t}\n\treturn fmt.Sprintf(\"no common hash function, expected one of %s, got %s\", types(e.Expected), types(e.Actual))\n}\n\ntype ErrUnknownHashAlgorithm struct {\n\tName string\n}\n\nfunc (e ErrUnknownHashAlgorithm) Error() string {\n\treturn fmt.Sprintf(\"unknown hash algorithm: %s\", e.Name)\n}\n\ntype PassphraseFunc func(role string, confirm bool, change bool) ([]byte, error)\n\nfunc FileMetaEqual(actual data.FileMeta, expected data.FileMeta) error {\n\tif actual.Length != expected.Length {\n\t\treturn ErrWrongLength{expected.Length, actual.Length}\n\t}\n\n\tif err := hashEqual(actual.Hashes, expected.Hashes); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc hashEqual(actual data.Hashes, expected data.Hashes) error {\n\thashChecked := false\n\tfor typ, hash := range expected {\n\t\tif h, ok := actual[typ]; ok {\n\t\t\thashChecked = true\n\t\t\tif !hmac.Equal(h, hash) {\n\t\t\t\treturn ErrWrongHash{typ, hash, h}\n\t\t\t}\n\t\t}\n\t}\n\tif !hashChecked {\n\t\treturn ErrNoCommonHash{expected, actual}\n\t}\n\treturn nil\n}\n\nfunc versionEqual(actual int64, expected int64) error {\n\tif actual != expected {\n\t\treturn ErrWrongVersion{expected, actual}\n\t}\n\treturn nil\n}\n\nfunc SnapshotFileMetaEqual(actual data.SnapshotFileMeta, expected data.SnapshotFileMeta) error {\n\t// TUF-1.0 no longer considers the length and hashes to be a required\n\t// member of snapshots. However they are considering requiring hashes\n\t// for delegated roles to avoid an attack described in Section 5.6 of\n\t// the Mercury paper:\n\t// https://github.com/theupdateframework/specification/pull/40\n\tif expected.Length != 0 && actual.Length != expected.Length {\n\t\treturn ErrWrongLength{expected.Length, actual.Length}\n\t}\n\t// 5.6.2 - Check against snapshot role's targets hash\n\tif len(expected.Hashes) != 0 {\n\t\tif err := hashEqual(actual.Hashes, expected.Hashes); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t// 5.6.4 - Check against snapshot role's snapshot version\n\tif err := versionEqual(actual.Version, expected.Version); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc TargetFileMetaEqual(actual data.TargetFileMeta, expected data.TargetFileMeta) error {\n\treturn FileMetaEqual(actual.FileMeta, expected.FileMeta)\n}\n\nfunc TimestampFileMetaEqual(actual data.TimestampFileMeta, expected data.TimestampFileMeta) error {\n\t// TUF no longer considers the length and hashes to be a required\n\t// member of Timestamp.\n\tif expected.Length != 0 && actual.Length != expected.Length {\n\t\treturn ErrWrongLength{expected.Length, actual.Length}\n\t}\n\t// 5.5.2 - Check against timestamp role's snapshot hash\n\tif len(expected.Hashes) != 0 {\n\t\tif err := hashEqual(actual.Hashes, expected.Hashes); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t// 5.5.4 - Check against timestamp role's snapshot version\n\tif err := versionEqual(actual.Version, expected.Version); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nconst defaultHashAlgorithm = \"sha512\"\n\nfunc GenerateFileMeta(r io.Reader, hashAlgorithms ...string) (data.FileMeta, error) {\n\tif len(hashAlgorithms) == 0 {\n\t\thashAlgorithms = []string{defaultHashAlgorithm}\n\t}\n\thashes := make(map[string]hash.Hash, len(hashAlgorithms))\n\tfor _, hashAlgorithm := range hashAlgorithms {\n\t\tvar h hash.Hash\n\t\tswitch hashAlgorithm {\n\t\tcase \"sha256\":\n\t\t\th = sha256.New()\n\t\tcase \"sha512\":\n\t\t\th = sha512.New()\n\t\tdefault:\n\t\t\treturn data.FileMeta{}, ErrUnknownHashAlgorithm{hashAlgorithm}\n\t\t}\n\t\thashes[hashAlgorithm] = h\n\t\tr = io.TeeReader(r, h)\n\t}\n\tn, err := io.Copy(ioutil.Discard, r)\n\tif err != nil {\n\t\treturn data.FileMeta{}, err\n\t}\n\tm := data.FileMeta{Length: n, Hashes: make(data.Hashes, len(hashes))}\n\tfor hashAlgorithm, h := range hashes {\n\t\tm.Hashes[hashAlgorithm] = h.Sum(nil)\n\t}\n\treturn m, nil\n}\n\ntype versionedMeta struct {\n\tVersion int64 `json:\"version\"`\n}\n\nfunc generateVersionedFileMeta(r io.Reader, hashAlgorithms ...string) (data.FileMeta, int64, error) {\n\tb, err := ioutil.ReadAll(r)\n\tif err != nil {\n\t\treturn data.FileMeta{}, 0, err\n\t}\n\n\tm, err := GenerateFileMeta(bytes.NewReader(b), hashAlgorithms...)\n\tif err != nil {\n\t\treturn data.FileMeta{}, 0, err\n\t}\n\n\ts := data.Signed{}\n\tif err := json.Unmarshal(b, &s); err != nil {\n\t\treturn data.FileMeta{}, 0, err\n\t}\n\n\tvm := versionedMeta{}\n\tif err := json.Unmarshal(s.Signed, &vm); err != nil {\n\t\treturn data.FileMeta{}, 0, err\n\t}\n\n\treturn m, vm.Version, nil\n}\n\nfunc GenerateSnapshotFileMeta(r io.Reader, hashAlgorithms ...string) (data.SnapshotFileMeta, error) {\n\tm, v, err := generateVersionedFileMeta(r, hashAlgorithms...)\n\tif err != nil {\n\t\treturn data.SnapshotFileMeta{}, err\n\t}\n\treturn data.SnapshotFileMeta{\n\t\tFileMeta: m,\n\t\tVersion:  v,\n\t}, nil\n}\n\nfunc GenerateTargetFileMeta(r io.Reader, hashAlgorithms ...string) (data.TargetFileMeta, error) {\n\tm, err := GenerateFileMeta(r, hashAlgorithms...)\n\tif err != nil {\n\t\treturn data.TargetFileMeta{}, err\n\t}\n\treturn data.TargetFileMeta{\n\t\tFileMeta: m,\n\t}, nil\n}\n\nfunc GenerateTimestampFileMeta(r io.Reader, hashAlgorithms ...string) (data.TimestampFileMeta, error) {\n\tm, v, err := generateVersionedFileMeta(r, hashAlgorithms...)\n\tif err != nil {\n\t\treturn data.TimestampFileMeta{}, err\n\t}\n\treturn data.TimestampFileMeta{\n\t\tFileMeta: m,\n\t\tVersion:  v,\n\t}, nil\n}\n\nfunc NormalizeTarget(p string) string {\n\t// FIXME(TUF-0.9) TUF-1.0 is considering banning paths that begin with\n\t// a leading path separator, to avoid surprising behavior when joining\n\t// target and delgated paths. python-tuf raises an exception if any\n\t// path starts with '/', but since we need to be cross compatible with\n\t// TUF-0.9 we still need to support leading slashes. For now, we will\n\t// just strip them out, but eventually we should also consider turning\n\t// them into an error.\n\treturn strings.TrimPrefix(path.Join(\"/\", p), \"/\")\n}\n\nfunc VersionedPath(p string, version int64) string {\n\treturn path.Join(path.Dir(p), strconv.FormatInt(version, 10)+\".\"+path.Base(p))\n}\n\nfunc HashedPaths(p string, hashes data.Hashes) []string {\n\tpaths := make([]string, 0, len(hashes))\n\tfor _, hash := range hashes {\n\t\thashedPath := path.Join(path.Dir(p), hash.String()+\".\"+path.Base(p))\n\t\tpaths = append(paths, hashedPath)\n\t}\n\treturn paths\n}\n\nfunc AtomicallyWriteFile(filename string, data []byte, perm os.FileMode) error {\n\tdir, name := filepath.Split(filename)\n\tf, err := ioutil.TempFile(dir, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = f.Write(data)\n\tif err != nil {\n\t\tf.Close()\n\t\tos.Remove(f.Name())\n\t\treturn err\n\t}\n\n\tif err = f.Chmod(perm); err != nil {\n\t\tf.Close()\n\t\tos.Remove(f.Name())\n\t\treturn err\n\t}\n\n\tif err := f.Close(); err != nil {\n\t\tos.Remove(f.Name())\n\t\treturn err\n\t}\n\n\tif err := os.Rename(f.Name(), filename); err != nil {\n\t\tos.Remove(f.Name())\n\t\treturn err\n\t}\n\n\treturn nil\n}\n", "package verify\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"time\"\n)\n\nvar (\n\tErrMissingKey           = errors.New(\"tuf: missing key\")\n\tErrNoSignatures         = errors.New(\"tuf: data has no signatures\")\n\tErrInvalid              = errors.New(\"tuf: signature verification failed\")\n\tErrWrongMethod          = errors.New(\"tuf: invalid signature type\")\n\tErrWrongMetaType        = errors.New(\"tuf: meta file has wrong type\")\n\tErrExists               = errors.New(\"tuf: key already in db\")\n\tErrInvalidKey           = errors.New(\"tuf: invalid key\")\n\tErrInvalidRole          = errors.New(\"tuf: invalid role\")\n\tErrInvalidDelegatedRole = errors.New(\"tuf: invalid delegated role\")\n\tErrInvalidKeyID         = errors.New(\"tuf: invalid key id\")\n\tErrInvalidThreshold     = errors.New(\"tuf: invalid role threshold\")\n\tErrMissingTargetFile    = errors.New(\"tuf: missing previously listed targets metadata file\")\n)\n\ntype ErrWrongID struct{}\n\nfunc (ErrWrongID) Error() string {\n\treturn \"tuf: key id mismatch\"\n}\n\ntype ErrUnknownRole struct {\n\tRole string\n}\n\nfunc (e ErrUnknownRole) Error() string {\n\treturn fmt.Sprintf(\"tuf: unknown role %q\", e.Role)\n}\n\ntype ErrExpired struct {\n\tExpired time.Time\n}\n\nfunc (e ErrExpired) Error() string {\n\treturn fmt.Sprintf(\"expired at %s\", e.Expired)\n}\n\ntype ErrLowVersion struct {\n\tActual  int64\n\tCurrent int64\n}\n\nfunc (e ErrLowVersion) Error() string {\n\treturn fmt.Sprintf(\"version %d is lower than current version %d\", e.Actual, e.Current)\n}\n\ntype ErrWrongVersion struct {\n\tGiven    int64\n\tExpected int64\n}\n\nfunc (e ErrWrongVersion) Error() string {\n\treturn fmt.Sprintf(\"version %d does not match the expected version %d\", e.Given, e.Expected)\n}\n\ntype ErrRoleThreshold struct {\n\tExpected int\n\tActual   int\n}\n\nfunc (e ErrRoleThreshold) Error() string {\n\treturn \"tuf: valid signatures did not meet threshold\"\n}\n", "package verify\n\nimport (\n\t\"encoding/json\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/secure-systems-lab/go-securesystemslib/cjson\"\n\t\"github.com/theupdateframework/go-tuf/data\"\n\t\"github.com/theupdateframework/go-tuf/internal/roles\"\n)\n\ntype signedMeta struct {\n\tType    string    `json:\"_type\"`\n\tExpires time.Time `json:\"expires\"`\n\tVersion int64     `json:\"version\"`\n}\n\nfunc (db *DB) VerifyIgnoreExpiredCheck(s *data.Signed, role string, minVersion int64) error {\n\tif err := db.VerifySignatures(s, role); err != nil {\n\t\treturn err\n\t}\n\n\tsm := &signedMeta{}\n\tif err := json.Unmarshal(s.Signed, sm); err != nil {\n\t\treturn err\n\t}\n\n\tif roles.IsTopLevelRole(role) {\n\t\t// Top-level roles can only sign metadata of the same type (e.g. snapshot\n\t\t// metadata must be signed by the snapshot role).\n\t\tif !strings.EqualFold(sm.Type, role) {\n\t\t\treturn ErrWrongMetaType\n\t\t}\n\t} else {\n\t\t// Delegated (non-top-level) roles may only sign targets metadata.\n\t\tif strings.ToLower(sm.Type) != \"targets\" {\n\t\t\treturn ErrWrongMetaType\n\t\t}\n\t}\n\n\tif sm.Version < minVersion {\n\t\treturn ErrLowVersion{sm.Version, minVersion}\n\t}\n\n\treturn nil\n}\n\nfunc (db *DB) Verify(s *data.Signed, role string, minVersion int64) error {\n\t// Verify signatures and versions\n\terr := db.VerifyIgnoreExpiredCheck(s, role, minVersion)\n\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsm := &signedMeta{}\n\tif err := json.Unmarshal(s.Signed, sm); err != nil {\n\t\treturn err\n\t}\n\t// Verify expiration\n\tif IsExpired(sm.Expires) {\n\t\treturn ErrExpired{sm.Expires}\n\t}\n\n\treturn nil\n}\n\nvar IsExpired = func(t time.Time) bool {\n\treturn time.Until(t) <= 0\n}\n\nfunc (db *DB) VerifySignatures(s *data.Signed, role string) error {\n\tif len(s.Signatures) == 0 {\n\t\treturn ErrNoSignatures\n\t}\n\n\troleData := db.GetRole(role)\n\tif roleData == nil {\n\t\treturn ErrUnknownRole{role}\n\t}\n\n\tvar decoded map[string]interface{}\n\tif err := json.Unmarshal(s.Signed, &decoded); err != nil {\n\t\treturn err\n\t}\n\tmsg, err := cjson.EncodeCanonical(decoded)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Verify that a threshold of keys signed the data. Since keys can have\n\t// multiple key ids, we need to protect against multiple attached\n\t// signatures that just differ on the key id.\n\tseen := make(map[string]struct{})\n\tvalid := 0\n\tfor _, sig := range s.Signatures {\n\t\tif !roleData.ValidKey(sig.KeyID) {\n\t\t\tcontinue\n\t\t}\n\t\tverifier, err := db.GetVerifier(sig.KeyID)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tif err := verifier.Verify(msg, sig.Signature); err != nil {\n\t\t\treturn ErrInvalid\n\t\t}\n\n\t\t// Only consider this key valid if we haven't seen any of it's\n\t\t// key ids before.\n\t\tif _, ok := seen[sig.KeyID]; !ok {\n\t\t\tfor _, id := range verifier.MarshalPublicKey().IDs() {\n\t\t\t\tseen[id] = struct{}{}\n\t\t\t}\n\n\t\t\tvalid++\n\t\t}\n\t}\n\tif valid < roleData.Threshold {\n\t\treturn ErrRoleThreshold{roleData.Threshold, valid}\n\t}\n\n\treturn nil\n}\n\nfunc (db *DB) Unmarshal(b []byte, v interface{}, role string, minVersion int64) error {\n\ts := &data.Signed{}\n\tif err := json.Unmarshal(b, s); err != nil {\n\t\treturn err\n\t}\n\tif err := db.Verify(s, role, minVersion); err != nil {\n\t\treturn err\n\t}\n\treturn json.Unmarshal(s.Signed, v)\n}\n\n// UnmarshalExpired is exactly like Unmarshal except ignores expired timestamp error.\nfunc (db *DB) UnmarshalIgnoreExpired(b []byte, v interface{}, role string, minVersion int64) error {\n\ts := &data.Signed{}\n\tif err := json.Unmarshal(b, s); err != nil {\n\t\treturn err\n\t}\n\t// Note: If verification fails, then we wont attempt to unmarshal\n\t// unless when verification error is errExpired.\n\tverifyErr := db.Verify(s, role, minVersion)\n\tif verifyErr != nil {\n\t\tif _, ok := verifyErr.(ErrExpired); !ok {\n\t\t\treturn verifyErr\n\t\t}\n\t}\n\treturn json.Unmarshal(s.Signed, v)\n}\n\nfunc (db *DB) UnmarshalTrusted(b []byte, v interface{}, role string) error {\n\ts := &data.Signed{}\n\tif err := json.Unmarshal(b, s); err != nil {\n\t\treturn err\n\t}\n\tif err := db.VerifySignatures(s, role); err != nil {\n\t\treturn err\n\t}\n\treturn json.Unmarshal(s.Signed, v)\n}\n"], "filenames": ["client/client.go", "client/errors.go", "client/interop_test.go", "cmd/tuf-client/get.go", "cmd/tuf-client/list.go", "util/util.go", "verify/errors.go", "verify/verify.go"], "buggy_code_start_loc": [180, 73, 12, 34, 25, 121, 20, 50], "buggy_code_end_loc": [737, 86, 165, 35, 26, 147, 20, 62], "fixing_code_start_loc": [180, 72, 11, 34, 25, 121, 21, 50], "fixing_code_end_loc": [815, 72, 172, 35, 26, 152, 22, 62], "type": "CWE-354", "message": "go-tuf is a Go implementation of The Update Framework (TUF). go-tuf does not correctly implement the client workflow for updating the metadata files for roles other than the root role. Specifically, checks for rollback attacks are not implemented correctly meaning an attacker can cause clients to install software that is older than the software which the client previously knew to be available, and may include software with known vulnerabilities. In more detail, the client code of go-tuf has several issues in regards to preventing rollback attacks: 1. It does not take into account the content of any previously trusted metadata, if available, before proceeding with updating roles other than the root role (i.e., steps 5.4.3.1 and 5.5.5 of the detailed client workflow). This means that any form of version verification done on the newly-downloaded metadata is made using the default value of zero, which always passes. 2. For both timestamp and snapshot roles, go-tuf saves these metadata files as trusted before verifying if the version of the metafiles they refer to is correct (i.e., steps 5.5.4 and 5.6.4 of the detailed client workflow). A fix is available in version 0.3.0 or newer. No workarounds are known for this issue apart from upgrading.", "other": {"cve": {"id": "CVE-2022-29173", "sourceIdentifier": "security-advisories@github.com", "published": "2022-05-05T23:15:09.220", "lastModified": "2022-05-17T19:55:42.820", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "go-tuf is a Go implementation of The Update Framework (TUF). go-tuf does not correctly implement the client workflow for updating the metadata files for roles other than the root role. Specifically, checks for rollback attacks are not implemented correctly meaning an attacker can cause clients to install software that is older than the software which the client previously knew to be available, and may include software with known vulnerabilities. In more detail, the client code of go-tuf has several issues in regards to preventing rollback attacks: 1. It does not take into account the content of any previously trusted metadata, if available, before proceeding with updating roles other than the root role (i.e., steps 5.4.3.1 and 5.5.5 of the detailed client workflow). This means that any form of version verification done on the newly-downloaded metadata is made using the default value of zero, which always passes. 2. For both timestamp and snapshot roles, go-tuf saves these metadata files as trusted before verifying if the version of the metafiles they refer to is correct (i.e., steps 5.5.4 and 5.6.4 of the detailed client workflow). A fix is available in version 0.3.0 or newer. No workarounds are known for this issue apart from upgrading."}, {"lang": "es", "value": "go-tuf es una implementaci\u00f3n en Go de El Update Framework (TUF). go-tuf no implementa correctamente el flujo de trabajo del cliente para la actualizaci\u00f3n de los archivos de metadatos para los roles que no sean el rol de root. Espec\u00edficamente, las comprobaciones para los ataques de retroceso no est\u00e1n implementadas correctamente, lo que significa que un atacante puede causar que los clientes instalen software que es m\u00e1s antiguo que el software que el cliente sab\u00eda previamente que estaba disponible, y puede incluir software con vulnerabilidades conocidas. En m\u00e1s detalle, el c\u00f3digo del cliente de go-tuf presenta varios problemas en cuanto a la prevenci\u00f3n de ataques de retroceso: 1. No presenta en cuenta el contenido de cualquier metadato previamente confiable, si est\u00e1 disponible, antes de proceder con la actualizaci\u00f3n de roles que no sean el rol root (es decir, los pasos 5.4.3.1 y 5.5.5 del flujo de trabajo detallado del cliente). Esto significa que cualquier forma de verificaci\u00f3n de la versi\u00f3n realizada en los metadatos reci\u00e9n descargados es realizada usando el valor por defecto de cero, que siempre pasa. 2. Para los roles de marca de tiempo e instant\u00e1nea, go-tuf guarda estos archivos de metadatos como confiables antes de verificar si la versi\u00f3n de los metaficheros a los que son referidos es correcta (es decir, los pasos 5.5.4 y 5.6.4 del flujo de trabajo detallado del cliente). Se presenta una correcci\u00f3n disponible en versi\u00f3n 0.3.0 o m\u00e1s reciente. No se  conocen medidas de mitigaci\u00f3n para este problema, aparte de la actualizaci\u00f3n"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.0, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.1, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:N/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-354"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-354"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:theupdateframework:go-tuf:0.2.0:*:*:*:*:*:*:*", "matchCriteriaId": "07B11DE6-6488-4B21-B641-A5B5BE3A5A55"}]}]}], "references": [{"url": "https://github.com/theupdateframework/go-tuf/commit/ed6788e710fc3093a7ecc2d078bf734c0f200d8d", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/theupdateframework/go-tuf/security/advisories/GHSA-66x3-6cw3-v5gj", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/theupdateframework/go-tuf/commit/ed6788e710fc3093a7ecc2d078bf734c0f200d8d"}}
{"buggy_code": ["#ifndef PROXY_H\n#define PROXY_H\n\n#include \"memcached.h\"\n#include \"extstore.h\"\n#include <string.h>\n#include <stdlib.h>\n#include <ctype.h>\n#include <errno.h>\n\n#include <lua.h>\n#include <lualib.h>\n#include <lauxlib.h>\n\n#include \"config.h\"\n\n#if defined(__linux__)\n#define USE_EVENTFD 1\n#include <sys/eventfd.h>\n#endif\n\n#ifdef HAVE_LIBURING\n#include <liburing.h>\n#include <poll.h> // POLLOUT for liburing.\n#define PRING_QUEUE_SQ_ENTRIES 2048\n#define PRING_QUEUE_CQ_ENTRIES 16384\n#endif\n\n#include \"proto_proxy.h\"\n#include \"proto_text.h\"\n#include \"queue.h\"\n#define XXH_INLINE_ALL // modifier for xxh3's include below\n#include \"xxhash.h\"\n\n#ifdef PROXY_DEBUG\n#define P_DEBUG(...) \\\n    do { \\\n        fprintf(stderr, __VA_ARGS__); \\\n    } while (0)\n#else\n#define P_DEBUG(...)\n#endif\n\n#define WSTAT_L(t) pthread_mutex_lock(&t->stats.mutex);\n#define WSTAT_UL(t) pthread_mutex_unlock(&t->stats.mutex);\n#define WSTAT_INCR(t, stat, amount) { \\\n    pthread_mutex_lock(&t->stats.mutex); \\\n    t->stats.stat += amount; \\\n    pthread_mutex_unlock(&t->stats.mutex); \\\n}\n#define WSTAT_DECR(t, stat, amount) { \\\n    pthread_mutex_lock(&t->stats.mutex); \\\n    t->stats.stat -= amount; \\\n    pthread_mutex_unlock(&t->stats.mutex); \\\n}\n#define STAT_L(ctx) pthread_mutex_lock(&ctx->stats_lock);\n#define STAT_UL(ctx) pthread_mutex_unlock(&ctx->stats_lock);\n#define STAT_INCR(ctx, stat, amount) { \\\n        pthread_mutex_lock(&ctx->stats_lock); \\\n        ctx->global_stats.stat += amount; \\\n        pthread_mutex_unlock(&ctx->stats_lock); \\\n}\n\n#define STAT_DECR(ctx, stat, amount) { \\\n        pthread_mutex_lock(&ctx->stats_lock); \\\n        ctx->global_stats.stat -= amount; \\\n        pthread_mutex_unlock(&ctx->stats_lock); \\\n}\n\n// FIXME (v2): do include dir properly.\n#include \"vendor/mcmc/mcmc.h\"\n\n// Note: value created from thin air. Could be shorter.\n#define MCP_REQUEST_MAXLEN KEY_MAX_LENGTH * 2\n\n#define ENDSTR \"END\\r\\n\"\n#define ENDLEN sizeof(ENDSTR)-1\n\n#define MCP_BACKEND_UPVALUE 1\n\n#define MCP_YIELD_POOL 1\n#define MCP_YIELD_AWAIT 2\n#define MCP_YIELD_LOCAL 3\n\n// all possible commands.\n#define CMD_FIELDS \\\n    X(CMD_MG) \\\n    X(CMD_MS) \\\n    X(CMD_MD) \\\n    X(CMD_MN) \\\n    X(CMD_MA) \\\n    X(CMD_ME) \\\n    X(CMD_GET) \\\n    X(CMD_GAT) \\\n    X(CMD_SET) \\\n    X(CMD_ADD) \\\n    X(CMD_CAS) \\\n    X(CMD_GETS) \\\n    X(CMD_GATS) \\\n    X(CMD_INCR) \\\n    X(CMD_DECR) \\\n    X(CMD_TOUCH) \\\n    X(CMD_APPEND) \\\n    X(CMD_DELETE) \\\n    X(CMD_REPLACE) \\\n    X(CMD_PREPEND) \\\n    X(CMD_END_STORAGE) \\\n    X(CMD_QUIT) \\\n    X(CMD_STATS) \\\n    X(CMD_SLABS) \\\n    X(CMD_WATCH) \\\n    X(CMD_LRU) \\\n    X(CMD_VERSION) \\\n    X(CMD_SHUTDOWN) \\\n    X(CMD_EXTSTORE) \\\n    X(CMD_FLUSH_ALL) \\\n    X(CMD_VERBOSITY) \\\n    X(CMD_LRU_CRAWLER) \\\n    X(CMD_REFRESH_CERTS) \\\n    X(CMD_CACHE_MEMLIMIT)\n\n#define X(name) name,\nenum proxy_defines {\n    P_OK = 0,\n    CMD_FIELDS\n    CMD_SIZE, // used to define array size for command hooks.\n    CMD_ANY, // override _all_ commands\n    CMD_ANY_STORAGE, // override commands specific to key storage.\n    CMD_FINAL, // end cap for convenience.\n};\n#undef X\n\n// certain classes of ascii commands have similar parsing (ie;\n// get/gets/gat/gats). Use types so we don't have to test a ton of them.\nenum proxy_cmd_types {\n    CMD_TYPE_GENERIC = 0,\n    CMD_TYPE_GET, // get/gets/gat/gats\n    CMD_TYPE_META, // m*'s.\n};\n\ntypedef struct _io_pending_proxy_t io_pending_proxy_t;\ntypedef struct proxy_event_thread_s proxy_event_thread_t;\n\n#ifdef HAVE_LIBURING\n// TODO: pass in cqe->res instead of cqe?\ntypedef void (*proxy_event_cb)(void *udata, struct io_uring_cqe *cqe);\ntypedef struct {\n    void *udata;\n    proxy_event_cb cb;\n    bool set; // NOTE: not sure if necessary if code structured properly\n} proxy_event_t;\n\nvoid *proxy_event_thread_ur(void *arg);\n#endif\n\n// Note: This ends up wasting a few counters, but simplifies the rest of the\n// process for handling internal worker stats.\nstruct proxy_int_stats {\n    uint64_t counters[CMD_FINAL];\n};\n\nstruct proxy_user_stats {\n    size_t num_stats; // number of stats, for sizing various arrays\n    char **names; // not needed for worker threads\n    uint64_t *counters; // array of counters.\n};\n\nstruct proxy_global_stats {\n    uint64_t config_reloads;\n    uint64_t config_reload_fails;\n    uint64_t backend_total;\n    uint64_t backend_disconn; // backends with no connections\n    uint64_t backend_requests; // reqs sent to backends\n    uint64_t backend_responses; // responses received from backends\n    uint64_t backend_errors; // errors from backends\n    uint64_t backend_marked_bad; // backend set to autofail\n    uint64_t backend_failed; // an error caused a backend reset\n};\n\nstruct proxy_tunables {\n    struct timeval connect;\n    struct timeval retry; // wait time before retrying a dead backend\n    struct timeval read;\n    struct timeval flap; // need to stay connected this long or it's flapping\n    float flap_backoff_ramp; // factorial for retry time\n    uint32_t flap_backoff_max; // don't backoff longer than this.\n    int backend_failure_limit;\n    bool tcp_keepalive;\n    bool down; // backend is forced into a down/bad state.\n};\n\ntypedef STAILQ_HEAD(pool_head_s, mcp_pool_s) pool_head_t;\ntypedef struct {\n    lua_State *proxy_state;\n    void *proxy_code;\n    proxy_event_thread_t *proxy_io_thread;\n    uint64_t active_req_limit; // max total in-flight requests\n    uint64_t buffer_memory_limit; // max bytes for send/receive buffers.\n    pthread_mutex_t config_lock;\n    pthread_cond_t config_cond;\n    pthread_t config_tid;\n    pthread_mutex_t worker_lock;\n    pthread_cond_t worker_cond;\n    pthread_t manager_tid; // deallocation management thread\n    pthread_mutex_t manager_lock;\n    pthread_cond_t manager_cond;\n    pool_head_t manager_head; // stack for pool deallocation.\n    bool worker_done; // signal variable for the worker lock/cond system.\n    bool worker_failed; // covered by worker_lock as well.\n    bool use_uring; // use IO_URING for backend connections.\n    bool loading; // bool indicating an active config load.\n    struct proxy_global_stats global_stats;\n    struct proxy_user_stats user_stats;\n    struct proxy_tunables tunables; // NOTE: updates covered by stats_lock\n    pthread_mutex_t stats_lock; // used for rare global counters\n} proxy_ctx_t;\n\n#define PROXY_GET_THR_CTX(L) ((*(LIBEVENT_THREAD **)lua_getextraspace(L))->proxy_ctx)\n#define PROXY_GET_THR(L) (*(LIBEVENT_THREAD **)lua_getextraspace(L))\n// Operations from the config VM don't have a libevent thread.\n#define PROXY_GET_CTX(L) (*(proxy_ctx_t **)lua_getextraspace(L))\n\nstruct proxy_hook_tagged {\n    uint64_t tag;\n    int lua_ref;\n};\n\nstruct proxy_hook {\n    int lua_ref;\n    int tagcount;\n    struct proxy_hook_tagged *tagged; // array of possible tagged hooks.\n};\n\n// TODO (v2): some hash functions (crc?) might require initializers. If we run into\n// any the interface might need expanding.\ntypedef uint64_t (*key_hash_func)(const void *key, size_t len, uint64_t seed);\nstruct proxy_hash_func {\n    key_hash_func func;\n};\ntypedef const char *(*key_hash_filter_func)(const char *conf, const char *key, size_t klen, size_t *newlen);\ntypedef uint32_t (*hash_selector_func)(uint64_t hash, void *ctx);\nstruct proxy_hash_caller {\n    hash_selector_func selector_func;\n    void *ctx;\n};\n\nenum mcp_backend_states {\n    mcp_backend_read = 0, // waiting to read any response\n    mcp_backend_parse, // have some buffered data to check\n    mcp_backend_read_end, // looking for an \"END\" marker for GET\n    mcp_backend_want_read, // read more data to complete command\n    mcp_backend_next, // advance to the next IO\n    mcp_backend_next_close, // complete current request, then close socket\n};\n\ntypedef struct mcp_backend_wrap_s mcp_backend_wrap_t;\ntypedef struct mcp_backend_label_s mcp_backend_label_t;\ntypedef struct mcp_backend_s mcp_backend_t;\ntypedef struct mcp_request_s mcp_request_t;\ntypedef struct mcp_parser_s mcp_parser_t;\n\n#define PARSER_MAX_TOKENS 24\n\nstruct mcp_parser_meta_s {\n    uint64_t flags;\n};\n\n// Note that we must use offsets into request for tokens,\n// as *request can change between parsing and later accessors.\nstruct mcp_parser_s {\n    const char *request;\n    void *vbuf; // temporary buffer for holding value lengths.\n    uint8_t command;\n    uint8_t cmd_type; // command class.\n    uint8_t ntokens;\n    uint8_t keytoken; // because GAT. sigh. also cmds without a key.\n    uint32_t parsed; // how far into the request we parsed already\n    uint32_t reqlen; // full length of request buffer.\n    int vlen;\n    uint32_t klen; // length of key.\n    uint16_t tokens[PARSER_MAX_TOKENS]; // offsets for start of each token\n    bool has_space; // a space was found after the last byte parsed.\n    bool noreply; // if quiet/noreply mode is set.\n    union {\n        struct mcp_parser_meta_s meta;\n    } t;\n};\n\n#define MCP_PARSER_KEY(pr) (&pr.request[pr.tokens[pr.keytoken]])\n\n#define MAX_REQ_TOKENS 2\nstruct mcp_request_s {\n    mcp_parser_t pr; // non-lua-specific parser handling.\n    mcp_backend_t *be; // backend handling this request.\n    bool ascii_multiget; // ascii multiget mode. (hide errors/END)\n    char request[];\n};\n\ntypedef STAILQ_HEAD(io_head_s, _io_pending_proxy_t) io_head_t;\n#define MAX_LABELLEN 512\n#define MAX_NAMELEN 255\n#define MAX_PORTLEN 6\n// TODO (v2): IOV_MAX tends to be 1000+ which would allow for more batching but we\n// don't have a good temporary space and don't want to malloc/free on every\n// write. transmit() uses the stack but we can't do that for uring's use case.\n#if (IOV_MAX > 1024)\n#define BE_IOV_MAX 1024\n#else\n#define BE_IOV_MAX IOV_MAX\n#endif\n// lua descriptor object: passed to pools, which create wrappers.\nstruct mcp_backend_label_s {\n    char name[MAX_NAMELEN+1];\n    char port[MAX_PORTLEN+1];\n    char label[MAX_LABELLEN+1];\n    size_t llen; // cache label length for small speedup in pool creation.\n    int conncount; // number of sockets to make.\n    struct proxy_tunables tunables;\n};\n\n// lua object wrapper meant to own a malloc'ed conn structure\n// when this object is created, it ships its connection to the real owner\n// (worker, IO thread, etc)\n// when this object is garbage collected, it ships a notice to the owner\n// thread to stop using and free the backend conn memory.\nstruct mcp_backend_wrap_s {\n    mcp_backend_t *be;\n};\n\nstruct mcp_backendconn_s {\n    mcp_backend_t *be_parent; // find the wrapper.\n    int self; // our index into the parent array.\n    int depth; // total number of requests in queue\n    int pending_read; // number of requests written to socket, pending read.\n    int failed_count; // number of fails (timeouts) in a row\n    int flap_count; // number of times we've \"flapped\" into bad state.\n    proxy_event_thread_t *event_thread; // event thread owning this backend.\n    void *client; // mcmc client\n    io_head_t io_head; // stack of requests.\n    io_pending_proxy_t *io_next; // next request to write.\n    char *rbuf; // statically allocated read buffer.\n    size_t rbufused; // currently active bytes in the buffer\n    struct event main_event; // libevent: changes role, mostly for main read events\n    struct event write_event; // libevent: only used when socket wbuf full\n    struct event timeout_event; // libevent: alarm for pending reads\n    struct proxy_tunables tunables;\n    struct timeval last_failed; // time the backend was last reset.\n    enum mcp_backend_states state; // readback state machine\n    int connect_flags; // flags to pass to mcmc_connect\n    bool connecting; // in the process of an asynch connection.\n    bool validating; // in process of validating a new backend connection.\n    bool can_write; // recently got a WANT_WRITE or are connecting.\n    bool bad; // timed out, marked as bad.\n    struct iovec write_iovs[BE_IOV_MAX]; // iovs to stage batched writes\n};\n\n// TODO: move depth and flags to a second top level array so we can make index\n// decisions from fewer memory stalls.\nstruct mcp_backend_s {\n    int conncount; // total number of connections managed.\n    int depth; // temporary depth counter for io_head\n    bool transferred; // if beconn has been shipped to owner thread.\n    bool use_io_thread; // note if this backend is worker-local or not.\n    bool stacked; // if backend already queued for syscalls.\n    STAILQ_ENTRY(mcp_backend_s) beconn_next; // stack for connecting conns\n    STAILQ_ENTRY(mcp_backend_s) be_next; // stack for backends\n    io_head_t io_head; // stack of inbound requests.\n    char name[MAX_NAMELEN+1];\n    char port[MAX_PORTLEN+1];\n    struct proxy_tunables tunables; // this gets copied a few times for speed.\n    struct mcp_backendconn_s be[];\n};\ntypedef STAILQ_HEAD(be_head_s, mcp_backend_s) be_head_t;\ntypedef STAILQ_HEAD(beconn_head_s, mcp_backend_s) beconn_head_t;\n\nstruct proxy_event_thread_s {\n    pthread_t thread_id;\n    struct event_base *base;\n    struct event notify_event; // listen event for the notify pipe/eventfd.\n    struct event beconn_event; // listener for backends in connect state\n#ifdef HAVE_LIBURING\n    struct io_uring ring;\n    proxy_event_t ur_notify_event; // listen on eventfd.\n    proxy_event_t ur_benotify_event; // listen on eventfd for backend connections.\n    eventfd_t event_counter;\n    eventfd_t beevent_counter;\n    bool use_uring;\n#endif\n    pthread_mutex_t mutex; // covers stack.\n    pthread_cond_t cond; // condition to wait on while stack drains.\n    io_head_t io_head_in; // inbound requests to process.\n    be_head_t be_head; // stack of backends for processing.\n    beconn_head_t beconn_head_in; // stack of backends for connection processing.\n#ifdef USE_EVENTFD\n    int event_fd; // for request ingestion\n    int be_event_fd; // for backend ingestion\n#else\n    int notify_receive_fd;\n    int notify_send_fd;\n    int be_notify_receive_fd;\n    int be_notify_send_fd;\n#endif\n    proxy_ctx_t *ctx; // main context.\n};\n\nenum mcp_resp_mode {\n    RESP_MODE_NORMAL = 0,\n    RESP_MODE_NOREPLY,\n    RESP_MODE_METAQUIET\n};\n\n#define RESP_CMD_MAX 8\ntypedef struct {\n    mcmc_resp_t resp;\n    char *buf; // response line + potentially value.\n    mc_resp *cresp; // client mc_resp object during extstore fetches.\n    LIBEVENT_THREAD *thread; // cresp's owner thread needed for extstore cleanup.\n    unsigned int blen; // total size of the value to read.\n    struct timeval start; // time this object was created.\n    long elapsed; // time elapsed once handled.\n    int status; // status code from mcmc_read()\n    int bread; // amount of bytes read into value so far.\n    uint8_t cmd; // from parser (pr.command)\n    uint8_t extra; // ascii multiget hack for memory accounting. extra blen.\n    enum mcp_resp_mode mode; // reply mode (for noreply fixing)\n    char be_name[MAX_NAMELEN+1];\n    char be_port[MAX_PORTLEN+1];\n} mcp_resp_t;\n\n// re-cast an io_pending_t into this more descriptive structure.\n// the first few items _must_ match the original struct.\n#define IO_PENDING_TYPE_PROXY 0\n#define IO_PENDING_TYPE_EXTSTORE 1\nstruct _io_pending_proxy_t {\n    int io_queue_type;\n    LIBEVENT_THREAD *thread;\n    conn *c;\n    mc_resp *resp;\n    io_queue_cb return_cb; // called on worker thread.\n    io_queue_cb finalize_cb; // called back on the worker thread.\n    STAILQ_ENTRY(io_pending_t) iop_next; // queue chain.\n    // original struct ends here\n\n    int io_type; // extstore IO or backend IO\n    int coro_ref; // lua registry reference to the coroutine\n    lua_State *coro; // pointer directly to the coroutine\n    bool ascii_multiget; // passed on from mcp_r_t\n    union {\n        // extstore IO.\n        struct {\n            obj_io eio;\n            item *hdr_it;\n            mc_resp *tresp; // temporary mc_resp for storage to fill.\n            int gettype;\n            int iovec_data;\n            bool miss;\n            bool badcrc;\n            bool active;\n        };\n        // backend request IO\n        struct {\n            // FIXME: use top level next chain\n            struct _io_pending_proxy_t *next; // stack for IO submission\n            STAILQ_ENTRY(_io_pending_proxy_t) io_next; // stack for backends\n            int mcpres_ref; // mcp.res reference used for await()\n            mcp_backend_t *backend; // backend server to request from\n            struct iovec iov[2]; // request string + tail buffer\n            int iovcnt; // 1 or 2...\n            unsigned int iovbytes; // total bytes in the iovec\n            int await_ref; // lua reference if we were an await object\n            mcp_resp_t *client_resp; // reference (currently pointing to a lua object)\n            bool flushed; // whether we've fully written this request to a backend.\n            bool is_await; // are we an await object?\n            bool await_first; // are we the main route for an await object?\n            bool await_background; // dummy IO for backgrounded awaits\n        };\n    };\n};\n\n// Note: does *be have to be a sub-struct? how stable are userdata pointers?\n// https://stackoverflow.com/questions/38718475/lifetime-of-lua-userdata-pointers\n// - says no.\ntypedef struct {\n    int ref; // luaL_ref reference of backend_wrap_t obj.\n    mcp_backend_t *be;\n} mcp_pool_be_t;\n\n#define KEY_HASH_FILTER_MAX 5\ntypedef struct mcp_pool_s mcp_pool_t;\nstruct mcp_pool_s {\n    struct proxy_hash_caller phc;\n    key_hash_filter_func key_filter;\n    key_hash_func key_hasher;\n    pthread_mutex_t lock; // protects refcount.\n    proxy_ctx_t *ctx; // main context.\n    STAILQ_ENTRY(mcp_pool_s) next; // stack for deallocator.\n    char key_filter_conf[KEY_HASH_FILTER_MAX+1];\n    char beprefix[MAX_LABELLEN+1]; // TODO: should probably be shorter.\n    uint64_t hash_seed; // calculated from a string.\n    int refcount;\n    int phc_ref;\n    int self_ref; // TODO (v2): double check that this is needed.\n    int pool_size;\n    bool use_iothread;\n    mcp_pool_be_t pool[];\n};\n\ntypedef struct {\n    mcp_pool_t *main; // ptr to original\n    mcp_pool_be_t *pool; // ptr to main->pool starting offset for owner thread.\n} mcp_pool_proxy_t;\n\n// utils\nbool proxy_bufmem_checkadd(LIBEVENT_THREAD *t, int len);\n\n// networking interface\nvoid proxy_init_event_thread(proxy_event_thread_t *t, proxy_ctx_t *ctx, struct event_base *base);\nvoid *proxy_event_thread(void *arg);\nvoid proxy_run_backend_queue(be_head_t *head);\nstruct mcp_backendconn_s *proxy_choose_beconn(mcp_backend_t *be);\n\n// await interface\nenum mcp_await_e {\n    AWAIT_GOOD = 0, // looks for OK + NOT MISS\n    AWAIT_ANY, // any response, including errors,\n    AWAIT_OK, // any non-error response\n    AWAIT_FIRST, // return the result from the first pool\n    AWAIT_FASTGOOD, // returns on first hit or majority non-error\n    AWAIT_BACKGROUND, // returns as soon as background jobs are dispatched\n};\nint mcplib_await(lua_State *L);\nint mcplib_await_logerrors(lua_State *L);\nint mcplib_await_run(conn *c, mc_resp *resp, lua_State *L, int coro_ref);\nint mcplib_await_return(io_pending_proxy_t *p);\n\n// internal request interface\nint mcplib_internal(lua_State *L);\nint mcplib_internal_run(lua_State *L, conn *c, mc_resp *top_resp, int coro_ref);\n\n// user stats interface\nint mcplib_add_stat(lua_State *L);\nint mcplib_stat(lua_State *L);\nsize_t _process_request_next_key(mcp_parser_t *pr);\nint process_request(mcp_parser_t *pr, const char *command, size_t cmdlen);\nmcp_request_t *mcp_new_request(lua_State *L, mcp_parser_t *pr, const char *command, size_t cmdlen);\n\n// rate limit interfaces\nint mcplib_ratelim_tbf(lua_State *L);\nint mcplib_ratelim_tbf_call(lua_State *L);\n\n// request interface\nint mcplib_request(lua_State *L);\nint mcplib_request_command(lua_State *L);\nint mcplib_request_key(lua_State *L);\nint mcplib_request_ltrimkey(lua_State *L);\nint mcplib_request_rtrimkey(lua_State *L);\nint mcplib_request_token(lua_State *L);\nint mcplib_request_ntokens(lua_State *L);\nint mcplib_request_has_flag(lua_State *L);\nint mcplib_request_flag_token(lua_State *L);\nint mcplib_request_gc(lua_State *L);\n\nint mcplib_open_dist_jump_hash(lua_State *L);\nint mcplib_open_dist_ring_hash(lua_State *L);\n\nint proxy_run_coroutine(lua_State *Lc, mc_resp *resp, io_pending_proxy_t *p, conn *c);\nmcp_backend_t *mcplib_pool_proxy_call_helper(lua_State *L, mcp_pool_proxy_t *pp, const char *key, size_t len);\nvoid mcp_request_attach(lua_State *L, mcp_request_t *rq, io_pending_proxy_t *p);\nint mcp_request_render(mcp_request_t *rq, int idx, const char *tok, size_t len);\nvoid proxy_lua_error(lua_State *L, const char *s);\nvoid proxy_lua_ferror(lua_State *L, const char *fmt, ...);\n#define PROXY_SERVER_ERROR \"SERVER_ERROR \"\n#define PROXY_CLIENT_ERROR \"CLIENT_ERROR \"\nvoid proxy_out_errstring(mc_resp *resp, char *type, const char *str);\nint _start_proxy_config_threads(proxy_ctx_t *ctx);\nint proxy_thread_loadconf(proxy_ctx_t *ctx, LIBEVENT_THREAD *thr);\n\n// TODO (v2): more .h files, perhaps?\nint mcplib_open_hash_xxhash(lua_State *L);\n\n__attribute__((unused)) void dump_stack(lua_State *L);\n#endif\n", "/* -*- Mode: C; tab-width: 4; c-basic-offset: 4; indent-tabs-mode: nil -*- */\n\n#include \"proxy.h\"\n\n#define PARSER_MAXLEN USHRT_MAX-1\n\n// Find the starting offsets of each token; ignoring length.\n// This creates a fast small (<= cacheline) index into the request,\n// where we later scan or directly feed data into API's.\nstatic int _process_tokenize(mcp_parser_t *pr, const size_t max) {\n    const char *s = pr->request;\n    int len = pr->reqlen - 2;\n\n    // since multigets can be huge, we can't purely judge reqlen against this\n    // limit, but we also can't index past it since the tokens are shorts.\n    if (len > PARSER_MAXLEN) {\n        len = PARSER_MAXLEN;\n    }\n    const char *end = s + len;\n    int curtoken = 0;\n\n    int state = 0;\n    while (s != end) {\n        switch (state) {\n            case 0:\n                // scanning for first non-space to find a token.\n                if (*s != ' ') {\n                    pr->tokens[curtoken] = s - pr->request;\n                    if (++curtoken == max) {\n                        s++;\n                        state = 2;\n                        break;\n                    }\n                    state = 1;\n                }\n                s++;\n                break;\n            case 1:\n                // advance over a token\n                if (*s != ' ') {\n                    s++;\n                } else {\n                    state = 0;\n                }\n                break;\n            case 2:\n                // hit max tokens before end of the line.\n                // keep advancing so we can place endcap token.\n                if (*s == ' ') {\n                    goto endloop;\n                }\n                s++;\n                break;\n        }\n    }\nendloop:\n\n    // endcap token so we can quickly find the length of any token by looking\n    // at the next one.\n    pr->tokens[curtoken] = s - pr->request;\n    pr->ntokens = curtoken;\n    P_DEBUG(\"%s: cur_tokens: %d\\n\", __func__, curtoken);\n\n    return 0;\n}\n\nstatic int _process_token_len(mcp_parser_t *pr, size_t token) {\n    const char *s = pr->request + pr->tokens[token];\n    const char *e = pr->request + pr->tokens[token+1];\n    // start of next token is after any space delimiters, so back those out.\n    while (*(e-1) == ' ') {\n        e--;\n    }\n    return e - s;\n}\n\nstatic int _process_request_key(mcp_parser_t *pr) {\n    pr->klen = _process_token_len(pr, pr->keytoken);\n    // advance the parser in case of multikey.\n    pr->parsed = pr->tokens[pr->keytoken] + pr->klen + 1;\n\n    if (pr->request[pr->parsed-1] == ' ') {\n        P_DEBUG(\"%s: request_key found extra space\\n\", __func__);\n        pr->has_space = true;\n    } else {\n        pr->has_space = false;\n    }\n    return 0;\n}\n\n// Just for ascii multiget: search for next \"key\" beyond where we stopped\n// tokenizing before.\n// Returns the offset for the next key.\nsize_t _process_request_next_key(mcp_parser_t *pr) {\n    const char *cur = pr->request + pr->parsed;\n    int remain = pr->reqlen - pr->parsed - 2;\n\n    // chew off any leading whitespace.\n    while (remain) {\n        if (*cur == ' ') {\n            remain--;\n            cur++;\n            pr->parsed++;\n        } else {\n            break;\n        }\n    }\n\n    const char *s = memchr(cur, ' ', remain);\n    if (s != NULL) {\n        pr->klen = s - cur;\n        pr->parsed += s - cur;\n    } else {\n        pr->klen = remain;\n        pr->parsed += remain;\n    }\n\n    return cur - pr->request;\n}\n\n// for fast testing of existence of meta flags.\n// meta has all flags as final tokens\nstatic int _process_request_metaflags(mcp_parser_t *pr, int token) {\n    if (pr->ntokens <= token) {\n        pr->t.meta.flags = 0; // no flags found.\n        return 0;\n    }\n    const char *cur = pr->request + pr->tokens[token];\n    const char *end = pr->request + pr->reqlen - 2;\n\n    // We blindly convert flags into bits, since the range of possible\n    // flags is deliberately < 64.\n    int state = 0;\n    while (cur != end) {\n        switch (state) {\n            case 0:\n                if (*cur == ' ') {\n                    cur++;\n                } else {\n                    if (*cur < 65 || *cur > 122) {\n                        return -1;\n                    }\n                    P_DEBUG(\"%s: setting meta flag: %d\\n\", __func__, *cur - 65);\n                    pr->t.meta.flags |= (uint64_t)1 << (*cur - 65);\n                    state = 1;\n                }\n                break;\n            case 1:\n                if (*cur != ' ') {\n                    cur++;\n                } else {\n                    state = 0;\n                }\n                break;\n        }\n    }\n\n    // not too great hack for noreply detection: this can be flattened out\n    // once a few other contexts are fixed and we detect the noreply from the\n    // coroutine start instead.\n    if (pr->t.meta.flags & ((uint64_t)1 << 48)) {\n        pr->noreply = true;\n    }\n\n    return 0;\n}\n\n// All meta commands are of form: \"cm key f l a g S100\"\nstatic int _process_request_meta(mcp_parser_t *pr) {\n    _process_tokenize(pr, PARSER_MAX_TOKENS);\n    if (pr->ntokens < 2) {\n        P_DEBUG(\"%s: not enough tokens for meta command: %d\\n\", __func__, pr->ntokens);\n        return -1;\n    }\n    pr->keytoken = 1;\n    _process_request_key(pr);\n\n    // pass the first flag token.\n    return _process_request_metaflags(pr, 2);\n}\n\n// ms <key> <datalen> <flags>*\\r\\n\nstatic int _process_request_mset(mcp_parser_t *pr) {\n    _process_tokenize(pr, PARSER_MAX_TOKENS);\n    if (pr->ntokens < 3) {\n        P_DEBUG(\"%s: not enough tokens for meta set command: %d\\n\", __func__, pr->ntokens);\n        return -1;\n    }\n    pr->keytoken = 1;\n    _process_request_key(pr);\n\n    const char *cur = pr->request + pr->tokens[2];\n\n    errno = 0;\n    char *n = NULL;\n    int vlen = strtol(cur, &n, 10);\n    if ((errno == ERANGE) || (cur == n)) {\n        return -1;\n    }\n\n    if (vlen < 0 || vlen > (INT_MAX - 2)) {\n       return -1;\n    }\n    vlen += 2;\n\n    pr->vlen = vlen;\n\n    // pass the first flag token\n    return _process_request_metaflags(pr, 3);\n}\n\n// gat[s] <exptime> <key>*\\r\\n\nstatic int _process_request_gat(mcp_parser_t *pr) {\n    _process_tokenize(pr, 3);\n    if (pr->ntokens < 3) {\n        P_DEBUG(\"%s: not enough tokens for GAT: %d\\n\", __func__, pr->ntokens);\n        return -1;\n    }\n\n    pr->keytoken = 2;\n    _process_request_key(pr);\n    return 0;\n}\n\n#define NOREPLYSTR \"noreply\"\n#define NOREPLYLEN sizeof(NOREPLYSTR)-1\n// given a tokenized parser for a normal ASCII command, checks for noreply\n// mode.\nstatic int _process_request_noreply(mcp_parser_t *pr) {\n    if (pr->tokens[pr->ntokens] - pr->tokens[pr->ntokens-1] >= NOREPLYLEN\n            && strncmp(NOREPLYSTR, pr->request + pr->tokens[pr->ntokens-1], NOREPLYLEN) == 0) {\n        pr->noreply = true;\n    }\n    return 0;\n}\n\n// we need t find the bytes supplied immediately so we can read the request\n// from the client properly.\n// set <key> <flags> <exptime> <bytes> [noreply]\\r\\n\nstatic int _process_request_storage(mcp_parser_t *pr, size_t max) {\n    _process_tokenize(pr, max);\n    if (pr->ntokens < 5) {\n        P_DEBUG(\"%s: not enough tokens to storage command: %d\\n\", __func__, pr->ntokens);\n        return -1;\n    }\n    pr->keytoken = 1;\n    _process_request_key(pr);\n\n    errno = 0;\n    char *n = NULL;\n    const char *cur = pr->request + pr->tokens[4];\n\n    int vlen = strtol(cur, &n, 10);\n    if ((errno == ERANGE) || (cur == n)) {\n        return -1;\n    }\n\n    if (vlen < 0 || vlen > (INT_MAX - 2)) {\n       return -1;\n    }\n    vlen += 2;\n\n    pr->vlen = vlen;\n\n    return _process_request_noreply(pr);\n}\n\n// common request with key: <cmd> <key> <args>\nstatic int _process_request_simple(mcp_parser_t *pr, const int min, const int max) {\n    _process_tokenize(pr, max);\n    if (pr->ntokens < min) {\n        P_DEBUG(\"%s: not enough tokens for simple request: %d\\n\", __func__, pr->ntokens);\n        return -1;\n    }\n    pr->keytoken = 1; // second token is usually the key... stupid GAT.\n\n    _process_request_key(pr);\n    return _process_request_noreply(pr);\n}\n\n// TODO: return code ENUM with error types.\n// FIXME: the mcp_parser_t bits have ended up being more fragile than I hoped.\n// careful zero'ing is required. revisit?\n// I think this mostly refers to recursive work (maybe just multiget?)\n// Is a parser object run throgh process_request() twice, ever?\nint process_request(mcp_parser_t *pr, const char *command, size_t cmdlen) {\n    // we want to \"parse in place\" as much as possible, which allows us to\n    // forward an unmodified request without having to rebuild it.\n\n    const char *cm = command;\n    size_t cl = 0;\n    // min command length is 2, plus the \"\\r\\n\"\n    if (cmdlen < 4) {\n        return -1;\n    }\n\n    const char *s = memchr(command, ' ', cmdlen-2);\n    if (s != NULL) {\n        cl = s - command;\n    } else {\n        cl = cmdlen - 2;\n    }\n    pr->keytoken = 0;\n    pr->has_space = false;\n    pr->parsed = cl + 1;\n    pr->request = command;\n    pr->reqlen = cmdlen;\n    int token_max = PARSER_MAX_TOKENS;\n\n    int cmd = -1;\n    int type = CMD_TYPE_GENERIC;\n    int ret = 0;\n\n    switch (cl) {\n        case 0:\n        case 1:\n            // falls through with cmd as -1. should error.\n            break;\n        case 2:\n            if (cm[0] == 'm') {\n                type = CMD_TYPE_META;\n                switch (cm[1]) {\n                    case 'g':\n                        cmd = CMD_MG;\n                        ret = _process_request_meta(pr);\n                        break;\n                    case 's':\n                        cmd = CMD_MS;\n                        ret = _process_request_mset(pr);\n                        break;\n                    case 'd':\n                        cmd = CMD_MD;\n                        ret = _process_request_meta(pr);\n                        break;\n                    case 'n':\n                        // TODO: do we route/handle NOP's at all?\n                        // they should simply reflect to the client.\n                        cmd = CMD_MN;\n                        break;\n                    case 'a':\n                        cmd = CMD_MA;\n                        ret = _process_request_meta(pr);\n                        break;\n                    case 'e':\n                        cmd = CMD_ME;\n                        // TODO: not much special processing here; binary keys\n                        ret = _process_request_meta(pr);\n                        break;\n                }\n            }\n            break;\n        case 3:\n            if (cm[0] == 'g') {\n                if (cm[1] == 'e' && cm[2] == 't') {\n                    cmd = CMD_GET;\n                    type = CMD_TYPE_GET;\n                    token_max = 2; // don't chew through multigets.\n                    ret = _process_request_simple(pr, 2, 2);\n                }\n                if (cm[1] == 'a' && cm[2] == 't') {\n                    type = CMD_TYPE_GET;\n                    cmd = CMD_GAT;\n                    token_max = 2; // don't chew through multigets.\n                    ret = _process_request_gat(pr);\n                }\n            } else if (cm[0] == 's' && cm[1] == 'e' && cm[2] == 't') {\n                cmd = CMD_SET;\n                ret = _process_request_storage(pr, token_max);\n            } else if (cm[0] == 'a' && cm[1] == 'd' && cm[2] == 'd') {\n                cmd = CMD_ADD;\n                ret = _process_request_storage(pr, token_max);\n            } else if (cm[0] == 'c' && cm[1] == 'a' && cm[2] == 's') {\n                cmd = CMD_CAS;\n                ret = _process_request_storage(pr, token_max);\n            }\n            break;\n        case 4:\n            if (strncmp(cm, \"gets\", 4) == 0) {\n                cmd = CMD_GETS;\n                type = CMD_TYPE_GET;\n                token_max = 2; // don't chew through multigets.\n                ret = _process_request_simple(pr, 2, 2);\n            } else if (strncmp(cm, \"incr\", 4) == 0) {\n                cmd = CMD_INCR;\n                ret = _process_request_simple(pr, 3, 4);\n            } else if (strncmp(cm, \"decr\", 4) == 0) {\n                cmd = CMD_DECR;\n                ret = _process_request_simple(pr, 3, 4);\n            } else if (strncmp(cm, \"gats\", 4) == 0) {\n                cmd = CMD_GATS;\n                type = CMD_TYPE_GET;\n                ret = _process_request_gat(pr);\n            } else if (strncmp(cm, \"quit\", 4) == 0) {\n                cmd = CMD_QUIT;\n            }\n            break;\n        case 5:\n            if (strncmp(cm, \"touch\", 5) == 0) {\n                cmd = CMD_TOUCH;\n                ret = _process_request_simple(pr, 3, 4);\n            } else if (strncmp(cm, \"stats\", 5) == 0) {\n                cmd = CMD_STATS;\n                // Don't process a key; fetch via arguments.\n                _process_tokenize(pr, token_max);\n            } else if (strncmp(cm, \"watch\", 5) == 0) {\n                cmd = CMD_WATCH;\n                _process_tokenize(pr, token_max);\n            }\n            break;\n        case 6:\n            if (strncmp(cm, \"delete\", 6) == 0) {\n                cmd = CMD_DELETE;\n                ret = _process_request_simple(pr, 2, 4);\n            } else if (strncmp(cm, \"append\", 6) == 0) {\n                cmd = CMD_APPEND;\n                ret = _process_request_storage(pr, token_max);\n            }\n            break;\n        case 7:\n            if (strncmp(cm, \"replace\", 7) == 0) {\n                cmd = CMD_REPLACE;\n                ret = _process_request_storage(pr, token_max);\n            } else if (strncmp(cm, \"prepend\", 7) == 0) {\n                cmd = CMD_PREPEND;\n                ret = _process_request_storage(pr, token_max);\n            } else if (strncmp(cm, \"version\", 7) == 0) {\n                cmd = CMD_VERSION;\n                _process_tokenize(pr, token_max);\n            }\n            break;\n    }\n\n    // TODO: log more specific error code.\n    if (cmd == -1 || ret != 0) {\n        return -1;\n    }\n\n    pr->command = cmd;\n    pr->cmd_type = type;\n\n    return 0;\n}\n\n// FIXME (v2): any reason to pass in command/cmdlen separately?\nmcp_request_t *mcp_new_request(lua_State *L, mcp_parser_t *pr, const char *command, size_t cmdlen) {\n    // reserving an upvalue for key.\n    mcp_request_t *rq = lua_newuserdatauv(L, sizeof(mcp_request_t) + MCP_REQUEST_MAXLEN + KEY_MAX_LENGTH, 1);\n    // TODO (v2): memset only the non-data part? as the rest gets memcpy'd\n    // over.\n    memset(rq, 0, sizeof(mcp_request_t));\n    memcpy(&rq->pr, pr, sizeof(*pr));\n\n    memcpy(rq->request, command, cmdlen);\n    rq->pr.request = rq->request;\n    rq->pr.reqlen = cmdlen;\n\n    luaL_getmetatable(L, \"mcp.request\");\n    lua_setmetatable(L, -2);\n\n    // at this point we should know if we have to bounce through _nread to\n    // get item data or not.\n    return rq;\n}\n\n// Replaces a token inside a request and re-parses.\n// Note that this has some optimization opportunities. Delaying until\n// required.\n// We should not guarantee order when updating meta flags, which would allow\n// blanking tokens and appending new ones.\n// TODO (v2): function doesn't allow appending.\n// TODO (v2): much of the length is the key, avoid copying it.\nint mcp_request_render(mcp_request_t *rq, int idx, const char *tok, size_t len) {\n    char temp[MCP_REQUEST_MAXLEN];\n    char *p = temp;\n    mcp_parser_t *pr = &rq->pr;\n\n    if (pr->reqlen + len > MCP_REQUEST_MAXLEN) {\n        return -1;\n    }\n    // Cannot add/append tokens yet.\n    if (idx >= pr->ntokens) {\n        return -1;\n    }\n\n    memcpy(p, pr->request, pr->tokens[idx]);\n    p += pr->tokens[idx];\n\n    memcpy(p, tok, len);\n    p += len;\n\n    // Add a space and copy more tokens if there were more.\n    if (idx+1 < pr->ntokens) {\n        if (len != 0) {\n            // Only pre-space if not deleting the token.\n            *p = ' ';\n            p++;\n        }\n        memcpy(p, &pr->request[pr->tokens[idx+1]], pr->tokens[pr->ntokens] - pr->tokens[idx+1]);\n        p += pr->tokens[pr->ntokens] - pr->tokens[idx+1];\n    }\n\n    memcpy(p, \"\\r\\n\\0\", 3);\n    p += 2;\n\n    memcpy(rq->request, temp, p - temp);\n\n    // Hold the vlen/vbuf and restore after re-parsing. Since we can only edit\n    // the command line, not the value here, we would otherwise allow sending\n    // arbitrary memory over the network if someone modifies a SET.\n    void *vbuf = pr->vbuf;\n    int vlen = pr->vlen;\n\n    memset(pr, 0, sizeof(mcp_parser_t)); // TODO: required?\n    int ret = process_request(pr, rq->request, p - temp);\n    if (ret != 0) {\n        return ret;\n    }\n    pr->vbuf = vbuf;\n    pr->vlen = vlen;\n    return 0;\n}\n\nvoid mcp_request_attach(lua_State *L, mcp_request_t *rq, io_pending_proxy_t *p) {\n    mcp_parser_t *pr = &rq->pr;\n    char *r = (char *) pr->request;\n    size_t len = pr->reqlen;\n\n    // The stringified request. This is also referencing into the coroutine\n    // stack, which should be safe from gc.\n    p->iov[0].iov_base = r;\n    p->iov[0].iov_len = len;\n    p->iovcnt = 1;\n    p->iovbytes = len;\n    if (pr->vlen != 0) {\n        p->iov[1].iov_base = pr->vbuf;\n        p->iov[1].iov_len = pr->vlen;\n        p->iovcnt = 2;\n        p->iovbytes += pr->vlen;\n    }\n}\n\n// second argument is optional, for building set requests.\n// TODO: append the \\r\\n for the VAL?\nint mcplib_request(lua_State *L) {\n    LIBEVENT_THREAD *t = PROXY_GET_THR(L);\n    size_t len = 0;\n    size_t vlen = 0;\n    mcp_parser_t pr = {0};\n    const char *cmd = luaL_checklstring(L, 1, &len);\n    const char *val = NULL;\n    int type = lua_type(L, 2);\n    if (type == LUA_TSTRING) {\n        val = luaL_optlstring(L, 2, NULL, &vlen);\n        if (vlen < 2 || memcmp(val+vlen-2, \"\\r\\n\", 2) != 0) {\n            proxy_lua_error(L, \"value passed to mcp.request must end with \\\\r\\\\n\");\n        }\n    } else if (type == LUA_TUSERDATA) {\n        // vlen for requests and responses include the \"\\r\\n\" already.\n        mcp_resp_t *r = luaL_testudata(L, 2, \"mcp.response\");\n        if (r != NULL) {\n            if (r->resp.value) {\n                val = r->resp.value;\n                vlen = r->resp.vlen_read; // paranoia, so we can't overread into memory.\n            }\n        } else {\n            mcp_request_t *rq = luaL_testudata(L, 2, \"mcp.request\");\n            if (rq->pr.vbuf) {\n                val = rq->pr.vbuf;\n                vlen = rq->pr.vlen;\n            }\n        }\n    }\n\n    // FIXME (v2): if we inline the userdata we can avoid memcpy'ing the parser\n    // structure from the stack? but causes some code duplication.\n    if (process_request(&pr, cmd, len) != 0) {\n        proxy_lua_error(L, \"failed to parse request\");\n        return 0;\n    }\n    mcp_request_t *rq = mcp_new_request(L, &pr, cmd, len);\n\n    if (val != NULL) {\n        rq->pr.vlen = vlen;\n        rq->pr.vbuf = malloc(vlen);\n        if (rq->pr.vbuf == NULL) {\n            // Note: without *c we can't tick the appropriate counter.\n            // However, in practice raw malloc's are nearly never going to\n            // fail.\n            // TODO(v2): we can stack values into the request objects or use\n            // the slabber memory, so this isn't necessary anyway.\n            proxy_lua_error(L, \"failed to allocate value memory for request object\");\n        }\n        memcpy(rq->pr.vbuf, val, vlen);\n        // Note: Not enforcing the memory limit here is deliberate:\n        // - if we're over the memory limit, it'll get caught very soon after\n        // this, but we won't be causing some lua to bail mid-flight, which is\n        // more graceful to the end user.\n        pthread_mutex_lock(&t->proxy_limit_lock);\n        t->proxy_buffer_memory_used += rq->pr.vlen;\n        pthread_mutex_unlock(&t->proxy_limit_lock);\n    }\n\n    // rq is now created, parsed, and on the stack.\n    return 1;\n}\n\nint mcplib_request_key(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, -1, \"mcp.request\");\n    lua_pushlstring(L, MCP_PARSER_KEY(rq->pr), rq->pr.klen);\n    return 1;\n}\n\n// NOTE: I've mixed up const/non-const strings in the request. During parsing\n// we want it to be const, but after that's done the request is no longer\n// const. It might be better to just remove the const higher up the chain, but\n// I'd rather not. So for now these functions will be dumping the const to\n// modify the string.\nint mcplib_request_ltrimkey(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, -2, \"mcp.request\");\n    int totrim = luaL_checkinteger(L, -1);\n    char *key = (char *) MCP_PARSER_KEY(rq->pr);\n\n    if (totrim > rq->pr.klen) {\n        proxy_lua_error(L, \"ltrimkey cannot zero out key\");\n        return 0;\n    } else {\n        memset(key, ' ', totrim);\n        rq->pr.klen -= totrim;\n        rq->pr.tokens[rq->pr.keytoken] += totrim;\n    }\n    return 1;\n}\n\nint mcplib_request_rtrimkey(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, -2, \"mcp.request\");\n    int totrim = luaL_checkinteger(L, -1);\n    char *key = (char *) MCP_PARSER_KEY(rq->pr);\n\n    if (totrim > rq->pr.klen) {\n        proxy_lua_error(L, \"rtrimkey cannot zero out key\");\n        return 0;\n    } else {\n        memset(key + (rq->pr.klen - totrim), ' ', totrim);\n        rq->pr.klen -= totrim;\n        // don't need to change the key token.\n    }\n    return 1;\n}\n\n// Virtual table operations on the request.\nint mcplib_request_token(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, 1, \"mcp.request\");\n    int argc = lua_gettop(L);\n\n    if (argc == 1) {\n        lua_pushnil(L);\n        return 1;\n    }\n\n    int token = luaL_checkinteger(L, 2);\n\n    if (token < 1 || token > rq->pr.ntokens) {\n        // maybe an error?\n        lua_pushnil(L);\n        return 1;\n    }\n\n    size_t vlen = 0;\n    if (argc > 2) {\n        // overwriting a token.\n        size_t newlen = 0;\n        const char *newtok = lua_tolstring(L, 3, &newlen);\n        if (mcp_request_render(rq, token-1, newtok, newlen) != 0) {\n            proxy_lua_error(L, \"token(): request malformed after edit\");\n            return 0;\n        }\n        return 0;\n    } else {\n        // fetching a token.\n        const char *start = rq->pr.request + rq->pr.tokens[token-1];\n        vlen = _process_token_len(&rq->pr, token-1);\n\n        P_DEBUG(\"%s: pushing token of len: %lu\\n\", __func__, vlen);\n        lua_pushlstring(L, start, vlen);\n        return 1;\n    }\n\n    return 0;\n}\n\nint mcplib_request_ntokens(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, 1, \"mcp.request\");\n    lua_pushinteger(L, rq->pr.ntokens);\n    return 1;\n}\n\nint mcplib_request_command(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, -1, \"mcp.request\");\n    lua_pushinteger(L, rq->pr.command);\n    return 1;\n}\n\nint mcplib_request_has_flag(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, 1, \"mcp.request\");\n    size_t len = 0;\n    const char *flagstr = luaL_checklstring(L, 2, &len);\n    if (len != 1) {\n        proxy_lua_error(L, \"has_flag(): meta flag must be a single character\");\n        return 0;\n    }\n    if (flagstr[0] < 65 || flagstr[0] > 122) {\n        proxy_lua_error(L, \"has_flag(): invalid flag, must be A-Z,a-z\");\n        return 0;\n    }\n    uint64_t flagbit = (uint64_t)1 << (flagstr[0] - 65);\n    if (rq->pr.t.meta.flags & flagbit) {\n        lua_pushboolean(L, 1);\n    } else {\n        lua_pushboolean(L, 0);\n    }\n\n    return 1;\n}\n\n// req:flag_token(\"F\") -> (bool, nil|token)\n// req:flag_token(\"O\", \"Onewopauqe\") -> (bool, oldtoken)\nint mcplib_request_flag_token(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, 1, \"mcp.request\");\n    size_t len = 0;\n    const char *flagstr = luaL_checklstring(L, 2, &len);\n    bool replace = false;\n    if (len != 1) {\n        proxy_lua_error(L, \"has_flag(): meta flag must be a single character\");\n        return 0;\n    }\n    if (flagstr[0] < 65 || flagstr[0] > 122) {\n        proxy_lua_error(L, \"has_flag(): invalid flag, must be A-Z,a-z\");\n        return 0;\n    }\n    if (lua_isstring(L, 3)) {\n        // overwriting a flag/token with the third argument.\n        replace = true;\n    }\n    uint64_t flagbit = (uint64_t)1 << (flagstr[0] - 65);\n\n    int ret = 1;\n    if (rq->pr.t.meta.flags & flagbit) {\n        // The flag definitely exists, but sadly we need to scan for the\n        // actual flag to see if it has a token.\n        lua_pushboolean(L, 1);\n        for (int x = rq->pr.keytoken+1; x < rq->pr.ntokens; x++) {\n            const char *s = rq->pr.request + rq->pr.tokens[x];\n            if (s[0] == flagstr[0]) {\n                size_t vlen = _process_token_len(&rq->pr, x);\n                if (vlen > 1) {\n                    // strip the flag off the token and return.\n                    lua_pushlstring(L, s+1, vlen-1);\n                    ret = 2;\n                }\n\n                // Have something to replace the flag/token with.\n                if (replace) {\n                    size_t newlen = 0;\n                    const char *newtok = lua_tolstring(L, 3, &newlen);\n                    if (mcp_request_render(rq, x, newtok, newlen) != 0) {\n                        proxy_lua_error(L, \"token(): request malformed after edit\");\n                        return 0;\n                    }\n                }\n                break;\n            }\n        }\n    } else {\n        lua_pushboolean(L, 0);\n    }\n\n    return ret;\n}\n\nint mcplib_request_gc(lua_State *L) {\n    LIBEVENT_THREAD *t = PROXY_GET_THR(L);\n    mcp_request_t *rq = luaL_checkudata(L, -1, \"mcp.request\");\n    // During nread c->item is the malloc'ed buffer. not yet put into\n    // rq->buf - this gets freed because we've also set c->item_malloced if\n    // the connection closes before finishing nread.\n    if (rq->pr.vbuf != NULL) {\n        pthread_mutex_lock(&t->proxy_limit_lock);\n        t->proxy_buffer_memory_used -= rq->pr.vlen;\n        pthread_mutex_unlock(&t->proxy_limit_lock);\n        free(rq->pr.vbuf);\n    }\n\n    return 0;\n}\n\n// TODO (v2): check what lua does when it calls a function with a string argument\n// stored from a table/similar (ie; the prefix check code).\n// If it's not copying anything, we can add request-side functions to do most\n// forms of matching and avoid copying the key to lua space.\n", "#!/usr/bin/env perl\n\nuse strict;\nuse warnings;\nuse Test::More;\nuse FindBin qw($Bin);\nuse lib \"$Bin/lib\";\nuse Carp qw(croak);\nuse MemcachedTest;\n\n# TODO: to module?\n# or \"gettimedrun\" etc\nuse Cwd;\nmy $builddir = getcwd;\n\nif (!supports_proxy()) {\n    plan skip_all => 'proxy not enabled';\n    exit 0;\n}\n\n# TODO: the lua file has hardcoded ports. any way to make this dynamic?\n# TODO: once basic tests are done, actually split out the instances rather\n# than the shared backend; validate keys go where they should be going.\n\n# FIXME: this listend on unix socket still. either need a manual runner or a\n# fix upstream.\nmy @srv = ();\nfor (2 .. 6) {\n    my $srv = run_server(\"-p 1121$_\", 11210 + $_);\n    push(@srv, $srv);\n}\n#my $sock = $srv->sock;\n\nmy $p_srv = new_memcached('-o proxy_config=./t/startfile.lua');\nmy $p_sock = $p_srv->sock;\n\n# hack to help me use T_MEMD_USE_DAEMON for proxy.\n#print STDERR \"Sleeping\\n\";\n#sleep 900;\n\n# cmds to test:\n# - noreply for main text commands?\n# meta:\n# me\n# mn\n# mg\n# ms\n# md\n# ma\n# - noreply?\n# stats\n# pass-thru?\n\n# incr/decr\n{\n    print $p_sock \"set /foo/num 0 0 1\\r\\n1\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored num\");\n    mem_get_is($p_sock, \"/foo/num\", 1, \"stored 1\");\n\n    print $p_sock \"incr /foo/num 1\\r\\n\";\n    is(scalar <$p_sock>, \"2\\r\\n\", \"+ 1 = 2\");\n    mem_get_is($p_sock, \"/foo/num\", 2);\n\n    print $p_sock \"incr /foo/num 8\\r\\n\";\n    is(scalar <$p_sock>, \"10\\r\\n\", \"+ 8 = 10\");\n    mem_get_is($p_sock, \"/foo/num\", 10);\n\n    print $p_sock \"decr /foo/num 1\\r\\n\";\n    is(scalar <$p_sock>, \"9\\r\\n\", \"- 1 = 9\");\n\n    print $p_sock \"decr /foo/num 9\\r\\n\";\n    is(scalar <$p_sock>, \"0\\r\\n\", \"- 9 = 0\");\n\n    print $p_sock \"decr /foo/num 5\\r\\n\";\n    is(scalar <$p_sock>, \"0\\r\\n\", \"- 5 = 0\");\n}\n\n# gat\n{\n    # cache miss\n    print $p_sock \"gat 10 /foo/foo1\\r\\n\";\n    is(scalar <$p_sock>, \"END\\r\\n\", \"cache miss\");\n\n    # set /foo/foo1 and /foo/foo2 (and should get it)\n    print $p_sock \"set /foo/foo1 0 2 7\\r\\nfooval1\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored foo\");\n\n    print $p_sock \"set /foo/foo2 0 2 7\\r\\nfooval2\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored /foo/foo2\");\n\n    # get and touch it with cas\n    print $p_sock \"gats 10 /foo/foo1 /foo/foo2\\r\\n\";\n    like(scalar <$p_sock>, qr/VALUE \\/foo\\/foo1 0 7 (\\d+)\\r\\n/, \"get and touch foo1 with cas regexp success\");\n    is(scalar <$p_sock>, \"fooval1\\r\\n\",\"value\");\n    like(scalar <$p_sock>, qr/VALUE \\/foo\\/foo2 0 7 (\\d+)\\r\\n/, \"get and touch foo2 with cas regexp success\");\n    is(scalar <$p_sock>, \"fooval2\\r\\n\",\"value\");\n    is(scalar <$p_sock>, \"END\\r\\n\", \"end\");\n\n    # get and touch it without cas\n    print $p_sock \"gat 10 /foo/foo1 /foo/foo2\\r\\n\";\n    like(scalar <$p_sock>, qr/VALUE \\/foo\\/foo1 0 7\\r\\n/, \"get and touch foo1 without cas regexp success\");\n    is(scalar <$p_sock>, \"fooval1\\r\\n\",\"value\");\n    like(scalar <$p_sock>, qr/VALUE \\/foo\\/foo2 0 7\\r\\n/, \"get and touch foo2 without cas regexp success\");\n    is(scalar <$p_sock>, \"fooval2\\r\\n\",\"value\");\n    is(scalar <$p_sock>, \"END\\r\\n\", \"end\");\n}\n\n# gets/cas\n{\n    print $p_sock \"add /foo/moo 0 0 6\\r\\nmooval\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored mooval\");\n    mem_get_is($p_sock, \"/foo/moo\", \"mooval\");\n\n    # check-and-set (cas) failure case, try to set value with incorrect cas unique val\n    print $p_sock \"cas /foo/moo 0 0 6 0\\r\\nMOOVAL\\r\\n\";\n    is(scalar <$p_sock>, \"EXISTS\\r\\n\", \"check and set with invalid id\");\n\n    # test \"gets\", grab unique ID\n    print $p_sock \"gets /foo/moo\\r\\n\";\n    # VALUE moo 0 6 3084947704\n    #\n    my @retvals = split(/ /, scalar <$p_sock>);\n    my $data = scalar <$p_sock>; # grab data\n    my $dot  = scalar <$p_sock>; # grab dot on line by itself\n    is($retvals[0], \"VALUE\", \"get value using 'gets'\");\n    my $unique_id = $retvals[4];\n    # clean off \\r\\n\n    $unique_id =~ s/\\r\\n$//;\n    ok($unique_id =~ /^\\d+$/, \"unique ID '$unique_id' is an integer\");\n    # now test that we can store moo with the correct unique id\n    print $p_sock \"cas /foo/moo 0 0 6 $unique_id\\r\\nMOOVAL\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\");\n    mem_get_is($p_sock, \"/foo/moo\", \"MOOVAL\");\n}\n\n# touch\n{\n    print $p_sock \"set /foo/t 0 2 6\\r\\nfooval\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored foo\");\n    mem_get_is($p_sock, \"/foo/t\", \"fooval\");\n\n    # touch it\n    print $p_sock \"touch /foo/t 10\\r\\n\";\n    is(scalar <$p_sock>, \"TOUCHED\\r\\n\", \"touched foo\");\n\n    # don't need to sleep/validate the touch worked. We're testing the\n    # protocol, not the functionality.\n}\n\n# command endings\n# NOTE: memcached always allowed [\\r]\\n for single command lines, but payloads\n# (set/etc) require exactly \\r\\n as termination.\n# doc/protocol.txt has always specified \\r\\n for command/response.\n# Proxy is more strict than normal server in this case.\n{\n    my $s = $srv[0]->sock;\n    print $s \"version\\n\";\n    like(<$s>, qr/VERSION/, \"direct server version cmd with just newline\");\n    print $p_sock \"version\\n\";\n    like(<$p_sock>, qr/CLIENT_ERROR/, \"proxy version cmd with just newline\");\n    print $p_sock \"version\\r\\n\";\n    like(<$p_sock>, qr/VERSION/, \"proxy version cmd with full CRLF\");\n}\n\n# set through proxy.\n{\n    print $p_sock \"set /foo/z 0 0 5\\r\\nhello\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n    # ensure it's fetchable.\n    mem_get_is($p_sock, \"/foo/z\", \"hello\");\n    # delete it.\n    print $p_sock \"delete /foo/z\\r\\n\";\n    is(scalar <$p_sock>, \"DELETED\\r\\n\", \"removed test value\");\n    # ensure it's deleted.\n    mem_get_is($p_sock, \"/foo/z\", undef);\n}\n\n# test add.\n{\n    print $p_sock \"add /foo/a 0 0 3\\r\\nmoo\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"add test value through proxy\");\n    # ensure it's fetchable\n    mem_get_is($p_sock, \"/foo/a\", \"moo\");\n    # check re-adding fails.\n    print $p_sock \"add /foo/a 0 0 3\\r\\ngoo\\r\\n\";\n    is(scalar <$p_sock>, \"NOT_STORED\\r\\n\", \"re-add fails\");\n    # ensure we still hae the old value\n    mem_get_is($p_sock, \"/foo/a\", \"moo\");\n}\n\n# pipelined set.\n{\n    my $str = \"set /foo/k 0 0 5\\r\\nhello\\r\\n\";\n    print $p_sock \"$str$str$str$str$str\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n}\n\n# Load some keys through proxy.\nmy $bdata = 'x' x 256000;\n{\n    for (1..20) {\n        print $p_sock \"set /foo/a$_ 0 0 2\\r\\nhi\\r\\n\";\n        is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value\");\n        print $p_sock \"set /bar/b$_ 0 0 2\\r\\nhi\\r\\n\";\n        is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value\");\n    }\n\n    # load a couple larger values\n    for (1..4) {\n        print $p_sock \"set /foo/big$_ 0 0 256000\\r\\n$bdata\\r\\n\";\n        is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored big value\");\n    }\n    diag \"set large values\";\n}\n\n# fetch through proxy.\n{\n    for (1..20) {\n        mem_get_is($p_sock, \"/foo/a$_\", \"hi\");\n    }\n    diag \"fetched small values\";\n    mem_get_is($p_sock, \"/foo/big1\", $bdata);\n    diag \"fetched big value\";\n}\n\nsub run_server {\n    my ($args, $port) = @_;\n\n    my $exe = get_memcached_exe();\n\n    my $childpid = fork();\n\n    my $root = '';\n    $root = \"-u root\" if ($< == 0);\n\n    # test build requires more privileges\n    $args .= \" -o relaxed_privileges\";\n\n    my $cmd = \"$builddir/timedrun 120 $exe $root $args\";\n\n    unless($childpid) {\n        exec $cmd;\n        exit; # NOTREACHED\n    }\n\n    for (1..20) {\n        my $conn = IO::Socket::INET->new(PeerAddr => \"127.0.0.1:$port\");\n        if ($conn) {\n            return Memcached::Handle->new(pid  => $childpid,\n                conn => $conn,\n                host => \"127.0.0.1\",\n                port => $port);\n        }\n        select undef, undef, undef, 0.10;\n    }\n    croak \"Failed to start server.\";\n}\n\ndone_testing();\n"], "fixing_code": ["#ifndef PROXY_H\n#define PROXY_H\n\n#include \"memcached.h\"\n#include \"extstore.h\"\n#include <string.h>\n#include <stdlib.h>\n#include <ctype.h>\n#include <errno.h>\n\n#include <lua.h>\n#include <lualib.h>\n#include <lauxlib.h>\n\n#include \"config.h\"\n\n#if defined(__linux__)\n#define USE_EVENTFD 1\n#include <sys/eventfd.h>\n#endif\n\n#ifdef HAVE_LIBURING\n#include <liburing.h>\n#include <poll.h> // POLLOUT for liburing.\n#define PRING_QUEUE_SQ_ENTRIES 2048\n#define PRING_QUEUE_CQ_ENTRIES 16384\n#endif\n\n#include \"proto_proxy.h\"\n#include \"proto_text.h\"\n#include \"queue.h\"\n#define XXH_INLINE_ALL // modifier for xxh3's include below\n#include \"xxhash.h\"\n\n#ifdef PROXY_DEBUG\n#define P_DEBUG(...) \\\n    do { \\\n        fprintf(stderr, __VA_ARGS__); \\\n    } while (0)\n#else\n#define P_DEBUG(...)\n#endif\n\n#define WSTAT_L(t) pthread_mutex_lock(&t->stats.mutex);\n#define WSTAT_UL(t) pthread_mutex_unlock(&t->stats.mutex);\n#define WSTAT_INCR(t, stat, amount) { \\\n    pthread_mutex_lock(&t->stats.mutex); \\\n    t->stats.stat += amount; \\\n    pthread_mutex_unlock(&t->stats.mutex); \\\n}\n#define WSTAT_DECR(t, stat, amount) { \\\n    pthread_mutex_lock(&t->stats.mutex); \\\n    t->stats.stat -= amount; \\\n    pthread_mutex_unlock(&t->stats.mutex); \\\n}\n#define STAT_L(ctx) pthread_mutex_lock(&ctx->stats_lock);\n#define STAT_UL(ctx) pthread_mutex_unlock(&ctx->stats_lock);\n#define STAT_INCR(ctx, stat, amount) { \\\n        pthread_mutex_lock(&ctx->stats_lock); \\\n        ctx->global_stats.stat += amount; \\\n        pthread_mutex_unlock(&ctx->stats_lock); \\\n}\n\n#define STAT_DECR(ctx, stat, amount) { \\\n        pthread_mutex_lock(&ctx->stats_lock); \\\n        ctx->global_stats.stat -= amount; \\\n        pthread_mutex_unlock(&ctx->stats_lock); \\\n}\n\n// FIXME (v2): do include dir properly.\n#include \"vendor/mcmc/mcmc.h\"\n\n// Note: value created from thin air. Could be shorter.\n#define MCP_REQUEST_MAXLEN KEY_MAX_LENGTH * 2\n\n#define ENDSTR \"END\\r\\n\"\n#define ENDLEN sizeof(ENDSTR)-1\n\n#define MCP_BACKEND_UPVALUE 1\n\n#define MCP_YIELD_POOL 1\n#define MCP_YIELD_AWAIT 2\n#define MCP_YIELD_LOCAL 3\n\n// all possible commands.\n#define CMD_FIELDS \\\n    X(CMD_MG) \\\n    X(CMD_MS) \\\n    X(CMD_MD) \\\n    X(CMD_MN) \\\n    X(CMD_MA) \\\n    X(CMD_ME) \\\n    X(CMD_GET) \\\n    X(CMD_GAT) \\\n    X(CMD_SET) \\\n    X(CMD_ADD) \\\n    X(CMD_CAS) \\\n    X(CMD_GETS) \\\n    X(CMD_GATS) \\\n    X(CMD_INCR) \\\n    X(CMD_DECR) \\\n    X(CMD_TOUCH) \\\n    X(CMD_APPEND) \\\n    X(CMD_DELETE) \\\n    X(CMD_REPLACE) \\\n    X(CMD_PREPEND) \\\n    X(CMD_END_STORAGE) \\\n    X(CMD_QUIT) \\\n    X(CMD_STATS) \\\n    X(CMD_SLABS) \\\n    X(CMD_WATCH) \\\n    X(CMD_LRU) \\\n    X(CMD_VERSION) \\\n    X(CMD_SHUTDOWN) \\\n    X(CMD_EXTSTORE) \\\n    X(CMD_FLUSH_ALL) \\\n    X(CMD_VERBOSITY) \\\n    X(CMD_LRU_CRAWLER) \\\n    X(CMD_REFRESH_CERTS) \\\n    X(CMD_CACHE_MEMLIMIT)\n\n#define X(name) name,\nenum proxy_defines {\n    P_OK = 0,\n    CMD_FIELDS\n    CMD_SIZE, // used to define array size for command hooks.\n    CMD_ANY, // override _all_ commands\n    CMD_ANY_STORAGE, // override commands specific to key storage.\n    CMD_FINAL, // end cap for convenience.\n};\n#undef X\n\n// certain classes of ascii commands have similar parsing (ie;\n// get/gets/gat/gats). Use types so we don't have to test a ton of them.\nenum proxy_cmd_types {\n    CMD_TYPE_GENERIC = 0,\n    CMD_TYPE_GET, // get/gets/gat/gats\n    CMD_TYPE_META, // m*'s.\n};\n\ntypedef struct _io_pending_proxy_t io_pending_proxy_t;\ntypedef struct proxy_event_thread_s proxy_event_thread_t;\n\n#ifdef HAVE_LIBURING\n// TODO: pass in cqe->res instead of cqe?\ntypedef void (*proxy_event_cb)(void *udata, struct io_uring_cqe *cqe);\ntypedef struct {\n    void *udata;\n    proxy_event_cb cb;\n    bool set; // NOTE: not sure if necessary if code structured properly\n} proxy_event_t;\n\nvoid *proxy_event_thread_ur(void *arg);\n#endif\n\n// Note: This ends up wasting a few counters, but simplifies the rest of the\n// process for handling internal worker stats.\nstruct proxy_int_stats {\n    uint64_t counters[CMD_FINAL];\n};\n\nstruct proxy_user_stats {\n    size_t num_stats; // number of stats, for sizing various arrays\n    char **names; // not needed for worker threads\n    uint64_t *counters; // array of counters.\n};\n\nstruct proxy_global_stats {\n    uint64_t config_reloads;\n    uint64_t config_reload_fails;\n    uint64_t backend_total;\n    uint64_t backend_disconn; // backends with no connections\n    uint64_t backend_requests; // reqs sent to backends\n    uint64_t backend_responses; // responses received from backends\n    uint64_t backend_errors; // errors from backends\n    uint64_t backend_marked_bad; // backend set to autofail\n    uint64_t backend_failed; // an error caused a backend reset\n};\n\nstruct proxy_tunables {\n    struct timeval connect;\n    struct timeval retry; // wait time before retrying a dead backend\n    struct timeval read;\n    struct timeval flap; // need to stay connected this long or it's flapping\n    float flap_backoff_ramp; // factorial for retry time\n    uint32_t flap_backoff_max; // don't backoff longer than this.\n    int backend_failure_limit;\n    bool tcp_keepalive;\n    bool down; // backend is forced into a down/bad state.\n};\n\ntypedef STAILQ_HEAD(pool_head_s, mcp_pool_s) pool_head_t;\ntypedef struct {\n    lua_State *proxy_state;\n    void *proxy_code;\n    proxy_event_thread_t *proxy_io_thread;\n    uint64_t active_req_limit; // max total in-flight requests\n    uint64_t buffer_memory_limit; // max bytes for send/receive buffers.\n    pthread_mutex_t config_lock;\n    pthread_cond_t config_cond;\n    pthread_t config_tid;\n    pthread_mutex_t worker_lock;\n    pthread_cond_t worker_cond;\n    pthread_t manager_tid; // deallocation management thread\n    pthread_mutex_t manager_lock;\n    pthread_cond_t manager_cond;\n    pool_head_t manager_head; // stack for pool deallocation.\n    bool worker_done; // signal variable for the worker lock/cond system.\n    bool worker_failed; // covered by worker_lock as well.\n    bool use_uring; // use IO_URING for backend connections.\n    bool loading; // bool indicating an active config load.\n    struct proxy_global_stats global_stats;\n    struct proxy_user_stats user_stats;\n    struct proxy_tunables tunables; // NOTE: updates covered by stats_lock\n    pthread_mutex_t stats_lock; // used for rare global counters\n} proxy_ctx_t;\n\n#define PROXY_GET_THR_CTX(L) ((*(LIBEVENT_THREAD **)lua_getextraspace(L))->proxy_ctx)\n#define PROXY_GET_THR(L) (*(LIBEVENT_THREAD **)lua_getextraspace(L))\n// Operations from the config VM don't have a libevent thread.\n#define PROXY_GET_CTX(L) (*(proxy_ctx_t **)lua_getextraspace(L))\n\nstruct proxy_hook_tagged {\n    uint64_t tag;\n    int lua_ref;\n};\n\nstruct proxy_hook {\n    int lua_ref;\n    int tagcount;\n    struct proxy_hook_tagged *tagged; // array of possible tagged hooks.\n};\n\n// TODO (v2): some hash functions (crc?) might require initializers. If we run into\n// any the interface might need expanding.\ntypedef uint64_t (*key_hash_func)(const void *key, size_t len, uint64_t seed);\nstruct proxy_hash_func {\n    key_hash_func func;\n};\ntypedef const char *(*key_hash_filter_func)(const char *conf, const char *key, size_t klen, size_t *newlen);\ntypedef uint32_t (*hash_selector_func)(uint64_t hash, void *ctx);\nstruct proxy_hash_caller {\n    hash_selector_func selector_func;\n    void *ctx;\n};\n\nenum mcp_backend_states {\n    mcp_backend_read = 0, // waiting to read any response\n    mcp_backend_parse, // have some buffered data to check\n    mcp_backend_read_end, // looking for an \"END\" marker for GET\n    mcp_backend_want_read, // read more data to complete command\n    mcp_backend_next, // advance to the next IO\n    mcp_backend_next_close, // complete current request, then close socket\n};\n\ntypedef struct mcp_backend_wrap_s mcp_backend_wrap_t;\ntypedef struct mcp_backend_label_s mcp_backend_label_t;\ntypedef struct mcp_backend_s mcp_backend_t;\ntypedef struct mcp_request_s mcp_request_t;\ntypedef struct mcp_parser_s mcp_parser_t;\n\n#define PARSER_MAX_TOKENS 24\n\nstruct mcp_parser_meta_s {\n    uint64_t flags;\n};\n\n// Note that we must use offsets into request for tokens,\n// as *request can change between parsing and later accessors.\nstruct mcp_parser_s {\n    const char *request;\n    void *vbuf; // temporary buffer for holding value lengths.\n    uint8_t command;\n    uint8_t cmd_type; // command class.\n    uint8_t ntokens;\n    uint8_t keytoken; // because GAT. sigh. also cmds without a key.\n    uint32_t parsed; // how far into the request we parsed already\n    uint32_t reqlen; // full length of request buffer.\n    uint32_t endlen; // index to the start of \\r\\n or \\n\n    int vlen;\n    uint32_t klen; // length of key.\n    uint16_t tokens[PARSER_MAX_TOKENS]; // offsets for start of each token\n    bool has_space; // a space was found after the last byte parsed.\n    bool noreply; // if quiet/noreply mode is set.\n    union {\n        struct mcp_parser_meta_s meta;\n    } t;\n};\n\n#define MCP_PARSER_KEY(pr) (&pr.request[pr.tokens[pr.keytoken]])\n\n#define MAX_REQ_TOKENS 2\nstruct mcp_request_s {\n    mcp_parser_t pr; // non-lua-specific parser handling.\n    mcp_backend_t *be; // backend handling this request.\n    bool ascii_multiget; // ascii multiget mode. (hide errors/END)\n    char request[];\n};\n\ntypedef STAILQ_HEAD(io_head_s, _io_pending_proxy_t) io_head_t;\n#define MAX_LABELLEN 512\n#define MAX_NAMELEN 255\n#define MAX_PORTLEN 6\n// TODO (v2): IOV_MAX tends to be 1000+ which would allow for more batching but we\n// don't have a good temporary space and don't want to malloc/free on every\n// write. transmit() uses the stack but we can't do that for uring's use case.\n#if (IOV_MAX > 1024)\n#define BE_IOV_MAX 1024\n#else\n#define BE_IOV_MAX IOV_MAX\n#endif\n// lua descriptor object: passed to pools, which create wrappers.\nstruct mcp_backend_label_s {\n    char name[MAX_NAMELEN+1];\n    char port[MAX_PORTLEN+1];\n    char label[MAX_LABELLEN+1];\n    size_t llen; // cache label length for small speedup in pool creation.\n    int conncount; // number of sockets to make.\n    struct proxy_tunables tunables;\n};\n\n// lua object wrapper meant to own a malloc'ed conn structure\n// when this object is created, it ships its connection to the real owner\n// (worker, IO thread, etc)\n// when this object is garbage collected, it ships a notice to the owner\n// thread to stop using and free the backend conn memory.\nstruct mcp_backend_wrap_s {\n    mcp_backend_t *be;\n};\n\nstruct mcp_backendconn_s {\n    mcp_backend_t *be_parent; // find the wrapper.\n    int self; // our index into the parent array.\n    int depth; // total number of requests in queue\n    int pending_read; // number of requests written to socket, pending read.\n    int failed_count; // number of fails (timeouts) in a row\n    int flap_count; // number of times we've \"flapped\" into bad state.\n    proxy_event_thread_t *event_thread; // event thread owning this backend.\n    void *client; // mcmc client\n    io_head_t io_head; // stack of requests.\n    io_pending_proxy_t *io_next; // next request to write.\n    char *rbuf; // statically allocated read buffer.\n    size_t rbufused; // currently active bytes in the buffer\n    struct event main_event; // libevent: changes role, mostly for main read events\n    struct event write_event; // libevent: only used when socket wbuf full\n    struct event timeout_event; // libevent: alarm for pending reads\n    struct proxy_tunables tunables;\n    struct timeval last_failed; // time the backend was last reset.\n    enum mcp_backend_states state; // readback state machine\n    int connect_flags; // flags to pass to mcmc_connect\n    bool connecting; // in the process of an asynch connection.\n    bool validating; // in process of validating a new backend connection.\n    bool can_write; // recently got a WANT_WRITE or are connecting.\n    bool bad; // timed out, marked as bad.\n    struct iovec write_iovs[BE_IOV_MAX]; // iovs to stage batched writes\n};\n\n// TODO: move depth and flags to a second top level array so we can make index\n// decisions from fewer memory stalls.\nstruct mcp_backend_s {\n    int conncount; // total number of connections managed.\n    int depth; // temporary depth counter for io_head\n    bool transferred; // if beconn has been shipped to owner thread.\n    bool use_io_thread; // note if this backend is worker-local or not.\n    bool stacked; // if backend already queued for syscalls.\n    STAILQ_ENTRY(mcp_backend_s) beconn_next; // stack for connecting conns\n    STAILQ_ENTRY(mcp_backend_s) be_next; // stack for backends\n    io_head_t io_head; // stack of inbound requests.\n    char name[MAX_NAMELEN+1];\n    char port[MAX_PORTLEN+1];\n    struct proxy_tunables tunables; // this gets copied a few times for speed.\n    struct mcp_backendconn_s be[];\n};\ntypedef STAILQ_HEAD(be_head_s, mcp_backend_s) be_head_t;\ntypedef STAILQ_HEAD(beconn_head_s, mcp_backend_s) beconn_head_t;\n\nstruct proxy_event_thread_s {\n    pthread_t thread_id;\n    struct event_base *base;\n    struct event notify_event; // listen event for the notify pipe/eventfd.\n    struct event beconn_event; // listener for backends in connect state\n#ifdef HAVE_LIBURING\n    struct io_uring ring;\n    proxy_event_t ur_notify_event; // listen on eventfd.\n    proxy_event_t ur_benotify_event; // listen on eventfd for backend connections.\n    eventfd_t event_counter;\n    eventfd_t beevent_counter;\n    bool use_uring;\n#endif\n    pthread_mutex_t mutex; // covers stack.\n    pthread_cond_t cond; // condition to wait on while stack drains.\n    io_head_t io_head_in; // inbound requests to process.\n    be_head_t be_head; // stack of backends for processing.\n    beconn_head_t beconn_head_in; // stack of backends for connection processing.\n#ifdef USE_EVENTFD\n    int event_fd; // for request ingestion\n    int be_event_fd; // for backend ingestion\n#else\n    int notify_receive_fd;\n    int notify_send_fd;\n    int be_notify_receive_fd;\n    int be_notify_send_fd;\n#endif\n    proxy_ctx_t *ctx; // main context.\n};\n\nenum mcp_resp_mode {\n    RESP_MODE_NORMAL = 0,\n    RESP_MODE_NOREPLY,\n    RESP_MODE_METAQUIET\n};\n\n#define RESP_CMD_MAX 8\ntypedef struct {\n    mcmc_resp_t resp;\n    char *buf; // response line + potentially value.\n    mc_resp *cresp; // client mc_resp object during extstore fetches.\n    LIBEVENT_THREAD *thread; // cresp's owner thread needed for extstore cleanup.\n    unsigned int blen; // total size of the value to read.\n    struct timeval start; // time this object was created.\n    long elapsed; // time elapsed once handled.\n    int status; // status code from mcmc_read()\n    int bread; // amount of bytes read into value so far.\n    uint8_t cmd; // from parser (pr.command)\n    uint8_t extra; // ascii multiget hack for memory accounting. extra blen.\n    enum mcp_resp_mode mode; // reply mode (for noreply fixing)\n    char be_name[MAX_NAMELEN+1];\n    char be_port[MAX_PORTLEN+1];\n} mcp_resp_t;\n\n// re-cast an io_pending_t into this more descriptive structure.\n// the first few items _must_ match the original struct.\n#define IO_PENDING_TYPE_PROXY 0\n#define IO_PENDING_TYPE_EXTSTORE 1\nstruct _io_pending_proxy_t {\n    int io_queue_type;\n    LIBEVENT_THREAD *thread;\n    conn *c;\n    mc_resp *resp;\n    io_queue_cb return_cb; // called on worker thread.\n    io_queue_cb finalize_cb; // called back on the worker thread.\n    STAILQ_ENTRY(io_pending_t) iop_next; // queue chain.\n    // original struct ends here\n\n    int io_type; // extstore IO or backend IO\n    int coro_ref; // lua registry reference to the coroutine\n    lua_State *coro; // pointer directly to the coroutine\n    bool ascii_multiget; // passed on from mcp_r_t\n    union {\n        // extstore IO.\n        struct {\n            obj_io eio;\n            item *hdr_it;\n            mc_resp *tresp; // temporary mc_resp for storage to fill.\n            int gettype;\n            int iovec_data;\n            bool miss;\n            bool badcrc;\n            bool active;\n        };\n        // backend request IO\n        struct {\n            // FIXME: use top level next chain\n            struct _io_pending_proxy_t *next; // stack for IO submission\n            STAILQ_ENTRY(_io_pending_proxy_t) io_next; // stack for backends\n            int mcpres_ref; // mcp.res reference used for await()\n            mcp_backend_t *backend; // backend server to request from\n            struct iovec iov[2]; // request string + tail buffer\n            int iovcnt; // 1 or 2...\n            unsigned int iovbytes; // total bytes in the iovec\n            int await_ref; // lua reference if we were an await object\n            mcp_resp_t *client_resp; // reference (currently pointing to a lua object)\n            bool flushed; // whether we've fully written this request to a backend.\n            bool is_await; // are we an await object?\n            bool await_first; // are we the main route for an await object?\n            bool await_background; // dummy IO for backgrounded awaits\n        };\n    };\n};\n\n// Note: does *be have to be a sub-struct? how stable are userdata pointers?\n// https://stackoverflow.com/questions/38718475/lifetime-of-lua-userdata-pointers\n// - says no.\ntypedef struct {\n    int ref; // luaL_ref reference of backend_wrap_t obj.\n    mcp_backend_t *be;\n} mcp_pool_be_t;\n\n#define KEY_HASH_FILTER_MAX 5\ntypedef struct mcp_pool_s mcp_pool_t;\nstruct mcp_pool_s {\n    struct proxy_hash_caller phc;\n    key_hash_filter_func key_filter;\n    key_hash_func key_hasher;\n    pthread_mutex_t lock; // protects refcount.\n    proxy_ctx_t *ctx; // main context.\n    STAILQ_ENTRY(mcp_pool_s) next; // stack for deallocator.\n    char key_filter_conf[KEY_HASH_FILTER_MAX+1];\n    char beprefix[MAX_LABELLEN+1]; // TODO: should probably be shorter.\n    uint64_t hash_seed; // calculated from a string.\n    int refcount;\n    int phc_ref;\n    int self_ref; // TODO (v2): double check that this is needed.\n    int pool_size;\n    bool use_iothread;\n    mcp_pool_be_t pool[];\n};\n\ntypedef struct {\n    mcp_pool_t *main; // ptr to original\n    mcp_pool_be_t *pool; // ptr to main->pool starting offset for owner thread.\n} mcp_pool_proxy_t;\n\n// utils\nbool proxy_bufmem_checkadd(LIBEVENT_THREAD *t, int len);\n\n// networking interface\nvoid proxy_init_event_thread(proxy_event_thread_t *t, proxy_ctx_t *ctx, struct event_base *base);\nvoid *proxy_event_thread(void *arg);\nvoid proxy_run_backend_queue(be_head_t *head);\nstruct mcp_backendconn_s *proxy_choose_beconn(mcp_backend_t *be);\n\n// await interface\nenum mcp_await_e {\n    AWAIT_GOOD = 0, // looks for OK + NOT MISS\n    AWAIT_ANY, // any response, including errors,\n    AWAIT_OK, // any non-error response\n    AWAIT_FIRST, // return the result from the first pool\n    AWAIT_FASTGOOD, // returns on first hit or majority non-error\n    AWAIT_BACKGROUND, // returns as soon as background jobs are dispatched\n};\nint mcplib_await(lua_State *L);\nint mcplib_await_logerrors(lua_State *L);\nint mcplib_await_run(conn *c, mc_resp *resp, lua_State *L, int coro_ref);\nint mcplib_await_return(io_pending_proxy_t *p);\n\n// internal request interface\nint mcplib_internal(lua_State *L);\nint mcplib_internal_run(lua_State *L, conn *c, mc_resp *top_resp, int coro_ref);\n\n// user stats interface\nint mcplib_add_stat(lua_State *L);\nint mcplib_stat(lua_State *L);\nsize_t _process_request_next_key(mcp_parser_t *pr);\nint process_request(mcp_parser_t *pr, const char *command, size_t cmdlen);\nmcp_request_t *mcp_new_request(lua_State *L, mcp_parser_t *pr, const char *command, size_t cmdlen);\n\n// rate limit interfaces\nint mcplib_ratelim_tbf(lua_State *L);\nint mcplib_ratelim_tbf_call(lua_State *L);\n\n// request interface\nint mcplib_request(lua_State *L);\nint mcplib_request_command(lua_State *L);\nint mcplib_request_key(lua_State *L);\nint mcplib_request_ltrimkey(lua_State *L);\nint mcplib_request_rtrimkey(lua_State *L);\nint mcplib_request_token(lua_State *L);\nint mcplib_request_ntokens(lua_State *L);\nint mcplib_request_has_flag(lua_State *L);\nint mcplib_request_flag_token(lua_State *L);\nint mcplib_request_gc(lua_State *L);\n\nint mcplib_open_dist_jump_hash(lua_State *L);\nint mcplib_open_dist_ring_hash(lua_State *L);\n\nint proxy_run_coroutine(lua_State *Lc, mc_resp *resp, io_pending_proxy_t *p, conn *c);\nmcp_backend_t *mcplib_pool_proxy_call_helper(lua_State *L, mcp_pool_proxy_t *pp, const char *key, size_t len);\nvoid mcp_request_attach(lua_State *L, mcp_request_t *rq, io_pending_proxy_t *p);\nint mcp_request_render(mcp_request_t *rq, int idx, const char *tok, size_t len);\nvoid proxy_lua_error(lua_State *L, const char *s);\nvoid proxy_lua_ferror(lua_State *L, const char *fmt, ...);\n#define PROXY_SERVER_ERROR \"SERVER_ERROR \"\n#define PROXY_CLIENT_ERROR \"CLIENT_ERROR \"\nvoid proxy_out_errstring(mc_resp *resp, char *type, const char *str);\nint _start_proxy_config_threads(proxy_ctx_t *ctx);\nint proxy_thread_loadconf(proxy_ctx_t *ctx, LIBEVENT_THREAD *thr);\n\n// TODO (v2): more .h files, perhaps?\nint mcplib_open_hash_xxhash(lua_State *L);\n\n__attribute__((unused)) void dump_stack(lua_State *L);\n#endif\n", "/* -*- Mode: C; tab-width: 4; c-basic-offset: 4; indent-tabs-mode: nil -*- */\n\n#include \"proxy.h\"\n\n#define PARSER_MAXLEN USHRT_MAX-1\n\n// Find the starting offsets of each token; ignoring length.\n// This creates a fast small (<= cacheline) index into the request,\n// where we later scan or directly feed data into API's.\nstatic int _process_tokenize(mcp_parser_t *pr, const size_t max) {\n    const char *s = pr->request;\n    int len = pr->endlen;\n\n    // since multigets can be huge, we can't purely judge reqlen against this\n    // limit, but we also can't index past it since the tokens are shorts.\n    if (len > PARSER_MAXLEN) {\n        len = PARSER_MAXLEN;\n    }\n    const char *end = s + len;\n    int curtoken = 0;\n\n    int state = 0;\n    while (s != end) {\n        switch (state) {\n            case 0:\n                // scanning for first non-space to find a token.\n                if (*s != ' ') {\n                    pr->tokens[curtoken] = s - pr->request;\n                    if (++curtoken == max) {\n                        s++;\n                        state = 2;\n                        break;\n                    }\n                    state = 1;\n                }\n                s++;\n                break;\n            case 1:\n                // advance over a token\n                if (*s != ' ') {\n                    s++;\n                } else {\n                    state = 0;\n                }\n                break;\n            case 2:\n                // hit max tokens before end of the line.\n                // keep advancing so we can place endcap token.\n                if (*s == ' ') {\n                    goto endloop;\n                }\n                s++;\n                break;\n        }\n    }\nendloop:\n\n    // endcap token so we can quickly find the length of any token by looking\n    // at the next one.\n    pr->tokens[curtoken] = s - pr->request;\n    pr->ntokens = curtoken;\n    P_DEBUG(\"%s: cur_tokens: %d\\n\", __func__, curtoken);\n\n    return 0;\n}\n\nstatic int _process_token_len(mcp_parser_t *pr, size_t token) {\n    const char *s = pr->request + pr->tokens[token];\n    const char *e = pr->request + pr->tokens[token+1];\n    // start of next token is after any space delimiters, so back those out.\n    while (*(e-1) == ' ') {\n        e--;\n    }\n    return e - s;\n}\n\nstatic int _process_request_key(mcp_parser_t *pr) {\n    pr->klen = _process_token_len(pr, pr->keytoken);\n    // advance the parser in case of multikey.\n    pr->parsed = pr->tokens[pr->keytoken] + pr->klen + 1;\n\n    if (pr->request[pr->parsed-1] == ' ') {\n        P_DEBUG(\"%s: request_key found extra space\\n\", __func__);\n        pr->has_space = true;\n    } else {\n        pr->has_space = false;\n    }\n    return 0;\n}\n\n// Just for ascii multiget: search for next \"key\" beyond where we stopped\n// tokenizing before.\n// Returns the offset for the next key.\nsize_t _process_request_next_key(mcp_parser_t *pr) {\n    const char *cur = pr->request + pr->parsed;\n    int remain = pr->endlen - pr->parsed;\n\n    // chew off any leading whitespace.\n    while (remain) {\n        if (*cur == ' ') {\n            remain--;\n            cur++;\n            pr->parsed++;\n        } else {\n            break;\n        }\n    }\n\n    const char *s = memchr(cur, ' ', remain);\n    if (s != NULL) {\n        pr->klen = s - cur;\n        pr->parsed += s - cur;\n    } else {\n        pr->klen = remain;\n        pr->parsed += remain;\n    }\n\n    return cur - pr->request;\n}\n\n// for fast testing of existence of meta flags.\n// meta has all flags as final tokens\nstatic int _process_request_metaflags(mcp_parser_t *pr, int token) {\n    if (pr->ntokens <= token) {\n        pr->t.meta.flags = 0; // no flags found.\n        return 0;\n    }\n    const char *cur = pr->request + pr->tokens[token];\n    const char *end = pr->request + pr->endlen;\n\n    // We blindly convert flags into bits, since the range of possible\n    // flags is deliberately < 64.\n    int state = 0;\n    while (cur != end) {\n        switch (state) {\n            case 0:\n                if (*cur == ' ') {\n                    cur++;\n                } else {\n                    if (*cur < 65 || *cur > 122) {\n                        return -1;\n                    }\n                    P_DEBUG(\"%s: setting meta flag: %d\\n\", __func__, *cur - 65);\n                    pr->t.meta.flags |= (uint64_t)1 << (*cur - 65);\n                    state = 1;\n                }\n                break;\n            case 1:\n                if (*cur != ' ') {\n                    cur++;\n                } else {\n                    state = 0;\n                }\n                break;\n        }\n    }\n\n    // not too great hack for noreply detection: this can be flattened out\n    // once a few other contexts are fixed and we detect the noreply from the\n    // coroutine start instead.\n    if (pr->t.meta.flags & ((uint64_t)1 << 48)) {\n        pr->noreply = true;\n    }\n\n    return 0;\n}\n\n// All meta commands are of form: \"cm key f l a g S100\"\nstatic int _process_request_meta(mcp_parser_t *pr) {\n    _process_tokenize(pr, PARSER_MAX_TOKENS);\n    if (pr->ntokens < 2) {\n        P_DEBUG(\"%s: not enough tokens for meta command: %d\\n\", __func__, pr->ntokens);\n        return -1;\n    }\n    pr->keytoken = 1;\n    _process_request_key(pr);\n\n    // pass the first flag token.\n    return _process_request_metaflags(pr, 2);\n}\n\n// ms <key> <datalen> <flags>*\\r\\n\nstatic int _process_request_mset(mcp_parser_t *pr) {\n    _process_tokenize(pr, PARSER_MAX_TOKENS);\n    if (pr->ntokens < 3) {\n        P_DEBUG(\"%s: not enough tokens for meta set command: %d\\n\", __func__, pr->ntokens);\n        return -1;\n    }\n    pr->keytoken = 1;\n    _process_request_key(pr);\n\n    const char *cur = pr->request + pr->tokens[2];\n\n    errno = 0;\n    char *n = NULL;\n    int vlen = strtol(cur, &n, 10);\n    if ((errno == ERANGE) || (cur == n)) {\n        return -1;\n    }\n\n    if (vlen < 0 || vlen > (INT_MAX - 2)) {\n       return -1;\n    }\n    vlen += 2;\n\n    pr->vlen = vlen;\n\n    // pass the first flag token\n    return _process_request_metaflags(pr, 3);\n}\n\n// gat[s] <exptime> <key>*\\r\\n\nstatic int _process_request_gat(mcp_parser_t *pr) {\n    _process_tokenize(pr, 3);\n    if (pr->ntokens < 3) {\n        P_DEBUG(\"%s: not enough tokens for GAT: %d\\n\", __func__, pr->ntokens);\n        return -1;\n    }\n\n    pr->keytoken = 2;\n    _process_request_key(pr);\n    return 0;\n}\n\n#define NOREPLYSTR \"noreply\"\n#define NOREPLYLEN sizeof(NOREPLYSTR)-1\n// given a tokenized parser for a normal ASCII command, checks for noreply\n// mode.\nstatic int _process_request_noreply(mcp_parser_t *pr) {\n    if (pr->tokens[pr->ntokens] - pr->tokens[pr->ntokens-1] >= NOREPLYLEN\n            && strncmp(NOREPLYSTR, pr->request + pr->tokens[pr->ntokens-1], NOREPLYLEN) == 0) {\n        pr->noreply = true;\n    }\n    return 0;\n}\n\n// we need t find the bytes supplied immediately so we can read the request\n// from the client properly.\n// set <key> <flags> <exptime> <bytes> [noreply]\\r\\n\nstatic int _process_request_storage(mcp_parser_t *pr, size_t max) {\n    _process_tokenize(pr, max);\n    if (pr->ntokens < 5) {\n        P_DEBUG(\"%s: not enough tokens to storage command: %d\\n\", __func__, pr->ntokens);\n        return -1;\n    }\n    pr->keytoken = 1;\n    _process_request_key(pr);\n\n    errno = 0;\n    char *n = NULL;\n    const char *cur = pr->request + pr->tokens[4];\n\n    int vlen = strtol(cur, &n, 10);\n    if ((errno == ERANGE) || (cur == n)) {\n        return -1;\n    }\n\n    if (vlen < 0 || vlen > (INT_MAX - 2)) {\n       return -1;\n    }\n    vlen += 2;\n\n    pr->vlen = vlen;\n\n    return _process_request_noreply(pr);\n}\n\n// common request with key: <cmd> <key> <args>\nstatic int _process_request_simple(mcp_parser_t *pr, const int min, const int max) {\n    _process_tokenize(pr, max);\n    if (pr->ntokens < min) {\n        P_DEBUG(\"%s: not enough tokens for simple request: %d\\n\", __func__, pr->ntokens);\n        return -1;\n    }\n    pr->keytoken = 1; // second token is usually the key... stupid GAT.\n\n    _process_request_key(pr);\n    return _process_request_noreply(pr);\n}\n\n// TODO: return code ENUM with error types.\n// FIXME: the mcp_parser_t bits have ended up being more fragile than I hoped.\n// careful zero'ing is required. revisit?\n// I think this mostly refers to recursive work (maybe just multiget?)\n// Is a parser object run throgh process_request() twice, ever?\nint process_request(mcp_parser_t *pr, const char *command, size_t cmdlen) {\n    // we want to \"parse in place\" as much as possible, which allows us to\n    // forward an unmodified request without having to rebuild it.\n\n    const char *cm = command;\n    size_t cl = 0;\n    // min command length is 2, plus the \"\\r\\n\"\n    if (cmdlen < 4) {\n        return -1;\n    }\n\n    // Commands can end with bare '\\n's. Depressingly I intended to be strict\n    // with a \\r\\n requirement but never did this and need backcompat.\n    // In this case we _know_ \\n is at cmdlen because we can't enter this\n    // function otherwise.\n    if (cm[cmdlen-2] == '\\r') {\n        pr->endlen = cmdlen - 2;\n    } else {\n        pr->endlen = cmdlen - 1;\n    }\n\n    const char *s = memchr(command, ' ', pr->endlen);\n    if (s != NULL) {\n        cl = s - command;\n    } else {\n        cl = pr->endlen;\n    }\n    pr->keytoken = 0;\n    pr->has_space = false;\n    pr->parsed = cl;\n    pr->request = command;\n    pr->reqlen = cmdlen;\n    int token_max = PARSER_MAX_TOKENS;\n\n    int cmd = -1;\n    int type = CMD_TYPE_GENERIC;\n    int ret = 0;\n\n    switch (cl) {\n        case 0:\n        case 1:\n            // falls through with cmd as -1. should error.\n            break;\n        case 2:\n            if (cm[0] == 'm') {\n                type = CMD_TYPE_META;\n                switch (cm[1]) {\n                    case 'g':\n                        cmd = CMD_MG;\n                        ret = _process_request_meta(pr);\n                        break;\n                    case 's':\n                        cmd = CMD_MS;\n                        ret = _process_request_mset(pr);\n                        break;\n                    case 'd':\n                        cmd = CMD_MD;\n                        ret = _process_request_meta(pr);\n                        break;\n                    case 'n':\n                        // TODO: do we route/handle NOP's at all?\n                        // they should simply reflect to the client.\n                        cmd = CMD_MN;\n                        break;\n                    case 'a':\n                        cmd = CMD_MA;\n                        ret = _process_request_meta(pr);\n                        break;\n                    case 'e':\n                        cmd = CMD_ME;\n                        // TODO: not much special processing here; binary keys\n                        ret = _process_request_meta(pr);\n                        break;\n                }\n            }\n            break;\n        case 3:\n            if (cm[0] == 'g') {\n                if (cm[1] == 'e' && cm[2] == 't') {\n                    cmd = CMD_GET;\n                    type = CMD_TYPE_GET;\n                    token_max = 2; // don't chew through multigets.\n                    ret = _process_request_simple(pr, 2, 2);\n                }\n                if (cm[1] == 'a' && cm[2] == 't') {\n                    type = CMD_TYPE_GET;\n                    cmd = CMD_GAT;\n                    token_max = 2; // don't chew through multigets.\n                    ret = _process_request_gat(pr);\n                }\n            } else if (cm[0] == 's' && cm[1] == 'e' && cm[2] == 't') {\n                cmd = CMD_SET;\n                ret = _process_request_storage(pr, token_max);\n            } else if (cm[0] == 'a' && cm[1] == 'd' && cm[2] == 'd') {\n                cmd = CMD_ADD;\n                ret = _process_request_storage(pr, token_max);\n            } else if (cm[0] == 'c' && cm[1] == 'a' && cm[2] == 's') {\n                cmd = CMD_CAS;\n                ret = _process_request_storage(pr, token_max);\n            }\n            break;\n        case 4:\n            if (strncmp(cm, \"gets\", 4) == 0) {\n                cmd = CMD_GETS;\n                type = CMD_TYPE_GET;\n                token_max = 2; // don't chew through multigets.\n                ret = _process_request_simple(pr, 2, 2);\n            } else if (strncmp(cm, \"incr\", 4) == 0) {\n                cmd = CMD_INCR;\n                ret = _process_request_simple(pr, 3, 4);\n            } else if (strncmp(cm, \"decr\", 4) == 0) {\n                cmd = CMD_DECR;\n                ret = _process_request_simple(pr, 3, 4);\n            } else if (strncmp(cm, \"gats\", 4) == 0) {\n                cmd = CMD_GATS;\n                type = CMD_TYPE_GET;\n                ret = _process_request_gat(pr);\n            } else if (strncmp(cm, \"quit\", 4) == 0) {\n                cmd = CMD_QUIT;\n            }\n            break;\n        case 5:\n            if (strncmp(cm, \"touch\", 5) == 0) {\n                cmd = CMD_TOUCH;\n                ret = _process_request_simple(pr, 3, 4);\n            } else if (strncmp(cm, \"stats\", 5) == 0) {\n                cmd = CMD_STATS;\n                // Don't process a key; fetch via arguments.\n                _process_tokenize(pr, token_max);\n            } else if (strncmp(cm, \"watch\", 5) == 0) {\n                cmd = CMD_WATCH;\n                _process_tokenize(pr, token_max);\n            }\n            break;\n        case 6:\n            if (strncmp(cm, \"delete\", 6) == 0) {\n                cmd = CMD_DELETE;\n                ret = _process_request_simple(pr, 2, 4);\n            } else if (strncmp(cm, \"append\", 6) == 0) {\n                cmd = CMD_APPEND;\n                ret = _process_request_storage(pr, token_max);\n            }\n            break;\n        case 7:\n            if (strncmp(cm, \"replace\", 7) == 0) {\n                cmd = CMD_REPLACE;\n                ret = _process_request_storage(pr, token_max);\n            } else if (strncmp(cm, \"prepend\", 7) == 0) {\n                cmd = CMD_PREPEND;\n                ret = _process_request_storage(pr, token_max);\n            } else if (strncmp(cm, \"version\", 7) == 0) {\n                cmd = CMD_VERSION;\n                _process_tokenize(pr, token_max);\n            }\n            break;\n    }\n\n    // TODO: log more specific error code.\n    if (cmd == -1 || ret != 0) {\n        return -1;\n    }\n\n    pr->command = cmd;\n    pr->cmd_type = type;\n\n    return 0;\n}\n\n// FIXME (v2): any reason to pass in command/cmdlen separately?\nmcp_request_t *mcp_new_request(lua_State *L, mcp_parser_t *pr, const char *command, size_t cmdlen) {\n    // reserving an upvalue for key.\n    mcp_request_t *rq = lua_newuserdatauv(L, sizeof(mcp_request_t) + MCP_REQUEST_MAXLEN + KEY_MAX_LENGTH, 1);\n    // TODO (v2): memset only the non-data part? as the rest gets memcpy'd\n    // over.\n    memset(rq, 0, sizeof(mcp_request_t));\n    memcpy(&rq->pr, pr, sizeof(*pr));\n\n    memcpy(rq->request, command, cmdlen);\n    rq->pr.request = rq->request;\n    rq->pr.reqlen = cmdlen;\n\n    luaL_getmetatable(L, \"mcp.request\");\n    lua_setmetatable(L, -2);\n\n    // at this point we should know if we have to bounce through _nread to\n    // get item data or not.\n    return rq;\n}\n\n// Replaces a token inside a request and re-parses.\n// Note that this has some optimization opportunities. Delaying until\n// required.\n// We should not guarantee order when updating meta flags, which would allow\n// blanking tokens and appending new ones.\n// TODO (v2): function doesn't allow appending.\n// TODO (v2): much of the length is the key, avoid copying it.\nint mcp_request_render(mcp_request_t *rq, int idx, const char *tok, size_t len) {\n    char temp[MCP_REQUEST_MAXLEN];\n    char *p = temp;\n    mcp_parser_t *pr = &rq->pr;\n\n    if (pr->reqlen + len > MCP_REQUEST_MAXLEN) {\n        return -1;\n    }\n    // Cannot add/append tokens yet.\n    if (idx >= pr->ntokens) {\n        return -1;\n    }\n\n    memcpy(p, pr->request, pr->tokens[idx]);\n    p += pr->tokens[idx];\n\n    memcpy(p, tok, len);\n    p += len;\n\n    // Add a space and copy more tokens if there were more.\n    if (idx+1 < pr->ntokens) {\n        if (len != 0) {\n            // Only pre-space if not deleting the token.\n            *p = ' ';\n            p++;\n        }\n        memcpy(p, &pr->request[pr->tokens[idx+1]], pr->tokens[pr->ntokens] - pr->tokens[idx+1]);\n        p += pr->tokens[pr->ntokens] - pr->tokens[idx+1];\n    }\n\n    memcpy(p, \"\\r\\n\\0\", 3);\n    p += 2;\n\n    memcpy(rq->request, temp, p - temp);\n\n    // Hold the vlen/vbuf and restore after re-parsing. Since we can only edit\n    // the command line, not the value here, we would otherwise allow sending\n    // arbitrary memory over the network if someone modifies a SET.\n    void *vbuf = pr->vbuf;\n    int vlen = pr->vlen;\n\n    memset(pr, 0, sizeof(mcp_parser_t)); // TODO: required?\n    int ret = process_request(pr, rq->request, p - temp);\n    if (ret != 0) {\n        return ret;\n    }\n    pr->vbuf = vbuf;\n    pr->vlen = vlen;\n    return 0;\n}\n\nvoid mcp_request_attach(lua_State *L, mcp_request_t *rq, io_pending_proxy_t *p) {\n    mcp_parser_t *pr = &rq->pr;\n    char *r = (char *) pr->request;\n    size_t len = pr->reqlen;\n\n    // The stringified request. This is also referencing into the coroutine\n    // stack, which should be safe from gc.\n    p->iov[0].iov_base = r;\n    p->iov[0].iov_len = len;\n    p->iovcnt = 1;\n    p->iovbytes = len;\n    if (pr->vlen != 0) {\n        p->iov[1].iov_base = pr->vbuf;\n        p->iov[1].iov_len = pr->vlen;\n        p->iovcnt = 2;\n        p->iovbytes += pr->vlen;\n    }\n}\n\n// second argument is optional, for building set requests.\n// TODO: append the \\r\\n for the VAL?\nint mcplib_request(lua_State *L) {\n    LIBEVENT_THREAD *t = PROXY_GET_THR(L);\n    size_t len = 0;\n    size_t vlen = 0;\n    mcp_parser_t pr = {0};\n    const char *cmd = luaL_checklstring(L, 1, &len);\n    const char *val = NULL;\n    int type = lua_type(L, 2);\n    if (type == LUA_TSTRING) {\n        val = luaL_optlstring(L, 2, NULL, &vlen);\n        if (vlen < 2 || memcmp(val+vlen-2, \"\\r\\n\", 2) != 0) {\n            proxy_lua_error(L, \"value passed to mcp.request must end with \\\\r\\\\n\");\n        }\n    } else if (type == LUA_TUSERDATA) {\n        // vlen for requests and responses include the \"\\r\\n\" already.\n        mcp_resp_t *r = luaL_testudata(L, 2, \"mcp.response\");\n        if (r != NULL) {\n            if (r->resp.value) {\n                val = r->resp.value;\n                vlen = r->resp.vlen_read; // paranoia, so we can't overread into memory.\n            }\n        } else {\n            mcp_request_t *rq = luaL_testudata(L, 2, \"mcp.request\");\n            if (rq->pr.vbuf) {\n                val = rq->pr.vbuf;\n                vlen = rq->pr.vlen;\n            }\n        }\n    }\n\n    // FIXME (v2): if we inline the userdata we can avoid memcpy'ing the parser\n    // structure from the stack? but causes some code duplication.\n    if (process_request(&pr, cmd, len) != 0) {\n        proxy_lua_error(L, \"failed to parse request\");\n        return 0;\n    }\n    mcp_request_t *rq = mcp_new_request(L, &pr, cmd, len);\n\n    if (val != NULL) {\n        rq->pr.vlen = vlen;\n        rq->pr.vbuf = malloc(vlen);\n        if (rq->pr.vbuf == NULL) {\n            // Note: without *c we can't tick the appropriate counter.\n            // However, in practice raw malloc's are nearly never going to\n            // fail.\n            // TODO(v2): we can stack values into the request objects or use\n            // the slabber memory, so this isn't necessary anyway.\n            proxy_lua_error(L, \"failed to allocate value memory for request object\");\n        }\n        memcpy(rq->pr.vbuf, val, vlen);\n        // Note: Not enforcing the memory limit here is deliberate:\n        // - if we're over the memory limit, it'll get caught very soon after\n        // this, but we won't be causing some lua to bail mid-flight, which is\n        // more graceful to the end user.\n        pthread_mutex_lock(&t->proxy_limit_lock);\n        t->proxy_buffer_memory_used += rq->pr.vlen;\n        pthread_mutex_unlock(&t->proxy_limit_lock);\n    }\n\n    // rq is now created, parsed, and on the stack.\n    return 1;\n}\n\nint mcplib_request_key(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, -1, \"mcp.request\");\n    lua_pushlstring(L, MCP_PARSER_KEY(rq->pr), rq->pr.klen);\n    return 1;\n}\n\n// NOTE: I've mixed up const/non-const strings in the request. During parsing\n// we want it to be const, but after that's done the request is no longer\n// const. It might be better to just remove the const higher up the chain, but\n// I'd rather not. So for now these functions will be dumping the const to\n// modify the string.\nint mcplib_request_ltrimkey(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, -2, \"mcp.request\");\n    int totrim = luaL_checkinteger(L, -1);\n    char *key = (char *) MCP_PARSER_KEY(rq->pr);\n\n    if (totrim > rq->pr.klen) {\n        proxy_lua_error(L, \"ltrimkey cannot zero out key\");\n        return 0;\n    } else {\n        memset(key, ' ', totrim);\n        rq->pr.klen -= totrim;\n        rq->pr.tokens[rq->pr.keytoken] += totrim;\n    }\n    return 1;\n}\n\nint mcplib_request_rtrimkey(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, -2, \"mcp.request\");\n    int totrim = luaL_checkinteger(L, -1);\n    char *key = (char *) MCP_PARSER_KEY(rq->pr);\n\n    if (totrim > rq->pr.klen) {\n        proxy_lua_error(L, \"rtrimkey cannot zero out key\");\n        return 0;\n    } else {\n        memset(key + (rq->pr.klen - totrim), ' ', totrim);\n        rq->pr.klen -= totrim;\n        // don't need to change the key token.\n    }\n    return 1;\n}\n\n// Virtual table operations on the request.\nint mcplib_request_token(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, 1, \"mcp.request\");\n    int argc = lua_gettop(L);\n\n    if (argc == 1) {\n        lua_pushnil(L);\n        return 1;\n    }\n\n    int token = luaL_checkinteger(L, 2);\n\n    if (token < 1 || token > rq->pr.ntokens) {\n        // maybe an error?\n        lua_pushnil(L);\n        return 1;\n    }\n\n    size_t vlen = 0;\n    if (argc > 2) {\n        // overwriting a token.\n        size_t newlen = 0;\n        const char *newtok = lua_tolstring(L, 3, &newlen);\n        if (mcp_request_render(rq, token-1, newtok, newlen) != 0) {\n            proxy_lua_error(L, \"token(): request malformed after edit\");\n            return 0;\n        }\n        return 0;\n    } else {\n        // fetching a token.\n        const char *start = rq->pr.request + rq->pr.tokens[token-1];\n        vlen = _process_token_len(&rq->pr, token-1);\n\n        P_DEBUG(\"%s: pushing token of len: %lu\\n\", __func__, vlen);\n        lua_pushlstring(L, start, vlen);\n        return 1;\n    }\n\n    return 0;\n}\n\nint mcplib_request_ntokens(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, 1, \"mcp.request\");\n    lua_pushinteger(L, rq->pr.ntokens);\n    return 1;\n}\n\nint mcplib_request_command(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, -1, \"mcp.request\");\n    lua_pushinteger(L, rq->pr.command);\n    return 1;\n}\n\nint mcplib_request_has_flag(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, 1, \"mcp.request\");\n    size_t len = 0;\n    const char *flagstr = luaL_checklstring(L, 2, &len);\n    if (len != 1) {\n        proxy_lua_error(L, \"has_flag(): meta flag must be a single character\");\n        return 0;\n    }\n    if (flagstr[0] < 65 || flagstr[0] > 122) {\n        proxy_lua_error(L, \"has_flag(): invalid flag, must be A-Z,a-z\");\n        return 0;\n    }\n    uint64_t flagbit = (uint64_t)1 << (flagstr[0] - 65);\n    if (rq->pr.t.meta.flags & flagbit) {\n        lua_pushboolean(L, 1);\n    } else {\n        lua_pushboolean(L, 0);\n    }\n\n    return 1;\n}\n\n// req:flag_token(\"F\") -> (bool, nil|token)\n// req:flag_token(\"O\", \"Onewopauqe\") -> (bool, oldtoken)\nint mcplib_request_flag_token(lua_State *L) {\n    mcp_request_t *rq = luaL_checkudata(L, 1, \"mcp.request\");\n    size_t len = 0;\n    const char *flagstr = luaL_checklstring(L, 2, &len);\n    bool replace = false;\n    if (len != 1) {\n        proxy_lua_error(L, \"has_flag(): meta flag must be a single character\");\n        return 0;\n    }\n    if (flagstr[0] < 65 || flagstr[0] > 122) {\n        proxy_lua_error(L, \"has_flag(): invalid flag, must be A-Z,a-z\");\n        return 0;\n    }\n    if (lua_isstring(L, 3)) {\n        // overwriting a flag/token with the third argument.\n        replace = true;\n    }\n    uint64_t flagbit = (uint64_t)1 << (flagstr[0] - 65);\n\n    int ret = 1;\n    if (rq->pr.t.meta.flags & flagbit) {\n        // The flag definitely exists, but sadly we need to scan for the\n        // actual flag to see if it has a token.\n        lua_pushboolean(L, 1);\n        for (int x = rq->pr.keytoken+1; x < rq->pr.ntokens; x++) {\n            const char *s = rq->pr.request + rq->pr.tokens[x];\n            if (s[0] == flagstr[0]) {\n                size_t vlen = _process_token_len(&rq->pr, x);\n                if (vlen > 1) {\n                    // strip the flag off the token and return.\n                    lua_pushlstring(L, s+1, vlen-1);\n                    ret = 2;\n                }\n\n                // Have something to replace the flag/token with.\n                if (replace) {\n                    size_t newlen = 0;\n                    const char *newtok = lua_tolstring(L, 3, &newlen);\n                    if (mcp_request_render(rq, x, newtok, newlen) != 0) {\n                        proxy_lua_error(L, \"token(): request malformed after edit\");\n                        return 0;\n                    }\n                }\n                break;\n            }\n        }\n    } else {\n        lua_pushboolean(L, 0);\n    }\n\n    return ret;\n}\n\nint mcplib_request_gc(lua_State *L) {\n    LIBEVENT_THREAD *t = PROXY_GET_THR(L);\n    mcp_request_t *rq = luaL_checkudata(L, -1, \"mcp.request\");\n    // During nread c->item is the malloc'ed buffer. not yet put into\n    // rq->buf - this gets freed because we've also set c->item_malloced if\n    // the connection closes before finishing nread.\n    if (rq->pr.vbuf != NULL) {\n        pthread_mutex_lock(&t->proxy_limit_lock);\n        t->proxy_buffer_memory_used -= rq->pr.vlen;\n        pthread_mutex_unlock(&t->proxy_limit_lock);\n        free(rq->pr.vbuf);\n    }\n\n    return 0;\n}\n\n// TODO (v2): check what lua does when it calls a function with a string argument\n// stored from a table/similar (ie; the prefix check code).\n// If it's not copying anything, we can add request-side functions to do most\n// forms of matching and avoid copying the key to lua space.\n", "#!/usr/bin/env perl\n\nuse strict;\nuse warnings;\nuse Test::More;\nuse FindBin qw($Bin);\nuse lib \"$Bin/lib\";\nuse Carp qw(croak);\nuse MemcachedTest;\n\n# TODO: to module?\n# or \"gettimedrun\" etc\nuse Cwd;\nmy $builddir = getcwd;\n\nif (!supports_proxy()) {\n    plan skip_all => 'proxy not enabled';\n    exit 0;\n}\n\n# TODO: the lua file has hardcoded ports. any way to make this dynamic?\n# TODO: once basic tests are done, actually split out the instances rather\n# than the shared backend; validate keys go where they should be going.\n\n# FIXME: this listend on unix socket still. either need a manual runner or a\n# fix upstream.\nmy @srv = ();\nfor (2 .. 6) {\n    my $srv = run_server(\"-p 1121$_\", 11210 + $_);\n    push(@srv, $srv);\n}\n#my $sock = $srv->sock;\n\nmy $p_srv = new_memcached('-o proxy_config=./t/startfile.lua');\nmy $p_sock = $p_srv->sock;\n\n# hack to help me use T_MEMD_USE_DAEMON for proxy.\n#print STDERR \"Sleeping\\n\";\n#sleep 900;\n\n# cmds to test:\n# - noreply for main text commands?\n# meta:\n# me\n# mn\n# mg\n# ms\n# md\n# ma\n# - noreply?\n# stats\n# pass-thru?\n\n# incr/decr\n{\n    print $p_sock \"set /foo/num 0 0 1\\r\\n1\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored num\");\n    mem_get_is($p_sock, \"/foo/num\", 1, \"stored 1\");\n\n    print $p_sock \"incr /foo/num 1\\r\\n\";\n    is(scalar <$p_sock>, \"2\\r\\n\", \"+ 1 = 2\");\n    mem_get_is($p_sock, \"/foo/num\", 2);\n\n    print $p_sock \"incr /foo/num 8\\r\\n\";\n    is(scalar <$p_sock>, \"10\\r\\n\", \"+ 8 = 10\");\n    mem_get_is($p_sock, \"/foo/num\", 10);\n\n    print $p_sock \"decr /foo/num 1\\r\\n\";\n    is(scalar <$p_sock>, \"9\\r\\n\", \"- 1 = 9\");\n\n    print $p_sock \"decr /foo/num 9\\r\\n\";\n    is(scalar <$p_sock>, \"0\\r\\n\", \"- 9 = 0\");\n\n    print $p_sock \"decr /foo/num 5\\r\\n\";\n    is(scalar <$p_sock>, \"0\\r\\n\", \"- 5 = 0\");\n}\n\n# gat\n{\n    # cache miss\n    print $p_sock \"gat 10 /foo/foo1\\r\\n\";\n    is(scalar <$p_sock>, \"END\\r\\n\", \"cache miss\");\n\n    # set /foo/foo1 and /foo/foo2 (and should get it)\n    print $p_sock \"set /foo/foo1 0 2 7\\r\\nfooval1\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored foo\");\n\n    print $p_sock \"set /foo/foo2 0 2 7\\r\\nfooval2\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored /foo/foo2\");\n\n    # get and touch it with cas\n    print $p_sock \"gats 10 /foo/foo1 /foo/foo2\\r\\n\";\n    like(scalar <$p_sock>, qr/VALUE \\/foo\\/foo1 0 7 (\\d+)\\r\\n/, \"get and touch foo1 with cas regexp success\");\n    is(scalar <$p_sock>, \"fooval1\\r\\n\",\"value\");\n    like(scalar <$p_sock>, qr/VALUE \\/foo\\/foo2 0 7 (\\d+)\\r\\n/, \"get and touch foo2 with cas regexp success\");\n    is(scalar <$p_sock>, \"fooval2\\r\\n\",\"value\");\n    is(scalar <$p_sock>, \"END\\r\\n\", \"end\");\n\n    # get and touch it without cas\n    print $p_sock \"gat 10 /foo/foo1 /foo/foo2\\r\\n\";\n    like(scalar <$p_sock>, qr/VALUE \\/foo\\/foo1 0 7\\r\\n/, \"get and touch foo1 without cas regexp success\");\n    is(scalar <$p_sock>, \"fooval1\\r\\n\",\"value\");\n    like(scalar <$p_sock>, qr/VALUE \\/foo\\/foo2 0 7\\r\\n/, \"get and touch foo2 without cas regexp success\");\n    is(scalar <$p_sock>, \"fooval2\\r\\n\",\"value\");\n    is(scalar <$p_sock>, \"END\\r\\n\", \"end\");\n}\n\n# gets/cas\n{\n    print $p_sock \"add /foo/moo 0 0 6\\r\\nmooval\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored mooval\");\n    mem_get_is($p_sock, \"/foo/moo\", \"mooval\");\n\n    # check-and-set (cas) failure case, try to set value with incorrect cas unique val\n    print $p_sock \"cas /foo/moo 0 0 6 0\\r\\nMOOVAL\\r\\n\";\n    is(scalar <$p_sock>, \"EXISTS\\r\\n\", \"check and set with invalid id\");\n\n    # test \"gets\", grab unique ID\n    print $p_sock \"gets /foo/moo\\r\\n\";\n    # VALUE moo 0 6 3084947704\n    #\n    my @retvals = split(/ /, scalar <$p_sock>);\n    my $data = scalar <$p_sock>; # grab data\n    my $dot  = scalar <$p_sock>; # grab dot on line by itself\n    is($retvals[0], \"VALUE\", \"get value using 'gets'\");\n    my $unique_id = $retvals[4];\n    # clean off \\r\\n\n    $unique_id =~ s/\\r\\n$//;\n    ok($unique_id =~ /^\\d+$/, \"unique ID '$unique_id' is an integer\");\n    # now test that we can store moo with the correct unique id\n    print $p_sock \"cas /foo/moo 0 0 6 $unique_id\\r\\nMOOVAL\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\");\n    mem_get_is($p_sock, \"/foo/moo\", \"MOOVAL\");\n}\n\n# touch\n{\n    print $p_sock \"set /foo/t 0 2 6\\r\\nfooval\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored foo\");\n    mem_get_is($p_sock, \"/foo/t\", \"fooval\");\n\n    # touch it\n    print $p_sock \"touch /foo/t 10\\r\\n\";\n    is(scalar <$p_sock>, \"TOUCHED\\r\\n\", \"touched foo\");\n\n    # don't need to sleep/validate the touch worked. We're testing the\n    # protocol, not the functionality.\n}\n\n# command endings\n# NOTE: memcached always allowed [\\r]\\n for single command lines, but payloads\n# (set/etc) require exactly \\r\\n as termination.\n# doc/protocol.txt has always specified \\r\\n for command/response.\n# Note a bug lead me to believe that the proxy was more strict, we accept any\n# \\n or \\r\\n terminated commands.\n{\n    my $s = $srv[0]->sock;\n    print $s \"version\\n\";\n    like(<$s>, qr/VERSION/, \"direct server version cmd with just newline\");\n    print $p_sock \"version\\n\";\n    like(<$p_sock>, qr/VERSION/, \"proxy version cmd with just newline\");\n    print $p_sock \"version\\r\\n\";\n    like(<$p_sock>, qr/VERSION/, \"proxy version cmd with full CRLF\");\n}\n\n# set through proxy.\n{\n    print $p_sock \"set /foo/z 0 0 5\\r\\nhello\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n    # ensure it's fetchable.\n    mem_get_is($p_sock, \"/foo/z\", \"hello\");\n    # delete it.\n    print $p_sock \"delete /foo/z\\r\\n\";\n    is(scalar <$p_sock>, \"DELETED\\r\\n\", \"removed test value\");\n    # ensure it's deleted.\n    mem_get_is($p_sock, \"/foo/z\", undef);\n}\n\n# test add.\n{\n    print $p_sock \"add /foo/a 0 0 3\\r\\nmoo\\r\\n\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"add test value through proxy\");\n    # ensure it's fetchable\n    mem_get_is($p_sock, \"/foo/a\", \"moo\");\n    # check re-adding fails.\n    print $p_sock \"add /foo/a 0 0 3\\r\\ngoo\\r\\n\";\n    is(scalar <$p_sock>, \"NOT_STORED\\r\\n\", \"re-add fails\");\n    # ensure we still hae the old value\n    mem_get_is($p_sock, \"/foo/a\", \"moo\");\n}\n\n# pipelined set.\n{\n    my $str = \"set /foo/k 0 0 5\\r\\nhello\\r\\n\";\n    print $p_sock \"$str$str$str$str$str\";\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n    is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value through proxy\");\n}\n\n# Load some keys through proxy.\nmy $bdata = 'x' x 256000;\n{\n    for (1..20) {\n        print $p_sock \"set /foo/a$_ 0 0 2\\r\\nhi\\r\\n\";\n        is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value\");\n        print $p_sock \"set /bar/b$_ 0 0 2\\r\\nhi\\r\\n\";\n        is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored test value\");\n    }\n\n    # load a couple larger values\n    for (1..4) {\n        print $p_sock \"set /foo/big$_ 0 0 256000\\r\\n$bdata\\r\\n\";\n        is(scalar <$p_sock>, \"STORED\\r\\n\", \"stored big value\");\n    }\n    diag \"set large values\";\n}\n\n# fetch through proxy.\n{\n    for (1..20) {\n        mem_get_is($p_sock, \"/foo/a$_\", \"hi\");\n    }\n    diag \"fetched small values\";\n    mem_get_is($p_sock, \"/foo/big1\", $bdata);\n    diag \"fetched big value\";\n}\n\nsub run_server {\n    my ($args, $port) = @_;\n\n    my $exe = get_memcached_exe();\n\n    my $childpid = fork();\n\n    my $root = '';\n    $root = \"-u root\" if ($< == 0);\n\n    # test build requires more privileges\n    $args .= \" -o relaxed_privileges\";\n\n    my $cmd = \"$builddir/timedrun 120 $exe $root $args\";\n\n    unless($childpid) {\n        exec $cmd;\n        exit; # NOTREACHED\n    }\n\n    for (1..20) {\n        my $conn = IO::Socket::INET->new(PeerAddr => \"127.0.0.1:$port\");\n        if ($conn) {\n            return Memcached::Handle->new(pid  => $childpid,\n                conn => $conn,\n                host => \"127.0.0.1\",\n                port => $port);\n        }\n        select undef, undef, undef, 0.10;\n    }\n    croak \"Failed to start server.\";\n}\n\ndone_testing();\n"], "filenames": ["proxy.h", "proxy_request.c", "t/proxy.t"], "buggy_code_start_loc": [278, 12, 154], "buggy_code_end_loc": [278, 306, 161], "fixing_code_start_loc": [279, 12, 154], "fixing_code_end_loc": [280, 316, 162], "type": "CWE-193", "message": "In Memcached before 1.6.22, an off-by-one error exists when processing proxy requests in proxy mode, if \\n is used instead of \\r\\n.", "other": {"cve": {"id": "CVE-2023-46853", "sourceIdentifier": "cve@mitre.org", "published": "2023-10-27T20:15:09.177", "lastModified": "2023-11-07T19:04:15.560", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "In Memcached before 1.6.22, an off-by-one error exists when processing proxy requests in proxy mode, if \\n is used instead of \\r\\n."}, {"lang": "es", "value": "En Memcached anterior a 1.6.22, existe un error uno por uno al procesar solicitudes de proxy en modo proxy, si se usa \\n en lugar de \\r\\n."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-193"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:memcached:memcached:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.6.22", "matchCriteriaId": "CEB5B313-3710-4308-933A-764A76E8D77A"}]}]}], "references": [{"url": "https://github.com/memcached/memcached/commit/6987918e9a3094ec4fc8976f01f769f624d790fa", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://github.com/memcached/memcached/compare/1.6.21...1.6.22", "source": "cve@mitre.org", "tags": ["Release Notes"]}]}, "github_commit_url": "https://github.com/memcached/memcached/commit/6987918e9a3094ec4fc8976f01f769f624d790fa"}}
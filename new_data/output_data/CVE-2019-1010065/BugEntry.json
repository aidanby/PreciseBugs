{"buggy_code": ["/*\n** The Sleuth Kit\n**\n** This software is subject to the IBM Public License ver. 1.0,\n** which was displayed prior to download and is included in the readme.txt\n** file accompanying the Sleuth Kit files.  It may also be requested from:\n** Crucial Security Inc.\n** 14900 Conference Center Drive\n** Chantilly, VA 20151\n**\n\n** Copyright (c) 2009 Brian Carrier.  All rights reserved.\n**\n** Judson Powers [jpowers@atc-nycorp.com]\n** Matt Stillerman [matt@atc-nycorp.com]\n** Rob Joyce [rob@atc-nycorp.com]\n** Copyright (c) 2008, 2012 ATC-NY.  All rights reserved.\n** This file contains data developed with support from the National\n** Institute of Justice, Office of Justice Programs, U.S. Department of Justice.\n**\n** Wyatt Banks [wbanks@crucialsecurity.com]\n** Copyright (c) 2005 Crucial Security Inc.  All rights reserved.\n**\n** Brian Carrier [carrier@sleuthkit.org]\n** Copyright (c) 2003-2005 Brian Carrier.  All rights reserved\n**\n** Copyright (c) 1997,1998,1999, International Business Machines\n** Corporation and others. All Rights Reserved.\n*/\n\n/* TCT\n * LICENSE\n *      This software is distributed under the IBM Public License.\n * AUTHOR(S)\n *      Wietse Venema\n *      IBM T.J. Watson Research\n *      P.O. Box 704\n *      Yorktown Heights, NY 10598, USA\n --*/\n\n/*\n** You may distribute the Sleuth Kit, or other software that incorporates\n** part of all of the Sleuth Kit, in object code form under a license agreement,\n** provided that:\n** a) you comply with the terms and conditions of the IBM Public License\n**    ver 1.0; and\n** b) the license agreement\n**     i) effectively disclaims on behalf of all Contributors all warranties\n**        and conditions, express and implied, including warranties or\n**        conditions of title and non-infringement, and implied warranties\n**        or conditions of merchantability and fitness for a particular\n**        purpose.\n**    ii) effectively excludes on behalf of all Contributors liability for\n**        damages, including direct, indirect, special, incidental and\n**        consequential damages such as lost profits.\n**   iii) states that any provisions which differ from IBM Public License\n**        ver. 1.0 are offered by that Contributor alone and not by any\n**        other party; and\n**    iv) states that the source code for the program is available from you,\n**        and informs licensees how to obtain it in a reasonable manner on or\n**        through a medium customarily used for software exchange.\n**\n** When the Sleuth Kit or other software that incorporates part or all of\n** the Sleuth Kit is made available in source code form:\n**     a) it must be made available under IBM Public License ver. 1.0; and\n**     b) a copy of the IBM Public License ver. 1.0 must be included with\n**        each copy of the program.\n*/\n\n/** \\file hfs.c\n * Contains the general internal TSK HFS metadata and data unit code\n */\n\n#include \"tsk_fs_i.h\"\n#include \"tsk_hfs.h\"\n\n#include <stdarg.h>\n#ifdef TSK_WIN32\n#include <string.h>\n#else\n#include <strings.h>\n#endif\n\n#define XSWAP(a,b) { a ^= b; b ^= a; a ^= b; }\n\n// Compression Stuff\n\n#ifdef HAVE_LIBZ\n#include <zlib.h>\n#endif\n\n#include \"lzvn.h\"\n\n// Forward declarations:\nstatic uint8_t hfs_load_attrs(TSK_FS_FILE * fs_file);\nstatic uint8_t hfs_load_extended_attrs(TSK_FS_FILE * file,\n    unsigned char *isCompressed, unsigned char *cmpType,\n    uint64_t * uncSize);\nvoid error_detected(uint32_t errnum, char *errstr, ...);\nvoid error_returned(char *errstr, ...);\n\n#ifdef HAVE_LIBZ\n\n/***************** ZLIB stuff *******************************/\n\n// Adapted from zpipe.c (part of zlib) at http://zlib.net/zpipe.c\n#define CHUNK 16384\n\n/*\n * Invokes the zlib library to inflate (uncompress) data.\n *\n * Returns and error code.  Places the uncompressed data in a buffer supplied by the caller.  Also\n * returns the uncompressed length, and the number of compressed bytes consumed.\n *\n * Will stop short of the end of compressed data, if a natural end of a compression unit is reached.  Using\n * bytesConsumed, the caller can then advance the source pointer, and re-invoke the function.  This will then\n * inflate the next following compression unit in the data stream.\n *\n * @param source - buffer of compressed data\n * @param sourceLen  - length of the compressed data.\n * @param dest  -- buffer to  hold the uncompressed results\n * @param destLen -- length of the dest buffer\n * @param uncompressedLength  -- return of the length of the uncompressed data found.\n * @param bytesConsumed  -- return of the number of input bytes of compressed data used.\n * @return 0 on success, a negative number on error\n */\nstatic int\nzlib_inflate(char *source, uint64_t sourceLen, char *dest, uint64_t destLen, uint64_t * uncompressedLength, unsigned long *bytesConsumed)       // this is unsigned long because that's what zlib uses.\n{\n\n    int ret;\n    unsigned have;\n    z_stream strm;\n    unsigned char in[CHUNK];\n    unsigned char out[CHUNK];\n\n    // Some vars to help with copying bytes into \"in\"\n    char *srcPtr = source;\n    char *destPtr = dest;\n    uint64_t srcAvail = sourceLen;      //uint64_t\n    uint64_t amtToCopy;\n    uint64_t copiedSoFar = 0;\n\n    /* allocate inflate state */\n    strm.zalloc = Z_NULL;\n    strm.zfree = Z_NULL;\n    strm.opaque = Z_NULL;\n    strm.avail_in = 0;\n    strm.next_in = Z_NULL;\n    ret = inflateInit(&strm);\n    if (ret != Z_OK) {\n        error_detected(TSK_ERR_FS_READ,\n            \"zlib_inflate: failed to initialize inflation engine (%d)\",\n            ret);\n        return ret;\n    }\n\n    /* decompress until deflate stream ends or end of file */\n    do {\n\n        // Copy up to CHUNK bytes into \"in\" from source, advancing the pointer, and\n        // setting strm.avail_in equal to the number of bytes copied.\n        if (srcAvail >= CHUNK) {\n            amtToCopy = CHUNK;\n            srcAvail -= CHUNK;\n        }\n        else {\n            amtToCopy = srcAvail;\n            srcAvail = 0;\n        }\n        // wipe out any previous value, copy in the bytes, advance the pointer, record number of bytes.\n        memset(in, 0, CHUNK);\n        if (amtToCopy > SIZE_MAX || amtToCopy > UINT_MAX) {\n            error_detected(TSK_ERR_FS_READ,\n                \"zlib_inflate: amtToCopy in one chunk is too large\");\n            return -100;\n        }\n        memcpy(in, srcPtr, (size_t) amtToCopy); // cast OK because of above test\n        srcPtr += amtToCopy;\n        strm.avail_in = (uInt) amtToCopy;       // cast OK because of above test\n\n        if (strm.avail_in == 0)\n            break;\n        strm.next_in = in;\n\n        /* run inflate() on input until output buffer not full */\n        do {\n            strm.avail_out = CHUNK;\n            strm.next_out = out;\n            ret = inflate(&strm, Z_NO_FLUSH);\n            if (ret == Z_NEED_DICT)\n                ret = Z_DATA_ERROR;     // we don't have a custom dict\n            if (ret < 0 && ret != Z_BUF_ERROR) { // Z_BUF_ERROR is not fatal\n                error_detected(TSK_ERR_FS_READ,\n                    \" zlib_inflate: zlib returned error %d (%s)\", ret,\n                    strm.msg);\n                (void) inflateEnd(&strm);\n                return ret;\n            }\n\n            have = CHUNK - strm.avail_out;\n            // Is there enough space in dest to copy the current chunk?\n            if (copiedSoFar + have > destLen) {\n                // There is not enough space, so better return an error\n                error_detected(TSK_ERR_FS_READ,\n                    \" zlib_inflate: not enough space in inflation destination\\n\");\n                (void) inflateEnd(&strm);\n                return -200;\n            }\n\n            // Copy \"have\" bytes from out to destPtr, advance destPtr\n            memcpy(destPtr, out, have);\n            destPtr += have;\n            copiedSoFar += have;\n\n        } while ((strm.avail_out == 0) && (ret != Z_STREAM_END));\n\n\n        /* done when inflate() says it's done */\n    } while (ret != Z_STREAM_END);\n\n    if (ret == Z_STREAM_END)\n        *uncompressedLength = copiedSoFar;\n\n    *bytesConsumed = strm.total_in;\n    /* clean up and return */\n    (void) inflateEnd(&strm);\n    return ret == Z_STREAM_END ? Z_OK : Z_DATA_ERROR;\n}\n\n#endif\n\n/* may set error up to string 1\n * returns 0 on success, 1 on failure */\nuint8_t\nhfs_checked_read_random(TSK_FS_INFO * fs, char *buf, size_t len,\n    TSK_OFF_T offs)\n{\n    ssize_t r;\n\n    r = tsk_fs_read(fs, offs, buf, len);\n    if (r != len) {\n        if (r >= 0) {\n            tsk_error_reset();\n            tsk_error_set_errno(TSK_ERR_FS_READ);\n        }\n        return 1;\n    }\n    return 0;\n}\n\n/**********************************************************************\n *\n *  MISC FUNCS\n *\n **********************************************************************/\n\n/* convert the HFS Time (seconds from 1/1/1904)\n * to UNIX (UTC seconds from 1/1/1970)\n * The number is borrowed from linux HFS driver source\n */\nuint32_t\nhfs_convert_2_unix_time(uint32_t hfsdate)\n{\n    if (hfsdate < NSEC_BTWN_1904_1970)\n        return 0;\n    return (uint32_t) (hfsdate - NSEC_BTWN_1904_1970);\n}\n\n\n/**\n * Convert a cnid (metadata address) to big endian array.\n * This is used to create the key for tree lookups.\n * @param cnid Metadata address to convert\n * @param array [out] Array to write data into.\n */\nstatic void\ncnid_to_array(uint32_t cnid, uint8_t array[4])\n{\n    array[3] = (cnid >> 0) & 0xff;\n    array[2] = (cnid >> 8) & 0xff;\n    array[1] = (cnid >> 16) & 0xff;\n    array[0] = (cnid >> 24) & 0xff;\n}\n\n/**********************************************************************\n *\n * Lookup Functions\n *\n **********************************************************************/\n\n\n\n/* Compares the given HFS+ Extents B-tree key to key constructed\n * for finding the beginning of the data fork extents for the given\n * CNID. (That is, the search key uses the given CNID and has\n * fork = 0 and start_block = 0.)\n */\nstatic int\nhfs_ext_compare_keys(HFS_INFO * hfs, uint32_t cnid,\n    const hfs_btree_key_ext * key)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    uint32_t key_cnid;\n\n    key_cnid = tsk_getu32(fs->endian, key->file_id);\n    if (key_cnid < cnid)\n        return -1;\n    if (key_cnid > cnid)\n        return 1;\n\n    /* referring to the same cnids */\n\n    /* we are always looking for the data fork */\n    if (key->fork_type != HFS_EXT_KEY_TYPE_DATA)\n        return 1;\n\n    /* we are always looking for a start_block of zero\n       (interested in the beginning of the extents, regardless\n       of what the start_block is); all files except the bad\n       blocks file should have a start_block greater than\n       zero */\n    if (tsk_getu32(fs->endian, key->start_block) == 0)\n        return 0;\n    return 1;\n}\n\n\n/** \\internal\n * Returns the length of an HFS+ B-tree INDEX key based on the tree header\n * structure and the length claimed in the record.  With some trees,\n * the length given in the record is not used.\n * Note that this neither detects nor correctly handles 8-bit keys\n * (which should not be present in HFS+).\n *\n * This does not give the right answer for the Attributes File B-tree, for some\n * HFS+ file systems produced by the Apple OS, while it works for others.  For\n * the Attributes file, INDEX keys should always be as stated in the record itself,\n * never the \"maxKeyLen\" of the B-tree header.\n *\n * In this software, this function is only invoked when dealing with the Extents file.  In\n * that usage, it is not sufficiently well tested to know if it always gives the right\n * answer or not.  We can only test that with a highly fragmented disk.\n * @param hfs File System\n * @param keylen Length of key as given in record\n * @param header Tree header\n * @returns Length of key\n */\nuint16_t\nhfs_get_idxkeylen(HFS_INFO * hfs, uint16_t keylen,\n    const hfs_btree_header_record * header)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n\n    // if the flag is set, use the length given in the record\n    if (tsk_getu32(fs->endian, header->attr) & HFS_BT_HEAD_ATTR_VARIDXKEYS)\n        return keylen;\n    else\n        return tsk_getu16(fs->endian, header->maxKeyLen);\n}\n\n\n/**\n * Convert the extents runs to TSK_FS_ATTR_RUN runs.\n *\n * @param a_fs File system to analyze\n * @param a_extents Raw extents to process (in an array of 8)\n * @param a_start_off Starting block offset of these runs\n * @returns NULL on error or if no runs are in extents (test tsk_errno)\n */\nstatic TSK_FS_ATTR_RUN *\nhfs_extents_to_attr(TSK_FS_INFO * a_fs, const hfs_ext_desc * a_extents,\n    TSK_OFF_T a_start_off)\n{\n    TSK_FS_ATTR_RUN *head_run = NULL;\n    TSK_FS_ATTR_RUN *prev_run = NULL;\n    int i;\n    TSK_OFF_T cur_off = a_start_off;\n\n    // since tsk_errno is checked as a return value, make sure it is clean.\n    tsk_error_reset();\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_extents_to_attr: Converting extents from offset %\" PRIuOFF\n            \" to runlist\\n\", a_start_off);\n\n    for (i = 0; i < 8; ++i) {\n        TSK_FS_ATTR_RUN *cur_run;\n\n        uint32_t addr = tsk_getu32(a_fs->endian, a_extents[i].start_blk);\n        uint32_t len = tsk_getu32(a_fs->endian, a_extents[i].blk_cnt);\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_extents_to_attr: run %i at addr %\" PRIu32\n                \" with len %\" PRIu32 \"\\n\", i, addr, len);\n\n        if ((addr == 0) && (len == 0)) {\n            break;\n        }\n\n        // make a non-resident run\n        if ((cur_run = tsk_fs_attr_run_alloc()) == NULL) {\n            error_returned(\" - hfs_extents_to_attr\");\n            return NULL;\n        }\n\n        cur_run->addr = addr;\n        cur_run->len = len;\n        cur_run->offset = cur_off;\n\n        if (head_run == NULL)\n            head_run = cur_run;\n        if (prev_run != NULL)\n            prev_run->next = cur_run;\n        cur_off += cur_run->len;\n        prev_run = cur_run;\n    }\n\n    return head_run;\n}\n\n\n/**\n * Look in the extents catalog for entries for a given file. Add the runs\n * to the passed attribute structure.\n *\n * @param hfs File system being analyzed\n * @param cnid file id of file to search for\n * @param a_attr Attribute to add extents runs to\n * @param dataForkQ  if true, then find extents for the data fork.  If false, then find extents for the Resource fork.\n * @returns 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_ext_find_extent_record_attr(HFS_INFO * hfs, uint32_t cnid,\n    TSK_FS_ATTR * a_attr, unsigned char dataForkQ)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    uint16_t nodesize;          /* size of nodes (all, regardless of the name) */\n    uint32_t cur_node;          /* node id of the current node */\n    char *node = NULL;\n    uint8_t is_done;\n    uint8_t desiredType;\n\n    tsk_error_reset();\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_ext_find_extent_record_attr: Looking for extents for file %\"\n            PRIu32 \" %s\\n\", cnid,\n            dataForkQ ? \"data fork\" : \"resource fork\");\n\n    if (!hfs->has_extents_file) {\n        // No extents file (which is optional), and so, no further extents are possible.\n        return 0;\n    }\n\n    // Are we looking for extents of the data fork or the resource fork?\n    desiredType =\n        dataForkQ ? HFS_EXT_KEY_TYPE_DATA : HFS_EXT_KEY_TYPE_RSRC;\n\n    // Load the extents attribute, if it has not been done so yet.\n    if (hfs->extents_file == NULL) {\n        ssize_t cnt;\n\n        if ((hfs->extents_file =\n                tsk_fs_file_open_meta(fs, NULL,\n                    HFS_EXTENTS_FILE_ID)) == NULL) {\n            return 1;\n        }\n\n        /* cache the data attribute */\n        hfs->extents_attr =\n            tsk_fs_attrlist_get(hfs->extents_file->meta->attr,\n            TSK_FS_ATTR_TYPE_DEFAULT);\n        if (!hfs->extents_attr) {\n            tsk_error_errstr2_concat\n                (\" - Default Attribute not found in Extents File\");\n            return 1;\n        }\n\n        // cache the extents file header\n        cnt = tsk_fs_attr_read(hfs->extents_attr, 14,\n            (char *) &(hfs->extents_header),\n            sizeof(hfs_btree_header_record), 0);\n        if (cnt != sizeof(hfs_btree_header_record)) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_ext_find_extent_record_attr: Error reading header\");\n            return 1;\n        }\n    }\n\n    // allocate a node buffer\n    nodesize = tsk_getu16(fs->endian, hfs->extents_header.nodesize);\n    if ((node = (char *) tsk_malloc(nodesize)) == NULL) {\n        return 1;\n    }\n\n    /* start at root node */\n    cur_node = tsk_getu32(fs->endian, hfs->extents_header.rootNode);\n\n    /* if the root node is zero, then the extents btree is empty */\n    /* if no files have overflow extents, the Extents B-tree still\n       exists on disk, but is an empty B-tree containing only\n       the header node */\n    if (cur_node == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_ext_find_extent_record: \"\n                \"empty extents btree\\n\");\n        free(node);\n        return 0;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_ext_find_extent_record: starting at \"\n            \"root node %\" PRIu32 \"; nodesize = %\"\n            PRIu16 \"\\n\", cur_node, nodesize);\n\n    /* Recurse down to the needed leaf nodes and then go forward */\n    is_done = 0;\n    while (is_done == 0) {\n        TSK_OFF_T cur_off;      /* start address of cur_node */\n        uint16_t num_rec;       /* number of records in this node */\n        ssize_t cnt;\n        hfs_btree_node *node_desc;\n\n        // sanity check\n        if (cur_node > tsk_getu32(fs->endian,\n                hfs->extents_header.totalNodes)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_ext_find_extent_record_attr: Node %d too large for file\",\n                cur_node);\n            free(node);\n            return 1;\n        }\n\n        // read the current node\n        cur_off = (TSK_OFF_T)cur_node * nodesize;\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_ext_find_extent_record: reading node %\" PRIu32\n                \" at offset %\" PRIuOFF \"\\n\", cur_node, cur_off);\n\n        cnt = tsk_fs_attr_read(hfs->extents_attr, cur_off,\n            node, nodesize, 0);\n        if (cnt != nodesize) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_ext_find_extent_record_attr: Error reading node %d at offset %\"\n                PRIuOFF, cur_node, cur_off);\n            free(node);\n            return 1;\n        }\n\n        // process the header / descriptor\n        if (nodesize < sizeof(hfs_btree_node)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_ext_find_extent_record_attr: Node size %d is too small to be valid\", nodesize);\n            free(node);\n            return 1;\n        }\n        node_desc = (hfs_btree_node *) node;\n        num_rec = tsk_getu16(fs->endian, node_desc->num_rec);\n\n        if (num_rec == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_ext_find_extent_record: zero records in node %\"\n                PRIu32, cur_node);\n            free(node);\n            return 1;\n        }\n\n\n        /* With an index node, find the record with the largest key that is smaller\n         * to or equal to cnid */\n        if (node_desc->type == HFS_BT_NODE_TYPE_IDX) {\n            uint32_t next_node = 0;\n            int rec;\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_ext_find_extent_record: Index node %\" PRIu32\n                    \" @ %\" PRIu64 \" has %\" PRIu16 \" records\\n\", cur_node,\n                    cur_off, num_rec);\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                int cmp;\n                size_t rec_off;\n                hfs_btree_key_ext *key;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off + sizeof(hfs_btree_key_ext) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_ext_find_extent_record_attr: offset of record %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_ext *) & node[rec_off];\n\n                cmp = hfs_ext_compare_keys(hfs, cnid, key);\n\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_ext_find_extent_record: record %\" PRIu16\n                        \" ; keylen %\" PRIu16 \" (FileId: %\" PRIu32\n                        \", ForkType: %\" PRIu8 \", StartBlk: %\" PRIu32\n                        \"); compare: %d\\n\", rec, tsk_getu16(fs->endian,\n                            key->key_len), tsk_getu32(fs->endian,\n                            key->file_id), key->fork_type,\n                        tsk_getu32(fs->endian, key->start_block), cmp);\n\n                /* save the info from this record unless it is bigger than cnid */\n                if ((cmp <= 0) || (next_node == 0)) {\n                    hfs_btree_index_record *idx_rec;\n                    int keylen =\n                        2 + hfs_get_idxkeylen(hfs, tsk_getu16(fs->endian,\n                            key->key_len), &(hfs->extents_header));\n                    if (rec_off + keylen > nodesize) {\n                        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                        tsk_error_set_errstr\n                            (\"hfs_ext_find_extent_record_attr: offset and keylenth of record %d in index node %d too large (%d vs %\"\n                            PRIu16 \")\", rec, cur_node,\n                            (int) rec_off + keylen, nodesize);\n                        free(node);\n                        return 1;\n                    }\n                    idx_rec =\n                        (hfs_btree_index_record *) & node[rec_off +\n                        keylen];\n                    next_node = tsk_getu32(fs->endian, idx_rec->childNode);\n                }\n\n                // we are bigger than cnid, so move on to the next node\n                if (cmp > 0) {\n                    break;\n                }\n            }\n\n            // check if we found a relevant node, if not stop.\n            if (next_node == 0) {\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_ext_find_extent_record_attr: did not find any keys for %d in index node %d\",\n                        cnid, cur_node);\n                is_done = 1;\n                break;\n            }\n            cur_node = next_node;\n        }\n\n        /* with a leaf, we process until we are past cnid.  We move right too if we can */\n        else if (node_desc->type == HFS_BT_NODE_TYPE_LEAF) {\n            int rec;\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_ext_find_extent_record: Leaf node %\" PRIu32 \" @ %\"\n                    PRIu64 \" has %\" PRIu16 \" records\\n\", cur_node, cur_off,\n                    num_rec);\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_ext *key;\n                uint32_t rec_cnid;\n                hfs_extents *extents;\n                TSK_OFF_T ext_off = 0;\n                int keylen;\n                TSK_FS_ATTR_RUN *attr_run;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_ext_find_extent_record_attr: offset of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_ext *) & node[rec_off];\n\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_ext_find_extent_record: record %\" PRIu16\n                        \"; keylen %\" PRIu16 \" (%\" PRIu32\n                        \", %\" PRIu8 \", %\" PRIu32 \")\\n\", rec,\n                        tsk_getu16(fs->endian, key->key_len),\n                        tsk_getu32(fs->endian, key->file_id),\n                        key->fork_type, tsk_getu32(fs->endian,\n                            key->start_block));\n\n                rec_cnid = tsk_getu32(fs->endian, key->file_id);\n\n                // see if this record is for our file\n                // OLD logic, just handles the DATA fork\n//                if (rec_cnid < cnid) {\n//                    continue;\n//                }\n//                else if ((rec_cnid > cnid)\n//                    || (key->fork_type != HFS_EXT_KEY_TYPE_DATA)) {\n//                    is_done = 1;\n//                    break;\n//                }\n\n                // NEW logic, handles both DATA and RSRC forks.\n                if (rec_cnid < cnid) {\n                    continue;\n                }\n                if (rec_cnid > cnid) {\n                    is_done = 1;\n                    break;\n                }\n\n\n                if (key->fork_type != desiredType) {\n                    if (dataForkQ) {\n                        is_done = 1;\n                        break;\n                    }\n                    else\n                        continue;\n                }\n\n                // OK, this is one of the extents records that we are seeking, so save it.\n                // Make sure there is room for the hfs_extents struct\n                keylen = 2 + tsk_getu16(fs->endian, key->key_len);\n                if (rec_off + keylen + sizeof(hfs_extents) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_ext_find_extent_record_attr: offset and keylenth of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off + keylen,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                // get the starting offset of this extent\n                ext_off = tsk_getu32(fs->endian, key->start_block);\n\n                // convert the extents to the TSK format\n                extents = (hfs_extents *) & node[rec_off + keylen];\n\n                attr_run =\n                    hfs_extents_to_attr(fs, extents->extents, ext_off);\n                if ((attr_run == NULL) && (tsk_error_get_errno() != 0)) {\n                    tsk_error_errstr2_concat\n                        (\" - hfs_ext_find_extent_record_attr\");\n                    free(node);\n                    return 1;\n                }\n\n                if (tsk_fs_attr_add_run(fs, a_attr, attr_run)) {\n                    tsk_error_errstr2_concat\n                        (\" - hfs_ext_find_extent_record_attr\");\n                    free(node);\n                    return 1;\n                }\n            }\n            cur_node = tsk_getu32(fs->endian, node_desc->flink);\n            if (cur_node == 0) {\n                is_done = 1;\n                break;\n            }\n        }\n        else {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_ext_find_extent_record: btree node %\"\n                PRIu32 \" (%\" PRIuOFF \") is neither index nor leaf (%\" PRIu8\n                \")\", cur_node, cur_off, node_desc->type);\n            free(node);\n            return 1;\n        }\n    }\n    free(node);\n    return 0;\n}\n\n\n/** \\internal\n * Compares two Catalog B-tree keys.\n * @param hfs File System being analyzed\n * @param key1 Key 1 to compare\n * @param key2 Key 2 to compare\n * @returns -1 if key1 is smaller, 0 if equal, and 1 if key1 is larger\n */\nint\nhfs_cat_compare_keys(HFS_INFO * hfs, const hfs_btree_key_cat * key1,\n    const hfs_btree_key_cat * key2)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    uint32_t cnid1, cnid2;\n\n    cnid1 = tsk_getu32(fs->endian, key1->parent_cnid);\n    cnid2 = tsk_getu32(fs->endian, key2->parent_cnid);\n\n    if (cnid1 < cnid2)\n        return -1;\n    if (cnid1 > cnid2)\n        return 1;\n\n    return hfs_unicode_compare(hfs, &key1->name, &key2->name);\n}\n\n\n/** \\internal\n * \n * Traverse the HFS catalog file.  Call the callback for each\n * record. \n *\n * @param hfs File system\n * @param a_cb callback \n * @param ptr Pointer to pass to callback\n * @returns 1 on error\n */\nuint8_t\nhfs_cat_traverse(HFS_INFO * hfs,\n    TSK_HFS_BTREE_CB a_cb, void *ptr)\n{\n    TSK_FS_INFO *fs = &(hfs->fs_info);\n    uint32_t cur_node;          /* node id of the current node */\n    char *node;\n\n    uint16_t nodesize;\n    uint8_t is_done = 0;\n\n    tsk_error_reset();\n\n    nodesize = tsk_getu16(fs->endian, hfs->catalog_header.nodesize);\n    if ((node = (char *) tsk_malloc(nodesize)) == NULL)\n        return 1;\n\n    /* start at root node */\n    cur_node = tsk_getu32(fs->endian, hfs->catalog_header.rootNode);\n\n    /* if the root node is zero, then the extents btree is empty */\n    /* if no files have overflow extents, the Extents B-tree still\n       exists on disk, but is an empty B-tree containing only\n       the header node */\n    if (cur_node == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: \"\n                \"empty extents btree\\n\");\n        free(node);\n        return 1;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_cat_traverse: starting at \"\n            \"root node %\" PRIu32 \"; nodesize = %\"\n            PRIu16 \"\\n\", cur_node, nodesize);\n\n    /* Recurse down to the needed leaf nodes and then go forward */\n    is_done = 0;\n    while (is_done == 0) {\n        TSK_OFF_T cur_off;      /* start address of cur_node */\n        uint16_t num_rec;       /* number of records in this node */\n        ssize_t cnt;\n        hfs_btree_node *node_desc;\n\n        // sanity check\n        if (cur_node > tsk_getu32(fs->endian,\n                hfs->catalog_header.totalNodes)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_cat_traverse: Node %d too large for file\", cur_node);\n            free(node);\n            return 1;\n        }\n\n        // read the current node\n        cur_off = cur_node * nodesize;\n        cnt = tsk_fs_attr_read(hfs->catalog_attr, cur_off,\n            node, nodesize, 0);\n        if (cnt != nodesize) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_traverse: Error reading node %d at offset %\"\n                PRIuOFF, cur_node, cur_off);\n            free(node);\n            return 1;\n        }\n\n        // process the header / descriptor\n        if (nodesize < sizeof(hfs_btree_node)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n            (\"hfs_cat_traverse: Node size %d is too small to be valid\", nodesize);\n            free(node);\n            return 1;\n        }\n        node_desc = (hfs_btree_node *) node;\n        num_rec = tsk_getu16(fs->endian, node_desc->num_rec);\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: node %\" PRIu32\n                \" @ %\" PRIu64 \" has %\" PRIu16 \" records\\n\",\n                cur_node, cur_off, num_rec);\n\n        if (num_rec == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: zero records in node %\"\n                PRIu32, cur_node);\n            free(node);\n            return 1;\n        }\n\n        /* With an index node, find the record with the largest key that is smaller\n         * to or equal to cnid */\n        if (node_desc->type == HFS_BT_NODE_TYPE_IDX) {\n            uint32_t next_node = 0;\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                uint16_t keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \" ; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n\n\n                /* save the info from this record unless it is too big */\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_IDX, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n                // record the closest entry\n                else if ((retval == HFS_BTREE_CB_IDX_LT)\n                    || (next_node == 0)) {\n                    hfs_btree_index_record *idx_rec;\n                    int keylen =\n                        2 + hfs_get_idxkeylen(hfs, tsk_getu16(fs->endian,\n                            key->key_len), &(hfs->catalog_header));\n                    if (rec_off + keylen > nodesize) {\n                        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                        tsk_error_set_errstr\n                            (\"hfs_cat_traverse: offset of record and keylength %d in index node %d too large (%d vs %\"\n                            PRIu16 \")\", rec, cur_node,\n                            (int) rec_off + keylen, nodesize);\n                        free(node);\n                        return 1;\n                    }\n                    idx_rec =\n                        (hfs_btree_index_record *) & node[rec_off +\n                        keylen];\n                    next_node = tsk_getu32(fs->endian, idx_rec->childNode);\n                }\n                if (retval == HFS_BTREE_CB_IDX_EQGT) {\n                    // move down to the next node\n                    break;\n                }\n            }\n            // check if we found a relevant node\n            if (next_node == 0) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: did not find any keys in index node %d\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            // TODO: Handle multinode loops\n            if (next_node == cur_node) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: node %d references itself as next node\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            cur_node = next_node;\n        }\n\n        /* With a leaf, we look for the specific record. */\n        else if (node_desc->type == HFS_BT_NODE_TYPE_LEAF) {\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                uint16_t keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \"; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n                //                rec_cnid = tsk_getu32(fs->endian, key->file_id);\n\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_LEAF, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_LEAF_STOP) {\n                    is_done = 1;\n                    break;\n                }\n                else if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n            }\n\n            // move right to the next node if we got this far\n            if (is_done == 0) {\n                cur_node = tsk_getu32(fs->endian, node_desc->flink);\n                if (cur_node == 0) {\n                    is_done = 1;\n                }\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_cat_traverse: moving forward to next leaf\");\n            }\n        }\n        else {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: btree node %\" PRIu32\n                \" (%\" PRIu64 \") is neither index nor leaf (%\" PRIu8 \")\",\n                cur_node, cur_off, node_desc->type);\n            free(node);\n            return 1;\n        }\n    }\n    free(node);\n    return 0;\n}\n\ntypedef struct {\n    const hfs_btree_key_cat *targ_key;\n    TSK_OFF_T off;\n} HFS_CAT_GET_RECORD_OFFSET_DATA;\n\nstatic uint8_t\nhfs_cat_get_record_offset_cb(HFS_INFO * hfs, int8_t level_type,\n    const hfs_btree_key_cat * cur_key,\n    TSK_OFF_T key_off, void *ptr)\n{\n    HFS_CAT_GET_RECORD_OFFSET_DATA *offset_data = (HFS_CAT_GET_RECORD_OFFSET_DATA *)ptr;\n    const hfs_btree_key_cat *targ_key = offset_data->targ_key;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_cat_get_record_offset_cb: %s node want: %\" PRIu32\n            \" vs have: %\" PRIu32 \"\\n\",\n            (level_type == HFS_BT_NODE_TYPE_IDX) ? \"Index\" : \"Leaf\",\n            tsk_getu32(hfs->fs_info.endian, targ_key->parent_cnid),\n            tsk_getu32(hfs->fs_info.endian, cur_key->parent_cnid));\n\n    if (level_type == HFS_BT_NODE_TYPE_IDX) {\n        int diff = hfs_cat_compare_keys(hfs, cur_key, targ_key);\n        if (diff < 0)\n            return HFS_BTREE_CB_IDX_LT;\n        else\n            return HFS_BTREE_CB_IDX_EQGT;\n    }\n    else {\n        int diff = hfs_cat_compare_keys(hfs, cur_key, targ_key);\n\n        // see if this record is for our file or if we passed the interesting entries\n        if (diff < 0) {\n            return HFS_BTREE_CB_LEAF_GO;\n        }\n        else if (diff == 0) {\n            offset_data->off = \n                key_off + 2 + tsk_getu16(hfs->fs_info.endian,\n                cur_key->key_len);\n        }\n        return HFS_BTREE_CB_LEAF_STOP;\n    }\n}\n\n\n/** \\internal\n * Find the byte offset (from the start of the catalog file) to a record\n * in the catalog file.\n * @param hfs File System being analyzed\n * @param needle Key to search for\n * @returns Byte offset or 0 on error. 0 is also returned if catalog\n * record was not found. Check tsk_errno to determine if error occurred.\n */\nstatic TSK_OFF_T\nhfs_cat_get_record_offset(HFS_INFO * hfs, const hfs_btree_key_cat * needle)\n{\n    HFS_CAT_GET_RECORD_OFFSET_DATA offset_data;\n    offset_data.off = 0;\n    offset_data.targ_key = needle;\n    if (hfs_cat_traverse(hfs, hfs_cat_get_record_offset_cb, &offset_data)) {\n        return 0;\n    }\n    return offset_data.off;\n}\n\n\n\n/** \\internal\n * Given a byte offset to a leaf record in teh catalog file, read the data as\n * a thread record. This will zero the buffer and read in the size of the thread\n * data.\n * @param hfs File System\n * @param off Byte offset of record in catalog file (not including key)\n * @param thread [out] Buffer to write thread data into.\n * @returns 0 on success, 1 on failure; sets up to error string 1 */\nuint8_t\nhfs_cat_read_thread_record(HFS_INFO * hfs, TSK_OFF_T off,\n    hfs_thread * thread)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    uint16_t uni_len;\n    ssize_t cnt;\n\n    memset(thread, 0, sizeof(hfs_thread));\n    cnt = tsk_fs_attr_read(hfs->catalog_attr, off, (char *) thread, 10, 0);\n    if (cnt != 10) {\n        if (cnt >= 0) {\n            tsk_error_reset();\n            tsk_error_set_errno(TSK_ERR_FS_READ);\n        }\n        tsk_error_set_errstr2\n            (\"hfs_cat_read_thread_record: Error reading catalog offset %\"\n            PRIuOFF \" (header)\", off);\n        return 1;\n    }\n\n    if ((tsk_getu16(fs->endian, thread->rec_type) != HFS_FOLDER_THREAD)\n        && (tsk_getu16(fs->endian, thread->rec_type) != HFS_FILE_THREAD)) {\n        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n        tsk_error_set_errstr\n            (\"hfs_cat_read_thread_record: unexpected record type %\" PRIu16,\n            tsk_getu16(fs->endian, thread->rec_type));\n        return 1;\n    }\n\n    uni_len = tsk_getu16(fs->endian, thread->name.length);\n\n    if (uni_len > 255) {\n        tsk_error_set_errno(TSK_ERR_FS_INODE_COR);\n        tsk_error_set_errstr\n            (\"hfs_cat_read_thread_record: invalid string length (%\" PRIu16\n            \")\", uni_len);\n        return 1;\n    }\n\n    cnt =\n        tsk_fs_attr_read(hfs->catalog_attr, off + 10,\n        (char *) thread->name.unicode, uni_len * 2, 0);\n    if (cnt != uni_len * 2) {\n        if (cnt >= 0) {\n            tsk_error_reset();\n            tsk_error_set_errno(TSK_ERR_FS_READ);\n        }\n        tsk_error_set_errstr2\n            (\"hfs_cat_read_thread_record: Error reading catalog offset %\"\n            PRIuOFF \" (name)\", off + 10);\n        return 1;\n    }\n\n    return 0;\n}\n\n/** \\internal\n * Read a catalog record into a local data structure.  This reads the\n * correct amount, depending on if it is a file or folder.\n * @param hfs File system being analyzed\n * @param off Byte offset (in catalog file) of record (not including key)\n * @param record [out] Structure to read data into\n * @returns 1 on error\n */\nuint8_t\nhfs_cat_read_file_folder_record(HFS_INFO * hfs, TSK_OFF_T off,\n    hfs_file_folder * record)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    ssize_t cnt;\n    char rec_type[2];\n\n    memset(record, 0, sizeof(hfs_file_folder));\n\n    cnt = tsk_fs_attr_read(hfs->catalog_attr, off, rec_type, 2, 0);\n    if (cnt != 2) {\n        if (cnt >= 0) {\n            tsk_error_reset();\n            tsk_error_set_errno(TSK_ERR_FS_READ);\n        }\n        tsk_error_set_errstr2\n            (\"hfs_cat_read_file_folder_record: Error reading record type from catalog offset %\"\n            PRIuOFF \" (header)\", off);\n        return 1;\n    }\n\n    if (tsk_getu16(fs->endian, rec_type) == HFS_FOLDER_RECORD) {\n        cnt =\n            tsk_fs_attr_read(hfs->catalog_attr, off, (char *) record,\n            sizeof(hfs_folder), 0);\n        if (cnt != sizeof(hfs_folder)) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_read_file_folder_record: Error reading catalog offset %\"\n                PRIuOFF \" (folder)\", off);\n            return 1;\n        }\n    }\n    else if (tsk_getu16(fs->endian, rec_type) == HFS_FILE_RECORD) {\n        cnt =\n            tsk_fs_attr_read(hfs->catalog_attr, off, (char *) record,\n            sizeof(hfs_file), 0);\n        if (cnt != sizeof(hfs_file)) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_read_file_folder_record: Error reading catalog offset %\"\n                PRIuOFF \" (file)\", off);\n            return 1;\n        }\n    }\n    else {\n        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n        tsk_error_set_errstr\n            (\"hfs_cat_read_file_folder_record: unexpected record type %\"\n            PRIu16, tsk_getu16(fs->endian, rec_type));\n        return 1;\n    }\n\n    return 0;\n}\n\n\n// hfs_lookup_hard_link appears to be unnecessary - it looks up the cnid\n// by seeing if there's a file/dir with the standard hard link name plus\n// linknum and returns the meta_addr. But this should always be the same as linknum,\n// and is very slow when there are many hard links, so it shouldn't be used.\n//static TSK_INUM_T\n//hfs_lookup_hard_link(HFS_INFO * hfs, TSK_INUM_T linknum,\n//    unsigned char is_directory)\n//{\n//    char fBuff[30];\n//    TSK_FS_DIR *mdir;\n//    size_t indx;\n//    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n//\n//    memset(fBuff, 0, 30);\n//\n//    if (is_directory) {\n//\n//        tsk_take_lock(&(hfs->metadata_dir_cache_lock));\n//        if (hfs->dir_meta_dir == NULL) {\n//            hfs->dir_meta_dir =\n//                tsk_fs_dir_open_meta(fs, hfs->meta_dir_inum);\n//        }\n//        tsk_release_lock(&(hfs->metadata_dir_cache_lock));\n//\n//        if (hfs->dir_meta_dir == NULL) {\n//            error_returned\n//                (\"hfs_lookup_hard_link: could not open the dir metadata directory\");\n//            return 0;\n//        }\n//        else {\n//            mdir = hfs->dir_meta_dir;\n//        }\n//        snprintf(fBuff, 30, \"dir_%\" PRIuINUM, linknum);\n//\n//    }\n//    else {\n//\n//        tsk_take_lock(&(hfs->metadata_dir_cache_lock));\n//        if (hfs->meta_dir == NULL) {\n//            hfs->meta_dir = tsk_fs_dir_open_meta(fs, hfs->meta_inum);\n//        }\n//        tsk_release_lock(&(hfs->metadata_dir_cache_lock));\n//\n//        if (hfs->meta_dir == NULL) {\n//            error_returned\n//                (\"hfs_lookup_hard_link: could not open file metadata directory\");\n//            return 0;\n//        }\n//        else {\n//            mdir = hfs->meta_dir;\n//        }\n//        snprintf(fBuff, 30, \"iNode%\" PRIuINUM, linknum);\n//    }\n//\n//    for (indx = 0; indx < tsk_fs_dir_getsize(mdir); ++indx) {\n//        if ((mdir->names != NULL) && mdir->names[indx].name &&\n//            (fs->name_cmp(fs, mdir->names[indx].name, fBuff) == 0)) {\n//            // OK this is the one\n//            return mdir->names[indx].meta_addr;\n//        }\n//    }\n//\n//    // OK, we did not find that linknum\n//    return 0;\n//}\n\n/*\n * Given a catalog entry, will test that entry to see if it is a hard link.\n * If it is a hard link, the function returns the inum (or cnid) of the target file.\n * If it is NOT a hard link, then then function returns the inum of the given entry.\n * In both cases, the parameter is_error is set to zero.\n *\n * If an ERROR occurs, if it is a mild error, then is_error is set to 1, and the\n * inum of the given entry is returned.  This signals that hard link detection cannot\n * be carried out.\n *\n * If the error is serious, then is_error is set to 2 or 3, depending on the kind of error, and\n * the TSK error code is set, and the function returns zero.  is_error==2 means that an error\n * occurred in looking up the target file in the Catalog.  is_error==3 means that the given\n * entry appears to be a hard link, but the target file does not exist in the Catalog.\n *\n * @param hfs The file system\n * @param entry The catalog entry to check\n * @param is_error A Boolean that is returned indicating an error, or no error.\\\n * @return The inum (or cnid) of the hard link target, or of the given catalog entry, or zero.\n */\nTSK_INUM_T\nhfs_follow_hard_link(HFS_INFO * hfs, hfs_file * cat,\n    unsigned char *is_error)\n{\n\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_INUM_T cnid;\n    time_t crtime;\n    uint32_t file_type;\n    uint32_t file_creator;\n\n    *is_error = 0;              // default, not an error\n\n    if (cat == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_follow_hard_link: Pointer to Catalog entry (2nd arg) is null\");\n        return 0;\n    }\n\n    cnid = tsk_getu32(fs->endian, cat->std.cnid);\n\n    if (cnid < HFS_FIRST_USER_CNID) {\n        // Can't be a hard link.  And, cannot look up in Catalog file either!\n        return cnid;\n    }\n\n    crtime =\n        (time_t) hfs_convert_2_unix_time(tsk_getu32(fs->endian,\n            cat->std.crtime));\n\n\n    file_type = tsk_getu32(fs->endian, cat->std.u_info.file_type);\n    file_creator = tsk_getu32(fs->endian, cat->std.u_info.file_cr);\n\n    // Only proceed with the rest of this if the flags etc are right\n    if (file_type == HFS_HARDLINK_FILE_TYPE\n        && file_creator == HFS_HARDLINK_FILE_CREATOR) {\n\n        // see if we have the HFS+ Private Data dir for file links;\n        // if not, it can't be a hard link.  (We could warn the user, but\n        // we also rely on this when finding the HFS+ Private Data dir in\n        // the first place and we don't want a warning on every hfs_open.)\n        if (hfs->meta_inum == 0)\n            return cnid;\n\n        // For this to work, we need the FS creation times.  Is at least one of these set?\n        if ((!hfs->has_root_crtime) && (!hfs->has_meta_dir_crtime)\n            && (!hfs->has_meta_crtime)) {\n            uint32_t linkNum =\n                tsk_getu32(fs->endian, cat->std.perm.special.inum);\n            *is_error = 1;\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"WARNING: hfs_follow_hard_link: File system creation times are not set. \"\n                    \"Cannot test inode for hard link. File type and creator indicate that this\"\n                    \" is a hard link (file), with LINK ID = %\" PRIu32 \"\\n\",\n                    linkNum);\n            return cnid;\n        }\n\n        if ((!hfs->has_root_crtime) || (!hfs->has_meta_crtime)) {\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"WARNING: hfs_follow_hard_link: Either the root folder or the\"\n                    \" file metadata folder is not accessible.  Testing this potential hard link\"\n                    \" may be impaired.\\n\");\n        }\n\n        // Now we need to check the creation time against the three FS creation times\n        if ((hfs->has_meta_crtime && (crtime == hfs->meta_crtime)) ||\n            (hfs->has_meta_dir_crtime && (crtime == hfs->metadir_crtime))\n            || (hfs->has_root_crtime && (crtime == hfs->root_crtime))) {\n            // OK, this is a hard link to a file.\n            uint32_t linkNum =\n                tsk_getu32(fs->endian, cat->std.perm.special.inum);\n\n            // We used to resolve this ID to a file in X folder using hfs_lookup_hard_link, but found \n            // that it was very ineffecient and always resulted in the same linkNum value. \n            // We now just use linkNum\n            return linkNum;\n        }\n    }\n    else if (file_type == HFS_LINKDIR_FILE_TYPE\n        && file_creator == HFS_LINKDIR_FILE_CREATOR) {\n\n        // see if we have the HFS+ Private Directory Data dir for links;\n        // if not, it can't be a hard link.  (We could warn the user, but\n        // we also rely on this when finding the HFS+ Private Directory Data dir in\n        // the first place and we don't want a warning on every hfs_open.)\n        if (hfs->meta_dir_inum == 0)\n            return cnid;\n\n        // For this to work, we need the FS creation times.  Is at least one of these set?\n        if ((!hfs->has_root_crtime) && (!hfs->has_meta_dir_crtime)\n            && (!hfs->has_meta_crtime)) {\n            uint32_t linkNum =\n                tsk_getu32(fs->endian, cat->std.perm.special.inum);\n            *is_error = 1;\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"WARNING: hfs_follow_hard_link: File system creation times are not set. \"\n                    \"Cannot test inode for hard link. File type and creator indicate that this\"\n                    \" is a hard link (directory), with LINK ID = %\" PRIu32\n                    \"\\n\", linkNum);\n            return cnid;\n        }\n\n        if ((!hfs->has_root_crtime) || (!hfs->has_meta_crtime)\n            || (!hfs->has_meta_dir_crtime)) {\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"WARNING: hfs_follow_hard_link: Either the root folder or the\"\n                    \" file metadata folder or the directory metatdata folder is\"\n                    \" not accessible.  Testing this potential hard linked folder \"\n                    \"may be impaired.\\n\");\n        }\n\n        // Now we need to check the creation time against the three FS creation times\n        if ((hfs->has_meta_crtime && (crtime == hfs->meta_crtime)) ||\n            (hfs->has_meta_dir_crtime && (crtime == hfs->metadir_crtime))\n            || (hfs->has_root_crtime && (crtime == hfs->root_crtime))) {\n            // OK, this is a hard link to a directory.\n            uint32_t linkNum =\n                tsk_getu32(fs->endian, cat->std.perm.special.inum);\n\n            // We used to resolve this ID to a file in X folder using hfs_lookup_hard_link, but found \n            // that it was very ineffecient and always resulted in the same linkNum value. \n            // We now just use linkNum\n            return linkNum;\n        }\n    }\n\n    // It cannot be a hard link (file or directory)\n    return cnid;\n}\n\n\n/** \\internal\n * Lookup an entry in the catalog file and save it into the entry.  Do not\n * call this for the special files that do not have an entry in the catalog.\n * data structure.\n * @param hfs File system being analyzed\n * @param inum Address (cnid) of file to open\n * @param entry [out] Structure to read data into\n * @returns 1 on error or not found, 0 on success. Check tsk_errno\n * to differentiate between error and not found.  If it is not found, then the\n * errno will be TSK_ERR_FS_INODE_NUM.  Else, it will be some other value.\n */\nuint8_t\nhfs_cat_file_lookup(HFS_INFO * hfs, TSK_INUM_T inum, HFS_ENTRY * entry,\n    unsigned char follow_hard_link)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    hfs_btree_key_cat key;      /* current catalog key */\n    hfs_thread thread;          /* thread record */\n    hfs_file_folder record;     /* file/folder record */\n    TSK_OFF_T off;\n\n    tsk_error_reset();\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_cat_file_lookup: called for inum %\" PRIuINUM \"\\n\", inum);\n\n    // Test if this is a special file that is not located in the catalog\n    if ((inum == HFS_EXTENTS_FILE_ID) ||\n        (inum == HFS_CATALOG_FILE_ID) ||\n        (inum == HFS_ALLOCATION_FILE_ID) ||\n        (inum == HFS_STARTUP_FILE_ID) ||\n        (inum == HFS_ATTRIBUTES_FILE_ID)) {\n        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n        tsk_error_set_errstr\n            (\"hfs_cat_file_lookup: Called on special file: %\" PRIuINUM,\n            inum);\n        return 1;\n    }\n\n\n    /* first look up the thread record for the item we're searching for */\n\n    /* set up the thread record key */\n    memset((char *) &key, 0, sizeof(hfs_btree_key_cat));\n    cnid_to_array((uint32_t) inum, key.parent_cnid);\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_cat_file_lookup: Looking up thread record (%\" PRIuINUM\n            \")\\n\", inum);\n\n    /* look up the thread record */\n    off = hfs_cat_get_record_offset(hfs, &key);\n    if (off == 0) {\n        // no parsing error, just not found\n        if (tsk_error_get_errno() == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_INODE_NUM);\n            tsk_error_set_errstr\n                (\"hfs_cat_file_lookup: Error finding thread node for file (%\"\n                PRIuINUM \")\", inum);\n        }\n        else {\n            tsk_error_set_errstr2\n                (\" hfs_cat_file_lookup: thread for file (%\" PRIuINUM \")\",\n                inum);\n        }\n        return 1;\n    }\n\n    /* read the thread record */\n    if (hfs_cat_read_thread_record(hfs, off, &thread)) {\n        tsk_error_set_errstr2(\" hfs_cat_file_lookup: file (%\" PRIuINUM \")\",\n            inum);\n        return 1;\n    }\n\n    /* now look up the actual file/folder record */\n\n    /* build key */\n    memset((char *) &key, 0, sizeof(hfs_btree_key_cat));\n    memcpy((char *) key.parent_cnid, (char *) thread.parent_cnid,\n        sizeof(key.parent_cnid));\n    memcpy((char *) &key.name, (char *) &thread.name, sizeof(key.name));\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_cat_file_lookup: Looking up file record (parent: %\"\n            PRIuINUM \")\\n\", (uint64_t) tsk_getu32(fs->endian,\n                key.parent_cnid));\n\n    /* look up the record */\n    off = hfs_cat_get_record_offset(hfs, &key);\n    if (off == 0) {\n        // no parsing error, just not found\n        if (tsk_error_get_errno() == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_INODE_NUM);\n            tsk_error_set_errstr\n                (\"hfs_cat_file_lookup: Error finding record node %\"\n                PRIuINUM, inum);\n        }\n        else {\n            tsk_error_set_errstr2(\" hfs_cat_file_lookup: file (%\" PRIuINUM\n                \")\", inum);\n        }\n        return 1;\n    }\n\n    /* read the record */\n    if (hfs_cat_read_file_folder_record(hfs, off, &record)) {\n        tsk_error_set_errstr2(\" hfs_cat_file_lookup: file (%\" PRIuINUM \")\",\n            inum);\n        return 1;\n    }\n\n    /* these memcpy can be gotten rid of, really */\n    if (tsk_getu16(fs->endian,\n            record.file.std.rec_type) == HFS_FOLDER_RECORD) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_cat_file_lookup: found folder record valence %\" PRIu32\n                \", cnid %\" PRIu32 \"\\n\", tsk_getu32(fs->endian,\n                    record.folder.std.valence), tsk_getu32(fs->endian,\n                    record.folder.std.cnid));\n        memcpy((char *) &entry->cat, (char *) &record, sizeof(hfs_folder));\n    }\n    else if (tsk_getu16(fs->endian,\n            record.file.std.rec_type) == HFS_FILE_RECORD) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_cat_file_lookup: found file record cnid %\" PRIu32\n                \"\\n\", tsk_getu32(fs->endian, record.file.std.cnid));\n        memcpy((char *) &entry->cat, (char *) &record, sizeof(hfs_file));\n    }\n    /* other cases already caught by hfs_cat_read_file_folder_record */\n\n    memcpy((char *) &entry->thread, (char *) &thread, sizeof(hfs_thread));\n\n    entry->flags = TSK_FS_META_FLAG_ALLOC | TSK_FS_META_FLAG_USED;\n    entry->inum = inum;\n\n    if (follow_hard_link) {\n        // TEST to see if this is a hard link\n        unsigned char is_err;\n        TSK_INUM_T target_cnid =\n            hfs_follow_hard_link(hfs, &(entry->cat), &is_err);\n        if (is_err > 1) {\n            error_returned\n                (\"hfs_cat_file_lookup: error occurred while following a possible hard link for \"\n                \"inum (cnid) =  %\" PRIuINUM, inum);\n            return 1;\n        }\n        if (target_cnid != inum) {\n            // This is a hard link, and we have got the cnid of the target file, so look it up.\n            uint8_t res =\n                hfs_cat_file_lookup(hfs, target_cnid, entry, FALSE);\n            if (res != 0) {\n                error_returned\n                    (\"hfs_cat_file_lookup: error occurred while looking up the Catalog entry for \"\n                    \"the target of inum (cnid) = %\" PRIuINUM \" target\",\n                    inum);\n            }\n            return 1;\n        }\n\n        // Target is NOT a hard link, so fall through to the non-hard link exit.\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_cat_file_lookup exiting\\n\");\n    return 0;\n}\n\n\nstatic uint8_t\nhfs_find_highest_inum_cb(HFS_INFO * hfs, int8_t level_type,\n    const hfs_btree_key_cat * cur_key,\n    TSK_OFF_T key_off, void *ptr)\n{\n    // NOTE: This assumes that the biggest inum is the last one that we\n    // see.  the traverse method does not currently promise that as part of\n    // its callback \"contract\". \n    *((TSK_INUM_T*) ptr) = tsk_getu32(hfs->fs_info.endian, cur_key->parent_cnid);\n    return HFS_BTREE_CB_IDX_LT;\n}\n\n/** \\internal\n* Returns the largest inode number in file system\n* @param hfs File system being analyzed\n* @returns largest metadata address\n*/\nstatic TSK_INUM_T\nhfs_find_highest_inum(HFS_INFO * hfs)\n{\n    // @@@ get actual number from Catalog file (go to far right) (we can't always trust the vol header)\n    TSK_INUM_T inum;\n    if (hfs_cat_traverse(hfs, hfs_find_highest_inum_cb, &inum)) {\n      /* Catalog traversal failed, fallback on legacy method :\n         if HFS_VH_ATTR_CNIDS_REUSED is set, then\n         the maximum CNID is 2^32-1; if it's not set, then nextCatalogId is\n         supposed to be larger than all CNIDs on disk.\n       */\n        TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n        if (tsk_getu32(fs->endian, hfs->fs->attr) & HFS_VH_ATTR_CNIDS_REUSED)\n            return (TSK_INUM_T) 0xffffffff;\n        else\n            return (TSK_INUM_T) tsk_getu32(fs->endian,\n                hfs->fs->next_cat_id) - 1;\n    }\n    return inum;\n}\n\n\nstatic TSK_FS_META_MODE_ENUM\nhfs_mode_to_tsk_mode(uint16_t a_mode)\n{\n    TSK_FS_META_MODE_ENUM mode = 0;\n\n    if (a_mode & HFS_IN_ISUID)\n        mode |= TSK_FS_META_MODE_ISUID;\n    if (a_mode & HFS_IN_ISGID)\n        mode |= TSK_FS_META_MODE_ISGID;\n    if (a_mode & HFS_IN_ISVTX)\n        mode |= TSK_FS_META_MODE_ISVTX;\n\n    if (a_mode & HFS_IN_IRUSR)\n        mode |= TSK_FS_META_MODE_IRUSR;\n    if (a_mode & HFS_IN_IWUSR)\n        mode |= TSK_FS_META_MODE_IWUSR;\n    if (a_mode & HFS_IN_IXUSR)\n        mode |= TSK_FS_META_MODE_IXUSR;\n\n    if (a_mode & HFS_IN_IRGRP)\n        mode |= TSK_FS_META_MODE_IRGRP;\n    if (a_mode & HFS_IN_IWGRP)\n        mode |= TSK_FS_META_MODE_IWGRP;\n    if (a_mode & HFS_IN_IXGRP)\n        mode |= TSK_FS_META_MODE_IXGRP;\n\n    if (a_mode & HFS_IN_IROTH)\n        mode |= TSK_FS_META_MODE_IROTH;\n    if (a_mode & HFS_IN_IWOTH)\n        mode |= TSK_FS_META_MODE_IWOTH;\n    if (a_mode & HFS_IN_IXOTH)\n        mode |= TSK_FS_META_MODE_IXOTH;\n\n    return mode;\n}\n\nstatic TSK_FS_META_TYPE_ENUM\nhfs_mode_to_tsk_meta_type(uint16_t a_mode)\n{\n    switch (a_mode & HFS_IN_IFMT) {\n    case HFS_IN_IFIFO:\n        return TSK_FS_META_TYPE_FIFO;\n    case HFS_IN_IFCHR:\n        return TSK_FS_META_TYPE_CHR;\n    case HFS_IN_IFDIR:\n        return TSK_FS_META_TYPE_DIR;\n    case HFS_IN_IFBLK:\n        return TSK_FS_META_TYPE_BLK;\n    case HFS_IN_IFREG:\n        return TSK_FS_META_TYPE_REG;\n    case HFS_IN_IFLNK:\n        return TSK_FS_META_TYPE_LNK;\n    case HFS_IN_IFSOCK:\n        return TSK_FS_META_TYPE_SOCK;\n    case HFS_IFWHT:\n        return TSK_FS_META_TYPE_WHT;\n    case HFS_IFXATTR:\n        return TSK_FS_META_TYPE_UNDEF;\n    default:\n        /* error */\n        return TSK_FS_META_TYPE_UNDEF;\n    }\n}\n\n\nstatic uint8_t\nhfs_make_specialbase(TSK_FS_FILE * fs_file)\n{\n    fs_file->meta->type = TSK_FS_META_TYPE_REG;\n    fs_file->meta->mode = 0;\n    fs_file->meta->nlink = 1;\n    fs_file->meta->flags =\n        (TSK_FS_META_FLAG_USED | TSK_FS_META_FLAG_ALLOC);\n    fs_file->meta->uid = fs_file->meta->gid = 0;\n    fs_file->meta->mtime = fs_file->meta->atime = fs_file->meta->ctime =\n        fs_file->meta->crtime = 0;\n    fs_file->meta->mtime_nano = fs_file->meta->atime_nano =\n        fs_file->meta->ctime_nano = fs_file->meta->crtime_nano = 0;\n\n    if (fs_file->meta->name2 == NULL) {\n        if ((fs_file->meta->name2 = (TSK_FS_META_NAME_LIST *)\n                tsk_malloc(sizeof(TSK_FS_META_NAME_LIST))) == NULL) {\n            error_returned\n                (\" - hfs_make_specialbase, couldn't malloc space for a name list\");\n            return 1;\n        }\n        fs_file->meta->name2->next = NULL;\n    }\n\n    if (fs_file->meta->attr != NULL) {\n        tsk_fs_attrlist_markunused(fs_file->meta->attr);\n    }\n    else {\n        fs_file->meta->attr = tsk_fs_attrlist_alloc();\n    }\n    return 0;\n}\n\n/**\n * \\internal\n * Create an FS_INODE structure for the catalog file.\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_catalog(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n    unsigned char dummy1, dummy2;\n    uint64_t dummy3;\n    uint8_t result;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_catalog: Making virtual catalog file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_catalog\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_CATALOG_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_CATALOGNAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size =\n        tsk_getu64(fs->endian, hfs->fs->cat_file.logic_sz);\n\n\n    // convert the  runs in the volume header to attribute runs\n    if (((attr_run =\n                hfs_extents_to_attr(fs, hfs->fs->cat_file.extents,\n                    0)) == NULL) && (tsk_error_get_errno() != 0)) {\n        error_returned(\" - hfs_make_catalog\");\n        return 1;\n    }\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_catalog\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // initialize the data run\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            tsk_getu64(fs->endian, hfs->fs->cat_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->cat_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->cat_file.logic_sz), 0, 0)) {\n        error_returned(\" - hfs_make_catalog\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // see if catalog file has additional runs\n    if (hfs_ext_find_extent_record_attr(hfs, HFS_CATALOG_FILE_ID, fs_attr,\n            TRUE)) {\n        error_returned(\" - hfs_make_catalog\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n    result = hfs_load_extended_attrs(fs_file, &dummy1, &dummy2, &dummy3);\n    if (result != 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"WARNING: Extended attributes failed to load for the Catalog file.\\n\");\n        tsk_error_reset();\n    }\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n/**\n* \\internal\n * Create an FS_FILE for the extents file\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_extents(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_extents: Making virtual extents file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_extents\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_EXTENTS_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_EXTENTSNAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size =\n        tsk_getu64(fs->endian, hfs->fs->ext_file.logic_sz);\n\n\n    if (((attr_run =\n                hfs_extents_to_attr(fs, hfs->fs->ext_file.extents,\n                    0)) == NULL) && (tsk_error_get_errno() != 0)) {\n        error_returned(\" - hfs_make_extents\");\n        return 1;\n    }\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_extents\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // initialize the data run\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            tsk_getu64(fs->endian, hfs->fs->ext_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->ext_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->ext_file.logic_sz), 0, 0)) {\n        error_returned(\" - hfs_make_extents\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    //hfs_load_extended_attrs(fs_file);\n\n    // Extents doesn't have an entry in itself\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n\n/**\n * \\internal\n * Create an FS_INODE structure for the blockmap / allocation file.\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_blockmap(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n    unsigned char dummy1, dummy2;\n    uint64_t dummy3;\n    uint8_t result;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_blockmap: Making virtual blockmap file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_blockmap\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_ALLOCATION_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_ALLOCATIONNAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size =\n        tsk_getu64(fs->endian, hfs->fs->alloc_file.logic_sz);\n\n    if (((attr_run =\n                hfs_extents_to_attr(fs, hfs->fs->alloc_file.extents,\n                    0)) == NULL) && (tsk_error_get_errno() != 0)) {\n        error_returned(\" - hfs_make_blockmap\");\n        return 1;\n    }\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_blockmap\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // initialize the data run\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            tsk_getu64(fs->endian, hfs->fs->alloc_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->alloc_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->alloc_file.logic_sz), 0, 0)) {\n        error_returned(\" - hfs_make_blockmap\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // see if catalog file has additional runs\n    if (hfs_ext_find_extent_record_attr(hfs, HFS_ALLOCATION_FILE_ID,\n            fs_attr, TRUE)) {\n        error_returned(\" - hfs_make_blockmap\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n\n    result = hfs_load_extended_attrs(fs_file, &dummy1, &dummy2, &dummy3);\n    if (result != 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"WARNING: Extended attributes failed to load for the Allocation file.\\n\");\n        tsk_error_reset();\n    }\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n/**\n* \\internal\n * Create an FS_INODE structure for the startup / boot file.\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_startfile(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n    unsigned char dummy1, dummy2;\n    uint64_t dummy3;\n    uint8_t result;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_startfile: Making virtual startup file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_startfile\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_STARTUP_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_STARTUPNAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size =\n        tsk_getu64(fs->endian, hfs->fs->start_file.logic_sz);\n\n    if (((attr_run =\n                hfs_extents_to_attr(fs, hfs->fs->start_file.extents,\n                    0)) == NULL) && (tsk_error_get_errno() != 0)) {\n        error_returned(\" - hfs_make_startfile\");\n        return 1;\n    }\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_startfile\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // initialize the data run\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            tsk_getu64(fs->endian, hfs->fs->start_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->start_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->start_file.logic_sz), 0, 0)) {\n        error_returned(\" - hfs_make_startfile\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // see if catalog file has additional runs\n    if (hfs_ext_find_extent_record_attr(hfs, HFS_STARTUP_FILE_ID, fs_attr,\n            TRUE)) {\n        error_returned(\" - hfs_make_startfile\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n    result = hfs_load_extended_attrs(fs_file, &dummy1, &dummy2, &dummy3);\n    if (result != 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"WARNING: Extended attributes failed to load for the Start file.\\n\");\n        tsk_error_reset();\n    }\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n\n/**\n * \\internal\n * Create an FS_INODE structure for the attributes file.\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_attrfile(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_attrfile: Making virtual attributes file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_attrfile\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_ATTRIBUTES_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_ATTRIBUTESNAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size =\n        tsk_getu64(fs->endian, hfs->fs->attr_file.logic_sz);\n\n    if (((attr_run =\n                hfs_extents_to_attr(fs, hfs->fs->attr_file.extents,\n                    0)) == NULL) && (tsk_error_get_errno() != 0)) {\n        error_returned(\" - hfs_make_attrfile\");\n        return 1;\n    }\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_attrfile\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // initialize the data run\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            tsk_getu64(fs->endian, hfs->fs->attr_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->attr_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->attr_file.logic_sz), 0, 0)) {\n        error_returned(\" - hfs_make_attrfile\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // see if catalog file has additional runs\n    if (hfs_ext_find_extent_record_attr(hfs, HFS_ATTRIBUTES_FILE_ID,\n            fs_attr, TRUE)) {\n        error_returned(\" - hfs_make_attrfile\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n    //hfs_load_extended_attrs(fs_file);\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n\n\n/**\n * \\internal\n * Create an FS_FILE structure for the BadBlocks file.\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_badblockfile(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_ATTR *fs_attr;\n    unsigned char dummy1, dummy2;\n    uint64_t dummy3;\n    uint8_t result;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_badblockfile: Making virtual badblock file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_badblockfile\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_BAD_BLOCK_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_BAD_BLOCK_FILE_NAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size = 0;\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_badblockfile\");\n        return 1;\n    }\n\n    // add the run to the file.\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, NULL, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            fs_file->meta->size, fs_file->meta->size, fs_file->meta->size,\n            0, 0)) {\n        error_returned(\" - hfs_make_badblockfile\");\n        return 1;\n    }\n\n    // see if file has additional runs\n    if (hfs_ext_find_extent_record_attr(hfs, HFS_BAD_BLOCK_FILE_ID,\n            fs_attr, TRUE)) {\n        error_returned(\" - hfs_make_badblockfile\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n    /* @@@ We have a chicken and egg problem here...  The current design of\n     * fs_attr_set() requires the size to be set, but we dont' know the size\n     * until we look into the extents file (which adds to an attribute...).\n     * This does not seem to be the best design...  neeed a way to test this. */\n    fs_file->meta->size = fs_attr->nrd.initsize;\n    fs_attr->size = fs_file->meta->size;\n    fs_attr->nrd.allocsize = fs_file->meta->size;\n\n    result = hfs_load_extended_attrs(fs_file, &dummy1, &dummy2, &dummy3);\n    if (result != 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"WARNING: Extended attributes failed to load for the BadBlocks file.\\n\");\n        tsk_error_reset();\n    }\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n\n/** \\internal\n * Copy the catalog file or folder record entry into a TSK data structure.\n * @param a_hfs File system being analyzed\n * @param a_hfs_entry Catalog record entry (HFS_ENTRY *)\n * @param a_fs_file Structure to copy data into (TSK_FS_FILE *)\n * Returns 1 on error.\n */\nstatic uint8_t\nhfs_dinode_copy(HFS_INFO * a_hfs, const HFS_ENTRY * a_hfs_entry,\n    TSK_FS_FILE * a_fs_file)\n{\n\n    // Note, a_hfs_entry->cat is really of type hfs_file.  But, hfs_file_folder is a union\n    // of that type with hfs_folder.  Both of hfs_file and hfs_folder have the same first member.\n    // So, this cast is appropriate.\n    const hfs_file_folder *a_entry =\n        (hfs_file_folder *) & (a_hfs_entry->cat);\n    const hfs_file_fold_std *std;\n    TSK_FS_META *a_fs_meta = a_fs_file->meta;\n    TSK_FS_INFO *fs;\n    uint16_t hfsmode;\n    TSK_INUM_T iStd;            // the inum (or CNID) that occurs in the standard file metadata\n\n    if (a_entry == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_dinode_copy: a_entry = a_hfs_entry->cat is NULL\");\n        return 1;\n    }\n\n    fs = (TSK_FS_INFO *) & a_hfs->fs_info;\n\n\n    // Just a sanity check.  The inum (or cnid) occurs in two places in the\n    // entry data structure.\n    iStd = tsk_getu32(fs->endian, a_entry->file.std.cnid);\n    if (iStd != a_hfs_entry->inum) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"WARNING: hfs_dinode_copy:  HFS_ENTRY with conflicting values for inum (or cnid).\\n\");\n    }\n\n    if (a_fs_meta == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"hfs_dinode_copy: a_fs_meta is NULL\");\n        return 1;\n    }\n\n    // both files and folders start off the same\n    std = &(a_entry->file.std);\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_dinode_copy: called for file/folder %\" PRIu32 \"\\n\",\n            tsk_getu32(fs->endian, std->cnid));\n\n    if (a_fs_meta->content_len < HFS_FILE_CONTENT_LEN) {\n        if ((a_fs_meta =\n                tsk_fs_meta_realloc(a_fs_meta,\n                    HFS_FILE_CONTENT_LEN)) == NULL) {\n            return 1;\n        }\n    }\n    a_fs_meta->attr_state = TSK_FS_META_ATTR_EMPTY;\n    if (a_fs_meta->attr) {\n        tsk_fs_attrlist_markunused(a_fs_meta->attr);\n    }\n\n\n    /*\n     * Copy the file type specific stuff first\n     */\n    hfsmode = tsk_getu16(fs->endian, std->perm.mode);\n\n    if (tsk_getu16(fs->endian, std->rec_type) == HFS_FOLDER_RECORD) {\n        // set the type of mode is not set\n        if ((hfsmode & HFS_IN_IFMT) == 0)\n            a_fs_meta->type = TSK_FS_META_TYPE_DIR;\n        a_fs_meta->size = 0;\n        memset(a_fs_meta->content_ptr, 0, HFS_FILE_CONTENT_LEN);\n    }\n    else if (tsk_getu16(fs->endian, std->rec_type) == HFS_FILE_RECORD) {\n        hfs_fork *fork;\n        // set the type of mode is not set\n        if ((hfsmode & HFS_IN_IFMT) == 0)\n            a_fs_meta->type = TSK_FS_META_TYPE_REG;\n        a_fs_meta->size =\n            tsk_getu64(fs->endian, a_entry->file.data.logic_sz);\n\n        // copy the data and resource forks\n        fork = (hfs_fork *) a_fs_meta->content_ptr;\n        memcpy(fork, &(a_entry->file.data), sizeof(hfs_fork));\n        memcpy(&fork[1], &(a_entry->file.resource), sizeof(hfs_fork));\n    }\n    else {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_dinode_copy error: catalog entry is neither file nor folder\\n\");\n        return 1;\n    }\n\n    /*\n     * Copy the standard stuff.\n     * Use default values (as defined in spec) if mode is not defined.\n     */\n    if ((hfsmode & HFS_IN_IFMT) == 0) {\n        a_fs_meta->mode = 0;\n        a_fs_meta->uid = 99;\n        a_fs_meta->gid = 99;\n    }\n    else {\n        a_fs_meta->mode = hfs_mode_to_tsk_mode(hfsmode);\n        a_fs_meta->type = hfs_mode_to_tsk_meta_type(hfsmode);\n        a_fs_meta->uid = tsk_getu32(fs->endian, std->perm.owner);\n        a_fs_meta->gid = tsk_getu32(fs->endian, std->perm.group);\n    }\n\n    // this field is set only for \"indirect\" entries\n    if (tsk_getu32(fs->endian, std->perm.special.nlink))\n        a_fs_meta->nlink = tsk_getu32(fs->endian, std->perm.special.nlink);\n    else\n        a_fs_meta->nlink = 1;\n\n    a_fs_meta->mtime =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, std->cmtime));\n    a_fs_meta->atime =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, std->atime));\n    a_fs_meta->crtime =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, std->crtime));\n    a_fs_meta->ctime =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, std->amtime));\n    a_fs_meta->time2.hfs.bkup_time =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, std->bkup_date));\n    a_fs_meta->mtime_nano = a_fs_meta->atime_nano = a_fs_meta->ctime_nano =\n        a_fs_meta->crtime_nano = 0;\n    a_fs_meta->time2.hfs.bkup_time_nano = 0;\n\n    a_fs_meta->addr = tsk_getu32(fs->endian, std->cnid);\n\n    // All entries here are used.\n    a_fs_meta->flags = TSK_FS_META_FLAG_ALLOC | TSK_FS_META_FLAG_USED;\n\n    if (std->perm.o_flags & HFS_PERM_OFLAG_COMPRESSED)\n        a_fs_meta->flags |= TSK_FS_META_FLAG_COMP;\n\n    // We copy this inum (or cnid) here, because this file *might* have been a hard link.  In\n    // that case, we want to make sure that a_fs_file points consistently to the target of the\n    // link.\n\n    if (a_fs_file->name != NULL) {\n        a_fs_file->name->meta_addr = a_fs_meta->addr;\n    }\n\n    /* TODO @@@ could fill in name2 with this entry's name and parent inode\n       from Catalog entry */\n\n    /* set the link string (if the file is a link)\n     * The size check is a sanity check so that we don't try to allocate\n     * a huge amount of memory for a bad inode value\n     */\n    if ((a_fs_meta->type == TSK_FS_META_TYPE_LNK) &&\n        (a_fs_meta->size >= 0) && (a_fs_meta->size < HFS_MAXPATHLEN)) {\n\n        ssize_t bytes_read;\n\n        a_fs_meta->link = tsk_malloc((size_t) a_fs_meta->size + 1);\n        if (a_fs_meta->link == NULL)\n            return 1;\n\n        bytes_read = tsk_fs_file_read(a_fs_file, (TSK_OFF_T) 0,\n            a_fs_meta->link, (size_t) a_fs_meta->size,\n            TSK_FS_FILE_READ_FLAG_NONE);\n        a_fs_meta->link[a_fs_meta->size] = '\\0';\n\n        if (bytes_read != a_fs_meta->size) {\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_dinode_copy: failed to read contents of symbolic link; \"\n                    \"expected %u bytes but tsk_fs_file_read() returned %u\\n\",\n                    a_fs_meta->size, bytes_read);\n            free(a_fs_meta->link);\n            a_fs_meta->link = NULL;\n            return 1;\n        }\n    }\n\n    return 0;\n}\n\n\n/** \\internal\n * Load a catalog file entry and save it in the TSK_FS_FILE structure.\n *\n * @param fs File system to read from.\n * @param a_fs_file Structure to read into.\n * @param inum File address to load\n * @returns 1 on error\n */\nstatic uint8_t\nhfs_inode_lookup(TSK_FS_INFO * fs, TSK_FS_FILE * a_fs_file,\n    TSK_INUM_T inum)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    HFS_ENTRY entry;\n\n    if (a_fs_file == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"hfs_inode_lookup: fs_file is NULL\");\n        return 1;\n    }\n\n    if (a_fs_file->meta == NULL) {\n        a_fs_file->meta = tsk_fs_meta_alloc(HFS_FILE_CONTENT_LEN);\n    }\n\n    if (a_fs_file->meta == NULL) {\n        return 1;\n    }\n    else {\n        tsk_fs_meta_reset(a_fs_file->meta);\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_inode_lookup: looking up %\" PRIuINUM \"\\n\",\n            inum);\n\n    // @@@ Will need to add orphan stuff here too\n\n    /* First see if this is a special entry\n     * the special ones have their metadata stored in the volume header */\n    if (inum == HFS_EXTENTS_FILE_ID) {\n        if (!hfs->has_extents_file) {\n            error_detected(TSK_ERR_FS_INODE_NUM,\n                \"Extents File not present\");\n            return 1;\n        }\n\n        return hfs_make_extents(hfs, a_fs_file);\n    }\n    else if (inum == HFS_CATALOG_FILE_ID) {\n        return hfs_make_catalog(hfs, a_fs_file);\n    }\n    else if (inum == HFS_BAD_BLOCK_FILE_ID) {\n        // Note: the Extents file and the BadBlocks file are really the same.\n        if (!hfs->has_extents_file) {\n            error_detected(TSK_ERR_FS_INODE_NUM,\n                \"BadBlocks File not present\");\n            return 1;\n        }\n        return hfs_make_badblockfile(hfs, a_fs_file);\n    }\n    else if (inum == HFS_ALLOCATION_FILE_ID) {\n        return hfs_make_blockmap(hfs, a_fs_file);\n    }\n    else if (inum == HFS_STARTUP_FILE_ID) {\n        if (!hfs->has_startup_file) {\n            error_detected(TSK_ERR_FS_INODE_NUM,\n                \"Startup File not present\");\n            return 1;\n        }\n        return hfs_make_startfile(hfs, a_fs_file);\n    }\n    else if (inum == HFS_ATTRIBUTES_FILE_ID) {\n        if (!hfs->has_attributes_file) {\n            error_detected(TSK_ERR_FS_INODE_NUM,\n                \"Attributes File not present\");\n            return 1;\n        }\n        return hfs_make_attrfile(hfs, a_fs_file);\n    }\n\n    /* Lookup inode and store it in the HFS structure */\n    if (hfs_cat_file_lookup(hfs, inum, &entry, TRUE)) {\n        return 1;\n    }\n\n    /* Copy the structure in hfs to generic fs_inode */\n    if (hfs_dinode_copy(hfs, &entry, a_fs_file)) {\n        return 1;\n    }\n\n    /* If this is potentially a compressed file, its\n     * actual size is unknown until we examine the\n     * extended attributes */\n    if ((a_fs_file->meta->size == 0) &&\n        (a_fs_file->meta->type == TSK_FS_META_TYPE_REG) &&\n        (a_fs_file->meta->attr_state != TSK_FS_META_ATTR_ERROR) &&\n        ((a_fs_file->meta->attr_state != TSK_FS_META_ATTR_STUDIED) ||\n            (a_fs_file->meta->attr == NULL))) {\n        hfs_load_attrs(a_fs_file);\n    }\n\n    return 0;\n}\n\n\ntypedef struct {\n    uint32_t offset;\n    uint32_t length;\n} CMP_OFFSET_ENTRY;\n\n\nstatic int\nhfs_read_zlib_block_table(const TSK_FS_ATTR *rAttr, CMP_OFFSET_ENTRY** offsetTableOut, uint32_t* tableSizeOut, uint32_t* tableOffsetOut) {\n    int attrReadResult;\n    hfs_resource_fork_header rfHeader;\n    uint32_t dataOffset;\n    uint32_t offsetTableOffset;\n    char fourBytes[4];          // Size of the offset table, little endian\n    uint32_t tableSize;         // Size of the offset table\n    char *offsetTableData = NULL;\n    CMP_OFFSET_ENTRY *offsetTable = NULL;\n    size_t indx;\n\n    // Read the resource fork header\n    attrReadResult = tsk_fs_attr_read(rAttr, 0, (char *) &rfHeader,\n        sizeof(hfs_resource_fork_header), TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != sizeof(hfs_resource_fork_header)) {\n        error_returned\n            (\" %s: trying to read the resource fork header\", __func__);\n        return 0;\n    }\n\n    // Begin to parse the resource fork. For now, we just need the data offset.\n    dataOffset = tsk_getu32(TSK_BIG_ENDIAN, rfHeader.dataOffset);\n\n    // The resource's data begins with an offset table, which defines blocks\n    // of (optionally) zlib-compressed data (so that the OS can do file seeks\n    // efficiently; each uncompressed block is 64KB).\n    offsetTableOffset = dataOffset + 4;\n\n    // read 4 bytes, the number of table entries, little endian\n    attrReadResult =\n        tsk_fs_attr_read(rAttr, offsetTableOffset, fourBytes, 4,\n        TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != 4) {\n        error_returned\n            (\" %s: trying to read the offset table size, \"\n            \"return value of %u should have been 4\", __func__, attrReadResult);\n        return 0;\n    }\n    tableSize = tsk_getu32(TSK_LIT_ENDIAN, fourBytes);\n\n    // Each table entry is 8 bytes long\n    offsetTableData = tsk_malloc(tableSize * 8);\n    if (offsetTableData == NULL) {\n        error_returned\n            (\" %s: space for the offset table raw data\", __func__);\n        return 0;\n    }\n\n    offsetTable =\n        (CMP_OFFSET_ENTRY *) tsk_malloc(tableSize *\n        sizeof(CMP_OFFSET_ENTRY));\n    if (offsetTable == NULL) {\n        error_returned\n            (\" %s: space for the offset table\", __func__);\n        goto on_error;\n    }\n\n    attrReadResult = tsk_fs_attr_read(rAttr, offsetTableOffset + 4,\n        offsetTableData, tableSize * 8, TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != tableSize * 8) {\n        error_returned\n            (\" %s: reading in the compression offset table, \"\n            \"return value %u should have been %u\", __func__, attrReadResult,\n            tableSize * 8);\n        goto on_error;\n    }\n\n    for (indx = 0; indx < tableSize; ++indx) {\n        offsetTable[indx].offset =\n            tsk_getu32(TSK_LIT_ENDIAN, offsetTableData + indx * 8);\n        offsetTable[indx].length =\n            tsk_getu32(TSK_LIT_ENDIAN, offsetTableData + indx * 8 + 4);\n    }\n\n    free(offsetTableData);\n\n    *offsetTableOut = offsetTable;\n    *tableSizeOut = tableSize;\n    *tableOffsetOut = offsetTableOffset;\n    return 1;\n\non_error:\n    free(offsetTable);\n    free(offsetTableData);\n    return 0;\n}\n\n\nstatic int\nhfs_read_lzvn_block_table(const TSK_FS_ATTR *rAttr, CMP_OFFSET_ENTRY** offsetTableOut, uint32_t* tableSizeOut, uint32_t* tableOffsetOut) {\n    int attrReadResult;\n    char fourBytes[4];\n    uint32_t tableDataSize;\n    uint32_t tableSize;         // Size of the offset table\n    char *offsetTableData = NULL;\n    CMP_OFFSET_ENTRY *offsetTable = NULL;\n\n    // The offset table is a sequence of 4-byte offsets of compressed\n    // blocks. The first 4 bytes is thus the offset of the first block,\n    // but also 4 times the number of entries in the table.\n    attrReadResult = tsk_fs_attr_read(rAttr, 0, fourBytes, 4,\n                                      TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != 4) {\n        error_returned\n            (\" %s: trying to read the offset table size, \"\n            \"return value of %u should have been 4\", __func__, attrReadResult);\n        return 0;\n    }\n\n    tableDataSize = tsk_getu32(TSK_LIT_ENDIAN, fourBytes);\n\n    offsetTableData = tsk_malloc(tableDataSize);\n    if (offsetTableData == NULL) {\n        error_returned\n            (\" %s: space for the offset table raw data\", __func__);\n        return 0;\n    }\n\n    // table entries are 4 bytes, last entry is end of data\n    tableSize = tableDataSize / 4 - 1;\n\n    offsetTable =\n        (CMP_OFFSET_ENTRY *) tsk_malloc(tableSize *\n        sizeof(CMP_OFFSET_ENTRY));\n    if (offsetTable == NULL) {\n        error_returned\n            (\" %s: space for the offset table\", __func__);\n        goto on_error;\n    }\n\n    attrReadResult = tsk_fs_attr_read(rAttr, 0,\n        offsetTableData, tableDataSize, TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != tableDataSize) {\n        error_returned\n            (\" %s: reading in the compression offset table, \"\n            \"return value %u should have been %u\", __func__, attrReadResult,\n            tableDataSize);\n        goto on_error;\n    }\n\n    uint32_t a = tableDataSize;\n    uint32_t b;\n    size_t i;\n\n    for (i = 0; i < tableSize; ++i) {\n        b = tsk_getu32(TSK_LIT_ENDIAN, offsetTableData + 4*(i+1));\n        offsetTable[i].offset = a;\n        offsetTable[i].length = b - a;\n        a = b;\n    }\n\n    free(offsetTableData);\n\n    *offsetTableOut = offsetTable;\n    *tableSizeOut = tableSize;\n    *tableOffsetOut = 0;\n    return 1;\n\non_error:\n    free(offsetTable);\n    free(offsetTableData);\n    return 0;\n}\n\n\nstatic int hfs_decompress_noncompressed_block(char* rawBuf, uint32_t len, char* uncBuf, uint64_t* uncLen) {\n    // actually an uncompressed block of data; just copy\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n           \"%s: Copying an uncompressed compression unit\\n\", __func__);\n\n    if ((len - 1) > COMPRESSION_UNIT_SIZE) {\n        error_detected(TSK_ERR_FS_READ,\n            \"%s: uncompressed block length %u is longer \"\n            \"than compression unit size %u\", __func__, len - 1,\n            COMPRESSION_UNIT_SIZE);\n        return 0;\n    }\n    memcpy(uncBuf, rawBuf + 1, len - 1);\n    *uncLen = len - 1;\n    return 1;\n}\n\n\n#ifdef HAVE_LIBZ\nstatic int hfs_decompress_zlib_block(char* rawBuf, uint32_t len, char* uncBuf, uint64_t* uncLen)\n{\n    // see if this block is compressed\n    if (len > 0 && (rawBuf[0] & 0x0F) != 0x0F) {\n        // Uncompress the chunk of data\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                        \"%s: Inflating the compression unit\\n\", __func__);\n\n        unsigned long bytesConsumed;\n        int infResult = zlib_inflate(rawBuf, (uint64_t) len,\n            uncBuf, (uint64_t) COMPRESSION_UNIT_SIZE,\n            uncLen, &bytesConsumed);\n        if (infResult != 0) {\n            error_returned\n                  (\" %s: zlib inflation (uncompression) failed\",\n                  __func__, infResult);\n            return 0;\n        }\n\n        if (bytesConsumed != len) {\n            error_detected(TSK_ERR_FS_READ,\n                \" %s, decompressor did not consume the whole compressed data\",\n                __func__);\n            return 0;\n        }\n\n        return 1;\n    }\n    else {\n        // actually an uncompressed block of data; just copy\n        return hfs_decompress_noncompressed_block(rawBuf, len, uncBuf, uncLen);\n    }\n}\n#endif\n\n\nstatic int hfs_decompress_lzvn_block(char* rawBuf, uint32_t len, char* uncBuf, uint64_t* uncLen)\n{\n    // see if this block is compressed\n    if (len > 0 && rawBuf[0] != 0x06) {\n        *uncLen = lzvn_decode_buffer(uncBuf, COMPRESSION_UNIT_SIZE, rawBuf, len);\n        return 1;  // apparently this can't fail\n    }\n    else {\n        // actually an uncompressed block of data; just copy\n        return hfs_decompress_noncompressed_block(rawBuf, len, uncBuf, uncLen);\n    }\n}\n\n\nstatic ssize_t read_and_decompress_block(\n  const TSK_FS_ATTR* rAttr,\n  char* rawBuf,\n  char* uncBuf,\n  const CMP_OFFSET_ENTRY* offsetTable,\n  uint32_t offsetTableSize,\n  uint32_t offsetTableOffset,\n  size_t indx,\n  int (*decompress_block)(char* rawBuf,\n                          uint32_t len,\n                          char* uncBuf,\n                          uint64_t* uncLen)\n)\n{\n    int attrReadResult;\n    uint32_t offset = offsetTableOffset + offsetTable[indx].offset;\n    uint32_t len = offsetTable[indx].length;\n    uint64_t uncLen;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: Reading compression unit %d, length %d\\n\",\n            __func__, indx, len);\n\n    /* Github #383 referenced that if len is 0, then the below code causes\n     * problems. Added this check, but I don't have data to verify this on.\n     * it looks like it should at least not crash, but it isn't clear if it\n     * will also do the right thing and if should actually break here\n     * instead. */\n    if (len == 0) {\n      return 0;\n    }\n\n    if (len > COMPRESSION_UNIT_SIZE + 1) {\n      error_detected(TSK_ERR_FS_READ,\n          \"%s: block size is too large: %u\", __func__, len);\n      return -1;\n    }\n\n    // Read in the block of compressed data\n    attrReadResult = tsk_fs_attr_read(rAttr, offset,\n        rawBuf, len, TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != len) {\n        char msg[] =\n            \"%s%s: reading in the compression offset table, \"\n            \"return value %u should have been %u\";\n\n        if (attrReadResult < 0 ) {\n            error_returned(msg, \" \", __func__, attrReadResult, len);\n        }\n        else {\n            error_detected(TSK_ERR_FS_READ, \"\", __func__, attrReadResult, len);\n        }\n        return -1;\n    }\n\n    if (!decompress_block(rawBuf, len, uncBuf, &uncLen)) {\n        return -1;\n    }\n\n    // If size is a multiple of COMPRESSION_UNIT_SIZE,\n    // expected uncompressed length is COMPRESSION_UNIT_SIZE\n    const uint32_t expUncLen = indx == offsetTableSize - 1 ?\n        ((rAttr->fs_file->meta->size - 1) % COMPRESSION_UNIT_SIZE) + 1 :\n        COMPRESSION_UNIT_SIZE;\n\n    if (uncLen != expUncLen) {\n        error_detected(TSK_ERR_FS_READ,\n            \"%s: compressed block decompressed to %u bytes, \"\n            \"should have been %u bytes\", __func__, uncLen, expUncLen);\n        return -1;\n    }\n\n    // There are now uncLen bytes of uncompressed data available from\n    // this comp unit.\n    return (ssize_t)uncLen;\n}\n\n\nstatic uint8_t\nhfs_attr_walk_compressed_rsrc(const TSK_FS_ATTR * fs_attr,\n    int flags, TSK_FS_FILE_WALK_CB a_action, void *ptr,\n    int (*read_block_table)(const TSK_FS_ATTR *rAttr,\n                            CMP_OFFSET_ENTRY** offsetTableOut,\n                            uint32_t* tableSizeOut,\n                            uint32_t* tableOffsetOut),\n    int (*decompress_block)(char* rawBuf,\n                            uint32_t len,\n                            char* uncBuf,\n                            uint64_t* uncLen))\n{\n    TSK_FS_INFO *fs;\n    TSK_FS_FILE *fs_file;\n    const TSK_FS_ATTR *rAttr;   // resource fork attribute\n    char *rawBuf = NULL;               // compressed data\n    char *uncBuf = NULL;               // uncompressed data\n    uint32_t offsetTableOffset;\n    uint32_t offsetTableSize;         // The number of table entries\n    CMP_OFFSET_ENTRY *offsetTable = NULL;\n    size_t indx;                // index for looping over the offset table\n    TSK_OFF_T off = 0;          // the offset in the uncompressed data stream consumed thus far\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s:  Entered, because this is a compressed file with compressed data in the resource fork\\n\", __func__);\n\n    // clean up any error messages that are lying around\n    tsk_error_reset();\n    if ((fs_attr == NULL) || (fs_attr->fs_file == NULL)\n        || (fs_attr->fs_file->meta == NULL)\n        || (fs_attr->fs_file->fs_info == NULL)) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"%s: Null arguments given\\n\", __func__);\n        return 1;\n    }\n\n    // Check that the ATTR being read is the main DATA resource, 128-0,\n    // because this is the only one that can be compressed in HFS+\n    if ((fs_attr->id != HFS_FS_ATTR_ID_DATA) ||\n        (fs_attr->type != TSK_FS_ATTR_TYPE_HFS_DATA)) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: arg specified an attribute %u-%u that is not the data fork, \"\n            \"Only the data fork can be compressed.\", __func__, fs_attr->type,\n            fs_attr->id);\n        return 1;\n    }\n\n    /* This MUST be a compressed attribute     */\n    if (!(fs_attr->flags & TSK_FS_ATTR_COMP)) {\n        error_detected(TSK_ERR_FS_FWALK,\n            \"%s: called with non-special attribute: %x\",\n            __func__, fs_attr->flags);\n        return 1;\n    }\n\n    fs = fs_attr->fs_file->fs_info;\n    fs_file = fs_attr->fs_file;\n\n    /********  Open the Resource Fork ***********/\n\n    // find the attribute for the resource fork\n    rAttr =\n        tsk_fs_file_attr_get_type(fs_file, TSK_FS_ATTR_TYPE_HFS_RSRC,\n        HFS_FS_ATTR_ID_RSRC, TRUE);\n    if (rAttr == NULL) {\n        error_returned\n            (\" %s: could not get the attribute for the resource fork of the file\", __func__);\n        return 1;\n    }\n\n    // read the offset table from the fork header\n    if (!read_block_table(rAttr, &offsetTable, &offsetTableSize, &offsetTableOffset)) {\n      return 1;\n    }\n\n    // Allocate two buffers for the raw and uncompressed data\n    /* Raw data can be COMPRESSION_UNIT_SIZE+1 if the data is not\n     * compressed and there is a 1-byte flag that indicates that\n     * the data is not compressed. */\n    rawBuf = (char *) tsk_malloc(COMPRESSION_UNIT_SIZE + 1);\n    if (rawBuf == NULL) {\n        error_returned\n            (\" %s: buffers for reading and uncompressing\", __func__);\n        goto on_error;\n    }\n\n    uncBuf = (char *) tsk_malloc(COMPRESSION_UNIT_SIZE);\n    if (uncBuf == NULL) {\n        error_returned\n            (\" %s: buffers for reading and uncompressing\", __func__);\n        goto on_error;\n    }\n\n    // FOR entry in the table DO\n    for (indx = 0; indx < offsetTableSize; ++indx) {\n        ssize_t uncLen;        // uncompressed length\n        unsigned int blockSize;\n        uint64_t lumpSize;\n        uint64_t remaining;\n        char *lumpStart;\n\n        switch ((uncLen = read_and_decompress_block(\n                    rAttr, rawBuf, uncBuf,\n                    offsetTable, offsetTableSize, offsetTableOffset, indx,\n                    decompress_block)))\n        {\n        case -1:\n            goto on_error;\n        case  0:\n            continue;\n        default:\n            break;\n        }\n\n        // Call the a_action callback with \"Lumps\"\n        // that are at most the block size.\n        blockSize = fs->block_size;\n        remaining = uncLen;\n        lumpStart = uncBuf;\n\n        while (remaining > 0) {\n            int retval;         // action return value\n            lumpSize = remaining <= blockSize ? remaining : blockSize;\n\n            // Apply the callback function\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"%s: Calling action on lump of size %\"\n                    PRIu64 \" offset %\" PRIu64 \" in the compression unit\\n\",\n                    __func__, lumpSize, uncLen - remaining);\n            if (lumpSize > SIZE_MAX) {\n                error_detected(TSK_ERR_FS_FWALK,\n                    \" %s: lumpSize is too large for the action\", __func__);\n                goto on_error;\n            }\n\n            retval = a_action(fs_attr->fs_file, off, 0, lumpStart,\n                (size_t) lumpSize,   // cast OK because of above test\n                TSK_FS_BLOCK_FLAG_COMP, ptr);\n\n            if (retval == TSK_WALK_ERROR) {\n                error_detected(TSK_ERR_FS | 201,\n                    \"%s: callback returned an error\", __func__);\n                goto on_error;\n            }\n            else if (retval == TSK_WALK_STOP) {\n                break;\n            }\n\n            // Find the next lump\n            off += lumpSize;\n            remaining -= lumpSize;\n            lumpStart += lumpSize;\n        }\n    }\n\n    // Done, so free up the allocated resources.\n    free(offsetTable);\n    free(rawBuf);\n    free(uncBuf);\n    return 0;\n\non_error:\n    free(offsetTable);\n    free(rawBuf);\n    free(uncBuf);\n    return 0;\n}\n\n\n#ifdef HAVE_LIBZ\nstatic uint8_t\nhfs_attr_walk_zlib_rsrc(const TSK_FS_ATTR * fs_attr,\n    int flags, TSK_FS_FILE_WALK_CB a_action, void *ptr)\n{\n    return hfs_attr_walk_compressed_rsrc(\n      fs_attr, flags, a_action, ptr,\n      hfs_read_zlib_block_table,\n      hfs_decompress_zlib_block\n    );\n}\n#endif\n\n\nstatic uint8_t\nhfs_attr_walk_lzvn_rsrc(const TSK_FS_ATTR * fs_attr,\n    int flags, TSK_FS_FILE_WALK_CB a_action, void *ptr)\n{\n    return hfs_attr_walk_compressed_rsrc(\n      fs_attr, flags, a_action, ptr,\n      hfs_read_lzvn_block_table,\n      hfs_decompress_lzvn_block\n    );\n}\n\n\n/** \\internal\n *\n * @returns number of bytes read or -1 on error (incl if offset is past EOF)\n */\nstatic ssize_t\nhfs_file_read_compressed_rsrc(const TSK_FS_ATTR * a_fs_attr,\n    TSK_OFF_T a_offset, char *a_buf, size_t a_len,\n    int (*read_block_table)(const TSK_FS_ATTR *rAttr,\n                            CMP_OFFSET_ENTRY** offsetTableOut,\n                            uint32_t* tableSizeOut,\n                            uint32_t* tableOffsetOut),\n    int (*decompress_block)(char* rawBuf,\n                            uint32_t len,\n                            char* uncBuf,\n                            uint64_t* uncLen))\n{\n    TSK_FS_FILE *fs_file;\n    const TSK_FS_ATTR *rAttr;\n    char *rawBuf = NULL;\n    char *uncBuf = NULL;\n    uint32_t offsetTableOffset;\n    uint32_t offsetTableSize;         // Size of the offset table\n    CMP_OFFSET_ENTRY *offsetTable = NULL;\n    size_t indx;                // index for looping over the offset table\n    uint32_t startUnit = 0;\n    uint32_t startUnitOffset = 0;\n    uint32_t endUnit = 0;\n    uint64_t bytesCopied;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: called because this file is compressed, with data in the resource fork\\n\", __func__);\n\n    // Reading zero bytes?  OK at any offset, I say!\n    if (a_len == 0)\n        return 0;\n\n    if (a_offset < 0) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: reading from file at a negative offset, or negative length\",\n             __func__);\n        return -1;\n    }\n\n    if (a_len > SIZE_MAX / 2) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: trying to read more than SIZE_MAX/2 is not supported.\",\n            __func__);\n        return -1;\n    }\n\n    if ((a_fs_attr == NULL) || (a_fs_attr->fs_file == NULL)\n        || (a_fs_attr->fs_file->meta == NULL)\n        || (a_fs_attr->fs_file->fs_info == NULL)) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: NULL parameters passed\", __func__);\n        return -1;\n    }\n\n    // This should be a compressed file.  If not, that's an error!\n    if (!(a_fs_attr->flags & TSK_FS_ATTR_COMP)) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: called with non-special attribute: %x\",\n            __func__, a_fs_attr->flags);\n        return -1;\n    }\n\n    // Check that the ATTR being read is the main DATA resource, 4352-0,\n    // because this is the only one that can be compressed in HFS+\n    if ((a_fs_attr->id != HFS_FS_ATTR_ID_DATA) ||\n        (a_fs_attr->type != TSK_FS_ATTR_TYPE_HFS_DATA)) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: arg specified an attribute %u-%u that is not the data fork, \"\n            \"Only the data fork can be compressed.\", __func__,\n            a_fs_attr->type, a_fs_attr->id);\n        return -1;\n    }\n\n    /********  Open the Resource Fork ***********/\n    // The file\n    fs_file = a_fs_attr->fs_file;\n\n    // find the attribute for the resource fork\n    rAttr =\n        tsk_fs_file_attr_get_type(fs_file, TSK_FS_ATTR_TYPE_HFS_RSRC,\n        HFS_FS_ATTR_ID_RSRC, TRUE);\n    if (rAttr == NULL) {\n        error_returned\n            (\" %s: could not get the attribute for the resource fork of the file\", __func__);\n        return -1;\n    }\n\n    // read the offset table from the fork header\n    if (!read_block_table(rAttr, &offsetTable, &offsetTableSize, &offsetTableOffset)) {\n      return -1;\n    }\n\n    // Compute the range of compression units needed for the request\n    startUnit = a_offset / COMPRESSION_UNIT_SIZE;\n    startUnitOffset = a_offset % COMPRESSION_UNIT_SIZE;\n    endUnit = (a_offset + a_len - 1) / COMPRESSION_UNIT_SIZE;\n\n    if (startUnit >= offsetTableSize || endUnit >= offsetTableSize) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: range of bytes requested %lld - %lld falls past the \"\n            \"end of the uncompressed stream %llu\\n\",\n            __func__, a_offset, a_offset + a_len,\n            offsetTable[offsetTableSize-1].offset +\n            offsetTable[offsetTableSize-1].length);\n        goto on_error;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: reading compression units: %\" PRIu32\n            \" to %\" PRIu32 \"\\n\", __func__, startUnit, endUnit);\n    bytesCopied = 0;\n\n    // Allocate buffers for the raw and uncompressed data\n    /* Raw data can be COMPRESSION_UNIT_SIZE+1 if the zlib data is not\n     * compressed and there is a 1-byte flag that indicates that\n     * the data is not compressed. */\n    rawBuf = (char *) tsk_malloc(COMPRESSION_UNIT_SIZE + 1);\n    if (rawBuf == NULL) {\n        error_returned\n            (\" %s: buffers for reading and uncompressing\", __func__);\n        goto on_error;\n    }\n\n    uncBuf = (char *) tsk_malloc(COMPRESSION_UNIT_SIZE);\n    if (uncBuf == NULL) {\n        error_returned\n            (\" %s: buffers for reading and uncompressing\", __func__);\n        goto on_error;\n    }\n\n    // Read from the indicated comp units\n    for (indx = startUnit; indx <= endUnit; ++indx) {\n        uint64_t uncLen;\n        char *uncBufPtr = uncBuf;\n        size_t bytesToCopy;\n\n        switch ((uncLen = read_and_decompress_block(\n                    rAttr, rawBuf, uncBuf,\n                    offsetTable, offsetTableSize, offsetTableOffset, indx,\n                    decompress_block)))\n        {\n        case -1:\n            goto on_error;\n        case  0:\n            continue;\n        default:\n            break;\n        }\n\n        // If this is the first comp unit, then we must skip over the\n        // startUnitOffset bytes.\n        if (indx == startUnit) {\n            uncLen -= startUnitOffset;\n            uncBufPtr += startUnitOffset;\n        }\n\n        // How many bytes to copy from this compression unit?\n\n        if (bytesCopied + uncLen < (uint64_t) a_len)    // cast OK because a_len > 0\n            bytesToCopy = (size_t) uncLen;      // uncLen <= size of compression unit, which is small, so cast is OK\n        else\n            bytesToCopy = (size_t) (((uint64_t) a_len) - bytesCopied);  // diff <= compression unit size, so cast is OK\n\n        // Copy into the output buffer, and update bookkeeping.\n        memcpy(a_buf + bytesCopied, uncBufPtr, bytesToCopy);\n        bytesCopied += bytesToCopy;\n    }\n\n    // Well, we don't know (without a lot of work) what the\n    // true uncompressed size of the stream is.  All we know is the \"upper bound\" which\n    // assumes that all of the compression units expand to their full size.  If we did\n    // know the true size, then we could reject requests that go beyond the end of the\n    // stream.  Instead, we treat the stream as if it is padded out to the full size of\n    // the last compression unit with zeros.\n\n    // Have we read and copied all of the bytes requested?\n    if (bytesCopied < a_len) {\n        // set the remaining bytes to zero\n        memset(a_buf + bytesCopied, 0, a_len - (size_t) bytesCopied);   // cast OK because diff must be < compression unit size\n    }\n\n    free(offsetTable);\n    free(rawBuf);\n    free(uncBuf);\n\n    return (ssize_t) bytesCopied;       // cast OK, cannot be greater than a_len which cannot be greater than SIZE_MAX/2 (rounded down).\n\non_error:\n    free(offsetTable);\n    free(rawBuf);\n    free(uncBuf);\n    return -1;\n}\n\n\n#ifdef HAVE_LIBZ\nstatic ssize_t\nhfs_file_read_zlib_rsrc(const TSK_FS_ATTR * a_fs_attr,\n    TSK_OFF_T a_offset, char *a_buf, size_t a_len)\n{\n    return hfs_file_read_compressed_rsrc(\n        a_fs_attr, a_offset, a_buf, a_len,\n        hfs_read_zlib_block_table,\n        hfs_decompress_zlib_block\n    );\n}\n#endif\n\n\nstatic ssize_t\nhfs_file_read_lzvn_rsrc(const TSK_FS_ATTR * a_fs_attr,\n    TSK_OFF_T a_offset, char *a_buf, size_t a_len)\n{\n    return hfs_file_read_compressed_rsrc(\n        a_fs_attr, a_offset, a_buf, a_len,\n        hfs_read_lzvn_block_table,\n        hfs_decompress_lzvn_block\n    );\n}\n\n\nstatic int hfs_decompress_noncompressed_attr(char* rawBuf, uint32_t rawSize, uint64_t uncSize, char** dstBuf, uint64_t* dstSize, int* dstBufFree) {\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: Leading byte, 0x%02x, indicates that the data is not really compressed.\\n\"\n            \"%s:  Loading the default DATA attribute.\", __func__, rawBuf[0], __func__);\n\n    *dstBuf = rawBuf + 1;  // + 1 indicator byte\n    *dstSize = uncSize;\n    *dstBufFree = FALSE;\n    return 1;\n}\n\n\nstatic int hfs_decompress_zlib_attr(char* rawBuf, uint32_t rawSize, uint64_t uncSize, char** dstBuf, uint64_t* dstSize, int* dstBufFree)\n{\n    if ((rawBuf[0] & 0x0F) == 0x0F) {\n        return hfs_decompress_noncompressed_attr(\n            rawBuf, rawSize, uncSize, dstBuf, dstSize, dstBufFree);\n    }\n    else {\n#ifdef HAVE_LIBZ\n        char* uncBuf = NULL;\n        uint64_t uLen;\n        unsigned long bytesConsumed;\n        int infResult;\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                        \"%s: Uncompressing (inflating) data.\", __func__);\n        // Uncompress the remainder of the attribute, and load as 128-0\n        // Note: cast is OK because uncSize will be quite modest, < 4000.\n\n        uncBuf = (char *) tsk_malloc((size_t) uncSize + 100); // add some extra space\n        if (uncBuf == NULL) {\n            error_returned\n                (\" - %s, space for the uncompressed attr\", __func__);\n            return 0;\n        }\n\n        infResult = zlib_inflate(rawBuf, (uint64_t) rawSize,\n                                 uncBuf, (uint64_t) (uncSize + 100),\n                                 &uLen, &bytesConsumed);\n        if (infResult != 0) {\n            error_returned\n                (\" %s, zlib could not uncompress attr\", __func__);\n            free(uncBuf);\n            return 0;\n        }\n\n        if (bytesConsumed != rawSize) {\n            error_detected(TSK_ERR_FS_READ,\n                \" %s, decompressor did not consume the whole compressed data\",\n                __func__);\n            free(uncBuf);\n            return 0;\n        }\n\n        *dstBuf = uncBuf;\n        *dstSize = uncSize;\n        *dstBufFree = TRUE;\n#else\n        // ZLIB compression library is not available, so we will load a\n        // zero-length default DATA attribute. Without this, icat may\n        // misbehave.\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                        \"%s: ZLIB not available, so loading an empty default DATA attribute.\\n\", __func__);\n\n        // Dummy is one byte long, so the ptr is not null, but we set the\n        // length to zero bytes, so it is never read.\n        static uint8_t dummy[1];\n\n        *dstBuf = dummy;\n        *dstSize = 0;\n        *dstBufFree = FALSE;\n#endif\n    }\n\n    return 1;\n}\n\n\nstatic int hfs_decompress_lzvn_attr(char* rawBuf, uint32_t rawSize, uint64_t uncSize, char** dstBuf, uint64_t* dstSize, int* dstBufFree)\n{\n    if (rawBuf[0] == 0x06) {\n        return hfs_decompress_noncompressed_attr(\n            rawBuf, rawSize, uncSize, dstBuf, dstSize, dstBufFree);\n    }\n    \n    char* uncBuf = (char *) tsk_malloc((size_t) uncSize);\n    *dstSize = lzvn_decode_buffer(uncBuf, uncSize, rawBuf, rawSize);\n    *dstBuf = uncBuf;\n    *dstBufFree = TRUE;\n\n    return 1;\n}\n\n\nstatic int\nhfs_file_read_compressed_attr(TSK_FS_FILE* fs_file,\n                              uint8_t cmpType,\n                              char* buffer,\n                              uint32_t attributeLength,\n                              uint64_t uncSize,\n                              int (*decompress_attr)(char* rawBuf,\n                                                     uint32_t rawSize,\n                                                     uint64_t uncSize,\n                                                     char** dstBuf,\n                                                     uint64_t* dstSize,\n                                                     int* dstBufFree))\n{\n    // Data is inline. We will load the uncompressed data as a\n    // resident attribute.\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: Compressed data is inline in the attribute, will load this as the default DATA attribute.\\n\", __func__);\n\n    if (attributeLength <= 16) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"%s: WARNING, Compression Record of type %u is not followed by\"\n                \" compressed data. No data will be loaded into the DATA\"\n                \" attribute.\\n\", __func__, cmpType);\n\n        // oddly, this is not actually considered an error\n        return 1;\n    }\n\n    TSK_FS_ATTR *fs_attr_unc;\n\n    // There is data following the compression record, as there should be.\n    if ((fs_attr_unc = tsk_fs_attrlist_getnew(\n          fs_file->meta->attr, TSK_FS_ATTR_RES)) == NULL)\n    {\n        error_returned(\" - %s, FS_ATTR for uncompressed data\", __func__);\n        return 0;\n    }\n\n    char* dstBuf;\n    uint64_t dstSize;\n    int dstBufFree = FALSE;\n\n    if (!decompress_attr(buffer + 16, attributeLength - 16, uncSize,\n                         &dstBuf, &dstSize, &dstBufFree)) {\n        return 0;\n    }\n\n    if (dstSize != uncSize) {\n        error_detected(TSK_ERR_FS_READ,\n            \" %s, actual uncompressed size not equal to the size in the compression record\", __func__);\n        goto on_error;\n    }\n\n    if (tsk_verbose)\n       tsk_fprintf(stderr,\n                   \"%s: Loading decompressed data as default DATA attribute.\",\n                   __func__);\n\n    // Load the remainder of the attribute as 128-0\n    // set the details in the fs_attr structure.\n    // Note, we are loading this as a RESIDENT attribute.\n    if (tsk_fs_attr_set_str(fs_file,\n                            fs_attr_unc, \"DATA\",\n                            TSK_FS_ATTR_TYPE_HFS_DATA,\n                            HFS_FS_ATTR_ID_DATA, dstBuf,\n                            dstSize))\n    {\n        error_returned(\" - %s\", __func__);\n        goto on_error;\n    }\n\n    if (dstBufFree) {\n        free(dstBuf);\n    }\n    return 1;\n\non_error:\n    if (dstBufFree) {\n        free(dstBuf);\n    }\n    return 0;\n}\n\n\nstatic int hfs_file_read_zlib_attr(TSK_FS_FILE* fs_file,\n                            char* buffer,\n                            uint32_t attributeLength,\n                            uint64_t uncSize)\n{\n    return hfs_file_read_compressed_attr(\n        fs_file, DECMPFS_TYPE_ZLIB_ATTR,\n        buffer, attributeLength, uncSize,\n        hfs_decompress_zlib_attr\n    );\n}\n\n\nstatic int hfs_file_read_lzvn_attr(TSK_FS_FILE* fs_file,\n                            char* buffer,\n                            uint32_t attributeLength,\n                            uint64_t uncSize)\n{\n    return hfs_file_read_compressed_attr(\n        fs_file, DECMPFS_TYPE_LZVN_ATTR,\n        buffer, attributeLength, uncSize,\n        hfs_decompress_lzvn_attr\n    );\n}\n\n\ntypedef struct {\n    TSK_FS_INFO *fs;            // the HFS file system\n    TSK_FS_FILE *file;          // the Attributes file, if open\n    hfs_btree_header_record *header;    // the Attributes btree header record.\n    // For Convenience, unpacked values.\n    TSK_ENDIAN_ENUM endian;\n    uint32_t rootNode;\n    uint16_t nodeSize;\n    uint16_t maxKeyLen;\n} ATTR_FILE_T;\n\n\n/** \\internal\n * Open the Attributes file, and read the btree header record. Fill in the fields of the ATTR_FILE_T struct.\n *\n * @param fs -- the HFS file system\n * @param header -- the header record struct\n *\n * @return 1 on error, 0 on success\n */\nstatic uint8_t\nopen_attr_file(TSK_FS_INFO * fs, ATTR_FILE_T * attr_file)\n{\n\n    int cnt;                    // will hold bytes read\n\n    hfs_btree_header_record *hrec;\n\n    // clean up any error messages that are lying around\n    tsk_error_reset();\n\n    if (fs == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"open_attr_file: fs is NULL\");\n        return 1;\n    }\n\n    if (attr_file == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"open_attr_file: attr_file is NULL\");\n        return 1;\n    }\n\n    // Open the Attributes File\n    attr_file->file =\n        tsk_fs_file_open_meta(fs, NULL, HFS_ATTRIBUTES_FILE_ID);\n\n    if (attr_file->file == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_READ);\n        tsk_error_set_errstr\n            (\"open_attr_file: could not open the Attributes file\");\n        return 1;\n    }\n\n    // Allocate some space for the Attributes btree header record (which\n    //       is passed back to the caller)\n    hrec = (hfs_btree_header_record *)\n        malloc(sizeof(hfs_btree_header_record));\n\n    if (hrec == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS);\n        tsk_error_set_errstr\n            (\"open_attr_file: could not malloc space for Attributes header record\");\n        return 1;\n    }\n\n    // Read the btree header record\n    cnt = tsk_fs_file_read(attr_file->file,\n        14,\n        (char *) hrec,\n        sizeof(hfs_btree_header_record), (TSK_FS_FILE_READ_FLAG_ENUM) 0);\n    if (cnt != sizeof(hfs_btree_header_record)) {\n        tsk_error_set_errno(TSK_ERR_FS_READ);\n        tsk_error_set_errstr\n            (\"open_attr_file: could not open the Attributes file\");\n        tsk_fs_file_close(attr_file->file);\n        free(hrec);\n        return 1;\n    }\n\n    // Fill in the fields of the attr_file struct (which was passed in by the caller)\n    attr_file->fs = fs;\n    attr_file->header = hrec;\n    attr_file->endian = fs->endian;\n    attr_file->nodeSize = tsk_getu16(attr_file->endian, hrec->nodesize);\n    attr_file->rootNode = tsk_getu32(attr_file->endian, hrec->rootNode);\n    attr_file->maxKeyLen = tsk_getu16(attr_file->endian, hrec->maxKeyLen);\n\n    return 0;\n}\n\n\n/** \\internal\n * Closes and frees the data structures associated with ATTR_FILE_T\n */\nstatic uint8_t\nclose_attr_file(ATTR_FILE_T * attr_file)\n{\n    if (attr_file == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_READ);\n        tsk_error_set_errstr(\"close_attr_file: NULL attr_file arg\");\n        return 1;\n    }\n\n    if (attr_file->file != NULL) {\n        tsk_fs_file_close(attr_file->file);\n        attr_file->file = NULL;\n    }\n    if (attr_file->header != NULL) {\n        free(attr_file->header);\n        attr_file->header = NULL;\n    }\n    attr_file->rootNode = 0;\n    attr_file->nodeSize = 0;\n    // Note that we leave the fs component alone.\n    return 0;\n}\n\n\nstatic const char *\nhfs_attrTypeName(uint32_t typeNum)\n{\n    switch (typeNum) {\n    case TSK_FS_ATTR_TYPE_HFS_DEFAULT:\n        return \"DFLT\";\n    case TSK_FS_ATTR_TYPE_HFS_DATA:\n        return \"DATA\";\n    case TSK_FS_ATTR_TYPE_HFS_EXT_ATTR:\n        return \"ExATTR\";\n    case TSK_FS_ATTR_TYPE_HFS_COMP_REC:\n        return \"CMPF\";\n    case TSK_FS_ATTR_TYPE_HFS_RSRC:\n        return \"RSRC\";\n    default:\n        return \"UNKN\";\n    }\n}\n\n\n// TODO: Function description missing here no idea what it is supposed to return\n// in which circumstances.\nstatic uint8_t\nhfs_load_extended_attrs(TSK_FS_FILE * fs_file,\n    unsigned char *isCompressed, unsigned char *cmpType,\n    uint64_t *uncompressedSize)\n{\n    TSK_FS_INFO *fs = fs_file->fs_info;\n    uint64_t fileID;\n    ATTR_FILE_T attrFile;\n    int cnt;                    // count of chars read from file.\n    uint8_t *nodeData;\n    TSK_ENDIAN_ENUM endian;\n    hfs_btree_node *nodeDescriptor;     // The node descriptor\n    uint32_t nodeID;            // The number or ID of the Attributes file node to read.\n    hfs_btree_key_attr *keyB;   // ptr to the key of the Attr file record.\n    unsigned char done;         // Flag to indicate that we are done looping over leaf nodes\n    uint16_t attribute_counter = 2;     // The ID of the next attribute to be loaded.\n    HFS_INFO *hfs;\n    char *buffer = NULL;   // buffer to hold the attribute\n    TSK_LIST *nodeIDs_processed = NULL; // Keep track of node IDs to prevent an infinite loop\n\n    tsk_error_reset();\n\n    // The CNID (or inode number) of the file\n    //  Note that in TSK such numbers are 64 bits, but in HFS+ they are only 32 bits.\n    fileID = fs_file->meta->addr;\n\n    if (fs == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_load_extended_attrs: NULL fs arg\");\n        return 1;\n    }\n\n    hfs = (HFS_INFO *) fs;\n\n    if (!hfs->has_attributes_file) {\n        // No attributes file, and so, no extended attributes\n        return 0;\n    }\n\n    if (tsk_verbose) {\n        tsk_fprintf(stderr,\n            \"hfs_load_extended_attrs:  Processing file %\" PRIuINUM \"\\n\",\n            fileID);\n    }\n\n    // Open the Attributes File\n    if (open_attr_file(fs, &attrFile)) {\n        error_returned\n            (\"hfs_load_extended_attrs: could not open Attributes file\");\n        return 1;\n    }\n\n    // Is the Attributes file empty?\n    if (attrFile.rootNode == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_extended_attrs: Attributes file is empty\\n\");\n        close_attr_file(&attrFile);\n        *isCompressed = FALSE;\n        *cmpType = 0;\n        return 0;\n    }\n\n    // A place to hold one node worth of data\n    nodeData = (uint8_t *) malloc(attrFile.nodeSize);\n    if (nodeData == NULL) {\n        error_detected(TSK_ERR_AUX_MALLOC,\n            \"hfs_load_extended_attrs: Could not malloc space for an Attributes file node\");\n        goto on_error;\n    }\n\n    // Initialize these\n    *isCompressed = FALSE;\n    *cmpType = 0;\n\n    endian = attrFile.fs->endian;\n\n    // Start with the root node\n    nodeID = attrFile.rootNode;\n\n    // While loop, over nodes in path from root node to the correct LEAF node.\n    while (1) {\n        uint16_t numRec;        // Number of records in the node\n        int recIndx;            // index for looping over records\n\n        if (tsk_verbose) {\n            tsk_fprintf(stderr,\n                \"hfs_load_extended_attrs: Reading Attributes File node with ID %\"\n                PRIu32 \"\\n\", nodeID);\n        }\n\n        /* Make sure we do not get into an infinite loop */\n        if (tsk_list_find(nodeIDs_processed, nodeID)) {\n            error_detected(TSK_ERR_FS_READ,\n                \"hfs_load_extended_attrs: Infinite loop detected - trying to read node %\" PRIu32 \" which has already been processed\", nodeID);\n            goto on_error;\n        }\n\n\n        /* Read the node */\n        cnt = tsk_fs_file_read(attrFile.file,\n            (TSK_OFF_T)nodeID * attrFile.nodeSize,\n            (char *) nodeData,\n            attrFile.nodeSize, (TSK_FS_FILE_READ_FLAG_ENUM) 0);\n        if (cnt != attrFile.nodeSize) {\n            error_returned\n                (\"hfs_load_extended_attrs: Could not read in a node from the Attributes File\");\n            goto on_error;\n        }\n\n        /* Save this node ID to the list of processed nodes */\n        if (tsk_list_add(&nodeIDs_processed, nodeID)) {\n            error_detected(TSK_ERR_FS_READ,\n                \"hfs_load_extended_attrs: Could not save nodeID to the list of processed nodes\");\n            goto on_error;\n        }\n\n        /** Node has a:\n         * Descriptor\n         * Set of records\n         * Table at the end with pointers to the records\n         */\n        // Parse the Node header\n        nodeDescriptor = (hfs_btree_node *) nodeData;\n\n        // If we are at a leaf node, then we have found the right node\n        if (nodeDescriptor->type == HFS_ATTR_NODE_LEAF) {\n            break;\n        }\n\n        // This had better be an INDEX node, if not its an error\n        else if (nodeDescriptor->type != HFS_ATTR_NODE_INDEX) {\n            error_detected(TSK_ERR_FS_READ,\n                \"hfs_load_extended_attrs: Reached a non-INDEX and non-LEAF node in searching the Attributes File\");\n            goto on_error;\n        }\n\n        // OK, we are in an INDEX node.  loop over the records to find the last one whose key is\n        // smaller than or equal to the desired key\n\n        numRec = tsk_getu16(endian, nodeDescriptor->num_rec);\n        if (numRec == 0) {\n            // This is wrong, there must always be at least 1 record in an INDEX node.\n            error_detected(TSK_ERR_FS_READ,\n                \"hfs_load_extended_attrs:Attributes File index node %\"\n                PRIu32 \" has zero records\", nodeID);\n            goto on_error;\n        }\n\n        for (recIndx = 0; recIndx < numRec; ++recIndx) {\n            uint16_t keyLength;\n            int comp;           // comparison result\n            char *compStr;      // comparison result, as a string\n            uint8_t *recData;   // pointer to the data part of the record\n            uint32_t keyFileID;\n\n            // The offset to the record is stored in table at end of node\n            uint8_t *recOffsetTblEntry = &nodeData[attrFile.nodeSize - (2 * (recIndx + 1))];  // data describing where this record is\n            uint16_t recOffset = tsk_getu16(endian, recOffsetTblEntry);\n            //uint8_t * nextRecOffsetData = &nodeData[attrFile.nodeSize - 2* (recIndx+2)];\n\n            // make sure the record and first fields are in the buffer\n            if (recOffset + 14 > attrFile.nodeSize) {\n                error_detected(TSK_ERR_FS_READ,\n                    \"hfs_load_extended_attrs: Unable to process attribute (offset too big)\");\n                goto on_error;\n            }\n\n            // Pointer to first byte of record\n            uint8_t *recordBytes = &nodeData[recOffset];\n\n\n            // Cast that to the Attributes file key (n.b., the key is the first thing in the record)\n            keyB = (hfs_btree_key_attr *) recordBytes;\n\n            // Is this key less than what we are seeking?\n            //int comp = comp_attr_key(endian, keyB, fileID, attrName, startBlock);\n\n            keyFileID = tsk_getu32(endian, keyB->file_id);\n            if (keyFileID < fileID) {\n                comp = -1;\n                compStr = \"less than\";\n            }\n            else if (keyFileID > fileID) {\n                comp = 1;\n                compStr = \"greater than\";\n            }\n            else {\n                comp = 0;\n                compStr = \"equal to\";\n            }\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_load_extended_attrs: INDEX record %d, fileID %\"\n                    PRIu32 \" is %s the file ID we are seeking, %\" PRIu32\n                    \".\\n\", recIndx, keyFileID, compStr, fileID);\n            if (comp > 0) {\n                // The key of this record is greater than what we are seeking\n                if (recIndx == 0) {\n                    // This is the first record, so no records are appropriate\n                    // Nothing in this btree will match.  We can stop right here.\n                    goto on_exit;\n                }\n\n                // This is not the first record, so, the previous record's child is the one we want.\n                break;\n            }\n\n            // CASE:  key in this record matches the key we are seeking.  The previous record's child\n            // is the one we want.  However, if this is the first record, then we want THIS record's child.\n            if (comp == 0 && recIndx != 0) {\n                break;\n            }\n\n            // Extract the child node ID from the record data (stored after the key)\n            keyLength = tsk_getu16(endian, keyB->key_len);\n            // make sure the fields we care about are still in the buffer\n            // +2 is because key_len doesn't include its own length\n            // +4 is because of the amount of data we read from the data\n            if (recOffset + keyLength + 2 + 4 > attrFile.nodeSize) {\n                error_detected(TSK_ERR_FS_READ,\n                    \"hfs_load_extended_attrs: Unable to process attribute\");\n                goto on_error;\n            }\n\n            recData = &recordBytes[keyLength + 2];   \n\n            // Data must start on an even offset from the beginning of the record.\n            // So, correct this if needed.\n            if ((recData - recordBytes) % 2) {\n                recData += 1;\n            }\n\n            // The next four bytes should be the Node ID of the child of this node.\n            nodeID = tsk_getu32(endian, recData);\n\n            // At this point, either comp<0 or comp=0 && recIndx=0.  In the latter case we want to\n            // descend to the child of this node, so we break.\n            if (recIndx == 0 && comp == 0) {\n                break;\n            }\n\n            // CASE: key in this record is less than key we seek.  comp < 0\n            // So, continue looping over records in this node.\n        }                       // END loop over records\n\n    }                           // END while loop over Nodes in path from root to LEAF node\n\n    // At this point nodeData holds the contents of a LEAF node with the right range of keys\n    // and nodeDescriptor points to the descriptor of that node.\n\n    // Loop over successive LEAF nodes, starting with this one\n    done = FALSE;\n    while (!done) {\n        uint16_t numRec;        // number of records\n        unsigned int recIndx;            // index for looping over records\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_extended_attrs: Attributes File LEAF Node %\"\n                PRIu32 \".\\n\", nodeID);\n        numRec = tsk_getu16(endian, nodeDescriptor->num_rec);\n        // Note, leaf node could have one (or maybe zero) records\n\n        // Loop over the records in this node\n        for (recIndx = 0; recIndx < numRec; ++recIndx) {\n            \n            // The offset to the record is stored in table at end of node\n            uint8_t *recOffsetTblEntry = &nodeData[attrFile.nodeSize - (2 * (recIndx + 1))];  // data describing where this record is\n            uint16_t recOffset = tsk_getu16(endian, recOffsetTblEntry);\n            \n            int comp;           // comparison result\n            char *compStr;      // comparison result as a string\n            uint32_t keyFileID;\n\n            // make sure the record and first fields are in the buffer\n            if (recOffset + 14 > attrFile.nodeSize) {\n                error_detected(TSK_ERR_FS_READ,\n                    \"hfs_load_extended_attrs: Unable to process attribute (offset too big)\");\n                goto on_error;\n            }\n\n            // Pointer to first byte of record\n            uint8_t *recordBytes = &nodeData[recOffset];\n\n            // Cast that to the Attributes file key\n            keyB = (hfs_btree_key_attr *) recordBytes;\n            \n            // Compare recordBytes key to the key that we are seeking\n            keyFileID = tsk_getu32(endian, keyB->file_id);\n\n            //fprintf(stdout, \" Key file ID = %lu\\n\", keyFileID);\n            if (keyFileID < fileID) {\n                comp = -1;\n                compStr = \"less than\";\n            }\n            else if (keyFileID > fileID) {\n                comp = 1;\n                compStr = \"greater than\";\n            }\n            else {\n                comp = 0;\n                compStr = \"equal to\";\n            }\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_load_extended_attrs: LEAF Record key file ID %\"\n                    PRIu32 \" is %s the desired file ID %\" PRIu32 \"\\n\",\n                    keyFileID, compStr, fileID);\n            // Are they the same?\n            if (comp == 0) {\n                // Yes, so load this attribute\n\n                uint8_t *recData;       // pointer to the data part of the recordBytes\n                hfs_attr_data *attrData;\n                uint32_t attributeLength;\n                uint32_t nameLength;\n                uint32_t recordType;\n                uint16_t keyLength;\n                int conversionResult;\n                char nameBuff[HFS_MAX_ATTR_NAME_LEN_UTF8_B+1];\n                TSK_FS_ATTR_TYPE_ENUM attrType;\n                TSK_FS_ATTR *fs_attr;   // Points to the attribute to be loaded.\n\n                keyLength = tsk_getu16(endian, keyB->key_len);\n                // make sure the fields we care about are still in the buffer\n                // +2 because key_len doesn't include its own length\n                // +16 for the amount of data we'll read from data\n                if (recOffset + keyLength + 2 + 16 > attrFile.nodeSize) {\n                    error_detected(TSK_ERR_FS_READ,\n                        \"hfs_load_extended_attrs: Unable to process attribute\");\n                    goto on_error;\n                }\n\n                recData = &recordBytes[keyLength + 2];\n\n                // Data must start on an even offset from the beginning of the record.\n                // So, correct this if needed.\n                if ((recData - recordBytes) % 2) {\n                    recData += 1;\n                }\n\n                attrData = (hfs_attr_data *) recData;\n\n                // Check we can process the record type before allocating memory\n                recordType = tsk_getu32(endian, attrData->record_type);\n                if (recordType != HFS_ATTR_RECORD_INLINE_DATA) {\n                  error_detected(TSK_ERR_FS_UNSUPTYPE,\n                      \"hfs_load_extended_attrs: Unsupported record type: (%d)\",\n                      recordType);\n                  goto on_error;\n                }\n\n                // This is the length of the useful data, not including the record header\n                attributeLength = tsk_getu32(endian, attrData->attr_size);\n\n                // Check the attribute fits in the node\n                //if (recordType != HFS_ATTR_RECORD_INLINE_DATA) {\n                if (recOffset + keyLength + 2 + attributeLength > attrFile.nodeSize) {\n                    error_detected(TSK_ERR_FS_READ,\n                        \"hfs_load_extended_attrs: Unable to process attribute\");\n                    goto on_error;\n                }\n\n                // attr_name_len is in UTF_16 chars\n                nameLength = tsk_getu16(endian, keyB->attr_name_len);\n                if (2*nameLength > HFS_MAX_ATTR_NAME_LEN_UTF16_B) {\n                    error_detected(TSK_ERR_FS_CORRUPT,\n                        \"hfs_load_extended_attrs: Name length (%d) is too long.\",\n                        nameLength);\n                    goto on_error;\n                }\n\n                buffer = tsk_malloc(attributeLength);\n                if (buffer == NULL) {\n                    error_detected(TSK_ERR_AUX_MALLOC,\n                        \"hfs_load_extended_attrs: Could not malloc space for the attribute.\");\n                    goto on_error;\n                }\n\n                memcpy(buffer, attrData->attr_data, attributeLength);\n\n                // Use the \"attr_name\" part of the key as the attribute name\n                // but must convert to UTF8.  Unfortunately, there does not seem to\n                // be any easy way to determine how long the converted string will\n                // be because UTF8 is a variable length encoding. However, the longest\n                // it will be is 3 * the max number of UTF16 code units.  Add one for null\n                // termination.   (thanks Judson!)\n                \n\n                conversionResult = hfs_UTF16toUTF8(fs, keyB->attr_name,\n                    nameLength, nameBuff, HFS_MAX_ATTR_NAME_LEN_UTF8_B+1, 0);\n                if (conversionResult != 0) {\n                    error_returned\n                        (\"-- hfs_load_extended_attrs could not convert the attr_name in the btree key into a UTF8 attribute name\");\n                    goto on_error;\n                }\n\n                // What is the type of this attribute?  If it is a compression record, then\n                // use TSK_FS_ATTR_TYPE_HFS_COMP_REC.  Else, use TSK_FS_ATTR_TYPE_HFS_EXT_ATTR\n                // Only \"inline data\" kind of record is handled.\n                if (strcmp(nameBuff, \"com.apple.decmpfs\") == 0 &&\n                    tsk_getu32(endian, attrData->record_type) == HFS_ATTR_RECORD_INLINE_DATA) {\n                    // Now, look at the compression record\n                    DECMPFS_DISK_HEADER *cmph = (DECMPFS_DISK_HEADER *) buffer;\n                    *cmpType =\n                        tsk_getu32(TSK_LIT_ENDIAN, cmph->compression_type);\n                    uint64_t uncSize = tsk_getu64(TSK_LIT_ENDIAN,\n                        cmph->uncompressed_size);\n\n                    if (tsk_verbose)\n                        tsk_fprintf(stderr,\n                            \"hfs_load_extended_attrs: This attribute is a compression record.\\n\");\n\n                    attrType = TSK_FS_ATTR_TYPE_HFS_COMP_REC;\n                    *isCompressed = TRUE;       // The data is governed by a compression record (but might not be compressed)\n                    *uncompressedSize = uncSize;\n\n                    switch (*cmpType) {\n                    // Data is inline. We will load the uncompressed\n                    // data as a resident attribute.\n                    case DECMPFS_TYPE_ZLIB_ATTR:\n                        if (!hfs_file_read_zlib_attr(\n                                fs_file, buffer, attributeLength, uncSize))\n                        {\n                            goto on_error;\n                        }\n                        break;\n\n                    case DECMPFS_TYPE_LZVN_ATTR:\n                        if (!hfs_file_read_lzvn_attr(\n                                fs_file, buffer, attributeLength, uncSize))\n                        {\n                            goto on_error;\n                        }\n                        break;\n\n                    // Data is compressed in the resource fork\n                    case DECMPFS_TYPE_ZLIB_RSRC:\n                    case DECMPFS_TYPE_LZVN_RSRC:\n                        if (tsk_verbose)\n                            tsk_fprintf(stderr,\n                                \"%s: Compressed data is in the file Resource Fork.\\n\", __func__);\n                        break;\n                    }\n                }\n                else {          // Attrbute name is NOT com.apple.decmpfs\n                    attrType = TSK_FS_ATTR_TYPE_HFS_EXT_ATTR;\n                }               // END if attribute name is com.apple.decmpfs  ELSE clause\n\n                if ((fs_attr =\n                        tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                            TSK_FS_ATTR_RES)) == NULL) {\n                    error_returned(\" - hfs_load_extended_attrs\");\n                    goto on_error;\n                }\n\n                if (tsk_verbose) {\n                    tsk_fprintf(stderr,\n                        \"hfs_load_extended_attrs: loading attribute %s, type %u (%s)\\n\",\n                        nameBuff, (uint32_t) attrType,\n                        hfs_attrTypeName((uint32_t) attrType));\n                }\n\n                // set the details in the fs_attr structure\n                if (tsk_fs_attr_set_str(fs_file, fs_attr, nameBuff,\n                        attrType, attribute_counter, buffer,\n                        attributeLength)) {\n                    error_returned(\" - hfs_load_extended_attrs\");\n                    goto on_error;\n                }\n\n                free(buffer);\n                buffer = NULL;\n\n                ++attribute_counter;\n            }                   // END if comp == 0\n            if (comp == 1) {\n                // since this record key is greater than our search key, all\n                // subsequent records will also be greater.\n                done = TRUE;\n                break;\n            }\n        }                       // END loop over records in one LEAF node\n\n        /*\n         * We get to this point if either:\n         *\n         * 1. We finish the loop over records and we are still loading attributes\n         *    for the given file.  In this case we are NOT done, and must read in\n         *    the next leaf node, and process its records.  The following code\n         *    loads the next leaf node before we return to the top of the loop.\n         *\n         * 2. We \"broke\" out of the loop over records because we found a key that\n         *    whose file ID is greater than the one we are working on.  In that case\n         *    we are done.  The following code does not run, and we exit the\n         *    while loop over successive leaf nodes.\n         */\n\n        if (!done) {\n            // We did not finish loading the attributes when we got to the end of that node,\n            // so we must get the next node, and continue.\n\n            // First determine the nodeID of the next LEAF node\n            uint32_t newNodeID = tsk_getu32(endian, nodeDescriptor->flink);\n\n            //fprintf(stdout, \"Next Node ID = %u\\n\",  newNodeID);\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_load_extended_attrs: Processed last record of THIS node, still gathering attributes.\\n\");\n\n            // If we are at the very last leaf node in the btree, then\n            // this \"flink\" will be zero.  We break out of this loop over LEAF nodes.\n            if (newNodeID == 0) {\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_load_extended_attrs: But, there are no more leaf nodes, so we are done.\\n\");\n                break;\n            }\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_load_extended_attrs: Reading the next LEAF node %\"\n                    PRIu32 \".\\n\", nodeID);\n\n            nodeID = newNodeID;\n\n            cnt = tsk_fs_file_read(attrFile.file,\n                nodeID * attrFile.nodeSize,\n                (char *) nodeData,\n                attrFile.nodeSize, (TSK_FS_FILE_READ_FLAG_ENUM) 0);\n            if (cnt != attrFile.nodeSize) {\n                error_returned\n                    (\"hfs_load_extended_attrs: Could not read in the next LEAF node from the Attributes File btree\");\n                goto on_error;\n            }\n\n            // Parse the Node header\n            nodeDescriptor = (hfs_btree_node *) nodeData;\n\n            // If we are NOT leaf node, then this is an error\n            if (nodeDescriptor->type != HFS_ATTR_NODE_LEAF) {\n                error_detected(TSK_ERR_FS_CORRUPT,\n                    \"hfs_load_extended_attrs: found a non-LEAF node as a successor to a LEAF node\");\n                goto on_error;\n            }\n        }                       // END if(! done)\n\n\n\n    }                           // END while(! done)  loop over successive LEAF nodes\n\non_exit:\n    free(nodeData);\n    tsk_list_free(nodeIDs_processed);\n    close_attr_file(&attrFile);\n    return 0;\n\non_error:\n    if (buffer != NULL) {\n        free(buffer);\n    }\n\n    if (nodeData != NULL) {\n        free(nodeData);\n    }\n\n    tsk_list_free(nodeIDs_processed);\n    close_attr_file(&attrFile);\n    return 1;\n}\n\ntypedef struct RES_DESCRIPTOR {\n    char type[5];               // type is really 4 chars, but we will null-terminate\n    uint16_t id;\n    uint32_t offset;\n    uint32_t length;\n    char *name;                 // NULL if a name is not defined for this resource\n    struct RES_DESCRIPTOR *next;\n} RES_DESCRIPTOR;\n\nvoid\nfree_res_descriptor(RES_DESCRIPTOR * rd)\n{\n    RES_DESCRIPTOR *nxt;\n\n    if (rd == NULL)\n        return;\n    nxt = rd->next;\n    if (rd->name != NULL)\n        free(rd->name);\n    free(rd);\n    free_res_descriptor(nxt);   // tail recursive\n}\n\n/**\n * The purpose of this function is to parse the resource fork of a file, and to return\n * a data structure that is, in effect, a table of contents for the resource fork.  The\n * data structure is a null-terminated linked list of entries.  Each one describes one\n * resource.  If the resource fork is empty, or if there is not a resource fork at all,\n * or an error occurs, this function returns NULL.\n *\n * A non-NULL answer should be freed by the caller, using free_res_descriptor.\n *\n */\n\nstatic RES_DESCRIPTOR *\nhfs_parse_resource_fork(TSK_FS_FILE * fs_file)\n{\n\n    RES_DESCRIPTOR *result = NULL;\n    RES_DESCRIPTOR *last = NULL;\n    TSK_FS_INFO *fs_info;\n    hfs_fork *fork_info;\n    hfs_fork *resForkInfo;\n    uint64_t resSize;\n    const TSK_FS_ATTR *rAttr;\n    hfs_resource_fork_header rfHeader;\n    hfs_resource_fork_header *resHead;\n    uint32_t dataOffset;\n    uint32_t mapOffset;\n    uint32_t mapLength;\n    char *map;\n    int attrReadResult;\n    int attrReadResult1;\n    int attrReadResult2;\n    hfs_resource_fork_map_header *mapHdr;\n    uint16_t typeListOffset;\n    uint16_t nameListOffset;\n    unsigned char hasNameList;\n    char *nameListBegin = NULL;\n    hfs_resource_type_list *typeList;\n    uint16_t numTypes;\n    hfs_resource_type_list_item *tlItem;\n    int mindx;                  // index for looping over resource types\n\n    if (fs_file == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_parse_resource_fork: null fs_file\");\n        return NULL;\n    }\n\n\n    if (fs_file->meta == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_parse_resource_fork: fs_file has null metadata\");\n        return NULL;\n    }\n\n    if (fs_file->meta->content_ptr == NULL) {\n        if (tsk_verbose)\n            fprintf(stderr,\n                \"hfs_parse_resource_fork: fs_file has null fork data structures, so no resources.\\n\");\n        return NULL;\n    }\n\n    // Extract the fs\n    fs_info = fs_file->fs_info;\n    if (fs_info == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_parse_resource_fork: null fs within fs_info\");\n        return NULL;\n    }\n\n    // Try to look at the Resource Fork for an HFS+ file\n    // Should be able to cast this to hfs_fork *\n    fork_info = (hfs_fork *) fs_file->meta->content_ptr;        // The data fork\n    // The resource fork is the second one.\n    resForkInfo = &fork_info[1];\n    resSize = tsk_getu64(fs_info->endian, resForkInfo->logic_sz);\n    //uint32_t numBlocks = tsk_getu32(fs_info->endian, resForkInfo->total_blk);\n    //uint32_t clmpSize = tsk_getu32(fs_info->endian, resForkInfo->clmp_sz);\n\n    // Hmm, certainly no resources here!\n    if (resSize == 0) {\n        return NULL;\n    }\n\n    // OK, resource size must be > 0\n\n    // find the attribute for the resource fork\n    rAttr =\n        tsk_fs_file_attr_get_type(fs_file, TSK_FS_ATTR_TYPE_HFS_RSRC,\n        HFS_FS_ATTR_ID_RSRC, TRUE);\n\n\n    if (rAttr == NULL) {\n        error_returned\n            (\"hfs_parse_resource_fork: could not get the resource fork attribute\");\n        return NULL;\n    }\n\n    // JUST read the resource fork header\n\n\n    attrReadResult1 =\n        tsk_fs_attr_read(rAttr, 0, (char *) &rfHeader,\n        sizeof(hfs_resource_fork_header), TSK_FS_FILE_READ_FLAG_NONE);\n\n    if (attrReadResult1 < 0\n        || attrReadResult1 != sizeof(hfs_resource_fork_header)) {\n        error_returned\n            (\" hfs_parse_resource_fork: trying to read the resource fork header\");\n        return NULL;\n    }\n\n    // Begin to parse the resource fork\n    resHead = &rfHeader;\n    dataOffset = tsk_getu32(fs_info->endian, resHead->dataOffset);\n    mapOffset = tsk_getu32(fs_info->endian, resHead->mapOffset);\n    //uint32_t dataLength = tsk_getu32(fs_info->endian, resHead->dataLength);\n    mapLength = tsk_getu32(fs_info->endian, resHead->mapLength);\n\n    // Read in the WHOLE map\n    map = (char *) tsk_malloc(mapLength);\n    if (map == NULL) {\n        error_returned\n            (\"- hfs_parse_resource_fork: could not allocate space for the resource fork map\");\n        return NULL;\n    }\n\n    attrReadResult =\n        tsk_fs_attr_read(rAttr, (uint64_t) mapOffset, map,\n        (size_t) mapLength, TSK_FS_FILE_READ_FLAG_NONE);\n\n    if (attrReadResult < 0 || attrReadResult != mapLength) {\n        error_returned\n            (\"- hfs_parse_resource_fork: could not read the map\");\n        free(map);\n        return NULL;\n    }\n\n    mapHdr = (hfs_resource_fork_map_header *) map;\n\n    typeListOffset = tsk_getu16(fs_info->endian, mapHdr->typeListOffset);\n\n    nameListOffset = tsk_getu16(fs_info->endian, mapHdr->nameListOffset);\n\n    if (nameListOffset >= mapLength || nameListOffset == 0) {\n        hasNameList = FALSE;\n    }\n    else {\n        hasNameList = TRUE;\n        nameListBegin = map + nameListOffset;\n    }\n\n    typeList = (hfs_resource_type_list *) (map + typeListOffset);\n    numTypes = tsk_getu16(fs_info->endian, typeList->typeCount) + 1;\n\n    for (mindx = 0; mindx < numTypes; ++mindx) {\n        uint16_t numRes;\n        uint16_t refOff;\n        int pindx;              // index for looping over resources\n        uint16_t rID;\n        uint32_t rOffset;\n\n        tlItem = &(typeList->type[mindx]);\n        numRes = tsk_getu16(fs_info->endian, tlItem->count) + 1;\n        refOff = tsk_getu16(fs_info->endian, tlItem->offset);\n\n\n        for (pindx = 0; pindx < numRes; ++pindx) {\n            int16_t nameOffset;\n            char *nameBuffer;\n            RES_DESCRIPTOR *rsrc;\n            char lenBuff[4];    // first 4 bytes of a resource encodes its length\n            uint32_t rLen;      // Resource length\n\n            hfs_resource_refListItem *item =\n                ((hfs_resource_refListItem *) (((uint8_t *) typeList) +\n                    refOff)) + pindx;\n            nameOffset = tsk_gets16(fs_info->endian, item->resNameOffset);\n            nameBuffer = NULL;\n\n            if (hasNameList && nameOffset != -1) {\n                char *name = nameListBegin + nameOffset;\n                uint8_t nameLen = (uint8_t) name[0];\n                nameBuffer = tsk_malloc(nameLen + 1);\n                if (nameBuffer == NULL) {\n                    error_returned\n                        (\"hfs_parse_resource_fork: allocating space for the name of a resource\");\n                    free_res_descriptor(result);\n                    return NULL;\n                }\n                memcpy(nameBuffer, name + 1, nameLen);\n                nameBuffer[nameLen] = (char) 0;\n            }\n            else {\n                nameBuffer = tsk_malloc(7);\n                if (nameBuffer == NULL) {\n                    error_returned\n                        (\"hfs_parse_resource_fork: allocating space for the (null) name of a resource\");\n                    free_res_descriptor(result);\n                    return NULL;\n                }\n                memcpy(nameBuffer, \"<none>\", 6);\n                nameBuffer[6] = (char) 0;\n            }\n\n            rsrc = (RES_DESCRIPTOR *) tsk_malloc(sizeof(RES_DESCRIPTOR));\n            if (rsrc == NULL) {\n                error_returned\n                    (\"hfs_parse_resource_fork: space for a resource descriptor\");\n                free_res_descriptor(result);\n                return NULL;\n            }\n\n            // Build the linked list\n            if (result == NULL)\n                result = rsrc;\n            if (last != NULL)\n                last->next = rsrc;\n            last = rsrc;\n            rsrc->next = NULL;\n\n            rID = tsk_getu16(fs_info->endian, item->resID);\n            rOffset =\n                tsk_getu24(fs_info->endian,\n                item->resDataOffset) + dataOffset;\n\n            // Just read the first four bytes of the resource to get its length.  It MUST\n            // be at least 4 bytes long\n            attrReadResult2 = tsk_fs_attr_read(rAttr, (uint64_t) rOffset,\n                lenBuff, (size_t) 4, TSK_FS_FILE_READ_FLAG_NONE);\n\n            if (attrReadResult2 != 4) {\n                error_returned\n                    (\"- hfs_parse_resource_fork: could not read the 4-byte length at beginning of resource\");\n                free_res_descriptor(result);\n                return NULL;\n            }\n            rLen = tsk_getu32(TSK_BIG_ENDIAN, lenBuff); //TODO\n\n            rsrc->id = rID;\n            rsrc->offset = rOffset + 4;\n            memcpy(rsrc->type, tlItem->type, 4);\n            rsrc->type[4] = (char) 0;\n            rsrc->length = rLen;\n            rsrc->name = nameBuffer;\n\n        }                       // END loop over resources of one type\n\n    }                           // END loop over resource types\n\n    return result;\n}\n\n\nstatic uint8_t\nhfs_load_attrs(TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs;\n    HFS_INFO *hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n    hfs_fork *forkx;\n    unsigned char resource_fork_has_contents = FALSE;\n    unsigned char compression_flag = FALSE;\n    unsigned char isCompressed = FALSE;\n    unsigned char compDataInRSRCFork = FALSE;\n    unsigned char cmpType = 0;\n    uint64_t uncompressedSize;\n    uint64_t logicalSize;       // of a fork\n\n    // clean up any error messages that are lying around\n    tsk_error_reset();\n\n    if ((fs_file == NULL) || (fs_file->meta == NULL)\n        || (fs_file->fs_info == NULL)) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_load_attrs: fs_file or meta is NULL\");\n        return 1;\n    }\n\n    fs = (TSK_FS_INFO *) fs_file->fs_info;\n    hfs = (HFS_INFO *) fs;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_load_attrs: Processing file %\" PRIuINUM \"\\n\",\n            fs_file->meta->addr);\n\n\n    // see if we have already loaded the runs\n    if (fs_file->meta->attr_state == TSK_FS_META_ATTR_STUDIED) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_attrs: Attributes already loaded\\n\");\n        return 0;\n    }\n    else if (fs_file->meta->attr_state == TSK_FS_META_ATTR_ERROR) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_attrs: Previous attempt to load attributes resulted in error\\n\");\n        return 1;\n    }\n\n    // Now (re)-initialize the attrlist that will hold the list of attributes\n    if (fs_file->meta->attr != NULL) {\n        tsk_fs_attrlist_markunused(fs_file->meta->attr);\n    }\n    else if (fs_file->meta->attr == NULL) {\n        fs_file->meta->attr = tsk_fs_attrlist_alloc();\n    }\n\n    /****************** EXTENDED ATTRIBUTES *******************************/\n    // We do these first, so that we can detect the mode of compression, if\n    // any.  We need to know that mode in order to handle the forks.\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_load_attrs: loading the HFS+ extended attributes\\n\");\n\n    if (hfs_load_extended_attrs(fs_file, &isCompressed,\n            &cmpType, &uncompressedSize)) {\n        error_returned(\" - hfs_load_attrs A\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n// TODO: What about DECMPFS_TYPE_RAW_RSRC?\n    switch (cmpType) {\n    case DECMPFS_TYPE_ZLIB_RSRC:\n    case DECMPFS_TYPE_LZVN_RSRC:\n        compDataInRSRCFork = TRUE;\n        break;\n    default:\n        compDataInRSRCFork = FALSE;\n        break;\n    }\n\n    if (isCompressed) {\n        fs_file->meta->size = uncompressedSize;\n    }\n\n    // This is the flag indicating compression, from the Catalog File record.\n    compression_flag = (fs_file->meta->flags & TSK_FS_META_FLAG_COMP) != 0;\n\n    if (compression_flag && !isCompressed) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_attrs: WARNING, HFS marks this as a\"\n                \" compressed file, but no compression record was found.\\n\");\n    }\n    if (isCompressed && !compression_flag) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_attrs: WARNING, this file has a compression\"\n                \" record, but the HFS compression flag is not set.\\n\");\n    }\n\n    /************* FORKS (both) ************************************/\n\n    // Process the data and resource forks.  We only do this if the\n    // fork data structures are non-null, so test that:\n    if (fs_file->meta->content_ptr != NULL) {\n\n        /**************  DATA FORK STUFF ***************************/\n\n        // Get the data fork data-structure\n        forkx = (hfs_fork *) fs_file->meta->content_ptr;\n\n        // If this is a compressed file, then either this attribute is already loaded\n        // because the data was in the compression record, OR\n        // the compressed data is in the resource fork.  We will load those runs when\n        // we handle the resource fork.\n        if (!isCompressed) {\n            // We only load this attribute if this fork has non-zero length\n            // or if this is a REG or LNK file.  Otherwise, we skip\n            logicalSize = tsk_getu64(fs->endian, forkx->logic_sz);\n\n            if (logicalSize > 0 ||\n                fs_file->meta->type == TSK_FS_META_TYPE_REG ||\n                fs_file->meta->type == TSK_FS_META_TYPE_LNK) {\n\n\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_load_attrs: loading the data fork attribute\\n\");\n\n                // get an attribute structure to store the data in\n                if ((fs_attr = tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                            TSK_FS_ATTR_NONRES)) == NULL) {\n                    error_returned(\" - hfs_load_attrs\");\n                    return 1;\n                }\n                /* NOTE that fs_attr is now tied to fs_file->meta->attr.\n                 * that means that we do not need to free it if we abort in the\n                 * following code (and doing so will cause double free errors). */\n\n                if (logicalSize > 0) {\n\n                    // Convert runs of blocks to the TSK internal form\n                    if (((attr_run =\n                                hfs_extents_to_attr(fs, forkx->extents,\n                                    0)) == NULL)\n                        && (tsk_error_get_errno() != 0)) {\n                        error_returned(\" - hfs_load_attrs\");\n                        return 1;\n                    }\n\n\n\n                    // add the runs to the attribute and the attribute to the file.\n                    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run,\n                            \"\", TSK_FS_ATTR_TYPE_HFS_DATA,\n                            HFS_FS_ATTR_ID_DATA, logicalSize, logicalSize,\n                            (TSK_OFF_T) tsk_getu32(fs->endian,\n                                forkx->total_blk) * fs->block_size, 0,\n                            0)) {\n                        error_returned(\" - hfs_load_attrs (DATA)\");\n                        tsk_fs_attr_run_free(attr_run);\n                        return 1;\n                    }\n\n                    // see if extents file has additional runs\n                    if (hfs_ext_find_extent_record_attr(hfs,\n                            (uint32_t) fs_file->meta->addr, fs_attr,\n                            TRUE)) {\n                        error_returned(\" - hfs_load_attrs B\");\n                        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n                        return 1;\n                    }\n\n                }\n                else {\n                    // logicalSize == 0, but this is either a REG or LNK file\n                    // so, it should have a DATA fork attribute of zero length.\n                    if (tsk_fs_attr_set_run(fs_file, fs_attr, NULL, \"\",\n                            TSK_FS_ATTR_TYPE_HFS_DATA, HFS_FS_ATTR_ID_DATA,\n                            0, 0, 0, 0, 0)) {\n                        error_returned(\" - hfs_load_attrs (non-file)\");\n                        return 1;\n                    }\n                }\n\n            }                   // END  logicalSize>0 or REG or LNK file type\n        }                       // END if not Compressed\n\n\n\n        /**************  RESOURCE FORK STUFF ************************************/\n\n        // Get the resource fork.\n        //Note that content_ptr points to an array of two\n        // hfs_fork data structures, the second of which\n        // describes the blocks of the resource fork.\n\n        forkx = &((hfs_fork *) fs_file->meta->content_ptr)[1];\n\n        logicalSize = tsk_getu64(fs->endian, forkx->logic_sz);\n\n        // Skip if the length of the resource fork is zero\n        if (logicalSize > 0) {\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_load_attrs: loading the resource fork\\n\");\n\n            resource_fork_has_contents = TRUE;\n\n            // get an attribute structure to store the resource fork data in.  We will\n            // reuse the fs_attr variable, since we are done with the data fork.\n            if ((fs_attr =\n                    tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                        TSK_FS_ATTR_NONRES)) == NULL) {\n                error_returned(\" - hfs_load_attrs (RSRC)\");\n                return 1;\n            }\n            /* NOTE that fs_attr is now tied to fs_file->meta->attr.\n             * that means that we do not need to free it if we abort in the\n             * following code (and doing so will cause double free errors). */\n\n\n            // convert the resource fork to the TSK format\n            if (((attr_run =\n                        hfs_extents_to_attr(fs, forkx->extents,\n                            0)) == NULL)\n                && (tsk_error_get_errno() != 0)) {\n                error_returned(\" - hfs_load_attrs\");\n                return 1;\n            }\n\n            // add the runs to the attribute and the attribute to the file.\n            if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, \"RSRC\",\n                    TSK_FS_ATTR_TYPE_HFS_RSRC, HFS_FS_ATTR_ID_RSRC,\n                    tsk_getu64(fs->endian, forkx->logic_sz),\n                    tsk_getu64(fs->endian, forkx->logic_sz),\n                    (TSK_OFF_T) tsk_getu32(fs->endian,\n                        forkx->total_blk) * fs->block_size, 0, 0)) {\n                error_returned(\" - hfs_load_attrs (RSRC)\");\n                tsk_fs_attr_run_free(attr_run);\n                return 1;\n            }\n\n            // see if extents file has additional runs for the resource fork.\n            if (hfs_ext_find_extent_record_attr(hfs,\n                    (uint32_t) fs_file->meta->addr, fs_attr, FALSE)) {\n                error_returned(\" - hfs_load_attrs C\");\n                fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n                return 1;\n            }\n\n            if (isCompressed && compDataInRSRCFork) {\n                // OK, we are going to load those same resource fork blocks as the \"DATA\"\n                // attribute, but will mark it as compressed.\n                // get an attribute structure to store the resource fork data in.  We will\n                // reuse the fs_attr variable, since we are done with the data fork.\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"File is compressed with data in the resource fork. \"\n                        \"Loading the default DATA attribute.\\n\");\n                if ((fs_attr =\n                        tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                            TSK_FS_ATTR_NONRES)) == NULL) {\n                    error_returned\n                        (\" - hfs_load_attrs (RSRC loading as DATA)\");\n                    return 1;\n                }\n                /* NOTE that fs_attr is now tied to fs_file->meta->attr.\n                 * that means that we do not need to free it if we abort in the\n                 * following code (and doing so will cause double free errors). */\n\n                switch (cmpType) {\n                case DECMPFS_TYPE_ZLIB_RSRC:\n#ifdef HAVE_LIBZ\n                    fs_attr->w = hfs_attr_walk_zlib_rsrc;\n                    fs_attr->r = hfs_file_read_zlib_rsrc;\n#else\n                    // We don't have zlib, so the uncompressed data is not\n                    // available to us; however, we must have a default DATA\n                    // attribute, or icat will misbehave.\n                    if (tsk_verbose)\n                        tsk_fprintf(stderr,\n                            \"hfs_load_attrs: No zlib compression library, so setting a zero-length default DATA attribute.\\n\");\n\n                    if (tsk_fs_attr_set_run(fs_file, fs_attr, NULL, \"DATA\",\n                            TSK_FS_ATTR_TYPE_HFS_DATA, HFS_FS_ATTR_ID_DATA, 0,\n                            0, 0, 0, 0)) {\n                        error_returned(\" - hfs_load_attrs (non-file)\");\n                        return 1;\n                    }\n#endif\n                    break;\n\n                case DECMPFS_TYPE_LZVN_RSRC:\n\n                    fs_attr->w = hfs_attr_walk_lzvn_rsrc;\n                    fs_attr->r = hfs_file_read_lzvn_rsrc;\n\n                    break;\n                }\n\n                // convert the resource fork to the TSK format\n                if (((attr_run =\n                            hfs_extents_to_attr(fs, forkx->extents,\n                                0)) == NULL)\n                    && (tsk_error_get_errno() != 0)) {\n                    error_returned\n                        (\" - hfs_load_attrs, RSRC fork as DATA fork\");\n                    return 1;\n                }\n\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_load_attrs:  Loading RSRC fork block runs as the default DATA attribute.\\n\");\n\n                // add the runs to the attribute and the attribute to the file.\n                if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, \"DECOMP\",\n                        TSK_FS_ATTR_TYPE_HFS_DATA, HFS_FS_ATTR_ID_DATA,\n                        logicalSize,\n                        logicalSize,\n                        (TSK_OFF_T) tsk_getu32(fs->endian,\n                            forkx->total_blk) * fs->block_size,\n                        TSK_FS_ATTR_COMP | TSK_FS_ATTR_NONRES, 0)) {\n                    error_returned\n                        (\" - hfs_load_attrs (RSRC loading as DATA)\");\n                    tsk_fs_attr_run_free(attr_run);\n                    return 1;\n                }\n\n                // see if extents file has additional runs for the resource fork.\n                if (hfs_ext_find_extent_record_attr(hfs,\n                        (uint32_t) fs_file->meta->addr, fs_attr, FALSE)) {\n                    error_returned\n                        (\" - hfs_load_attrs (RSRC loading as DATA\");\n                    fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n                    return 1;\n                }\n\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_load_attrs: setting the \\\"special\\\" function pointers to inflate compressed data.\\n\");\n            }\n\n        }                       // END resource fork size > 0\n\n    }                           // END the fork data structures are non-NULL\n\n    if (isCompressed && compDataInRSRCFork && !resource_fork_has_contents) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_attrs: WARNING, compression record claims that compressed data\"\n                \" is in the Resource Fork, but that fork is empty or non-existent.\\n\");\n    }\n\n    // Finish up.\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n\n    return 0;\n}\n\n\n/** \\internal\n* Get allocation status of file system block.\n* adapted from IsAllocationBlockUsed from:\n* http://developer.apple.com/technotes/tn/tn1150.html\n*\n* @param hfs File system being analyzed\n* @param b Block address\n* @returns 1 if allocated, 0 if not, -1 on error\n*/\nstatic int8_t\nhfs_block_is_alloc(HFS_INFO * hfs, TSK_DADDR_T a_addr)\n{\n    TSK_FS_INFO *fs = &(hfs->fs_info);\n    TSK_OFF_T b;\n    size_t b2;\n\n    // lazy loading\n    if (hfs->blockmap_file == NULL) {\n        if ((hfs->blockmap_file =\n                tsk_fs_file_open_meta(fs, NULL,\n                    HFS_ALLOCATION_FILE_ID)) == NULL) {\n            tsk_error_errstr2_concat(\" - Loading blockmap file\");\n            return -1;\n        }\n\n        /* cache the data attribute */\n        hfs->blockmap_attr =\n            tsk_fs_attrlist_get(hfs->blockmap_file->meta->attr,\n            TSK_FS_ATTR_TYPE_DEFAULT);\n        if (!hfs->blockmap_attr) {\n            tsk_error_errstr2_concat\n                (\" - Data Attribute not found in Blockmap File\");\n            return -1;\n        }\n        hfs->blockmap_cache_start = -1;\n        hfs->blockmap_cache_len = 0;\n    }\n\n    // get the byte offset\n    b = (TSK_OFF_T) a_addr / 8;\n    if (b > hfs->blockmap_file->meta->size) {\n        tsk_error_set_errno(TSK_ERR_FS_CORRUPT);\n        tsk_error_set_errstr(\"hfs_block_is_alloc: block %\" PRIuDADDR\n            \" is too large for bitmap (%\" PRIuOFF \")\", a_addr,\n            hfs->blockmap_file->meta->size);\n        return -1;\n    }\n\n    // see if it is in the cache\n    if ((hfs->blockmap_cache_start == -1)\n        || (hfs->blockmap_cache_start > b)\n        || (hfs->blockmap_cache_start + hfs->blockmap_cache_len <= b)) {\n        size_t cnt = tsk_fs_attr_read(hfs->blockmap_attr, b,\n            hfs->blockmap_cache,\n            sizeof(hfs->blockmap_cache), 0);\n        if (cnt < 1) {\n            tsk_error_set_errstr2\n                (\"hfs_block_is_alloc: Error reading block bitmap at offset %\"\n                PRIuOFF, b);\n            return -1;\n        }\n        hfs->blockmap_cache_start = b;\n        hfs->blockmap_cache_len = cnt;\n    }\n    b2 = (size_t) (b - hfs->blockmap_cache_start);\n    return (hfs->blockmap_cache[b2] & (1 << (7 - (a_addr % 8)))) != 0;\n}\n\n\nTSK_FS_BLOCK_FLAG_ENUM\nhfs_block_getflags(TSK_FS_INFO * a_fs, TSK_DADDR_T a_addr)\n{\n    return (hfs_block_is_alloc((HFS_INFO *) a_fs, a_addr) == 1) ?\n        TSK_FS_BLOCK_FLAG_ALLOC : TSK_FS_BLOCK_FLAG_UNALLOC;\n}\n\n\nstatic uint8_t\nhfs_block_walk(TSK_FS_INFO * fs, TSK_DADDR_T start_blk,\n    TSK_DADDR_T end_blk, TSK_FS_BLOCK_WALK_FLAG_ENUM flags,\n    TSK_FS_BLOCK_WALK_CB action, void *ptr)\n{\n    char *myname = \"hfs_block_walk\";\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    TSK_FS_BLOCK *fs_block;\n    TSK_DADDR_T addr;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: start_blk: %\" PRIuDADDR \" end_blk: %\"\n            PRIuDADDR \" flags: %\" PRIu32 \"\\n\", myname, start_blk, end_blk,\n            flags);\n\n    // clean up any error messages that are lying around\n    tsk_error_reset();\n\n    /*\n     * Sanity checks.\n     */\n    if (start_blk < fs->first_block || start_blk > fs->last_block) {\n        tsk_error_set_errno(TSK_ERR_FS_WALK_RNG);\n        tsk_error_set_errstr(\"%s: invalid start block number: %\" PRIuDADDR\n            \"\", myname, start_blk);\n        return 1;\n    }\n    if (end_blk < fs->first_block || end_blk > fs->last_block) {\n        tsk_error_set_errno(TSK_ERR_FS_WALK_RNG);\n        tsk_error_set_errstr(\"%s: invalid last block number: %\" PRIuDADDR\n            \"\", myname, end_blk);\n        return 1;\n    }\n\n    if (start_blk > end_blk)\n        XSWAP(start_blk, end_blk);\n\n    /* Sanity check on flags -- make sure at least one ALLOC is set */\n    if (((flags & TSK_FS_BLOCK_WALK_FLAG_ALLOC) == 0) &&\n        ((flags & TSK_FS_BLOCK_WALK_FLAG_UNALLOC) == 0)) {\n        flags |=\n            (TSK_FS_BLOCK_WALK_FLAG_ALLOC |\n            TSK_FS_BLOCK_WALK_FLAG_UNALLOC);\n    }\n    if (((flags & TSK_FS_BLOCK_WALK_FLAG_META) == 0) &&\n        ((flags & TSK_FS_BLOCK_WALK_FLAG_CONT) == 0)) {\n        flags |=\n            (TSK_FS_BLOCK_WALK_FLAG_CONT | TSK_FS_BLOCK_WALK_FLAG_META);\n    }\n\n    if ((fs_block = tsk_fs_block_alloc(fs)) == NULL) {\n        return 1;\n    }\n\n    /*\n     * Iterate\n     */\n    for (addr = start_blk; addr <= end_blk; ++addr) {\n        int retval;\n        int myflags;\n\n        /* identify if the block is allocated or not */\n        myflags = hfs_block_is_alloc(hfs, addr) ?\n            TSK_FS_BLOCK_FLAG_ALLOC : TSK_FS_BLOCK_FLAG_UNALLOC;\n\n        // test if we should call the callback with this one\n        if ((myflags & TSK_FS_BLOCK_FLAG_ALLOC)\n            && (!(flags & TSK_FS_BLOCK_WALK_FLAG_ALLOC)))\n            continue;\n        else if ((myflags & TSK_FS_BLOCK_FLAG_UNALLOC)\n            && (!(flags & TSK_FS_BLOCK_WALK_FLAG_UNALLOC)))\n            continue;\n\n        if (flags & TSK_FS_BLOCK_WALK_FLAG_AONLY)\n            myflags |= TSK_FS_BLOCK_FLAG_AONLY;\n\n        if (tsk_fs_block_get_flag(fs, fs_block, addr,\n                (TSK_FS_BLOCK_FLAG_ENUM) myflags) == NULL) {\n            tsk_fs_block_free(fs_block);\n            return 1;\n        }\n\n        retval = action(fs_block, ptr);\n        if (TSK_WALK_STOP == retval) {\n            break;\n        }\n        else if (TSK_WALK_ERROR == retval) {\n            tsk_fs_block_free(fs_block);\n            return 1;\n        }\n    }\n\n    tsk_fs_block_free(fs_block);\n    return 0;\n}\n\n\nuint8_t\nhfs_inode_walk(TSK_FS_INFO * fs, TSK_INUM_T start_inum,\n    TSK_INUM_T end_inum, TSK_FS_META_FLAG_ENUM flags,\n    TSK_FS_META_WALK_CB action, void *ptr)\n{\n    TSK_INUM_T inum;\n    TSK_FS_FILE *fs_file;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_inode_walk: start_inum: %\" PRIuINUM \" end_inum: %\"\n            PRIuINUM \" flags: %\" PRIu32 \"\\n\", start_inum, end_inum, flags);\n\n    /*\n     * Sanity checks.\n     */\n    if (start_inum < fs->first_inum || start_inum > fs->last_inum) {\n        tsk_error_reset();\n        tsk_error_set_errno(TSK_ERR_FS_WALK_RNG);\n        tsk_error_set_errstr(\"inode_walk: Start inode: %\" PRIuINUM \"\",\n            start_inum);\n        return 1;\n    }\n    else if (end_inum < fs->first_inum || end_inum > fs->last_inum\n        || end_inum < start_inum) {\n        tsk_error_reset();\n        tsk_error_set_errno(TSK_ERR_FS_WALK_RNG);\n        tsk_error_set_errstr(\"inode_walk: End inode: %\" PRIuINUM \"\",\n            end_inum);\n        return 1;\n    }\n\n    /* If ORPHAN is wanted, then make sure that the flags are correct */\n    if (flags & TSK_FS_META_FLAG_ORPHAN) {\n        flags |= TSK_FS_META_FLAG_UNALLOC;\n        flags &= ~TSK_FS_META_FLAG_ALLOC;\n        flags |= TSK_FS_META_FLAG_USED;\n        flags &= ~TSK_FS_META_FLAG_UNUSED;\n    }\n\n    else {\n        if (((flags & TSK_FS_META_FLAG_ALLOC) == 0) &&\n            ((flags & TSK_FS_META_FLAG_UNALLOC) == 0)) {\n            flags |= (TSK_FS_META_FLAG_ALLOC | TSK_FS_META_FLAG_UNALLOC);\n        }\n\n        /* If neither of the USED or UNUSED flags are set, then set them\n         * both\n         */\n        if (((flags & TSK_FS_META_FLAG_USED) == 0) &&\n            ((flags & TSK_FS_META_FLAG_UNUSED) == 0)) {\n            flags |= (TSK_FS_META_FLAG_USED | TSK_FS_META_FLAG_UNUSED);\n        }\n    }\n\n    if ((fs_file = tsk_fs_file_alloc(fs)) == NULL)\n        return 1;\n\n    if ((fs_file->meta = tsk_fs_meta_alloc(HFS_FILE_CONTENT_LEN)) == NULL)\n        return 1;\n\n    if (start_inum > end_inum)\n        XSWAP(start_inum, end_inum);\n\n    for (inum = start_inum; inum <= end_inum; ++inum) {\n        int retval;\n\n        if (hfs_inode_lookup(fs, fs_file, inum)) {\n            // deleted files may not exist in the catalog\n            if (tsk_error_get_errno() == TSK_ERR_FS_INODE_NUM) {\n                tsk_error_reset();\n                continue;\n            }\n            else {\n                return 1;\n            }\n        }\n\n        if ((fs_file->meta->flags & flags) != fs_file->meta->flags)\n            continue;\n\n        /* call action */\n        retval = action(fs_file, ptr);\n        if (retval == TSK_WALK_STOP) {\n            tsk_fs_file_close(fs_file);\n            return 0;\n        }\n        else if (retval == TSK_WALK_ERROR) {\n            tsk_fs_file_close(fs_file);\n            return 1;\n        }\n    }\n\n    tsk_fs_file_close(fs_file);\n    return 0;\n}\n\n/* return the name of a file at a given inode\n * in a newly-allocated string, or NULL on error\n */\nchar *\nhfs_get_inode_name(TSK_FS_INFO * fs, TSK_INUM_T inum)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    HFS_ENTRY entry;\n    char *fn = NULL;\n\n    if (hfs_cat_file_lookup(hfs, inum, &entry, FALSE))\n        return NULL;\n\n    fn = malloc(HFS_MAXNAMLEN + 1);\n    if (fn == NULL)\n        return NULL;\n\n    if (hfs_UTF16toUTF8(fs, entry.thread.name.unicode,\n            tsk_getu16(fs->endian, entry.thread.name.length), fn,\n            HFS_MAXNAMLEN + 1, HFS_U16U8_FLAG_REPLACE_SLASH)) {\n        free(fn);\n        return NULL;\n    }\n\n    return fn;\n}\n\n/* print the name of a file at a given inode\n * returns 0 on success, 1 on error */\nstatic uint8_t\nprint_inode_name(FILE * hFile, TSK_FS_INFO * fs, TSK_INUM_T inum)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    char fn[HFS_MAXNAMLEN + 1];\n    HFS_ENTRY entry;\n\n    if (hfs_cat_file_lookup(hfs, inum, &entry, FALSE))\n        return 1;\n\n    if (hfs_UTF16toUTF8(fs, entry.thread.name.unicode,\n            tsk_getu16(fs->endian, entry.thread.name.length), fn,\n            HFS_MAXNAMLEN + 1, HFS_U16U8_FLAG_REPLACE_SLASH))\n        return 1;\n\n    tsk_fprintf(hFile, \"%s\", fn);\n\n    return 0;\n}\n\n/* tail recursive function to print a path... prints the parent path, then\n * appends / and the name of the given inode. prints nothing for root\n * returns 0 on success, 1 on failure\n */\nstatic uint8_t\nprint_parent_path(FILE * hFile, TSK_FS_INFO * fs, TSK_INUM_T inum)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    char fn[HFS_MAXNAMLEN + 1];\n    HFS_ENTRY entry;\n\n    if (inum == HFS_ROOT_INUM)\n        return 0;\n\n    if (inum <= HFS_ROOT_INUM) {\n        tsk_error_set_errno(TSK_ERR_FS_INODE_NUM);\n        tsk_error_set_errstr(\"print_parent_path: out-of-range inode %\"\n            PRIuINUM, inum);\n        return 1;\n    }\n\n    if (hfs_cat_file_lookup(hfs, inum, &entry, FALSE))\n        return 1;\n\n    if (hfs_UTF16toUTF8(fs, entry.thread.name.unicode,\n            tsk_getu16(fs->endian, entry.thread.name.length), fn,\n            HFS_MAXNAMLEN + 1,\n            HFS_U16U8_FLAG_REPLACE_SLASH | HFS_U16U8_FLAG_REPLACE_CONTROL))\n        return 1;\n\n    if (print_parent_path(hFile, fs, (TSK_INUM_T) tsk_getu32(fs->endian,\n                entry.thread.parent_cnid)))\n        return 1;\n\n    tsk_fprintf(hFile, \"/%s\", fn);\n    return 0;\n}\n\n/* print the file name corresponding to an inode, in brackets after a space.\n * uses Unix path conventions, and does not include the volume name.\n * returns 0 on success, 1 on failure\n */\nstatic uint8_t\nprint_inode_file(FILE * hFile, TSK_FS_INFO * fs, TSK_INUM_T inum)\n{\n    tsk_fprintf(hFile, \" [\");\n    if (inum == HFS_ROOT_INUM)\n        tsk_fprintf(hFile, \"/\");\n    else {\n        if (print_parent_path(hFile, fs, inum)) {\n            tsk_fprintf(hFile, \"unknown]\");\n            return 1;\n        }\n    }\n    tsk_fprintf(hFile, \"]\");\n    return 0;\n}\n\nstatic uint8_t\nhfs_fscheck(TSK_FS_INFO * fs, FILE * hFile)\n{\n    tsk_error_reset();\n    tsk_error_set_errno(TSK_ERR_FS_UNSUPFUNC);\n    tsk_error_set_errstr(\"fscheck not implemented for HFS yet\");\n    return 1;\n}\n\n\nstatic uint8_t\nhfs_fsstat(TSK_FS_INFO * fs, FILE * hFile)\n{\n    // char *myname = \"hfs_fsstat\";\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    hfs_plus_vh *sb = hfs->fs;\n    time_t mac_time;\n    TSK_INUM_T inode;\n    char timeBuf[128];\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_fstat: called\\n\");\n\n    tsk_fprintf(hFile, \"FILE SYSTEM INFORMATION\\n\");\n    tsk_fprintf(hFile, \"--------------------------------------------\\n\");\n\n    tsk_fprintf(hFile, \"File System Type: \");\n    if (tsk_getu16(fs->endian, hfs->fs->signature) == HFS_VH_SIG_HFSPLUS)\n        tsk_fprintf(hFile, \"HFS+\\n\");\n    else if (tsk_getu16(fs->endian, hfs->fs->signature) == HFS_VH_SIG_HFSX)\n        tsk_fprintf(hFile, \"HFSX\\n\");\n    else\n        tsk_fprintf(hFile, \"Unknown\\n\");\n\n    // print name and number of version\n    tsk_fprintf(hFile, \"File System Version: \");\n    switch (tsk_getu16(fs->endian, hfs->fs->version)) {\n    case 4:\n        tsk_fprintf(hFile, \"HFS+\\n\");\n        break;\n    case 5:\n        tsk_fprintf(hFile, \"HFSX\\n\");\n        break;\n    default:\n        tsk_fprintf(hFile, \"Unknown (%\" PRIu16 \")\\n\",\n            tsk_getu16(fs->endian, hfs->fs->version));\n        break;\n    }\n\n    if (tsk_getu16(fs->endian, hfs->fs->signature) == HFS_VH_SIG_HFSX) {\n        tsk_fprintf(hFile, \"Case Sensitive: %s\\n\",\n            hfs->is_case_sensitive ? \"yes\" : \"no\");\n    }\n\n    if (hfs->hfs_wrapper_offset > 0) {\n        tsk_fprintf(hFile,\n            \"File system is embedded in an HFS wrapper at offset %\" PRIuOFF\n            \"\\n\", hfs->hfs_wrapper_offset);\n    }\n\n    tsk_fprintf(hFile, \"\\nVolume Name: \");\n    if (print_inode_name(hFile, fs, HFS_ROOT_INUM))\n        return 1;\n    tsk_fprintf(hFile, \"\\n\");\n\n    tsk_fprintf(hFile, \"Volume Identifier: %08\" PRIx32 \"%08\" PRIx32 \"\\n\",\n        tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_ID1]),\n        tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_ID2]));\n\n\n    // print last mounted info\n    tsk_fprintf(hFile, \"\\nLast Mounted By: \");\n    if (tsk_getu32(fs->endian, sb->last_mnt_ver) == HFS_VH_MVER_HFSPLUS)\n        tsk_fprintf(hFile, \"Mac OS X\\n\");\n    else if (tsk_getu32(fs->endian, sb->last_mnt_ver) == HFS_VH_MVER_HFSJ)\n        tsk_fprintf(hFile, \"Mac OS X, Journaled\\n\");\n    else if (tsk_getu32(fs->endian, sb->last_mnt_ver) == HFS_VH_MVER_FSK)\n        tsk_fprintf(hFile, \"failed journal replay\\n\");\n    else if (tsk_getu32(fs->endian, sb->last_mnt_ver) == HFS_VH_MVER_FSCK)\n        tsk_fprintf(hFile, \"fsck_hfs\\n\");\n    else if (tsk_getu32(fs->endian, sb->last_mnt_ver) == HFS_VH_MVER_OS89)\n        tsk_fprintf(hFile, \"Mac OS 8.1 - 9.2.2\\n\");\n    else\n        tsk_fprintf(hFile, \"Unknown (%\" PRIx32 \"\\n\",\n            tsk_getu32(fs->endian, sb->last_mnt_ver));\n\n    /* State of the file system */\n    if ((tsk_getu32(fs->endian, hfs->fs->attr) & HFS_VH_ATTR_UNMOUNTED)\n        && (!(tsk_getu32(fs->endian,\n                    hfs->fs->attr) & HFS_VH_ATTR_INCONSISTENT)))\n        tsk_fprintf(hFile, \"Volume Unmounted Properly\\n\");\n    else\n        tsk_fprintf(hFile, \"Volume Unmounted Improperly\\n\");\n\n    tsk_fprintf(hFile, \"Mount Count: %\" PRIu32 \"\\n\",\n        tsk_getu32(fs->endian, sb->write_cnt));\n\n\n    // Dates\n    // (creation date is in local time zone, not UTC, according to TN 1150)\n    mac_time =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, hfs->fs->cr_date));\n    tsk_fprintf(hFile, \"\\nCreation Date: \\t%s\\n\",\n        tsk_fs_time_to_str(mktime(gmtime(&mac_time)), timeBuf));\n\n    mac_time =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, hfs->fs->m_date));\n    tsk_fprintf(hFile, \"Last Written Date: \\t%s\\n\",\n        tsk_fs_time_to_str(mac_time, timeBuf));\n\n    mac_time =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian,\n            hfs->fs->bkup_date));\n    tsk_fprintf(hFile, \"Last Backup Date: \\t%s\\n\",\n        tsk_fs_time_to_str(mac_time, timeBuf));\n\n    mac_time =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, hfs->fs->chk_date));\n    tsk_fprintf(hFile, \"Last Checked Date: \\t%s\\n\",\n        tsk_fs_time_to_str(mac_time, timeBuf));\n\n\n    if (tsk_getu32(fs->endian, hfs->fs->attr) & HFS_VH_ATTR_SOFTWARE_LOCK)\n        tsk_fprintf(hFile, \"Software write protect enabled\\n\");\n\n    /* Print journal information */\n    if (tsk_getu32(fs->endian, sb->attr) & HFS_VH_ATTR_JOURNALED) {\n        tsk_fprintf(hFile, \"\\nJournal Info Block: %\" PRIu32 \"\\n\",\n            tsk_getu32(fs->endian, sb->jinfo_blk));\n    }\n\n    tsk_fprintf(hFile, \"\\nMETADATA INFORMATION\\n\");\n    tsk_fprintf(hFile, \"--------------------------------------------\\n\");\n\n    tsk_fprintf(hFile, \"Range: %\" PRIuINUM \" - %\" PRIuINUM \"\\n\",\n        fs->first_inum, fs->last_inum);\n\n    inode = tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_BOOT]);\n    tsk_fprintf(hFile, \"Bootable Folder ID: %\" PRIuINUM, inode);\n    if (inode > 0)\n        print_inode_file(hFile, fs, inode);\n    tsk_fprintf(hFile, \"\\n\");\n\n    inode = tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_START]);\n    tsk_fprintf(hFile, \"Startup App ID: %\" PRIuINUM, inode);\n    if (inode > 0)\n        print_inode_file(hFile, fs, inode);\n    tsk_fprintf(hFile, \"\\n\");\n\n    inode = tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_OPEN]);\n    tsk_fprintf(hFile, \"Startup Open Folder ID: %\" PRIuINUM, inode);\n    if (inode > 0)\n        print_inode_file(hFile, fs, inode);\n    tsk_fprintf(hFile, \"\\n\");\n\n    inode = tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_BOOT9]);\n    tsk_fprintf(hFile, \"Mac OS 8/9 Blessed System Folder ID: %\" PRIuINUM,\n        inode);\n    if (inode > 0)\n        print_inode_file(hFile, fs, inode);\n    tsk_fprintf(hFile, \"\\n\");\n\n    inode = tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_BOOTX]);\n    tsk_fprintf(hFile, \"Mac OS X Blessed System Folder ID: %\" PRIuINUM,\n        inode);\n    if (inode > 0)\n        print_inode_file(hFile, fs, inode);\n    tsk_fprintf(hFile, \"\\n\");\n\n    tsk_fprintf(hFile, \"Number of files: %\" PRIu32 \"\\n\",\n        tsk_getu32(fs->endian, sb->file_cnt));\n    tsk_fprintf(hFile, \"Number of folders: %\" PRIu32 \"\\n\",\n        tsk_getu32(fs->endian, sb->fldr_cnt));\n\n\n    tsk_fprintf(hFile, \"\\nCONTENT INFORMATION\\n\");\n    tsk_fprintf(hFile, \"--------------------------------------------\\n\");\n\n    tsk_fprintf(hFile, \"Block Range: %\" PRIuDADDR \" - %\" PRIuDADDR \"\\n\",\n        fs->first_block, fs->last_block);\n\n    if (fs->last_block != fs->last_block_act)\n        tsk_fprintf(hFile,\n            \"Total Range in Image: %\" PRIuDADDR \" - %\" PRIuDADDR \"\\n\",\n            fs->first_block, fs->last_block_act);\n\n    tsk_fprintf(hFile, \"Allocation Block Size: %u\\n\", fs->block_size);\n\n    tsk_fprintf(hFile, \"Number of Free Blocks: %\" PRIu32 \"\\n\",\n        tsk_getu32(fs->endian, sb->free_blks));\n\n    if (tsk_getu32(fs->endian, hfs->fs->attr) & HFS_VH_ATTR_BADBLOCKS)\n        tsk_fprintf(hFile, \"Volume has bad blocks\\n\");\n\n    return 0;\n}\n\n\n/************************* istat *******************************/\n\n\n/**\n * Text encoding names defined in TN1150, Table 2.\n */\nstatic char *\ntext_encoding_name(uint32_t enc)\n{\n    switch (enc) {\n    case 0:\n        return \"MacRoman\";\n    case 1:\n        return \"MacJapanese\";\n    case 2:\n        return \"MacChineseTrad\";\n    case 4:\n        return \"MacKorean\";\n    case 5:\n        return \"MacArabic\";\n    case 6:\n        return \"MacHebrew\";\n    case 7:\n        return \"MacGreek\";\n    case 8:\n        return \"MacCyrillic\";\n    case 9:\n        return \"MacDevanagari\";\n    case 10:\n        return \"MacGurmukhi\";\n    case 11:\n        return \"MacGujarati\";\n    case 12:\n        return \"MacOriya\";\n    case 13:\n        return \"MacBengali\";\n    case 14:\n        return \"MacTamil\";\n    case 15:\n        return \"Telugu\";\n    case 16:\n        return \"MacKannada\";\n    case 17:\n        return \"MacMalayalam\";\n    case 18:\n        return \"MacSinhalese\";\n    case 19:\n        return \"MacBurmese\";\n    case 20:\n        return \"MacKhmer\";\n    case 21:\n        return \"MacThai\";\n    case 22:\n        return \"MacLaotian\";\n    case 23:\n        return \"MacGeorgian\";\n    case 24:\n        return \"MacArmenian\";\n    case 25:\n        return \"MacChineseSimp\";\n    case 26:\n        return \"MacTibetan\";\n    case 27:\n        return \"MacMongolian\";\n    case 28:\n        return \"MacEthiopic\";\n    case 29:\n        return \"MacCentralEurRoman\";\n    case 30:\n        return \"MacVietnamese\";\n    case 31:\n        return \"MacExtArabic\";\n    case 33:\n        return \"MacSymbol\";\n    case 34:\n        return \"MacDingbats\";\n    case 35:\n        return \"MacTurkish\";\n    case 36:\n        return \"MacCroatian\";\n    case 37:\n        return \"MacIcelandic\";\n    case 38:\n        return \"MacRomanian\";\n    case 49:\n    case 140:\n        return \"MacFarsi\";\n    case 48:\n    case 152:\n        return \"MacUkrainian\";\n    default:\n        return \"Unknown encoding\";\n    }\n}\n\n#define HFS_PRINT_WIDTH 8\ntypedef struct {\n    FILE *hFile;\n    int idx;\n    TSK_DADDR_T startBlock;\n    uint32_t blockCount;\n    unsigned char accumulating;\n} HFS_PRINT_ADDR;\n\nstatic void\noutput_print_addr(HFS_PRINT_ADDR * print)\n{\n    if (!print->accumulating)\n        return;\n    if (print->blockCount == 1) {\n        tsk_fprintf(print->hFile, \"%\" PRIuDADDR \"  \", print->startBlock);\n        print->idx += 1;\n    }\n    else if (print->blockCount > 1) {\n        tsk_fprintf(print->hFile, \"%\" PRIuDADDR \"-%\" PRIuDADDR \"  \",\n            print->startBlock, print->startBlock + print->blockCount - 1);\n        print->idx += 2;\n    }\n    if (print->idx >= HFS_PRINT_WIDTH) {\n        tsk_fprintf(print->hFile, \"\\n\");\n        print->idx = 0;\n    }\n}\n\nstatic TSK_WALK_RET_ENUM\nprint_addr_act(TSK_FS_FILE * fs_file, TSK_OFF_T a_off, TSK_DADDR_T addr,\n    char *buf, size_t size, TSK_FS_BLOCK_FLAG_ENUM flags, void *ptr)\n{\n    HFS_PRINT_ADDR *print = (HFS_PRINT_ADDR *) ptr;\n\n    if (print->accumulating) {\n        if (addr == print->startBlock + print->blockCount) {\n            ++print->blockCount;\n        }\n        else {\n            output_print_addr(print);\n\n            print->startBlock = addr;\n            print->blockCount = 1;\n        }\n    }\n    else {\n        print->startBlock = addr;\n        print->blockCount = 1;\n        print->accumulating = TRUE;\n    }\n\n    return TSK_WALK_CONT;\n}\n\n/**\n * Print details on a specific file to a file handle.\n *\n * @param fs File system file is located in\n * @param hFile File name to print text to\n * @param inum Address of file in file system\n * @param numblock The number of blocks in file to force print (can go beyond file size)\n * @param sec_skew Clock skew in seconds to also print times in\n *\n * @returns 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_istat(TSK_FS_INFO * fs, TSK_FS_ISTAT_FLAG_ENUM istat_flags, FILE * hFile, TSK_INUM_T inum,\n    TSK_DADDR_T numblock, int32_t sec_skew)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    TSK_FS_FILE *fs_file;\n    char hfs_mode[12];\n    HFS_PRINT_ADDR print;\n    HFS_ENTRY entry;\n    char timeBuf[128];\n    // Compression ATTR, if there is one:\n    const TSK_FS_ATTR *compressionAttr = NULL;\n    RES_DESCRIPTOR *rd;         // descriptor of a resource\n\n    tsk_error_reset();\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_istat: inum: %\" PRIuINUM \" numblock: %\" PRIu32 \"\\n\",\n            inum, numblock);\n\n    if ((fs_file = tsk_fs_file_open_meta(fs, NULL, inum)) == NULL) {\n        error_returned(\"hfs_istat: getting metadata for the file\");\n        return 1;\n    }\n\n    if (inum >= HFS_FIRST_USER_CNID) {\n        int rslt;\n        tsk_fprintf(hFile, \"File Path: \");\n        rslt = print_parent_path(hFile, fs, inum);\n        if (rslt != 0)\n            tsk_fprintf(hFile, \" Error in printing path\\n\");\n        else\n            tsk_fprintf(hFile, \"\\n\");\n    }\n    else {\n        // All of the files in this inum range have names without nulls,\n        // slashes or control characters.  So, it is OK to print this UTF8\n        // string this way.\n        if (fs_file->meta->name2 != NULL)\n            tsk_fprintf(hFile, \"File Name: %s\\n\",\n                fs_file->meta->name2->name);\n    }\n\n    tsk_fprintf(hFile, \"Catalog Record: %\" PRIuINUM \"\\n\", inum);\n    tsk_fprintf(hFile, \"%sAllocated\\n\",\n        (fs_file->meta->flags & TSK_FS_META_FLAG_UNALLOC) ? \"Not \" : \"\");\n\n    tsk_fprintf(hFile, \"Type:\\t\");\n    if (fs_file->meta->type == TSK_FS_META_TYPE_REG)\n        tsk_fprintf(hFile, \"File\\n\");\n    else if (TSK_FS_IS_DIR_META(fs_file->meta->type))\n        tsk_fprintf(hFile, \"Folder\\n\");\n    else\n        tsk_fprintf(hFile, \"\\n\");\n\n    tsk_fs_meta_make_ls(fs_file->meta, hfs_mode, sizeof(hfs_mode));\n    tsk_fprintf(hFile, \"Mode:\\t%s\\n\", hfs_mode);\n    tsk_fprintf(hFile, \"Size:\\t%\" PRIuOFF \"\\n\", fs_file->meta->size);\n\n    if (fs_file->meta->link)\n        tsk_fprintf(hFile, \"Symbolic link to:\\t%s\\n\", fs_file->meta->link);\n\n    tsk_fprintf(hFile, \"uid / gid: %\" PRIuUID \" / %\" PRIuGID \"\\n\",\n        fs_file->meta->uid, fs_file->meta->gid);\n\n    tsk_fprintf(hFile, \"Link count:\\t%d\\n\", fs_file->meta->nlink);\n\n    if (hfs_cat_file_lookup(hfs, inum, &entry, TRUE) == 0) {\n        hfs_uni_str *nm = &entry.thread.name;\n        char name_buf[HFS_MAXNAMLEN + 1];\n        TSK_INUM_T par_cnid;    // parent CNID\n\n        tsk_fprintf(hFile, \"\\n\");\n        hfs_UTF16toUTF8(fs, nm->unicode, (int) tsk_getu16(fs->endian,\n                nm->length), &name_buf[0], HFS_MAXNAMLEN + 1,\n            HFS_U16U8_FLAG_REPLACE_SLASH | HFS_U16U8_FLAG_REPLACE_CONTROL);\n        tsk_fprintf(hFile, \"File Name: %s\\n\", name_buf);\n\n        // Test here to see if this is a hard link.\n        par_cnid = tsk_getu32(fs->endian, &(entry.thread.parent_cnid));\n        if ((hfs->has_meta_dir_crtime && par_cnid == hfs->meta_dir_inum) ||\n            (hfs->has_meta_crtime && par_cnid == hfs->meta_inum)) {\n            int instr = strncmp(name_buf, \"iNode\", 5);\n            int drstr = strncmp(name_buf, \"dir_\", 4);\n\n            if (instr == 0 &&\n                hfs->has_meta_crtime && par_cnid == hfs->meta_inum) {\n                tsk_fprintf(hFile, \"This is a hard link to a file\\n\");\n            }\n            else if (drstr == 0 &&\n                hfs->has_meta_dir_crtime &&\n                par_cnid == hfs->meta_dir_inum) {\n                tsk_fprintf(hFile, \"This is a hard link to a folder.\\n\");\n            }\n        }\n\n        /* The cat.perm union contains file-type specific values.\n         * Print them if they are relevant. */\n        if ((fs_file->meta->type == TSK_FS_META_TYPE_CHR) ||\n            (fs_file->meta->type == TSK_FS_META_TYPE_BLK)) {\n            tsk_fprintf(hFile, \"Device ID:\\t%\" PRIu32 \"\\n\",\n                tsk_getu32(fs->endian, entry.cat.std.perm.special.raw));\n        }\n        else if ((tsk_getu32(fs->endian,\n                    entry.cat.std.u_info.file_type) ==\n                HFS_HARDLINK_FILE_TYPE)\n            && (tsk_getu32(fs->endian,\n                    entry.cat.std.u_info.file_cr) ==\n                HFS_HARDLINK_FILE_CREATOR)) {\n            // technically, the creation date of this item should be the same as either the\n            // creation date of the \"HFS+ Private Data\" folder or the creation date of the root folder\n            tsk_fprintf(hFile, \"Hard link inode number\\t %\" PRIu32 \"\\n\",\n                tsk_getu32(fs->endian, entry.cat.std.perm.special.inum));\n        }\n\n        tsk_fprintf(hFile, \"Admin flags: %\" PRIu8,\n            entry.cat.std.perm.a_flags);\n        if (entry.cat.std.perm.a_flags != 0) {\n            tsk_fprintf(hFile, \" - \");\n            if (entry.cat.std.perm.a_flags & HFS_PERM_AFLAG_ARCHIVED)\n                tsk_fprintf(hFile, \"archived \");\n            if (entry.cat.std.perm.a_flags & HFS_PERM_AFLAG_IMMUTABLE)\n                tsk_fprintf(hFile, \"immutable \");\n            if (entry.cat.std.perm.a_flags & HFS_PERM_AFLAG_APPEND)\n                tsk_fprintf(hFile, \"append-only \");\n        }\n        tsk_fprintf(hFile, \"\\n\");\n\n        tsk_fprintf(hFile, \"Owner flags: %\" PRIu8,\n            entry.cat.std.perm.o_flags);\n        if (entry.cat.std.perm.o_flags != 0) {\n            tsk_fprintf(hFile, \" - \");\n            if (entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_NODUMP)\n                tsk_fprintf(hFile, \"no-dump \");\n            if (entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_IMMUTABLE)\n                tsk_fprintf(hFile, \"immutable \");\n            if (entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_APPEND)\n                tsk_fprintf(hFile, \"append-only \");\n            if (entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_OPAQUE)\n                tsk_fprintf(hFile, \"opaque \");\n            if (entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_COMPRESSED)\n                tsk_fprintf(hFile, \"compressed \");\n        }\n        tsk_fprintf(hFile, \"\\n\");\n\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.flags) & HFS_FILE_FLAG_LOCKED)\n            tsk_fprintf(hFile, \"Locked\\n\");\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.flags) & HFS_FILE_FLAG_ATTR)\n            tsk_fprintf(hFile, \"Has extended attributes\\n\");\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.flags) & HFS_FILE_FLAG_ACL)\n            tsk_fprintf(hFile, \"Has security data (ACLs)\\n\");\n\n        // File_type and file_cr are not relevant for Folders\n        if ( !TSK_FS_IS_DIR_META(fs_file->meta->type)){\n            int windx;          // loop index\n            tsk_fprintf(hFile,\n                \"File type:\\t%04\" PRIx32 \"  \",\n                tsk_getu32(fs->endian, entry.cat.std.u_info.file_type));\n\n            for (windx = 0; windx < 4; ++windx) {\n                uint8_t cu = entry.cat.std.u_info.file_type[windx];\n                if (cu >= 32 && cu <= 126)\n                    tsk_fprintf(hFile, \"%c\", (char) cu);\n                else\n                    tsk_fprintf(hFile, \" \");\n            }\n            tsk_fprintf(hFile, \"\\n\");\n            tsk_fprintf(hFile,\n                \"File creator:\\t%04\" PRIx32 \"  \",\n                tsk_getu32(fs->endian, entry.cat.std.u_info.file_cr));\n            for (windx = 0; windx < 4; ++windx) {\n                uint8_t cu = entry.cat.std.u_info.file_cr[windx];\n                if (cu >= 32 && cu <= 126)\n                    tsk_fprintf(hFile, \"%c\", (char) cu);\n                else\n                    tsk_fprintf(hFile, \" \");\n            }\n            tsk_fprintf(hFile, \"\\n\");\n        }                       // END if(not folder)\n\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.u_info.flags) & HFS_FINDER_FLAG_NAME_LOCKED)\n            tsk_fprintf(hFile, \"Name locked\\n\");\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.u_info.flags) & HFS_FINDER_FLAG_HAS_BUNDLE)\n            tsk_fprintf(hFile, \"Has bundle\\n\");\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.u_info.flags) & HFS_FINDER_FLAG_IS_INVISIBLE)\n            tsk_fprintf(hFile, \"Is invisible\\n\");\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.u_info.flags) & HFS_FINDER_FLAG_IS_ALIAS)\n            tsk_fprintf(hFile, \"Is alias\\n\");\n\n        tsk_fprintf(hFile, \"Text encoding:\\t%\" PRIx32 \" = %s\\n\",\n            tsk_getu32(fs->endian, entry.cat.std.text_enc),\n            text_encoding_name(tsk_getu32(fs->endian,\n                    entry.cat.std.text_enc)));\n\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.rec_type) == HFS_FILE_RECORD) {\n            tsk_fprintf(hFile, \"Resource fork size:\\t%\" PRIu64 \"\\n\",\n                tsk_getu64(fs->endian, entry.cat.resource.logic_sz));\n        }\n    }\n\n    if (sec_skew != 0) {\n        tsk_fprintf(hFile, \"\\nAdjusted times:\\n\");\n        if (fs_file->meta->mtime)\n            fs_file->meta->mtime -= sec_skew;\n        if (fs_file->meta->atime)\n            fs_file->meta->atime -= sec_skew;\n        if (fs_file->meta->ctime)\n            fs_file->meta->ctime -= sec_skew;\n        if (fs_file->meta->crtime)\n            fs_file->meta->crtime -= sec_skew;\n        if (fs_file->meta->time2.hfs.bkup_time)\n            fs_file->meta->time2.hfs.bkup_time -= sec_skew;\n\n        tsk_fprintf(hFile, \"Created:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_file->meta->crtime, timeBuf));\n        tsk_fprintf(hFile, \"Content Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_file->meta->mtime, timeBuf));\n        tsk_fprintf(hFile, \"Attributes Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_file->meta->ctime, timeBuf));\n        tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_file->meta->atime, timeBuf));\n        tsk_fprintf(hFile, \"Backed Up:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_file->meta->time2.hfs.bkup_time,\n                timeBuf));\n\n        if (fs_file->meta->mtime)\n            fs_file->meta->mtime += sec_skew;\n        if (fs_file->meta->atime)\n            fs_file->meta->atime += sec_skew;\n        if (fs_file->meta->ctime)\n            fs_file->meta->ctime += sec_skew;\n        if (fs_file->meta->crtime)\n            fs_file->meta->crtime += sec_skew;\n        if (fs_file->meta->time2.hfs.bkup_time)\n            fs_file->meta->time2.hfs.bkup_time += sec_skew;\n\n        tsk_fprintf(hFile, \"\\nOriginal times:\\n\");\n    }\n    else {\n        tsk_fprintf(hFile, \"\\nTimes:\\n\");\n    }\n\n    tsk_fprintf(hFile, \"Created:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_file->meta->crtime, timeBuf));\n    tsk_fprintf(hFile, \"Content Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_file->meta->mtime, timeBuf));\n    tsk_fprintf(hFile, \"Attributes Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_file->meta->ctime, timeBuf));\n    tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_file->meta->atime, timeBuf));\n    tsk_fprintf(hFile, \"Backed Up:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_file->meta->time2.hfs.bkup_time, timeBuf));\n\n    // IF this is a regular file, then print out the blocks of the DATA and RSRC forks.\n    if (tsk_getu16(fs->endian, entry.cat.std.rec_type) == HFS_FILE_RECORD) {\n        // Only print DATA fork blocks if this file is NOT compressed\n        // N.B., a compressed file has no data fork, and tsk_fs_file_walk() will\n        //   do the wrong thing!\n        if (!(entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_COMPRESSED)) {\n\n            if (!(istat_flags & TSK_FS_ISTAT_RUNLIST)) {\n                tsk_fprintf(hFile, \"\\nData Fork Blocks:\\n\");\n                print.idx = 0;\n                print.hFile = hFile;\n                print.accumulating = FALSE;\n                print.startBlock = 0;\n                print.blockCount = 0;\n\n                if (tsk_fs_file_walk_type(fs_file,\n                    TSK_FS_ATTR_TYPE_HFS_DATA, HFS_FS_ATTR_ID_DATA,\n                    (TSK_FS_FILE_WALK_FLAG_AONLY |\n                        TSK_FS_FILE_WALK_FLAG_SLACK), print_addr_act,\n                        (void *)&print)) {\n                    tsk_fprintf(hFile, \"\\nError reading file data fork\\n\");\n                    tsk_error_print(hFile);\n                    tsk_error_reset();\n                }\n                else {\n                    output_print_addr(&print);\n                    if (print.idx != 0)\n                        tsk_fprintf(hFile, \"\\n\");\n                }\n            }\n        }\n\n        // Only print out the blocks of the Resource fork if it has nonzero size\n        if (tsk_getu64(fs->endian, entry.cat.resource.logic_sz) > 0) {\n\n            if (! (istat_flags & TSK_FS_ISTAT_RUNLIST)) {\n                tsk_fprintf(hFile, \"\\nResource Fork Blocks:\\n\");\n\n                print.idx = 0;\n                print.hFile = hFile;\n                print.accumulating = FALSE;\n                print.startBlock = 0;\n                print.blockCount = 0;\n\n                if (tsk_fs_file_walk_type(fs_file,\n                    TSK_FS_ATTR_TYPE_HFS_RSRC, HFS_FS_ATTR_ID_RSRC,\n                    (TSK_FS_FILE_WALK_FLAG_AONLY |\n                        TSK_FS_FILE_WALK_FLAG_SLACK), print_addr_act,\n                        (void *)&print)) {\n                    tsk_fprintf(hFile, \"\\nError reading file resource fork\\n\");\n                    tsk_error_print(hFile);\n                    tsk_error_reset();\n                }\n                else {\n                    output_print_addr(&print);\n                    if (print.idx != 0)\n                        tsk_fprintf(hFile, \"\\n\");\n                }\n            }\n        }\n    }\n\n    // Force the loading of all attributes.\n    (void) tsk_fs_file_attr_get(fs_file);\n\n    /* Print all of the attributes */\n    tsk_fprintf(hFile, \"\\nAttributes: \\n\");\n    if (fs_file->meta->attr) {\n        int cnt, i;\n\n        // cycle through the attributes\n        cnt = tsk_fs_file_attr_getsize(fs_file);\n        for (i = 0; i < cnt; ++i) {\n            const char *type;   // type of the attribute as a string\n            const TSK_FS_ATTR *fs_attr =\n                tsk_fs_file_attr_get_idx(fs_file, i);\n            if (!fs_attr)\n                continue;\n\n            type = hfs_attrTypeName((uint32_t) fs_attr->type);\n\n            // We will need to do something better than this, in the end.\n            //type = \"Data\";\n\n            /* print the layout if it is non-resident and not \"special\" */\n            if (fs_attr->flags & TSK_FS_ATTR_NONRES) {\n                //NTFS_PRINT_ADDR print_addr;\n\n                tsk_fprintf(hFile,\n                    \"Type: %s (%\" PRIu32 \"-%\" PRIu16\n                    \")   Name: %s   Non-Resident%s%s%s   size: %\"\n                    PRIuOFF \"  init_size: %\" PRIuOFF \"\\n\", type,\n                    fs_attr->type, fs_attr->id,\n                    (fs_attr->name) ? fs_attr->name : \"N/A\",\n                    (fs_attr->flags & TSK_FS_ATTR_ENC) ? \", Encrypted\" :\n                    \"\",\n                    (fs_attr->flags & TSK_FS_ATTR_COMP) ? \", Compressed\" :\n                    \"\",\n                    (fs_attr->flags & TSK_FS_ATTR_SPARSE) ? \", Sparse\" :\n                    \"\", fs_attr->size, fs_attr->nrd.initsize);\n\n                if (istat_flags & TSK_FS_ISTAT_RUNLIST) {\n                    if (tsk_fs_attr_print(fs_attr, hFile)) {\n                        tsk_fprintf(hFile, \"\\nError creating run lists\\n\");\n                        tsk_error_print(hFile);\n                        tsk_error_reset();\n                    }\n                }\n            }                   // END:  non-resident attribute case\n            else {\n                tsk_fprintf(hFile,\n                    \"Type: %s (%\" PRIu32 \"-%\" PRIu16\n                    \")   Name: %s   Resident%s%s%s   size: %\"\n                    PRIuOFF \"\\n\",\n                    type,\n                    fs_attr->type,\n                    fs_attr->id,\n                    (fs_attr->name) ? fs_attr->name : \"N/A\",\n                    (fs_attr->flags & TSK_FS_ATTR_ENC) ? \", Encrypted\" :\n                    \"\",\n                    (fs_attr->flags & TSK_FS_ATTR_COMP) ? \", Compressed\" :\n                    \"\",\n                    (fs_attr->flags & TSK_FS_ATTR_SPARSE) ? \", Sparse\" :\n                    \"\", fs_attr->size);\n                if (fs_attr->type == TSK_FS_ATTR_TYPE_HFS_COMP_REC) {\n                    if (compressionAttr == NULL) {\n                        compressionAttr = fs_attr;\n                    }\n                    else {\n                        // Problem:  there is more than one compression attribute\n                        error_detected(TSK_ERR_FS_CORRUPT,\n                            \"hfs_istat: more than one compression attribute\");\n                        return 1;\n                    }\n                }\n            }                   // END: else (RESIDENT attribute case)\n        }                       // END:  for(;;)  loop over attributes\n    }                           // END:  if(fs_file->meta->attr is non-NULL)\n\n    if ((entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_COMPRESSED)\n        && (compressionAttr == NULL))\n        tsk_fprintf(hFile,\n            \"WARNING: Compression Flag is set, but there\"\n            \" is no compression record for this file.\\n\");\n    if (((entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_COMPRESSED) == 0)\n        && (compressionAttr != NULL))\n        tsk_fprintf(hFile,\n            \"WARNING: Compression Flag is NOT set, but there\"\n            \" is a compression record for this file.\\n\");\n\n    // IF this is a compressed file\n    if (compressionAttr != NULL) {\n        const TSK_FS_ATTR *fs_attr = compressionAttr;\n        int attrReadResult;\n        DECMPFS_DISK_HEADER *cmph;\n        uint32_t cmpType;\n        uint64_t uncSize;\n        uint64_t cmpSize = 0;\n\n        // Read the attribute.  It cannot be too large because it is stored in\n        // a btree node\n        char *aBuf = (char *) tsk_malloc((size_t) fs_attr->size);\n        if (aBuf == NULL) {\n            error_returned(\"hfs_istat: space for a compression attribute\");\n            return 1;\n        }\n        attrReadResult = tsk_fs_attr_read(fs_attr, (TSK_OFF_T) 0,\n            aBuf, (size_t) fs_attr->size,\n            (TSK_FS_FILE_READ_FLAG_ENUM) 0x00);\n        if (attrReadResult == -1) {\n            error_returned(\"hfs_istat: reading the compression attribute\");\n            free(aBuf);\n            return 1;\n        }\n        else if (attrReadResult < fs_attr->size) {\n            error_detected(TSK_ERR_FS_READ,\n                \"hfs_istat: could not read the whole compression attribute\");\n            free(aBuf);\n            return 1;\n        }\n        // Now, cast the attr into a compression header\n        cmph = (DECMPFS_DISK_HEADER *) aBuf;\n        cmpType = tsk_getu32(TSK_LIT_ENDIAN, cmph->compression_type);\n        uncSize = tsk_getu64(TSK_LIT_ENDIAN, cmph->uncompressed_size);\n\n        tsk_fprintf(hFile, \"\\nCompressed File:\\n\");\n        tsk_fprintf(hFile, \"    Uncompressed size: %llu\\n\", uncSize);\n\n        switch (cmpType) {\n        case DECMPFS_TYPE_ZLIB_ATTR:\n            // Data is inline\n            {\n                // size of header, with indicator byte if uncompressed\n                uint32_t off = (cmph->attr_bytes[0] & 0x0F) == 0x0F ? 17 : 16;\n                cmpSize = fs_attr->size - off;\n\n                tsk_fprintf(hFile,\n                    \"    Data follows compression record in the CMPF attribute\\n\"\n                    \"    %\" PRIu64 \" bytes of data at offset %u, %s compressed\\n\",\n                    cmpSize, off, off == 16 ? \"zlib\" : \"not\");\n            }\n            break;\n\n        case DECMPFS_TYPE_LZVN_ATTR:\n            // Data is inline\n            {\n                // size of header, with indicator byte if uncompressed\n                uint32_t off = cmph->attr_bytes[0] == 0x06 ? 17 : 16;\n                cmpSize = fs_attr->size - off;\n\n                tsk_fprintf(hFile,\n                    \"    Data follows compression record in the CMPF attribute\\n\"\n                    \"    %\" PRIu64 \" bytes of data at offset %u, %s compressed\\n\",\n                    cmpSize, off, off == 16 ? \"lzvn\" : \"not\");\n            }\n            break;\n\n        case DECMPFS_TYPE_ZLIB_RSRC:\n            // Data is zlib compressed in the resource fork\n            tsk_fprintf(hFile,\n                \"    Data is zlib compressed in the resource fork\\n\");\n            break;\n\n        case DECMPFS_TYPE_LZVN_RSRC:\n            // Data is lzvn compressed in the resource fork\n            tsk_fprintf(hFile,\n                \"    Data is lzvn compressed in the resource fork\\n\");\n            break;\n\n        default:\n            tsk_fprintf(hFile, \"    Compression type is %u: UNKNOWN\\n\",\n                cmpType);\n        }\n\n        free(aBuf);\n\n        if ((cmpType == DECMPFS_TYPE_ZLIB_RSRC ||\n             cmpType == DECMPFS_TYPE_LZVN_RSRC)\n            && (tsk_getu64(fs->endian, entry.cat.resource.logic_sz) == 0))\n            tsk_fprintf(hFile,\n                \"WARNING: Compression record indicates compressed data\"\n                \" in the RSRC Fork, but that fork is empty.\\n\");\n    }\n\n    // This will return NULL if there is an error, or if there are no resources\n    rd = hfs_parse_resource_fork(fs_file);\n    // TODO: Should check the errnum here to see if there was an error\n\n    if (rd != NULL) {\n        tsk_fprintf(hFile, \"\\nResources:\\n\");\n        while (rd) {\n            tsk_fprintf(hFile,\n                \"  Type: %s \\tID: %-5u \\tOffset: %-5u \\tSize: %-5u \\tName: %s\\n\",\n                rd->type, rd->id, rd->offset, rd->length, rd->name);\n            rd = rd->next;\n        }\n    }\n    // This is OK to call with NULL\n    free_res_descriptor(rd);\n\n    tsk_fs_file_close(fs_file);\n    return 0;\n}\n\n\n\nstatic TSK_FS_ATTR_TYPE_ENUM\nhfs_get_default_attr_type(const TSK_FS_FILE * a_file)\n{\n    // The HFS+ special files have a default attr type of \"Default\"\n    TSK_INUM_T inum = a_file->meta->addr;\n    if (inum == 3 ||            // Extents File\n        inum == 4 ||            // Catalog File\n        inum == 5 ||            // Bad Blocks File\n        inum == 6 ||            // Block Map (Allocation File)\n        inum == 7 ||            // Startup File\n        inum == 8 ||            // Attributes File\n        inum == 14 ||           // Not sure if these two will actually work.  I don't see\n        inum == 15)             // any code to load the attrs of these files, if they exist.\n        return TSK_FS_ATTR_TYPE_DEFAULT;\n    // The \"regular\" files and symbolic links have a DATA fork with type \"DATA\"\n    if (a_file->meta->type == TSK_FS_META_TYPE_REG ||\n        a_file->meta->type == TSK_FS_META_TYPE_LNK)\n        // This should be an HFS-specific type.\n        return TSK_FS_ATTR_TYPE_HFS_DATA;\n\n    // We've got to return *something* for every file, so we return this.\n    return TSK_FS_ATTR_TYPE_DEFAULT;\n}\n\nstatic void\nhfs_close(TSK_FS_INFO * fs)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    // We'll grab this lock a bit early.\n    tsk_take_lock(&(hfs->metadata_dir_cache_lock));\n    fs->tag = 0;\n\n    free(hfs->fs);\n\n    if (hfs->catalog_file) {\n        tsk_fs_file_close(hfs->catalog_file);\n        hfs->catalog_attr = NULL;\n    }\n\n    if (hfs->blockmap_file) {\n        tsk_fs_file_close(hfs->blockmap_file);\n        hfs->blockmap_attr = NULL;\n    }\n\n    if (hfs->meta_dir) {\n        tsk_fs_dir_close(hfs->meta_dir);\n        hfs->meta_dir = NULL;\n    }\n\n    if (hfs->dir_meta_dir) {\n        tsk_fs_dir_close(hfs->dir_meta_dir);\n        hfs->dir_meta_dir = NULL;\n    }\n\n    if (hfs->extents_file) {\n        tsk_fs_file_close(hfs->extents_file);\n        hfs->extents_file = NULL;\n    }\n\n    tsk_release_lock(&(hfs->metadata_dir_cache_lock));\n    tsk_deinit_lock(&(hfs->metadata_dir_cache_lock));\n\n    tsk_fs_free((TSK_FS_INFO *)hfs);\n}\n\n/* hfs_open - open an hfs file system\n *\n * Return NULL on error (or not an HFS or HFS+ file system)\n * */\n\nTSK_FS_INFO *\nhfs_open(TSK_IMG_INFO * img_info, TSK_OFF_T offset,\n    TSK_FS_TYPE_ENUM ftype, uint8_t test)\n{\n    HFS_INFO *hfs;\n    unsigned int len;\n    TSK_FS_INFO *fs;\n    ssize_t cnt;\n    TSK_FS_FILE *file;          // The root directory, or the metadata directories\n    TSK_INUM_T inum;            // The inum (or CNID) of the metadata directories\n    int8_t result;              // of tsk_fs_path2inum()\n\n    tsk_error_reset();\n\n    if (TSK_FS_TYPE_ISHFS(ftype) == 0) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"Invalid FS Type in hfs_open\");\n        return NULL;\n    }\n\n    if ((hfs = (HFS_INFO *) tsk_fs_malloc(sizeof(HFS_INFO))) == NULL)\n        return NULL;\n\n    fs = &(hfs->fs_info);\n\n    fs->ftype = TSK_FS_TYPE_HFS;\n    fs->duname = \"Allocation Block\";\n    fs->tag = TSK_FS_INFO_TAG;\n    fs->flags = 0;\n\n    fs->img_info = img_info;\n    fs->offset = offset;\n\n    /*\n     * Read the superblock.\n     */\n    len = sizeof(hfs_plus_vh);\n    if ((hfs->fs = (hfs_plus_vh *) tsk_malloc(len)) == NULL) {\n        fs->tag = 0;\n        tsk_fs_free((TSK_FS_INFO *)hfs);\n        return NULL;\n    }\n\n    if (hfs_checked_read_random(fs, (char *) hfs->fs, len,\n            (TSK_OFF_T) HFS_VH_OFF)) {\n        tsk_error_set_errstr2(\"hfs_open: superblock\");\n        fs->tag = 0;\n        free(hfs->fs);\n        tsk_fs_free((TSK_FS_INFO *)hfs);\n        return NULL;\n    }\n\n    /*\n     * Verify we are looking at an HFS+ image\n     */\n    if (tsk_fs_guessu16(fs, hfs->fs->signature, HFS_VH_SIG_HFSPLUS) &&\n        tsk_fs_guessu16(fs, hfs->fs->signature, HFS_VH_SIG_HFSX) &&\n        tsk_fs_guessu16(fs, hfs->fs->signature, HFS_VH_SIG_HFS)) {\n\n        fs->tag = 0;\n        free(hfs->fs);\n        tsk_fs_free((TSK_FS_INFO *)hfs);\n        tsk_error_set_errno(TSK_ERR_FS_MAGIC);\n        tsk_error_set_errstr(\"not an HFS+ file system (magic)\");\n        return NULL;\n    }\n\n    /*\n     * Handle an HFS-wrapped HFS+ image, which is a HFS volume that contains\n     * the HFS+ volume inside of it.\n     */\n    if (tsk_getu16(fs->endian, hfs->fs->signature) == HFS_VH_SIG_HFS) {\n\n        hfs_mdb *wrapper_sb = (hfs_mdb *) hfs->fs;\n\n        // Verify that we are setting a wrapper and not a normal HFS volume\n        if ((tsk_getu16(fs->endian,\n                    wrapper_sb->drEmbedSigWord) == HFS_VH_SIG_HFSPLUS)\n            || (tsk_getu16(fs->endian,\n                    wrapper_sb->drEmbedSigWord) == HFS_VH_SIG_HFSX)) {\n\n            TSK_FS_INFO *fs_info2;\n            // offset in sectors to start of first HFS block\n            uint16_t drAlBlSt =\n                tsk_getu16(fs->endian, wrapper_sb->drAlBlSt);\n\n            // size of each HFS block\n            uint32_t drAlBlkSiz =\n                tsk_getu32(fs->endian, wrapper_sb->drAlBlkSiz);\n\n            // start of embedded FS\n            uint16_t startBlock = tsk_getu16(fs->endian,\n                wrapper_sb->drEmbedExtent_startBlock);\n\n            // calculate the offset; 512 here is intentional.\n            // TN1150 says \"The drAlBlSt field contains the offset, in\n            // 512-byte blocks, of the wrapper's allocation block 0 relative\n            // to the start of the volume\"\n            TSK_OFF_T hfsplus_offset =\n                (drAlBlSt * (TSK_OFF_T) 512) +\n                (drAlBlkSiz * (TSK_OFF_T) startBlock);\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_open: HFS+/HFSX within HFS wrapper at byte offset %\"\n                    PRIuOFF \"\\n\", hfsplus_offset);\n\n            fs->tag = 0;\n            free(hfs->fs);\n            tsk_fs_free((TSK_FS_INFO *)hfs);\n\n            /* just re-open with the new offset, then record the offset */\n            if (hfsplus_offset == 0) {\n                tsk_error_set_errno(TSK_ERR_FS_CORRUPT);\n                tsk_error_set_errstr(\"HFS+ offset is zero\");\n                return NULL;\n            }\n            fs_info2 =\n                hfs_open(img_info, offset + hfsplus_offset, ftype, test);\n\n            if (fs_info2)\n                ((HFS_INFO *) fs_info2)->hfs_wrapper_offset =\n                    hfsplus_offset;\n\n            return fs_info2;\n        }\n        else {\n            fs->tag = 0;\n            free(hfs->fs);\n            tsk_fs_free((TSK_FS_INFO *)hfs);\n            tsk_error_set_errno(TSK_ERR_FS_MAGIC);\n            tsk_error_set_errstr\n                (\"HFS file systems (other than wrappers HFS+/HFSX file systems) are not supported\");\n            return NULL;\n        }\n    }\n\n    fs->block_count = tsk_getu32(fs->endian, hfs->fs->blk_cnt);\n    fs->first_block = 0;\n    fs->last_block = fs->last_block_act = fs->block_count - 1;\n\n    /* this isn't really accurate; fs->block_size reports only the size\n       of the allocation block; the size of the device block has to be\n       found from the device (allocation block size should always be\n       larger than device block size and an even multiple of the device\n       block size) */\n    fs->dev_bsize = fs->block_size =\n        tsk_getu32(fs->endian, hfs->fs->blk_sz);\n\n    // determine the last block we have in this image\n    if (fs->block_size <= 1) {\n        fs->tag = 0;\n        free(hfs->fs);\n        tsk_fs_free((TSK_FS_INFO *)hfs);\n        tsk_error_set_errno(TSK_ERR_FS_CORRUPT);\n        tsk_error_set_errstr(\"HFS+ allocation block size too small\");\n        return NULL;\n    }\n    if ((TSK_DADDR_T) ((img_info->size - offset) / fs->block_size) <\n        fs->block_count)\n        fs->last_block_act =\n            (img_info->size - offset) / fs->block_size - 1;\n\n    // Initialize the lock\n    tsk_init_lock(&(hfs->metadata_dir_cache_lock));\n\n    /*\n     * Set function pointers\n     */\n    fs->inode_walk = hfs_inode_walk;\n    fs->block_walk = hfs_block_walk;\n    fs->block_getflags = hfs_block_getflags;\n    fs->load_attrs = hfs_load_attrs;\n    fs->get_default_attr_type = hfs_get_default_attr_type;\n\n    fs->file_add_meta = hfs_inode_lookup;\n    fs->dir_open_meta = hfs_dir_open_meta;\n    fs->fsstat = hfs_fsstat;\n    fs->fscheck = hfs_fscheck;\n    fs->istat = hfs_istat;\n    fs->close = hfs_close;\n\n    // lazy loading of block map\n    hfs->blockmap_file = NULL;\n    hfs->blockmap_attr = NULL;\n    hfs->blockmap_cache_start = -1;\n    hfs->blockmap_cache_len = 0;\n\n    fs->first_inum = HFS_ROOT_INUM;\n    fs->root_inum = HFS_ROOT_INUM;\n    fs->last_inum = HFS_FIRST_USER_CNID - 1;    // we will later increase this\n    fs->inum_count = fs->last_inum - fs->first_inum + 1;\n\n    /* We will load the extents file data when we need it */\n    hfs->extents_file = NULL;\n    hfs->extents_attr = NULL;\n\n    if (tsk_getu32(fs->endian,\n                hfs->fs->start_file.extents[0].blk_cnt) == 0) {\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_open: Optional Startup File is not present.\\n\");\n            hfs->has_startup_file = FALSE;\n        }\n    else {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_open: Startup File is present.\\n\");\n        hfs->has_startup_file = TRUE;\n    }\n\n    if (tsk_getu32(fs->endian, hfs->fs->ext_file.extents[0].blk_cnt) == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: Optional Extents File (and Badblocks File) is not present.\\n\");\n        hfs->has_extents_file = FALSE;\n    }\n    else {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: Extents File (and BadBlocks File) is present.\\n\");\n        hfs->has_extents_file = TRUE;\n    }\n\n    if (tsk_getu32(fs->endian, hfs->fs->attr_file.extents[0].blk_cnt) == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: Optional Attributes File is not present.\\n\");\n        hfs->has_attributes_file = FALSE;\n    }\n    else {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_open: Attributes File is present.\\n\");\n        hfs->has_attributes_file = TRUE;\n    }\n\n    /* Load the catalog file though */\n    if ((hfs->catalog_file =\n            tsk_fs_file_open_meta(fs, NULL,\n                HFS_CATALOG_FILE_ID)) == NULL) {\n        hfs_close(fs);\n        return NULL;\n    }\n\n    /* cache the data attribute */\n    hfs->catalog_attr =\n        tsk_fs_attrlist_get(hfs->catalog_file->meta->attr,\n        TSK_FS_ATTR_TYPE_DEFAULT);\n    if (!hfs->catalog_attr) {\n        hfs_close(fs);\n        tsk_error_errstr2_concat\n            (\" - Data Attribute not found in Catalog File\");\n        return NULL;\n    }\n\n    // cache the catalog file header\n    cnt = tsk_fs_attr_read(hfs->catalog_attr, 14,\n        (char *) &(hfs->catalog_header),\n        sizeof(hfs_btree_header_record), 0);\n    if (cnt != sizeof(hfs_btree_header_record)) {\n        if (cnt >= 0) {\n            tsk_error_reset();\n            tsk_error_set_errno(TSK_ERR_FS_READ);\n        }\n        hfs_close(fs);\n        tsk_error_set_errstr2(\"hfs_open: Error reading catalog header\");\n        return NULL;\n    }\n\n    if (tsk_getu16(fs->endian, hfs->fs->version) == HFS_VH_VER_HFSPLUS)\n        hfs->is_case_sensitive = 0;\n    else if (tsk_getu16(fs->endian, hfs->fs->version) == HFS_VH_VER_HFSX) {\n        if (hfs->catalog_header.compType == HFS_BT_HEAD_COMP_SENS)\n            hfs->is_case_sensitive = 1;\n        else if (hfs->catalog_header.compType == HFS_BT_HEAD_COMP_INSENS)\n            hfs->is_case_sensitive = 0;\n        else {\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_open: invalid value (0x%02\" PRIx8\n                    \") for key compare type; using case-insensitive\\n\",\n                    hfs->catalog_header.compType);\n            hfs->is_case_sensitive = 0;\n        }\n    }\n    else {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: unknown HFS+/HFSX version (%\" PRIu16 \"\\n\",\n                tsk_getu16(fs->endian, hfs->fs->version));\n        hfs->is_case_sensitive = 0;\n    }\n\n    // update the numbers.\n    fs->last_inum = hfs_find_highest_inum(hfs);\n    fs->inum_count = fs->last_inum + 1;\n\n    snprintf((char *) fs->fs_id, 17, \"%08\" PRIx32 \"%08\" PRIx32,\n        tsk_getu32(fs->endian, hfs->fs->finder_info[HFS_VH_FI_ID1]),\n        tsk_getu32(fs->endian, hfs->fs->finder_info[HFS_VH_FI_ID2]));\n    fs->fs_id_used = 16;\n\n    /* journal */\n    fs->jblk_walk = hfs_jblk_walk;\n    fs->jentry_walk = hfs_jentry_walk;\n    fs->jopen = hfs_jopen;\n    fs->name_cmp = hfs_name_cmp;\n    fs->journ_inum = 0;\n\n    /* Creation Times */\n\n    // First, the root\n    file = tsk_fs_file_open_meta(fs, NULL, 2);\n    if (file != NULL) {\n        hfs->root_crtime = file->meta->crtime;\n        hfs->has_root_crtime = TRUE;\n        tsk_fs_file_close(file);\n    }\n    else {\n        hfs->has_root_crtime = FALSE;\n    }\n    file = NULL;\n\n    // disable hard link traversal while finding the hard\n    // link directories themselves (to prevent problems if\n    // there are hard links in the root directory)\n    hfs->meta_inum = 0;\n    hfs->meta_dir_inum = 0;\n\n    // Now the (file) metadata directory\n\n    // The metadata directory is a sub-directory of the root.  Its name begins with four nulls, followed\n    // by \"HFS+ Private Data\".  The file system parsing code replaces nulls in filenames with UTF8_NULL_REPLACE.\n    // In the released version of TSK, this replacement is the character '^'.\n    // NOTE: There is a standard Unicode replacement which is 0xfffd in UTF16 and 0xEF 0xBF 0xBD in UTF8.\n    // Systems that require the standard definition can redefine UTF8_NULL_REPLACE and UTF16_NULL_REPLACE\n    // in tsk_hfs.h\n    hfs->has_meta_crtime = FALSE;\n    result =\n        tsk_fs_path2inum(fs,\n        \"/\" UTF8_NULL_REPLACE UTF8_NULL_REPLACE UTF8_NULL_REPLACE\n        UTF8_NULL_REPLACE \"HFS+ Private Data\", &inum, NULL);\n    if (result == 0) {\n        TSK_FS_FILE *file_tmp = tsk_fs_file_open_meta(fs, NULL, inum);\n        if (file_tmp != NULL) {\n            hfs->meta_crtime = file_tmp->meta->crtime;\n            hfs->has_meta_crtime = TRUE;\n            hfs->meta_inum = inum;\n            tsk_fs_file_close(file_tmp);\n        }\n    }\n\n    // Now, the directory metadata directory\n\n    // The \"directory\" metadata directory, where hardlinked directories actually live, is a subdirectory\n    // of the root.  The beginning of the name of this directory is \".HFS+ Private Directory Data\" which\n    // is followed by a carriage return (ASCII 13).\n    hfs->has_meta_dir_crtime = FALSE;\n    result =\n        tsk_fs_path2inum(fs, \"/.HFS+ Private Directory Data\\r\", &inum,\n        NULL);\n    if (result == 0) {\n        TSK_FS_FILE *file_tmp = tsk_fs_file_open_meta(fs, NULL, inum);\n        if (file_tmp != NULL) {\n            hfs->metadir_crtime = file_tmp->meta->crtime;\n            hfs->has_meta_dir_crtime = TRUE;\n            hfs->meta_dir_inum = inum;\n            tsk_fs_file_close(file_tmp);\n        }\n    }\n\n    if (hfs->has_root_crtime && hfs->has_meta_crtime\n        && hfs->has_meta_dir_crtime) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: Creation times for key folders have been read and cached.\\n\");\n    }\n    if (!hfs->has_root_crtime) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: Warning: Could not open the root directory.  \"\n                \"Hard link detection and some other functions will be impaired\\n\");\n    }\n    else if (tsk_verbose) {\n        tsk_fprintf(stderr,\n            \"hfs_open: The root directory is accessible.\\n\");\n    }\n\n    if (tsk_verbose) {\n        if (hfs->has_meta_crtime)\n            tsk_fprintf(stderr,\n                \"hfs_open: \\\"/^^^^HFS+ Private Data\\\" metadata folder is accessible.\\n\");\n        else\n            tsk_fprintf(stderr,\n                \"hfs_open: Optional \\\"^^^^HFS+ Private Data\\\" metadata folder is not accessible, or does not exist.\\n\");\n        if (hfs->has_meta_dir_crtime)\n            tsk_fprintf(stderr,\n                \"hfs_open: \\\"/HFS+ Private Directory Data^\\\" metadata folder is accessible.\\n\");\n        else\n            tsk_fprintf(stderr,\n                \"hfs_open: Optional \\\"/HFS+ Private Directory Data^\\\" metadata folder is not accessible, or does not exist.\\n\");\n    }\n\n    // These caches will be set, if they are needed.\n    hfs->meta_dir = NULL;\n    hfs->dir_meta_dir = NULL;\n\n    return fs;\n}\n\n\n/*\n * Error Handling\n */\n\n/**\n * Call this when an error is first detected.  It sets the error code and it also\n * sets the primary error string, describing the lowest level of error.  (Actually,\n * it appends to the error string.)\n *\n * If the error code is already set, then this appends to the primary error\n * string an hex representation of the new error code, plus the new error message.\n *\n * @param errnum  The desired error code\n * @param errstr  The format string for the error message\n */\nvoid\nerror_detected(uint32_t errnum, char *errstr, ...)\n{\n    va_list args;\n\n    va_start(args, errstr);\n\n    {\n        TSK_ERROR_INFO *errInfo = tsk_error_get_info();\n        char *loc_errstr = errInfo->errstr;\n\n        if (errInfo->t_errno == 0)\n            errInfo->t_errno = errnum;\n        else {\n            //This should not happen!  We don't want to wipe out the existing error\n            //code, so we write the new code into the error string, in hex.\n            int sl = strlen(errstr);\n            snprintf(loc_errstr + sl, TSK_ERROR_STRING_MAX_LENGTH - sl,\n                \" Next errnum: 0x%x \", errnum);\n        }\n        if (errstr != NULL) {\n            int sl = strlen(loc_errstr);\n            vsnprintf(loc_errstr + sl, TSK_ERROR_STRING_MAX_LENGTH - sl,\n                errstr, args);\n        }\n    }\n\n    va_end(args);\n\n}\n\n/**\n * Call this when a called TSK function returns an error.  Presumably, that\n * function will have set the error code and the primary error string.  This\n * *appends* to the secondary error string.  It should be called to describe\n * the context of the call.  If no error code has been set, then this sets a\n * default code so that it is not zero.\n *\n * @param errstr  The format string for the error message\n */\nvoid\nerror_returned(char *errstr, ...)\n{\n    va_list args;\n    va_start(args, errstr);\n\n    {\n        TSK_ERROR_INFO *errInfo = tsk_error_get_info();\n        char *loc_errstr2 = errInfo->errstr2;\n\n        if (errInfo->t_errno == 0)\n            errInfo->t_errno = TSK_ERR_AUX_GENERIC;\n        if (errstr != NULL) {\n            int sl = strlen(loc_errstr2);\n            vsnprintf(loc_errstr2 + sl, TSK_ERROR_STRING_MAX_LENGTH - sl,\n                errstr, args);\n        }\n    }\n    va_end(args);\n}\n"], "fixing_code": ["/*\n** The Sleuth Kit\n**\n** This software is subject to the IBM Public License ver. 1.0,\n** which was displayed prior to download and is included in the readme.txt\n** file accompanying the Sleuth Kit files.  It may also be requested from:\n** Crucial Security Inc.\n** 14900 Conference Center Drive\n** Chantilly, VA 20151\n**\n\n** Copyright (c) 2009 Brian Carrier.  All rights reserved.\n**\n** Judson Powers [jpowers@atc-nycorp.com]\n** Matt Stillerman [matt@atc-nycorp.com]\n** Rob Joyce [rob@atc-nycorp.com]\n** Copyright (c) 2008, 2012 ATC-NY.  All rights reserved.\n** This file contains data developed with support from the National\n** Institute of Justice, Office of Justice Programs, U.S. Department of Justice.\n**\n** Wyatt Banks [wbanks@crucialsecurity.com]\n** Copyright (c) 2005 Crucial Security Inc.  All rights reserved.\n**\n** Brian Carrier [carrier@sleuthkit.org]\n** Copyright (c) 2003-2005 Brian Carrier.  All rights reserved\n**\n** Copyright (c) 1997,1998,1999, International Business Machines\n** Corporation and others. All Rights Reserved.\n*/\n\n/* TCT\n * LICENSE\n *      This software is distributed under the IBM Public License.\n * AUTHOR(S)\n *      Wietse Venema\n *      IBM T.J. Watson Research\n *      P.O. Box 704\n *      Yorktown Heights, NY 10598, USA\n --*/\n\n/*\n** You may distribute the Sleuth Kit, or other software that incorporates\n** part of all of the Sleuth Kit, in object code form under a license agreement,\n** provided that:\n** a) you comply with the terms and conditions of the IBM Public License\n**    ver 1.0; and\n** b) the license agreement\n**     i) effectively disclaims on behalf of all Contributors all warranties\n**        and conditions, express and implied, including warranties or\n**        conditions of title and non-infringement, and implied warranties\n**        or conditions of merchantability and fitness for a particular\n**        purpose.\n**    ii) effectively excludes on behalf of all Contributors liability for\n**        damages, including direct, indirect, special, incidental and\n**        consequential damages such as lost profits.\n**   iii) states that any provisions which differ from IBM Public License\n**        ver. 1.0 are offered by that Contributor alone and not by any\n**        other party; and\n**    iv) states that the source code for the program is available from you,\n**        and informs licensees how to obtain it in a reasonable manner on or\n**        through a medium customarily used for software exchange.\n**\n** When the Sleuth Kit or other software that incorporates part or all of\n** the Sleuth Kit is made available in source code form:\n**     a) it must be made available under IBM Public License ver. 1.0; and\n**     b) a copy of the IBM Public License ver. 1.0 must be included with\n**        each copy of the program.\n*/\n\n/** \\file hfs.c\n * Contains the general internal TSK HFS metadata and data unit code\n */\n\n#include \"tsk_fs_i.h\"\n#include \"tsk_hfs.h\"\n\n#include <stdarg.h>\n#ifdef TSK_WIN32\n#include <string.h>\n#else\n#include <strings.h>\n#endif\n\n#define XSWAP(a,b) { a ^= b; b ^= a; a ^= b; }\n\n// Compression Stuff\n\n#ifdef HAVE_LIBZ\n#include <zlib.h>\n#endif\n\n#include \"lzvn.h\"\n\n// Forward declarations:\nstatic uint8_t hfs_load_attrs(TSK_FS_FILE * fs_file);\nstatic uint8_t hfs_load_extended_attrs(TSK_FS_FILE * file,\n    unsigned char *isCompressed, unsigned char *cmpType,\n    uint64_t * uncSize);\nvoid error_detected(uint32_t errnum, char *errstr, ...);\nvoid error_returned(char *errstr, ...);\n\n#ifdef HAVE_LIBZ\n\n/***************** ZLIB stuff *******************************/\n\n// Adapted from zpipe.c (part of zlib) at http://zlib.net/zpipe.c\n#define CHUNK 16384\n\n/*\n * Invokes the zlib library to inflate (uncompress) data.\n *\n * Returns and error code.  Places the uncompressed data in a buffer supplied by the caller.  Also\n * returns the uncompressed length, and the number of compressed bytes consumed.\n *\n * Will stop short of the end of compressed data, if a natural end of a compression unit is reached.  Using\n * bytesConsumed, the caller can then advance the source pointer, and re-invoke the function.  This will then\n * inflate the next following compression unit in the data stream.\n *\n * @param source - buffer of compressed data\n * @param sourceLen  - length of the compressed data.\n * @param dest  -- buffer to  hold the uncompressed results\n * @param destLen -- length of the dest buffer\n * @param uncompressedLength  -- return of the length of the uncompressed data found.\n * @param bytesConsumed  -- return of the number of input bytes of compressed data used.\n * @return 0 on success, a negative number on error\n */\nstatic int\nzlib_inflate(char *source, uint64_t sourceLen, char *dest, uint64_t destLen, uint64_t * uncompressedLength, unsigned long *bytesConsumed)       // this is unsigned long because that's what zlib uses.\n{\n\n    int ret;\n    unsigned have;\n    z_stream strm;\n    unsigned char in[CHUNK];\n    unsigned char out[CHUNK];\n\n    // Some vars to help with copying bytes into \"in\"\n    char *srcPtr = source;\n    char *destPtr = dest;\n    uint64_t srcAvail = sourceLen;      //uint64_t\n    uint64_t amtToCopy;\n    uint64_t copiedSoFar = 0;\n\n    /* allocate inflate state */\n    strm.zalloc = Z_NULL;\n    strm.zfree = Z_NULL;\n    strm.opaque = Z_NULL;\n    strm.avail_in = 0;\n    strm.next_in = Z_NULL;\n    ret = inflateInit(&strm);\n    if (ret != Z_OK) {\n        error_detected(TSK_ERR_FS_READ,\n            \"zlib_inflate: failed to initialize inflation engine (%d)\",\n            ret);\n        return ret;\n    }\n\n    /* decompress until deflate stream ends or end of file */\n    do {\n\n        // Copy up to CHUNK bytes into \"in\" from source, advancing the pointer, and\n        // setting strm.avail_in equal to the number of bytes copied.\n        if (srcAvail >= CHUNK) {\n            amtToCopy = CHUNK;\n            srcAvail -= CHUNK;\n        }\n        else {\n            amtToCopy = srcAvail;\n            srcAvail = 0;\n        }\n        // wipe out any previous value, copy in the bytes, advance the pointer, record number of bytes.\n        memset(in, 0, CHUNK);\n        if (amtToCopy > SIZE_MAX || amtToCopy > UINT_MAX) {\n            error_detected(TSK_ERR_FS_READ,\n                \"zlib_inflate: amtToCopy in one chunk is too large\");\n            return -100;\n        }\n        memcpy(in, srcPtr, (size_t) amtToCopy); // cast OK because of above test\n        srcPtr += amtToCopy;\n        strm.avail_in = (uInt) amtToCopy;       // cast OK because of above test\n\n        if (strm.avail_in == 0)\n            break;\n        strm.next_in = in;\n\n        /* run inflate() on input until output buffer not full */\n        do {\n            strm.avail_out = CHUNK;\n            strm.next_out = out;\n            ret = inflate(&strm, Z_NO_FLUSH);\n            if (ret == Z_NEED_DICT)\n                ret = Z_DATA_ERROR;     // we don't have a custom dict\n            if (ret < 0 && ret != Z_BUF_ERROR) { // Z_BUF_ERROR is not fatal\n                error_detected(TSK_ERR_FS_READ,\n                    \" zlib_inflate: zlib returned error %d (%s)\", ret,\n                    strm.msg);\n                (void) inflateEnd(&strm);\n                return ret;\n            }\n\n            have = CHUNK - strm.avail_out;\n            // Is there enough space in dest to copy the current chunk?\n            if (copiedSoFar + have > destLen) {\n                // There is not enough space, so better return an error\n                error_detected(TSK_ERR_FS_READ,\n                    \" zlib_inflate: not enough space in inflation destination\\n\");\n                (void) inflateEnd(&strm);\n                return -200;\n            }\n\n            // Copy \"have\" bytes from out to destPtr, advance destPtr\n            memcpy(destPtr, out, have);\n            destPtr += have;\n            copiedSoFar += have;\n\n        } while ((strm.avail_out == 0) && (ret != Z_STREAM_END));\n\n\n        /* done when inflate() says it's done */\n    } while (ret != Z_STREAM_END);\n\n    if (ret == Z_STREAM_END)\n        *uncompressedLength = copiedSoFar;\n\n    *bytesConsumed = strm.total_in;\n    /* clean up and return */\n    (void) inflateEnd(&strm);\n    return ret == Z_STREAM_END ? Z_OK : Z_DATA_ERROR;\n}\n\n#endif\n\n/* may set error up to string 1\n * returns 0 on success, 1 on failure */\nuint8_t\nhfs_checked_read_random(TSK_FS_INFO * fs, char *buf, size_t len,\n    TSK_OFF_T offs)\n{\n    ssize_t r;\n\n    r = tsk_fs_read(fs, offs, buf, len);\n    if (r != len) {\n        if (r >= 0) {\n            tsk_error_reset();\n            tsk_error_set_errno(TSK_ERR_FS_READ);\n        }\n        return 1;\n    }\n    return 0;\n}\n\n/**********************************************************************\n *\n *  MISC FUNCS\n *\n **********************************************************************/\n\n/* convert the HFS Time (seconds from 1/1/1904)\n * to UNIX (UTC seconds from 1/1/1970)\n * The number is borrowed from linux HFS driver source\n */\nuint32_t\nhfs_convert_2_unix_time(uint32_t hfsdate)\n{\n    if (hfsdate < NSEC_BTWN_1904_1970)\n        return 0;\n    return (uint32_t) (hfsdate - NSEC_BTWN_1904_1970);\n}\n\n\n/**\n * Convert a cnid (metadata address) to big endian array.\n * This is used to create the key for tree lookups.\n * @param cnid Metadata address to convert\n * @param array [out] Array to write data into.\n */\nstatic void\ncnid_to_array(uint32_t cnid, uint8_t array[4])\n{\n    array[3] = (cnid >> 0) & 0xff;\n    array[2] = (cnid >> 8) & 0xff;\n    array[1] = (cnid >> 16) & 0xff;\n    array[0] = (cnid >> 24) & 0xff;\n}\n\n/**********************************************************************\n *\n * Lookup Functions\n *\n **********************************************************************/\n\n\n\n/* Compares the given HFS+ Extents B-tree key to key constructed\n * for finding the beginning of the data fork extents for the given\n * CNID. (That is, the search key uses the given CNID and has\n * fork = 0 and start_block = 0.)\n */\nstatic int\nhfs_ext_compare_keys(HFS_INFO * hfs, uint32_t cnid,\n    const hfs_btree_key_ext * key)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    uint32_t key_cnid;\n\n    key_cnid = tsk_getu32(fs->endian, key->file_id);\n    if (key_cnid < cnid)\n        return -1;\n    if (key_cnid > cnid)\n        return 1;\n\n    /* referring to the same cnids */\n\n    /* we are always looking for the data fork */\n    if (key->fork_type != HFS_EXT_KEY_TYPE_DATA)\n        return 1;\n\n    /* we are always looking for a start_block of zero\n       (interested in the beginning of the extents, regardless\n       of what the start_block is); all files except the bad\n       blocks file should have a start_block greater than\n       zero */\n    if (tsk_getu32(fs->endian, key->start_block) == 0)\n        return 0;\n    return 1;\n}\n\n\n/** \\internal\n * Returns the length of an HFS+ B-tree INDEX key based on the tree header\n * structure and the length claimed in the record.  With some trees,\n * the length given in the record is not used.\n * Note that this neither detects nor correctly handles 8-bit keys\n * (which should not be present in HFS+).\n *\n * This does not give the right answer for the Attributes File B-tree, for some\n * HFS+ file systems produced by the Apple OS, while it works for others.  For\n * the Attributes file, INDEX keys should always be as stated in the record itself,\n * never the \"maxKeyLen\" of the B-tree header.\n *\n * In this software, this function is only invoked when dealing with the Extents file.  In\n * that usage, it is not sufficiently well tested to know if it always gives the right\n * answer or not.  We can only test that with a highly fragmented disk.\n * @param hfs File System\n * @param keylen Length of key as given in record\n * @param header Tree header\n * @returns Length of key\n */\nuint16_t\nhfs_get_idxkeylen(HFS_INFO * hfs, uint16_t keylen,\n    const hfs_btree_header_record * header)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n\n    // if the flag is set, use the length given in the record\n    if (tsk_getu32(fs->endian, header->attr) & HFS_BT_HEAD_ATTR_VARIDXKEYS)\n        return keylen;\n    else\n        return tsk_getu16(fs->endian, header->maxKeyLen);\n}\n\n\n/**\n * Convert the extents runs to TSK_FS_ATTR_RUN runs.\n *\n * @param a_fs File system to analyze\n * @param a_extents Raw extents to process (in an array of 8)\n * @param a_start_off Starting block offset of these runs\n * @returns NULL on error or if no runs are in extents (test tsk_errno)\n */\nstatic TSK_FS_ATTR_RUN *\nhfs_extents_to_attr(TSK_FS_INFO * a_fs, const hfs_ext_desc * a_extents,\n    TSK_OFF_T a_start_off)\n{\n    TSK_FS_ATTR_RUN *head_run = NULL;\n    TSK_FS_ATTR_RUN *prev_run = NULL;\n    int i;\n    TSK_OFF_T cur_off = a_start_off;\n\n    // since tsk_errno is checked as a return value, make sure it is clean.\n    tsk_error_reset();\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_extents_to_attr: Converting extents from offset %\" PRIuOFF\n            \" to runlist\\n\", a_start_off);\n\n    for (i = 0; i < 8; ++i) {\n        TSK_FS_ATTR_RUN *cur_run;\n\n        uint32_t addr = tsk_getu32(a_fs->endian, a_extents[i].start_blk);\n        uint32_t len = tsk_getu32(a_fs->endian, a_extents[i].blk_cnt);\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_extents_to_attr: run %i at addr %\" PRIu32\n                \" with len %\" PRIu32 \"\\n\", i, addr, len);\n\n        if ((addr == 0) && (len == 0)) {\n            break;\n        }\n\n        // make a non-resident run\n        if ((cur_run = tsk_fs_attr_run_alloc()) == NULL) {\n            error_returned(\" - hfs_extents_to_attr\");\n            return NULL;\n        }\n\n        cur_run->addr = addr;\n        cur_run->len = len;\n        cur_run->offset = cur_off;\n\n        if (head_run == NULL)\n            head_run = cur_run;\n        if (prev_run != NULL)\n            prev_run->next = cur_run;\n        cur_off += cur_run->len;\n        prev_run = cur_run;\n    }\n\n    return head_run;\n}\n\n\n/**\n * Look in the extents catalog for entries for a given file. Add the runs\n * to the passed attribute structure.\n *\n * @param hfs File system being analyzed\n * @param cnid file id of file to search for\n * @param a_attr Attribute to add extents runs to\n * @param dataForkQ  if true, then find extents for the data fork.  If false, then find extents for the Resource fork.\n * @returns 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_ext_find_extent_record_attr(HFS_INFO * hfs, uint32_t cnid,\n    TSK_FS_ATTR * a_attr, unsigned char dataForkQ)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    uint16_t nodesize;          /* size of nodes (all, regardless of the name) */\n    uint32_t cur_node;          /* node id of the current node */\n    char *node = NULL;\n    uint8_t is_done;\n    uint8_t desiredType;\n\n    tsk_error_reset();\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_ext_find_extent_record_attr: Looking for extents for file %\"\n            PRIu32 \" %s\\n\", cnid,\n            dataForkQ ? \"data fork\" : \"resource fork\");\n\n    if (!hfs->has_extents_file) {\n        // No extents file (which is optional), and so, no further extents are possible.\n        return 0;\n    }\n\n    // Are we looking for extents of the data fork or the resource fork?\n    desiredType =\n        dataForkQ ? HFS_EXT_KEY_TYPE_DATA : HFS_EXT_KEY_TYPE_RSRC;\n\n    // Load the extents attribute, if it has not been done so yet.\n    if (hfs->extents_file == NULL) {\n        ssize_t cnt;\n\n        if ((hfs->extents_file =\n                tsk_fs_file_open_meta(fs, NULL,\n                    HFS_EXTENTS_FILE_ID)) == NULL) {\n            return 1;\n        }\n\n        /* cache the data attribute */\n        hfs->extents_attr =\n            tsk_fs_attrlist_get(hfs->extents_file->meta->attr,\n            TSK_FS_ATTR_TYPE_DEFAULT);\n        if (!hfs->extents_attr) {\n            tsk_error_errstr2_concat\n                (\" - Default Attribute not found in Extents File\");\n            return 1;\n        }\n\n        // cache the extents file header\n        cnt = tsk_fs_attr_read(hfs->extents_attr, 14,\n            (char *) &(hfs->extents_header),\n            sizeof(hfs_btree_header_record), 0);\n        if (cnt != sizeof(hfs_btree_header_record)) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_ext_find_extent_record_attr: Error reading header\");\n            return 1;\n        }\n    }\n\n    // allocate a node buffer\n    nodesize = tsk_getu16(fs->endian, hfs->extents_header.nodesize);\n    if ((node = (char *) tsk_malloc(nodesize)) == NULL) {\n        return 1;\n    }\n\n    /* start at root node */\n    cur_node = tsk_getu32(fs->endian, hfs->extents_header.rootNode);\n\n    /* if the root node is zero, then the extents btree is empty */\n    /* if no files have overflow extents, the Extents B-tree still\n       exists on disk, but is an empty B-tree containing only\n       the header node */\n    if (cur_node == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_ext_find_extent_record: \"\n                \"empty extents btree\\n\");\n        free(node);\n        return 0;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_ext_find_extent_record: starting at \"\n            \"root node %\" PRIu32 \"; nodesize = %\"\n            PRIu16 \"\\n\", cur_node, nodesize);\n\n    /* Recurse down to the needed leaf nodes and then go forward */\n    is_done = 0;\n    while (is_done == 0) {\n        TSK_OFF_T cur_off;      /* start address of cur_node */\n        uint16_t num_rec;       /* number of records in this node */\n        ssize_t cnt;\n        hfs_btree_node *node_desc;\n\n        // sanity check\n        if (cur_node > tsk_getu32(fs->endian,\n                hfs->extents_header.totalNodes)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_ext_find_extent_record_attr: Node %d too large for file\",\n                cur_node);\n            free(node);\n            return 1;\n        }\n\n        // read the current node\n        cur_off = (TSK_OFF_T)cur_node * nodesize;\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_ext_find_extent_record: reading node %\" PRIu32\n                \" at offset %\" PRIuOFF \"\\n\", cur_node, cur_off);\n\n        cnt = tsk_fs_attr_read(hfs->extents_attr, cur_off,\n            node, nodesize, 0);\n        if (cnt != nodesize) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_ext_find_extent_record_attr: Error reading node %d at offset %\"\n                PRIuOFF, cur_node, cur_off);\n            free(node);\n            return 1;\n        }\n\n        // process the header / descriptor\n        if (nodesize < sizeof(hfs_btree_node)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_ext_find_extent_record_attr: Node size %d is too small to be valid\", nodesize);\n            free(node);\n            return 1;\n        }\n        node_desc = (hfs_btree_node *) node;\n        num_rec = tsk_getu16(fs->endian, node_desc->num_rec);\n\n        if (num_rec == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_ext_find_extent_record: zero records in node %\"\n                PRIu32, cur_node);\n            free(node);\n            return 1;\n        }\n\n\n        /* With an index node, find the record with the largest key that is smaller\n         * to or equal to cnid */\n        if (node_desc->type == HFS_BT_NODE_TYPE_IDX) {\n            uint32_t next_node = 0;\n            int rec;\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_ext_find_extent_record: Index node %\" PRIu32\n                    \" @ %\" PRIu64 \" has %\" PRIu16 \" records\\n\", cur_node,\n                    cur_off, num_rec);\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                int cmp;\n                size_t rec_off;\n                hfs_btree_key_ext *key;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off + sizeof(hfs_btree_key_ext) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_ext_find_extent_record_attr: offset of record %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_ext *) & node[rec_off];\n\n                cmp = hfs_ext_compare_keys(hfs, cnid, key);\n\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_ext_find_extent_record: record %\" PRIu16\n                        \" ; keylen %\" PRIu16 \" (FileId: %\" PRIu32\n                        \", ForkType: %\" PRIu8 \", StartBlk: %\" PRIu32\n                        \"); compare: %d\\n\", rec, tsk_getu16(fs->endian,\n                            key->key_len), tsk_getu32(fs->endian,\n                            key->file_id), key->fork_type,\n                        tsk_getu32(fs->endian, key->start_block), cmp);\n\n                /* save the info from this record unless it is bigger than cnid */\n                if ((cmp <= 0) || (next_node == 0)) {\n                    hfs_btree_index_record *idx_rec;\n                    int keylen =\n                        2 + hfs_get_idxkeylen(hfs, tsk_getu16(fs->endian,\n                            key->key_len), &(hfs->extents_header));\n                    if (rec_off + keylen > nodesize) {\n                        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                        tsk_error_set_errstr\n                            (\"hfs_ext_find_extent_record_attr: offset and keylenth of record %d in index node %d too large (%d vs %\"\n                            PRIu16 \")\", rec, cur_node,\n                            (int) rec_off + keylen, nodesize);\n                        free(node);\n                        return 1;\n                    }\n                    idx_rec =\n                        (hfs_btree_index_record *) & node[rec_off +\n                        keylen];\n                    next_node = tsk_getu32(fs->endian, idx_rec->childNode);\n                }\n\n                // we are bigger than cnid, so move on to the next node\n                if (cmp > 0) {\n                    break;\n                }\n            }\n\n            // check if we found a relevant node, if not stop.\n            if (next_node == 0) {\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_ext_find_extent_record_attr: did not find any keys for %d in index node %d\",\n                        cnid, cur_node);\n                is_done = 1;\n                break;\n            }\n            cur_node = next_node;\n        }\n\n        /* with a leaf, we process until we are past cnid.  We move right too if we can */\n        else if (node_desc->type == HFS_BT_NODE_TYPE_LEAF) {\n            int rec;\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_ext_find_extent_record: Leaf node %\" PRIu32 \" @ %\"\n                    PRIu64 \" has %\" PRIu16 \" records\\n\", cur_node, cur_off,\n                    num_rec);\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_ext *key;\n                uint32_t rec_cnid;\n                hfs_extents *extents;\n                TSK_OFF_T ext_off = 0;\n                int keylen;\n                TSK_FS_ATTR_RUN *attr_run;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_ext_find_extent_record_attr: offset of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_ext *) & node[rec_off];\n\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_ext_find_extent_record: record %\" PRIu16\n                        \"; keylen %\" PRIu16 \" (%\" PRIu32\n                        \", %\" PRIu8 \", %\" PRIu32 \")\\n\", rec,\n                        tsk_getu16(fs->endian, key->key_len),\n                        tsk_getu32(fs->endian, key->file_id),\n                        key->fork_type, tsk_getu32(fs->endian,\n                            key->start_block));\n\n                rec_cnid = tsk_getu32(fs->endian, key->file_id);\n\n                // see if this record is for our file\n                // OLD logic, just handles the DATA fork\n//                if (rec_cnid < cnid) {\n//                    continue;\n//                }\n//                else if ((rec_cnid > cnid)\n//                    || (key->fork_type != HFS_EXT_KEY_TYPE_DATA)) {\n//                    is_done = 1;\n//                    break;\n//                }\n\n                // NEW logic, handles both DATA and RSRC forks.\n                if (rec_cnid < cnid) {\n                    continue;\n                }\n                if (rec_cnid > cnid) {\n                    is_done = 1;\n                    break;\n                }\n\n\n                if (key->fork_type != desiredType) {\n                    if (dataForkQ) {\n                        is_done = 1;\n                        break;\n                    }\n                    else\n                        continue;\n                }\n\n                // OK, this is one of the extents records that we are seeking, so save it.\n                // Make sure there is room for the hfs_extents struct\n                keylen = 2 + tsk_getu16(fs->endian, key->key_len);\n                if (rec_off + keylen + sizeof(hfs_extents) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_ext_find_extent_record_attr: offset and keylenth of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off + keylen,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                // get the starting offset of this extent\n                ext_off = tsk_getu32(fs->endian, key->start_block);\n\n                // convert the extents to the TSK format\n                extents = (hfs_extents *) & node[rec_off + keylen];\n\n                attr_run =\n                    hfs_extents_to_attr(fs, extents->extents, ext_off);\n                if ((attr_run == NULL) && (tsk_error_get_errno() != 0)) {\n                    tsk_error_errstr2_concat\n                        (\" - hfs_ext_find_extent_record_attr\");\n                    free(node);\n                    return 1;\n                }\n\n                if (tsk_fs_attr_add_run(fs, a_attr, attr_run)) {\n                    tsk_error_errstr2_concat\n                        (\" - hfs_ext_find_extent_record_attr\");\n                    free(node);\n                    return 1;\n                }\n            }\n            cur_node = tsk_getu32(fs->endian, node_desc->flink);\n            if (cur_node == 0) {\n                is_done = 1;\n                break;\n            }\n        }\n        else {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_ext_find_extent_record: btree node %\"\n                PRIu32 \" (%\" PRIuOFF \") is neither index nor leaf (%\" PRIu8\n                \")\", cur_node, cur_off, node_desc->type);\n            free(node);\n            return 1;\n        }\n    }\n    free(node);\n    return 0;\n}\n\n\n/** \\internal\n * Compares two Catalog B-tree keys.\n * @param hfs File System being analyzed\n * @param key1 Key 1 to compare\n * @param key2 Key 2 to compare\n * @returns -1 if key1 is smaller, 0 if equal, and 1 if key1 is larger\n */\nint\nhfs_cat_compare_keys(HFS_INFO * hfs, const hfs_btree_key_cat * key1,\n    const hfs_btree_key_cat * key2)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    uint32_t cnid1, cnid2;\n\n    cnid1 = tsk_getu32(fs->endian, key1->parent_cnid);\n    cnid2 = tsk_getu32(fs->endian, key2->parent_cnid);\n\n    if (cnid1 < cnid2)\n        return -1;\n    if (cnid1 > cnid2)\n        return 1;\n\n    return hfs_unicode_compare(hfs, &key1->name, &key2->name);\n}\n\n\n/** \\internal\n * \n * Traverse the HFS catalog file.  Call the callback for each\n * record. \n *\n * @param hfs File system\n * @param a_cb callback \n * @param ptr Pointer to pass to callback\n * @returns 1 on error\n */\nuint8_t\nhfs_cat_traverse(HFS_INFO * hfs,\n    TSK_HFS_BTREE_CB a_cb, void *ptr)\n{\n    TSK_FS_INFO *fs = &(hfs->fs_info);\n    uint32_t cur_node;          /* node id of the current node */\n    char *node;\n\n    uint16_t nodesize;\n    uint8_t is_done = 0;\n\n    tsk_error_reset();\n\n    nodesize = tsk_getu16(fs->endian, hfs->catalog_header.nodesize);\n    if ((node = (char *) tsk_malloc(nodesize)) == NULL)\n        return 1;\n\n    /* start at root node */\n    cur_node = tsk_getu32(fs->endian, hfs->catalog_header.rootNode);\n\n    /* if the root node is zero, then the extents btree is empty */\n    /* if no files have overflow extents, the Extents B-tree still\n       exists on disk, but is an empty B-tree containing only\n       the header node */\n    if (cur_node == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: \"\n                \"empty extents btree\\n\");\n        free(node);\n        return 1;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_cat_traverse: starting at \"\n            \"root node %\" PRIu32 \"; nodesize = %\"\n            PRIu16 \"\\n\", cur_node, nodesize);\n\n    /* Recurse down to the needed leaf nodes and then go forward */\n    is_done = 0;\n    while (is_done == 0) {\n        TSK_OFF_T cur_off;      /* start address of cur_node */\n        uint16_t num_rec;       /* number of records in this node */\n        ssize_t cnt;\n        hfs_btree_node *node_desc;\n\n        // sanity check\n        if (cur_node > tsk_getu32(fs->endian,\n                hfs->catalog_header.totalNodes)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_cat_traverse: Node %d too large for file\", cur_node);\n            free(node);\n            return 1;\n        }\n\n        // read the current node\n        cur_off = cur_node * nodesize;\n        cnt = tsk_fs_attr_read(hfs->catalog_attr, cur_off,\n            node, nodesize, 0);\n        if (cnt != nodesize) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_traverse: Error reading node %d at offset %\"\n                PRIuOFF, cur_node, cur_off);\n            free(node);\n            return 1;\n        }\n\n        // process the header / descriptor\n        if (nodesize < sizeof(hfs_btree_node)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n            (\"hfs_cat_traverse: Node size %d is too small to be valid\", nodesize);\n            free(node);\n            return 1;\n        }\n        node_desc = (hfs_btree_node *) node;\n        num_rec = tsk_getu16(fs->endian, node_desc->num_rec);\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: node %\" PRIu32\n                \" @ %\" PRIu64 \" has %\" PRIu16 \" records\\n\",\n                cur_node, cur_off, num_rec);\n\n        if (num_rec == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: zero records in node %\"\n                PRIu32, cur_node);\n            free(node);\n            return 1;\n        }\n\n        /* With an index node, find the record with the largest key that is smaller\n         * to or equal to cnid */\n        if (node_desc->type == HFS_BT_NODE_TYPE_IDX) {\n            uint32_t next_node = 0;\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                int keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \" ; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n\n\n                /* save the info from this record unless it is too big */\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_IDX, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n                // record the closest entry\n                else if ((retval == HFS_BTREE_CB_IDX_LT)\n                    || (next_node == 0)) {\n                    hfs_btree_index_record *idx_rec;\n                    int keylen =\n                        2 + hfs_get_idxkeylen(hfs, tsk_getu16(fs->endian,\n                            key->key_len), &(hfs->catalog_header));\n                    if (rec_off + keylen > nodesize) {\n                        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                        tsk_error_set_errstr\n                            (\"hfs_cat_traverse: offset of record and keylength %d in index node %d too large (%d vs %\"\n                            PRIu16 \")\", rec, cur_node,\n                            (int) rec_off + keylen, nodesize);\n                        free(node);\n                        return 1;\n                    }\n                    idx_rec =\n                        (hfs_btree_index_record *) & node[rec_off +\n                        keylen];\n                    next_node = tsk_getu32(fs->endian, idx_rec->childNode);\n                }\n                if (retval == HFS_BTREE_CB_IDX_EQGT) {\n                    // move down to the next node\n                    break;\n                }\n            }\n            // check if we found a relevant node\n            if (next_node == 0) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: did not find any keys in index node %d\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            // TODO: Handle multinode loops\n            if (next_node == cur_node) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: node %d references itself as next node\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            cur_node = next_node;\n        }\n\n        /* With a leaf, we look for the specific record. */\n        else if (node_desc->type == HFS_BT_NODE_TYPE_LEAF) {\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                int keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \"; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n                //                rec_cnid = tsk_getu32(fs->endian, key->file_id);\n\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_LEAF, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_LEAF_STOP) {\n                    is_done = 1;\n                    break;\n                }\n                else if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n            }\n\n            // move right to the next node if we got this far\n            if (is_done == 0) {\n                cur_node = tsk_getu32(fs->endian, node_desc->flink);\n                if (cur_node == 0) {\n                    is_done = 1;\n                }\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_cat_traverse: moving forward to next leaf\");\n            }\n        }\n        else {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: btree node %\" PRIu32\n                \" (%\" PRIu64 \") is neither index nor leaf (%\" PRIu8 \")\",\n                cur_node, cur_off, node_desc->type);\n            free(node);\n            return 1;\n        }\n    }\n    free(node);\n    return 0;\n}\n\ntypedef struct {\n    const hfs_btree_key_cat *targ_key;\n    TSK_OFF_T off;\n} HFS_CAT_GET_RECORD_OFFSET_DATA;\n\nstatic uint8_t\nhfs_cat_get_record_offset_cb(HFS_INFO * hfs, int8_t level_type,\n    const hfs_btree_key_cat * cur_key,\n    TSK_OFF_T key_off, void *ptr)\n{\n    HFS_CAT_GET_RECORD_OFFSET_DATA *offset_data = (HFS_CAT_GET_RECORD_OFFSET_DATA *)ptr;\n    const hfs_btree_key_cat *targ_key = offset_data->targ_key;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_cat_get_record_offset_cb: %s node want: %\" PRIu32\n            \" vs have: %\" PRIu32 \"\\n\",\n            (level_type == HFS_BT_NODE_TYPE_IDX) ? \"Index\" : \"Leaf\",\n            tsk_getu32(hfs->fs_info.endian, targ_key->parent_cnid),\n            tsk_getu32(hfs->fs_info.endian, cur_key->parent_cnid));\n\n    if (level_type == HFS_BT_NODE_TYPE_IDX) {\n        int diff = hfs_cat_compare_keys(hfs, cur_key, targ_key);\n        if (diff < 0)\n            return HFS_BTREE_CB_IDX_LT;\n        else\n            return HFS_BTREE_CB_IDX_EQGT;\n    }\n    else {\n        int diff = hfs_cat_compare_keys(hfs, cur_key, targ_key);\n\n        // see if this record is for our file or if we passed the interesting entries\n        if (diff < 0) {\n            return HFS_BTREE_CB_LEAF_GO;\n        }\n        else if (diff == 0) {\n            offset_data->off = \n                key_off + 2 + tsk_getu16(hfs->fs_info.endian,\n                cur_key->key_len);\n        }\n        return HFS_BTREE_CB_LEAF_STOP;\n    }\n}\n\n\n/** \\internal\n * Find the byte offset (from the start of the catalog file) to a record\n * in the catalog file.\n * @param hfs File System being analyzed\n * @param needle Key to search for\n * @returns Byte offset or 0 on error. 0 is also returned if catalog\n * record was not found. Check tsk_errno to determine if error occurred.\n */\nstatic TSK_OFF_T\nhfs_cat_get_record_offset(HFS_INFO * hfs, const hfs_btree_key_cat * needle)\n{\n    HFS_CAT_GET_RECORD_OFFSET_DATA offset_data;\n    offset_data.off = 0;\n    offset_data.targ_key = needle;\n    if (hfs_cat_traverse(hfs, hfs_cat_get_record_offset_cb, &offset_data)) {\n        return 0;\n    }\n    return offset_data.off;\n}\n\n\n\n/** \\internal\n * Given a byte offset to a leaf record in teh catalog file, read the data as\n * a thread record. This will zero the buffer and read in the size of the thread\n * data.\n * @param hfs File System\n * @param off Byte offset of record in catalog file (not including key)\n * @param thread [out] Buffer to write thread data into.\n * @returns 0 on success, 1 on failure; sets up to error string 1 */\nuint8_t\nhfs_cat_read_thread_record(HFS_INFO * hfs, TSK_OFF_T off,\n    hfs_thread * thread)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    uint16_t uni_len;\n    ssize_t cnt;\n\n    memset(thread, 0, sizeof(hfs_thread));\n    cnt = tsk_fs_attr_read(hfs->catalog_attr, off, (char *) thread, 10, 0);\n    if (cnt != 10) {\n        if (cnt >= 0) {\n            tsk_error_reset();\n            tsk_error_set_errno(TSK_ERR_FS_READ);\n        }\n        tsk_error_set_errstr2\n            (\"hfs_cat_read_thread_record: Error reading catalog offset %\"\n            PRIuOFF \" (header)\", off);\n        return 1;\n    }\n\n    if ((tsk_getu16(fs->endian, thread->rec_type) != HFS_FOLDER_THREAD)\n        && (tsk_getu16(fs->endian, thread->rec_type) != HFS_FILE_THREAD)) {\n        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n        tsk_error_set_errstr\n            (\"hfs_cat_read_thread_record: unexpected record type %\" PRIu16,\n            tsk_getu16(fs->endian, thread->rec_type));\n        return 1;\n    }\n\n    uni_len = tsk_getu16(fs->endian, thread->name.length);\n\n    if (uni_len > 255) {\n        tsk_error_set_errno(TSK_ERR_FS_INODE_COR);\n        tsk_error_set_errstr\n            (\"hfs_cat_read_thread_record: invalid string length (%\" PRIu16\n            \")\", uni_len);\n        return 1;\n    }\n\n    cnt =\n        tsk_fs_attr_read(hfs->catalog_attr, off + 10,\n        (char *) thread->name.unicode, uni_len * 2, 0);\n    if (cnt != uni_len * 2) {\n        if (cnt >= 0) {\n            tsk_error_reset();\n            tsk_error_set_errno(TSK_ERR_FS_READ);\n        }\n        tsk_error_set_errstr2\n            (\"hfs_cat_read_thread_record: Error reading catalog offset %\"\n            PRIuOFF \" (name)\", off + 10);\n        return 1;\n    }\n\n    return 0;\n}\n\n/** \\internal\n * Read a catalog record into a local data structure.  This reads the\n * correct amount, depending on if it is a file or folder.\n * @param hfs File system being analyzed\n * @param off Byte offset (in catalog file) of record (not including key)\n * @param record [out] Structure to read data into\n * @returns 1 on error\n */\nuint8_t\nhfs_cat_read_file_folder_record(HFS_INFO * hfs, TSK_OFF_T off,\n    hfs_file_folder * record)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    ssize_t cnt;\n    char rec_type[2];\n\n    memset(record, 0, sizeof(hfs_file_folder));\n\n    cnt = tsk_fs_attr_read(hfs->catalog_attr, off, rec_type, 2, 0);\n    if (cnt != 2) {\n        if (cnt >= 0) {\n            tsk_error_reset();\n            tsk_error_set_errno(TSK_ERR_FS_READ);\n        }\n        tsk_error_set_errstr2\n            (\"hfs_cat_read_file_folder_record: Error reading record type from catalog offset %\"\n            PRIuOFF \" (header)\", off);\n        return 1;\n    }\n\n    if (tsk_getu16(fs->endian, rec_type) == HFS_FOLDER_RECORD) {\n        cnt =\n            tsk_fs_attr_read(hfs->catalog_attr, off, (char *) record,\n            sizeof(hfs_folder), 0);\n        if (cnt != sizeof(hfs_folder)) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_read_file_folder_record: Error reading catalog offset %\"\n                PRIuOFF \" (folder)\", off);\n            return 1;\n        }\n    }\n    else if (tsk_getu16(fs->endian, rec_type) == HFS_FILE_RECORD) {\n        cnt =\n            tsk_fs_attr_read(hfs->catalog_attr, off, (char *) record,\n            sizeof(hfs_file), 0);\n        if (cnt != sizeof(hfs_file)) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_read_file_folder_record: Error reading catalog offset %\"\n                PRIuOFF \" (file)\", off);\n            return 1;\n        }\n    }\n    else {\n        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n        tsk_error_set_errstr\n            (\"hfs_cat_read_file_folder_record: unexpected record type %\"\n            PRIu16, tsk_getu16(fs->endian, rec_type));\n        return 1;\n    }\n\n    return 0;\n}\n\n\n// hfs_lookup_hard_link appears to be unnecessary - it looks up the cnid\n// by seeing if there's a file/dir with the standard hard link name plus\n// linknum and returns the meta_addr. But this should always be the same as linknum,\n// and is very slow when there are many hard links, so it shouldn't be used.\n//static TSK_INUM_T\n//hfs_lookup_hard_link(HFS_INFO * hfs, TSK_INUM_T linknum,\n//    unsigned char is_directory)\n//{\n//    char fBuff[30];\n//    TSK_FS_DIR *mdir;\n//    size_t indx;\n//    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n//\n//    memset(fBuff, 0, 30);\n//\n//    if (is_directory) {\n//\n//        tsk_take_lock(&(hfs->metadata_dir_cache_lock));\n//        if (hfs->dir_meta_dir == NULL) {\n//            hfs->dir_meta_dir =\n//                tsk_fs_dir_open_meta(fs, hfs->meta_dir_inum);\n//        }\n//        tsk_release_lock(&(hfs->metadata_dir_cache_lock));\n//\n//        if (hfs->dir_meta_dir == NULL) {\n//            error_returned\n//                (\"hfs_lookup_hard_link: could not open the dir metadata directory\");\n//            return 0;\n//        }\n//        else {\n//            mdir = hfs->dir_meta_dir;\n//        }\n//        snprintf(fBuff, 30, \"dir_%\" PRIuINUM, linknum);\n//\n//    }\n//    else {\n//\n//        tsk_take_lock(&(hfs->metadata_dir_cache_lock));\n//        if (hfs->meta_dir == NULL) {\n//            hfs->meta_dir = tsk_fs_dir_open_meta(fs, hfs->meta_inum);\n//        }\n//        tsk_release_lock(&(hfs->metadata_dir_cache_lock));\n//\n//        if (hfs->meta_dir == NULL) {\n//            error_returned\n//                (\"hfs_lookup_hard_link: could not open file metadata directory\");\n//            return 0;\n//        }\n//        else {\n//            mdir = hfs->meta_dir;\n//        }\n//        snprintf(fBuff, 30, \"iNode%\" PRIuINUM, linknum);\n//    }\n//\n//    for (indx = 0; indx < tsk_fs_dir_getsize(mdir); ++indx) {\n//        if ((mdir->names != NULL) && mdir->names[indx].name &&\n//            (fs->name_cmp(fs, mdir->names[indx].name, fBuff) == 0)) {\n//            // OK this is the one\n//            return mdir->names[indx].meta_addr;\n//        }\n//    }\n//\n//    // OK, we did not find that linknum\n//    return 0;\n//}\n\n/*\n * Given a catalog entry, will test that entry to see if it is a hard link.\n * If it is a hard link, the function returns the inum (or cnid) of the target file.\n * If it is NOT a hard link, then then function returns the inum of the given entry.\n * In both cases, the parameter is_error is set to zero.\n *\n * If an ERROR occurs, if it is a mild error, then is_error is set to 1, and the\n * inum of the given entry is returned.  This signals that hard link detection cannot\n * be carried out.\n *\n * If the error is serious, then is_error is set to 2 or 3, depending on the kind of error, and\n * the TSK error code is set, and the function returns zero.  is_error==2 means that an error\n * occurred in looking up the target file in the Catalog.  is_error==3 means that the given\n * entry appears to be a hard link, but the target file does not exist in the Catalog.\n *\n * @param hfs The file system\n * @param entry The catalog entry to check\n * @param is_error A Boolean that is returned indicating an error, or no error.\\\n * @return The inum (or cnid) of the hard link target, or of the given catalog entry, or zero.\n */\nTSK_INUM_T\nhfs_follow_hard_link(HFS_INFO * hfs, hfs_file * cat,\n    unsigned char *is_error)\n{\n\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_INUM_T cnid;\n    time_t crtime;\n    uint32_t file_type;\n    uint32_t file_creator;\n\n    *is_error = 0;              // default, not an error\n\n    if (cat == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_follow_hard_link: Pointer to Catalog entry (2nd arg) is null\");\n        return 0;\n    }\n\n    cnid = tsk_getu32(fs->endian, cat->std.cnid);\n\n    if (cnid < HFS_FIRST_USER_CNID) {\n        // Can't be a hard link.  And, cannot look up in Catalog file either!\n        return cnid;\n    }\n\n    crtime =\n        (time_t) hfs_convert_2_unix_time(tsk_getu32(fs->endian,\n            cat->std.crtime));\n\n\n    file_type = tsk_getu32(fs->endian, cat->std.u_info.file_type);\n    file_creator = tsk_getu32(fs->endian, cat->std.u_info.file_cr);\n\n    // Only proceed with the rest of this if the flags etc are right\n    if (file_type == HFS_HARDLINK_FILE_TYPE\n        && file_creator == HFS_HARDLINK_FILE_CREATOR) {\n\n        // see if we have the HFS+ Private Data dir for file links;\n        // if not, it can't be a hard link.  (We could warn the user, but\n        // we also rely on this when finding the HFS+ Private Data dir in\n        // the first place and we don't want a warning on every hfs_open.)\n        if (hfs->meta_inum == 0)\n            return cnid;\n\n        // For this to work, we need the FS creation times.  Is at least one of these set?\n        if ((!hfs->has_root_crtime) && (!hfs->has_meta_dir_crtime)\n            && (!hfs->has_meta_crtime)) {\n            uint32_t linkNum =\n                tsk_getu32(fs->endian, cat->std.perm.special.inum);\n            *is_error = 1;\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"WARNING: hfs_follow_hard_link: File system creation times are not set. \"\n                    \"Cannot test inode for hard link. File type and creator indicate that this\"\n                    \" is a hard link (file), with LINK ID = %\" PRIu32 \"\\n\",\n                    linkNum);\n            return cnid;\n        }\n\n        if ((!hfs->has_root_crtime) || (!hfs->has_meta_crtime)) {\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"WARNING: hfs_follow_hard_link: Either the root folder or the\"\n                    \" file metadata folder is not accessible.  Testing this potential hard link\"\n                    \" may be impaired.\\n\");\n        }\n\n        // Now we need to check the creation time against the three FS creation times\n        if ((hfs->has_meta_crtime && (crtime == hfs->meta_crtime)) ||\n            (hfs->has_meta_dir_crtime && (crtime == hfs->metadir_crtime))\n            || (hfs->has_root_crtime && (crtime == hfs->root_crtime))) {\n            // OK, this is a hard link to a file.\n            uint32_t linkNum =\n                tsk_getu32(fs->endian, cat->std.perm.special.inum);\n\n            // We used to resolve this ID to a file in X folder using hfs_lookup_hard_link, but found \n            // that it was very ineffecient and always resulted in the same linkNum value. \n            // We now just use linkNum\n            return linkNum;\n        }\n    }\n    else if (file_type == HFS_LINKDIR_FILE_TYPE\n        && file_creator == HFS_LINKDIR_FILE_CREATOR) {\n\n        // see if we have the HFS+ Private Directory Data dir for links;\n        // if not, it can't be a hard link.  (We could warn the user, but\n        // we also rely on this when finding the HFS+ Private Directory Data dir in\n        // the first place and we don't want a warning on every hfs_open.)\n        if (hfs->meta_dir_inum == 0)\n            return cnid;\n\n        // For this to work, we need the FS creation times.  Is at least one of these set?\n        if ((!hfs->has_root_crtime) && (!hfs->has_meta_dir_crtime)\n            && (!hfs->has_meta_crtime)) {\n            uint32_t linkNum =\n                tsk_getu32(fs->endian, cat->std.perm.special.inum);\n            *is_error = 1;\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"WARNING: hfs_follow_hard_link: File system creation times are not set. \"\n                    \"Cannot test inode for hard link. File type and creator indicate that this\"\n                    \" is a hard link (directory), with LINK ID = %\" PRIu32\n                    \"\\n\", linkNum);\n            return cnid;\n        }\n\n        if ((!hfs->has_root_crtime) || (!hfs->has_meta_crtime)\n            || (!hfs->has_meta_dir_crtime)) {\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"WARNING: hfs_follow_hard_link: Either the root folder or the\"\n                    \" file metadata folder or the directory metatdata folder is\"\n                    \" not accessible.  Testing this potential hard linked folder \"\n                    \"may be impaired.\\n\");\n        }\n\n        // Now we need to check the creation time against the three FS creation times\n        if ((hfs->has_meta_crtime && (crtime == hfs->meta_crtime)) ||\n            (hfs->has_meta_dir_crtime && (crtime == hfs->metadir_crtime))\n            || (hfs->has_root_crtime && (crtime == hfs->root_crtime))) {\n            // OK, this is a hard link to a directory.\n            uint32_t linkNum =\n                tsk_getu32(fs->endian, cat->std.perm.special.inum);\n\n            // We used to resolve this ID to a file in X folder using hfs_lookup_hard_link, but found \n            // that it was very ineffecient and always resulted in the same linkNum value. \n            // We now just use linkNum\n            return linkNum;\n        }\n    }\n\n    // It cannot be a hard link (file or directory)\n    return cnid;\n}\n\n\n/** \\internal\n * Lookup an entry in the catalog file and save it into the entry.  Do not\n * call this for the special files that do not have an entry in the catalog.\n * data structure.\n * @param hfs File system being analyzed\n * @param inum Address (cnid) of file to open\n * @param entry [out] Structure to read data into\n * @returns 1 on error or not found, 0 on success. Check tsk_errno\n * to differentiate between error and not found.  If it is not found, then the\n * errno will be TSK_ERR_FS_INODE_NUM.  Else, it will be some other value.\n */\nuint8_t\nhfs_cat_file_lookup(HFS_INFO * hfs, TSK_INUM_T inum, HFS_ENTRY * entry,\n    unsigned char follow_hard_link)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n    hfs_btree_key_cat key;      /* current catalog key */\n    hfs_thread thread;          /* thread record */\n    hfs_file_folder record;     /* file/folder record */\n    TSK_OFF_T off;\n\n    tsk_error_reset();\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_cat_file_lookup: called for inum %\" PRIuINUM \"\\n\", inum);\n\n    // Test if this is a special file that is not located in the catalog\n    if ((inum == HFS_EXTENTS_FILE_ID) ||\n        (inum == HFS_CATALOG_FILE_ID) ||\n        (inum == HFS_ALLOCATION_FILE_ID) ||\n        (inum == HFS_STARTUP_FILE_ID) ||\n        (inum == HFS_ATTRIBUTES_FILE_ID)) {\n        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n        tsk_error_set_errstr\n            (\"hfs_cat_file_lookup: Called on special file: %\" PRIuINUM,\n            inum);\n        return 1;\n    }\n\n\n    /* first look up the thread record for the item we're searching for */\n\n    /* set up the thread record key */\n    memset((char *) &key, 0, sizeof(hfs_btree_key_cat));\n    cnid_to_array((uint32_t) inum, key.parent_cnid);\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_cat_file_lookup: Looking up thread record (%\" PRIuINUM\n            \")\\n\", inum);\n\n    /* look up the thread record */\n    off = hfs_cat_get_record_offset(hfs, &key);\n    if (off == 0) {\n        // no parsing error, just not found\n        if (tsk_error_get_errno() == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_INODE_NUM);\n            tsk_error_set_errstr\n                (\"hfs_cat_file_lookup: Error finding thread node for file (%\"\n                PRIuINUM \")\", inum);\n        }\n        else {\n            tsk_error_set_errstr2\n                (\" hfs_cat_file_lookup: thread for file (%\" PRIuINUM \")\",\n                inum);\n        }\n        return 1;\n    }\n\n    /* read the thread record */\n    if (hfs_cat_read_thread_record(hfs, off, &thread)) {\n        tsk_error_set_errstr2(\" hfs_cat_file_lookup: file (%\" PRIuINUM \")\",\n            inum);\n        return 1;\n    }\n\n    /* now look up the actual file/folder record */\n\n    /* build key */\n    memset((char *) &key, 0, sizeof(hfs_btree_key_cat));\n    memcpy((char *) key.parent_cnid, (char *) thread.parent_cnid,\n        sizeof(key.parent_cnid));\n    memcpy((char *) &key.name, (char *) &thread.name, sizeof(key.name));\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_cat_file_lookup: Looking up file record (parent: %\"\n            PRIuINUM \")\\n\", (uint64_t) tsk_getu32(fs->endian,\n                key.parent_cnid));\n\n    /* look up the record */\n    off = hfs_cat_get_record_offset(hfs, &key);\n    if (off == 0) {\n        // no parsing error, just not found\n        if (tsk_error_get_errno() == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_INODE_NUM);\n            tsk_error_set_errstr\n                (\"hfs_cat_file_lookup: Error finding record node %\"\n                PRIuINUM, inum);\n        }\n        else {\n            tsk_error_set_errstr2(\" hfs_cat_file_lookup: file (%\" PRIuINUM\n                \")\", inum);\n        }\n        return 1;\n    }\n\n    /* read the record */\n    if (hfs_cat_read_file_folder_record(hfs, off, &record)) {\n        tsk_error_set_errstr2(\" hfs_cat_file_lookup: file (%\" PRIuINUM \")\",\n            inum);\n        return 1;\n    }\n\n    /* these memcpy can be gotten rid of, really */\n    if (tsk_getu16(fs->endian,\n            record.file.std.rec_type) == HFS_FOLDER_RECORD) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_cat_file_lookup: found folder record valence %\" PRIu32\n                \", cnid %\" PRIu32 \"\\n\", tsk_getu32(fs->endian,\n                    record.folder.std.valence), tsk_getu32(fs->endian,\n                    record.folder.std.cnid));\n        memcpy((char *) &entry->cat, (char *) &record, sizeof(hfs_folder));\n    }\n    else if (tsk_getu16(fs->endian,\n            record.file.std.rec_type) == HFS_FILE_RECORD) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_cat_file_lookup: found file record cnid %\" PRIu32\n                \"\\n\", tsk_getu32(fs->endian, record.file.std.cnid));\n        memcpy((char *) &entry->cat, (char *) &record, sizeof(hfs_file));\n    }\n    /* other cases already caught by hfs_cat_read_file_folder_record */\n\n    memcpy((char *) &entry->thread, (char *) &thread, sizeof(hfs_thread));\n\n    entry->flags = TSK_FS_META_FLAG_ALLOC | TSK_FS_META_FLAG_USED;\n    entry->inum = inum;\n\n    if (follow_hard_link) {\n        // TEST to see if this is a hard link\n        unsigned char is_err;\n        TSK_INUM_T target_cnid =\n            hfs_follow_hard_link(hfs, &(entry->cat), &is_err);\n        if (is_err > 1) {\n            error_returned\n                (\"hfs_cat_file_lookup: error occurred while following a possible hard link for \"\n                \"inum (cnid) =  %\" PRIuINUM, inum);\n            return 1;\n        }\n        if (target_cnid != inum) {\n            // This is a hard link, and we have got the cnid of the target file, so look it up.\n            uint8_t res =\n                hfs_cat_file_lookup(hfs, target_cnid, entry, FALSE);\n            if (res != 0) {\n                error_returned\n                    (\"hfs_cat_file_lookup: error occurred while looking up the Catalog entry for \"\n                    \"the target of inum (cnid) = %\" PRIuINUM \" target\",\n                    inum);\n            }\n            return 1;\n        }\n\n        // Target is NOT a hard link, so fall through to the non-hard link exit.\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_cat_file_lookup exiting\\n\");\n    return 0;\n}\n\n\nstatic uint8_t\nhfs_find_highest_inum_cb(HFS_INFO * hfs, int8_t level_type,\n    const hfs_btree_key_cat * cur_key,\n    TSK_OFF_T key_off, void *ptr)\n{\n    // NOTE: This assumes that the biggest inum is the last one that we\n    // see.  the traverse method does not currently promise that as part of\n    // its callback \"contract\". \n    *((TSK_INUM_T*) ptr) = tsk_getu32(hfs->fs_info.endian, cur_key->parent_cnid);\n    return HFS_BTREE_CB_IDX_LT;\n}\n\n/** \\internal\n* Returns the largest inode number in file system\n* @param hfs File system being analyzed\n* @returns largest metadata address\n*/\nstatic TSK_INUM_T\nhfs_find_highest_inum(HFS_INFO * hfs)\n{\n    // @@@ get actual number from Catalog file (go to far right) (we can't always trust the vol header)\n    TSK_INUM_T inum;\n    if (hfs_cat_traverse(hfs, hfs_find_highest_inum_cb, &inum)) {\n      /* Catalog traversal failed, fallback on legacy method :\n         if HFS_VH_ATTR_CNIDS_REUSED is set, then\n         the maximum CNID is 2^32-1; if it's not set, then nextCatalogId is\n         supposed to be larger than all CNIDs on disk.\n       */\n        TSK_FS_INFO *fs = (TSK_FS_INFO *) & (hfs->fs_info);\n        if (tsk_getu32(fs->endian, hfs->fs->attr) & HFS_VH_ATTR_CNIDS_REUSED)\n            return (TSK_INUM_T) 0xffffffff;\n        else\n            return (TSK_INUM_T) tsk_getu32(fs->endian,\n                hfs->fs->next_cat_id) - 1;\n    }\n    return inum;\n}\n\n\nstatic TSK_FS_META_MODE_ENUM\nhfs_mode_to_tsk_mode(uint16_t a_mode)\n{\n    TSK_FS_META_MODE_ENUM mode = 0;\n\n    if (a_mode & HFS_IN_ISUID)\n        mode |= TSK_FS_META_MODE_ISUID;\n    if (a_mode & HFS_IN_ISGID)\n        mode |= TSK_FS_META_MODE_ISGID;\n    if (a_mode & HFS_IN_ISVTX)\n        mode |= TSK_FS_META_MODE_ISVTX;\n\n    if (a_mode & HFS_IN_IRUSR)\n        mode |= TSK_FS_META_MODE_IRUSR;\n    if (a_mode & HFS_IN_IWUSR)\n        mode |= TSK_FS_META_MODE_IWUSR;\n    if (a_mode & HFS_IN_IXUSR)\n        mode |= TSK_FS_META_MODE_IXUSR;\n\n    if (a_mode & HFS_IN_IRGRP)\n        mode |= TSK_FS_META_MODE_IRGRP;\n    if (a_mode & HFS_IN_IWGRP)\n        mode |= TSK_FS_META_MODE_IWGRP;\n    if (a_mode & HFS_IN_IXGRP)\n        mode |= TSK_FS_META_MODE_IXGRP;\n\n    if (a_mode & HFS_IN_IROTH)\n        mode |= TSK_FS_META_MODE_IROTH;\n    if (a_mode & HFS_IN_IWOTH)\n        mode |= TSK_FS_META_MODE_IWOTH;\n    if (a_mode & HFS_IN_IXOTH)\n        mode |= TSK_FS_META_MODE_IXOTH;\n\n    return mode;\n}\n\nstatic TSK_FS_META_TYPE_ENUM\nhfs_mode_to_tsk_meta_type(uint16_t a_mode)\n{\n    switch (a_mode & HFS_IN_IFMT) {\n    case HFS_IN_IFIFO:\n        return TSK_FS_META_TYPE_FIFO;\n    case HFS_IN_IFCHR:\n        return TSK_FS_META_TYPE_CHR;\n    case HFS_IN_IFDIR:\n        return TSK_FS_META_TYPE_DIR;\n    case HFS_IN_IFBLK:\n        return TSK_FS_META_TYPE_BLK;\n    case HFS_IN_IFREG:\n        return TSK_FS_META_TYPE_REG;\n    case HFS_IN_IFLNK:\n        return TSK_FS_META_TYPE_LNK;\n    case HFS_IN_IFSOCK:\n        return TSK_FS_META_TYPE_SOCK;\n    case HFS_IFWHT:\n        return TSK_FS_META_TYPE_WHT;\n    case HFS_IFXATTR:\n        return TSK_FS_META_TYPE_UNDEF;\n    default:\n        /* error */\n        return TSK_FS_META_TYPE_UNDEF;\n    }\n}\n\n\nstatic uint8_t\nhfs_make_specialbase(TSK_FS_FILE * fs_file)\n{\n    fs_file->meta->type = TSK_FS_META_TYPE_REG;\n    fs_file->meta->mode = 0;\n    fs_file->meta->nlink = 1;\n    fs_file->meta->flags =\n        (TSK_FS_META_FLAG_USED | TSK_FS_META_FLAG_ALLOC);\n    fs_file->meta->uid = fs_file->meta->gid = 0;\n    fs_file->meta->mtime = fs_file->meta->atime = fs_file->meta->ctime =\n        fs_file->meta->crtime = 0;\n    fs_file->meta->mtime_nano = fs_file->meta->atime_nano =\n        fs_file->meta->ctime_nano = fs_file->meta->crtime_nano = 0;\n\n    if (fs_file->meta->name2 == NULL) {\n        if ((fs_file->meta->name2 = (TSK_FS_META_NAME_LIST *)\n                tsk_malloc(sizeof(TSK_FS_META_NAME_LIST))) == NULL) {\n            error_returned\n                (\" - hfs_make_specialbase, couldn't malloc space for a name list\");\n            return 1;\n        }\n        fs_file->meta->name2->next = NULL;\n    }\n\n    if (fs_file->meta->attr != NULL) {\n        tsk_fs_attrlist_markunused(fs_file->meta->attr);\n    }\n    else {\n        fs_file->meta->attr = tsk_fs_attrlist_alloc();\n    }\n    return 0;\n}\n\n/**\n * \\internal\n * Create an FS_INODE structure for the catalog file.\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_catalog(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n    unsigned char dummy1, dummy2;\n    uint64_t dummy3;\n    uint8_t result;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_catalog: Making virtual catalog file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_catalog\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_CATALOG_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_CATALOGNAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size =\n        tsk_getu64(fs->endian, hfs->fs->cat_file.logic_sz);\n\n\n    // convert the  runs in the volume header to attribute runs\n    if (((attr_run =\n                hfs_extents_to_attr(fs, hfs->fs->cat_file.extents,\n                    0)) == NULL) && (tsk_error_get_errno() != 0)) {\n        error_returned(\" - hfs_make_catalog\");\n        return 1;\n    }\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_catalog\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // initialize the data run\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            tsk_getu64(fs->endian, hfs->fs->cat_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->cat_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->cat_file.logic_sz), 0, 0)) {\n        error_returned(\" - hfs_make_catalog\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // see if catalog file has additional runs\n    if (hfs_ext_find_extent_record_attr(hfs, HFS_CATALOG_FILE_ID, fs_attr,\n            TRUE)) {\n        error_returned(\" - hfs_make_catalog\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n    result = hfs_load_extended_attrs(fs_file, &dummy1, &dummy2, &dummy3);\n    if (result != 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"WARNING: Extended attributes failed to load for the Catalog file.\\n\");\n        tsk_error_reset();\n    }\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n/**\n* \\internal\n * Create an FS_FILE for the extents file\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_extents(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_extents: Making virtual extents file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_extents\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_EXTENTS_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_EXTENTSNAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size =\n        tsk_getu64(fs->endian, hfs->fs->ext_file.logic_sz);\n\n\n    if (((attr_run =\n                hfs_extents_to_attr(fs, hfs->fs->ext_file.extents,\n                    0)) == NULL) && (tsk_error_get_errno() != 0)) {\n        error_returned(\" - hfs_make_extents\");\n        return 1;\n    }\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_extents\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // initialize the data run\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            tsk_getu64(fs->endian, hfs->fs->ext_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->ext_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->ext_file.logic_sz), 0, 0)) {\n        error_returned(\" - hfs_make_extents\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    //hfs_load_extended_attrs(fs_file);\n\n    // Extents doesn't have an entry in itself\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n\n/**\n * \\internal\n * Create an FS_INODE structure for the blockmap / allocation file.\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_blockmap(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n    unsigned char dummy1, dummy2;\n    uint64_t dummy3;\n    uint8_t result;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_blockmap: Making virtual blockmap file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_blockmap\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_ALLOCATION_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_ALLOCATIONNAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size =\n        tsk_getu64(fs->endian, hfs->fs->alloc_file.logic_sz);\n\n    if (((attr_run =\n                hfs_extents_to_attr(fs, hfs->fs->alloc_file.extents,\n                    0)) == NULL) && (tsk_error_get_errno() != 0)) {\n        error_returned(\" - hfs_make_blockmap\");\n        return 1;\n    }\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_blockmap\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // initialize the data run\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            tsk_getu64(fs->endian, hfs->fs->alloc_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->alloc_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->alloc_file.logic_sz), 0, 0)) {\n        error_returned(\" - hfs_make_blockmap\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // see if catalog file has additional runs\n    if (hfs_ext_find_extent_record_attr(hfs, HFS_ALLOCATION_FILE_ID,\n            fs_attr, TRUE)) {\n        error_returned(\" - hfs_make_blockmap\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n\n    result = hfs_load_extended_attrs(fs_file, &dummy1, &dummy2, &dummy3);\n    if (result != 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"WARNING: Extended attributes failed to load for the Allocation file.\\n\");\n        tsk_error_reset();\n    }\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n/**\n* \\internal\n * Create an FS_INODE structure for the startup / boot file.\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_startfile(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n    unsigned char dummy1, dummy2;\n    uint64_t dummy3;\n    uint8_t result;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_startfile: Making virtual startup file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_startfile\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_STARTUP_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_STARTUPNAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size =\n        tsk_getu64(fs->endian, hfs->fs->start_file.logic_sz);\n\n    if (((attr_run =\n                hfs_extents_to_attr(fs, hfs->fs->start_file.extents,\n                    0)) == NULL) && (tsk_error_get_errno() != 0)) {\n        error_returned(\" - hfs_make_startfile\");\n        return 1;\n    }\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_startfile\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // initialize the data run\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            tsk_getu64(fs->endian, hfs->fs->start_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->start_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->start_file.logic_sz), 0, 0)) {\n        error_returned(\" - hfs_make_startfile\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // see if catalog file has additional runs\n    if (hfs_ext_find_extent_record_attr(hfs, HFS_STARTUP_FILE_ID, fs_attr,\n            TRUE)) {\n        error_returned(\" - hfs_make_startfile\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n    result = hfs_load_extended_attrs(fs_file, &dummy1, &dummy2, &dummy3);\n    if (result != 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"WARNING: Extended attributes failed to load for the Start file.\\n\");\n        tsk_error_reset();\n    }\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n\n/**\n * \\internal\n * Create an FS_INODE structure for the attributes file.\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_attrfile(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs = (TSK_FS_INFO *) hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_attrfile: Making virtual attributes file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_attrfile\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_ATTRIBUTES_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_ATTRIBUTESNAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size =\n        tsk_getu64(fs->endian, hfs->fs->attr_file.logic_sz);\n\n    if (((attr_run =\n                hfs_extents_to_attr(fs, hfs->fs->attr_file.extents,\n                    0)) == NULL) && (tsk_error_get_errno() != 0)) {\n        error_returned(\" - hfs_make_attrfile\");\n        return 1;\n    }\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_attrfile\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // initialize the data run\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            tsk_getu64(fs->endian, hfs->fs->attr_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->attr_file.logic_sz),\n            tsk_getu64(fs->endian, hfs->fs->attr_file.logic_sz), 0, 0)) {\n        error_returned(\" - hfs_make_attrfile\");\n        tsk_fs_attr_run_free(attr_run);\n        return 1;\n    }\n\n    // see if catalog file has additional runs\n    if (hfs_ext_find_extent_record_attr(hfs, HFS_ATTRIBUTES_FILE_ID,\n            fs_attr, TRUE)) {\n        error_returned(\" - hfs_make_attrfile\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n    //hfs_load_extended_attrs(fs_file);\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n\n\n/**\n * \\internal\n * Create an FS_FILE structure for the BadBlocks file.\n *\n * @param hfs File system to analyze\n * @param fs_file Structure to copy file information into.\n * @return 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_make_badblockfile(HFS_INFO * hfs, TSK_FS_FILE * fs_file)\n{\n    TSK_FS_ATTR *fs_attr;\n    unsigned char dummy1, dummy2;\n    uint64_t dummy3;\n    uint8_t result;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_make_badblockfile: Making virtual badblock file\\n\");\n\n    if (hfs_make_specialbase(fs_file)) {\n        error_returned(\" - hfs_make_badblockfile\");\n        return 1;\n    }\n\n    fs_file->meta->addr = HFS_BAD_BLOCK_FILE_ID;\n    strncpy(fs_file->meta->name2->name, HFS_BAD_BLOCK_FILE_NAME,\n        TSK_FS_META_NAME_LIST_NSIZE);\n\n    fs_file->meta->size = 0;\n\n    if ((fs_attr =\n            tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                TSK_FS_ATTR_NONRES)) == NULL) {\n        error_returned(\" - hfs_make_badblockfile\");\n        return 1;\n    }\n\n    // add the run to the file.\n    if (tsk_fs_attr_set_run(fs_file, fs_attr, NULL, NULL,\n            TSK_FS_ATTR_TYPE_DEFAULT, HFS_FS_ATTR_ID_DATA,\n            fs_file->meta->size, fs_file->meta->size, fs_file->meta->size,\n            0, 0)) {\n        error_returned(\" - hfs_make_badblockfile\");\n        return 1;\n    }\n\n    // see if file has additional runs\n    if (hfs_ext_find_extent_record_attr(hfs, HFS_BAD_BLOCK_FILE_ID,\n            fs_attr, TRUE)) {\n        error_returned(\" - hfs_make_badblockfile\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n    /* @@@ We have a chicken and egg problem here...  The current design of\n     * fs_attr_set() requires the size to be set, but we dont' know the size\n     * until we look into the extents file (which adds to an attribute...).\n     * This does not seem to be the best design...  neeed a way to test this. */\n    fs_file->meta->size = fs_attr->nrd.initsize;\n    fs_attr->size = fs_file->meta->size;\n    fs_attr->nrd.allocsize = fs_file->meta->size;\n\n    result = hfs_load_extended_attrs(fs_file, &dummy1, &dummy2, &dummy3);\n    if (result != 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"WARNING: Extended attributes failed to load for the BadBlocks file.\\n\");\n        tsk_error_reset();\n    }\n\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n    return 0;\n}\n\n\n/** \\internal\n * Copy the catalog file or folder record entry into a TSK data structure.\n * @param a_hfs File system being analyzed\n * @param a_hfs_entry Catalog record entry (HFS_ENTRY *)\n * @param a_fs_file Structure to copy data into (TSK_FS_FILE *)\n * Returns 1 on error.\n */\nstatic uint8_t\nhfs_dinode_copy(HFS_INFO * a_hfs, const HFS_ENTRY * a_hfs_entry,\n    TSK_FS_FILE * a_fs_file)\n{\n\n    // Note, a_hfs_entry->cat is really of type hfs_file.  But, hfs_file_folder is a union\n    // of that type with hfs_folder.  Both of hfs_file and hfs_folder have the same first member.\n    // So, this cast is appropriate.\n    const hfs_file_folder *a_entry =\n        (hfs_file_folder *) & (a_hfs_entry->cat);\n    const hfs_file_fold_std *std;\n    TSK_FS_META *a_fs_meta = a_fs_file->meta;\n    TSK_FS_INFO *fs;\n    uint16_t hfsmode;\n    TSK_INUM_T iStd;            // the inum (or CNID) that occurs in the standard file metadata\n\n    if (a_entry == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_dinode_copy: a_entry = a_hfs_entry->cat is NULL\");\n        return 1;\n    }\n\n    fs = (TSK_FS_INFO *) & a_hfs->fs_info;\n\n\n    // Just a sanity check.  The inum (or cnid) occurs in two places in the\n    // entry data structure.\n    iStd = tsk_getu32(fs->endian, a_entry->file.std.cnid);\n    if (iStd != a_hfs_entry->inum) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"WARNING: hfs_dinode_copy:  HFS_ENTRY with conflicting values for inum (or cnid).\\n\");\n    }\n\n    if (a_fs_meta == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"hfs_dinode_copy: a_fs_meta is NULL\");\n        return 1;\n    }\n\n    // both files and folders start off the same\n    std = &(a_entry->file.std);\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_dinode_copy: called for file/folder %\" PRIu32 \"\\n\",\n            tsk_getu32(fs->endian, std->cnid));\n\n    if (a_fs_meta->content_len < HFS_FILE_CONTENT_LEN) {\n        if ((a_fs_meta =\n                tsk_fs_meta_realloc(a_fs_meta,\n                    HFS_FILE_CONTENT_LEN)) == NULL) {\n            return 1;\n        }\n    }\n    a_fs_meta->attr_state = TSK_FS_META_ATTR_EMPTY;\n    if (a_fs_meta->attr) {\n        tsk_fs_attrlist_markunused(a_fs_meta->attr);\n    }\n\n\n    /*\n     * Copy the file type specific stuff first\n     */\n    hfsmode = tsk_getu16(fs->endian, std->perm.mode);\n\n    if (tsk_getu16(fs->endian, std->rec_type) == HFS_FOLDER_RECORD) {\n        // set the type of mode is not set\n        if ((hfsmode & HFS_IN_IFMT) == 0)\n            a_fs_meta->type = TSK_FS_META_TYPE_DIR;\n        a_fs_meta->size = 0;\n        memset(a_fs_meta->content_ptr, 0, HFS_FILE_CONTENT_LEN);\n    }\n    else if (tsk_getu16(fs->endian, std->rec_type) == HFS_FILE_RECORD) {\n        hfs_fork *fork;\n        // set the type of mode is not set\n        if ((hfsmode & HFS_IN_IFMT) == 0)\n            a_fs_meta->type = TSK_FS_META_TYPE_REG;\n        a_fs_meta->size =\n            tsk_getu64(fs->endian, a_entry->file.data.logic_sz);\n\n        // copy the data and resource forks\n        fork = (hfs_fork *) a_fs_meta->content_ptr;\n        memcpy(fork, &(a_entry->file.data), sizeof(hfs_fork));\n        memcpy(&fork[1], &(a_entry->file.resource), sizeof(hfs_fork));\n    }\n    else {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_dinode_copy error: catalog entry is neither file nor folder\\n\");\n        return 1;\n    }\n\n    /*\n     * Copy the standard stuff.\n     * Use default values (as defined in spec) if mode is not defined.\n     */\n    if ((hfsmode & HFS_IN_IFMT) == 0) {\n        a_fs_meta->mode = 0;\n        a_fs_meta->uid = 99;\n        a_fs_meta->gid = 99;\n    }\n    else {\n        a_fs_meta->mode = hfs_mode_to_tsk_mode(hfsmode);\n        a_fs_meta->type = hfs_mode_to_tsk_meta_type(hfsmode);\n        a_fs_meta->uid = tsk_getu32(fs->endian, std->perm.owner);\n        a_fs_meta->gid = tsk_getu32(fs->endian, std->perm.group);\n    }\n\n    // this field is set only for \"indirect\" entries\n    if (tsk_getu32(fs->endian, std->perm.special.nlink))\n        a_fs_meta->nlink = tsk_getu32(fs->endian, std->perm.special.nlink);\n    else\n        a_fs_meta->nlink = 1;\n\n    a_fs_meta->mtime =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, std->cmtime));\n    a_fs_meta->atime =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, std->atime));\n    a_fs_meta->crtime =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, std->crtime));\n    a_fs_meta->ctime =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, std->amtime));\n    a_fs_meta->time2.hfs.bkup_time =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, std->bkup_date));\n    a_fs_meta->mtime_nano = a_fs_meta->atime_nano = a_fs_meta->ctime_nano =\n        a_fs_meta->crtime_nano = 0;\n    a_fs_meta->time2.hfs.bkup_time_nano = 0;\n\n    a_fs_meta->addr = tsk_getu32(fs->endian, std->cnid);\n\n    // All entries here are used.\n    a_fs_meta->flags = TSK_FS_META_FLAG_ALLOC | TSK_FS_META_FLAG_USED;\n\n    if (std->perm.o_flags & HFS_PERM_OFLAG_COMPRESSED)\n        a_fs_meta->flags |= TSK_FS_META_FLAG_COMP;\n\n    // We copy this inum (or cnid) here, because this file *might* have been a hard link.  In\n    // that case, we want to make sure that a_fs_file points consistently to the target of the\n    // link.\n\n    if (a_fs_file->name != NULL) {\n        a_fs_file->name->meta_addr = a_fs_meta->addr;\n    }\n\n    /* TODO @@@ could fill in name2 with this entry's name and parent inode\n       from Catalog entry */\n\n    /* set the link string (if the file is a link)\n     * The size check is a sanity check so that we don't try to allocate\n     * a huge amount of memory for a bad inode value\n     */\n    if ((a_fs_meta->type == TSK_FS_META_TYPE_LNK) &&\n        (a_fs_meta->size >= 0) && (a_fs_meta->size < HFS_MAXPATHLEN)) {\n\n        ssize_t bytes_read;\n\n        a_fs_meta->link = tsk_malloc((size_t) a_fs_meta->size + 1);\n        if (a_fs_meta->link == NULL)\n            return 1;\n\n        bytes_read = tsk_fs_file_read(a_fs_file, (TSK_OFF_T) 0,\n            a_fs_meta->link, (size_t) a_fs_meta->size,\n            TSK_FS_FILE_READ_FLAG_NONE);\n        a_fs_meta->link[a_fs_meta->size] = '\\0';\n\n        if (bytes_read != a_fs_meta->size) {\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_dinode_copy: failed to read contents of symbolic link; \"\n                    \"expected %u bytes but tsk_fs_file_read() returned %u\\n\",\n                    a_fs_meta->size, bytes_read);\n            free(a_fs_meta->link);\n            a_fs_meta->link = NULL;\n            return 1;\n        }\n    }\n\n    return 0;\n}\n\n\n/** \\internal\n * Load a catalog file entry and save it in the TSK_FS_FILE structure.\n *\n * @param fs File system to read from.\n * @param a_fs_file Structure to read into.\n * @param inum File address to load\n * @returns 1 on error\n */\nstatic uint8_t\nhfs_inode_lookup(TSK_FS_INFO * fs, TSK_FS_FILE * a_fs_file,\n    TSK_INUM_T inum)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    HFS_ENTRY entry;\n\n    if (a_fs_file == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"hfs_inode_lookup: fs_file is NULL\");\n        return 1;\n    }\n\n    if (a_fs_file->meta == NULL) {\n        a_fs_file->meta = tsk_fs_meta_alloc(HFS_FILE_CONTENT_LEN);\n    }\n\n    if (a_fs_file->meta == NULL) {\n        return 1;\n    }\n    else {\n        tsk_fs_meta_reset(a_fs_file->meta);\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_inode_lookup: looking up %\" PRIuINUM \"\\n\",\n            inum);\n\n    // @@@ Will need to add orphan stuff here too\n\n    /* First see if this is a special entry\n     * the special ones have their metadata stored in the volume header */\n    if (inum == HFS_EXTENTS_FILE_ID) {\n        if (!hfs->has_extents_file) {\n            error_detected(TSK_ERR_FS_INODE_NUM,\n                \"Extents File not present\");\n            return 1;\n        }\n\n        return hfs_make_extents(hfs, a_fs_file);\n    }\n    else if (inum == HFS_CATALOG_FILE_ID) {\n        return hfs_make_catalog(hfs, a_fs_file);\n    }\n    else if (inum == HFS_BAD_BLOCK_FILE_ID) {\n        // Note: the Extents file and the BadBlocks file are really the same.\n        if (!hfs->has_extents_file) {\n            error_detected(TSK_ERR_FS_INODE_NUM,\n                \"BadBlocks File not present\");\n            return 1;\n        }\n        return hfs_make_badblockfile(hfs, a_fs_file);\n    }\n    else if (inum == HFS_ALLOCATION_FILE_ID) {\n        return hfs_make_blockmap(hfs, a_fs_file);\n    }\n    else if (inum == HFS_STARTUP_FILE_ID) {\n        if (!hfs->has_startup_file) {\n            error_detected(TSK_ERR_FS_INODE_NUM,\n                \"Startup File not present\");\n            return 1;\n        }\n        return hfs_make_startfile(hfs, a_fs_file);\n    }\n    else if (inum == HFS_ATTRIBUTES_FILE_ID) {\n        if (!hfs->has_attributes_file) {\n            error_detected(TSK_ERR_FS_INODE_NUM,\n                \"Attributes File not present\");\n            return 1;\n        }\n        return hfs_make_attrfile(hfs, a_fs_file);\n    }\n\n    /* Lookup inode and store it in the HFS structure */\n    if (hfs_cat_file_lookup(hfs, inum, &entry, TRUE)) {\n        return 1;\n    }\n\n    /* Copy the structure in hfs to generic fs_inode */\n    if (hfs_dinode_copy(hfs, &entry, a_fs_file)) {\n        return 1;\n    }\n\n    /* If this is potentially a compressed file, its\n     * actual size is unknown until we examine the\n     * extended attributes */\n    if ((a_fs_file->meta->size == 0) &&\n        (a_fs_file->meta->type == TSK_FS_META_TYPE_REG) &&\n        (a_fs_file->meta->attr_state != TSK_FS_META_ATTR_ERROR) &&\n        ((a_fs_file->meta->attr_state != TSK_FS_META_ATTR_STUDIED) ||\n            (a_fs_file->meta->attr == NULL))) {\n        hfs_load_attrs(a_fs_file);\n    }\n\n    return 0;\n}\n\n\ntypedef struct {\n    uint32_t offset;\n    uint32_t length;\n} CMP_OFFSET_ENTRY;\n\n\nstatic int\nhfs_read_zlib_block_table(const TSK_FS_ATTR *rAttr, CMP_OFFSET_ENTRY** offsetTableOut, uint32_t* tableSizeOut, uint32_t* tableOffsetOut) {\n    int attrReadResult;\n    hfs_resource_fork_header rfHeader;\n    uint32_t dataOffset;\n    uint32_t offsetTableOffset;\n    char fourBytes[4];          // Size of the offset table, little endian\n    uint32_t tableSize;         // Size of the offset table\n    char *offsetTableData = NULL;\n    CMP_OFFSET_ENTRY *offsetTable = NULL;\n    size_t indx;\n\n    // Read the resource fork header\n    attrReadResult = tsk_fs_attr_read(rAttr, 0, (char *) &rfHeader,\n        sizeof(hfs_resource_fork_header), TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != sizeof(hfs_resource_fork_header)) {\n        error_returned\n            (\" %s: trying to read the resource fork header\", __func__);\n        return 0;\n    }\n\n    // Begin to parse the resource fork. For now, we just need the data offset.\n    dataOffset = tsk_getu32(TSK_BIG_ENDIAN, rfHeader.dataOffset);\n\n    // The resource's data begins with an offset table, which defines blocks\n    // of (optionally) zlib-compressed data (so that the OS can do file seeks\n    // efficiently; each uncompressed block is 64KB).\n    offsetTableOffset = dataOffset + 4;\n\n    // read 4 bytes, the number of table entries, little endian\n    attrReadResult =\n        tsk_fs_attr_read(rAttr, offsetTableOffset, fourBytes, 4,\n        TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != 4) {\n        error_returned\n            (\" %s: trying to read the offset table size, \"\n            \"return value of %u should have been 4\", __func__, attrReadResult);\n        return 0;\n    }\n    tableSize = tsk_getu32(TSK_LIT_ENDIAN, fourBytes);\n\n    // Each table entry is 8 bytes long\n    offsetTableData = tsk_malloc(tableSize * 8);\n    if (offsetTableData == NULL) {\n        error_returned\n            (\" %s: space for the offset table raw data\", __func__);\n        return 0;\n    }\n\n    offsetTable =\n        (CMP_OFFSET_ENTRY *) tsk_malloc(tableSize *\n        sizeof(CMP_OFFSET_ENTRY));\n    if (offsetTable == NULL) {\n        error_returned\n            (\" %s: space for the offset table\", __func__);\n        goto on_error;\n    }\n\n    attrReadResult = tsk_fs_attr_read(rAttr, offsetTableOffset + 4,\n        offsetTableData, tableSize * 8, TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != tableSize * 8) {\n        error_returned\n            (\" %s: reading in the compression offset table, \"\n            \"return value %u should have been %u\", __func__, attrReadResult,\n            tableSize * 8);\n        goto on_error;\n    }\n\n    for (indx = 0; indx < tableSize; ++indx) {\n        offsetTable[indx].offset =\n            tsk_getu32(TSK_LIT_ENDIAN, offsetTableData + indx * 8);\n        offsetTable[indx].length =\n            tsk_getu32(TSK_LIT_ENDIAN, offsetTableData + indx * 8 + 4);\n    }\n\n    free(offsetTableData);\n\n    *offsetTableOut = offsetTable;\n    *tableSizeOut = tableSize;\n    *tableOffsetOut = offsetTableOffset;\n    return 1;\n\non_error:\n    free(offsetTable);\n    free(offsetTableData);\n    return 0;\n}\n\n\nstatic int\nhfs_read_lzvn_block_table(const TSK_FS_ATTR *rAttr, CMP_OFFSET_ENTRY** offsetTableOut, uint32_t* tableSizeOut, uint32_t* tableOffsetOut) {\n    int attrReadResult;\n    char fourBytes[4];\n    uint32_t tableDataSize;\n    uint32_t tableSize;         // Size of the offset table\n    char *offsetTableData = NULL;\n    CMP_OFFSET_ENTRY *offsetTable = NULL;\n\n    // The offset table is a sequence of 4-byte offsets of compressed\n    // blocks. The first 4 bytes is thus the offset of the first block,\n    // but also 4 times the number of entries in the table.\n    attrReadResult = tsk_fs_attr_read(rAttr, 0, fourBytes, 4,\n                                      TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != 4) {\n        error_returned\n            (\" %s: trying to read the offset table size, \"\n            \"return value of %u should have been 4\", __func__, attrReadResult);\n        return 0;\n    }\n\n    tableDataSize = tsk_getu32(TSK_LIT_ENDIAN, fourBytes);\n\n    offsetTableData = tsk_malloc(tableDataSize);\n    if (offsetTableData == NULL) {\n        error_returned\n            (\" %s: space for the offset table raw data\", __func__);\n        return 0;\n    }\n\n    // table entries are 4 bytes, last entry is end of data\n    tableSize = tableDataSize / 4 - 1;\n\n    offsetTable =\n        (CMP_OFFSET_ENTRY *) tsk_malloc(tableSize *\n        sizeof(CMP_OFFSET_ENTRY));\n    if (offsetTable == NULL) {\n        error_returned\n            (\" %s: space for the offset table\", __func__);\n        goto on_error;\n    }\n\n    attrReadResult = tsk_fs_attr_read(rAttr, 0,\n        offsetTableData, tableDataSize, TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != tableDataSize) {\n        error_returned\n            (\" %s: reading in the compression offset table, \"\n            \"return value %u should have been %u\", __func__, attrReadResult,\n            tableDataSize);\n        goto on_error;\n    }\n\n    uint32_t a = tableDataSize;\n    uint32_t b;\n    size_t i;\n\n    for (i = 0; i < tableSize; ++i) {\n        b = tsk_getu32(TSK_LIT_ENDIAN, offsetTableData + 4*(i+1));\n        offsetTable[i].offset = a;\n        offsetTable[i].length = b - a;\n        a = b;\n    }\n\n    free(offsetTableData);\n\n    *offsetTableOut = offsetTable;\n    *tableSizeOut = tableSize;\n    *tableOffsetOut = 0;\n    return 1;\n\non_error:\n    free(offsetTable);\n    free(offsetTableData);\n    return 0;\n}\n\n\nstatic int hfs_decompress_noncompressed_block(char* rawBuf, uint32_t len, char* uncBuf, uint64_t* uncLen) {\n    // actually an uncompressed block of data; just copy\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n           \"%s: Copying an uncompressed compression unit\\n\", __func__);\n\n    if ((len - 1) > COMPRESSION_UNIT_SIZE) {\n        error_detected(TSK_ERR_FS_READ,\n            \"%s: uncompressed block length %u is longer \"\n            \"than compression unit size %u\", __func__, len - 1,\n            COMPRESSION_UNIT_SIZE);\n        return 0;\n    }\n    memcpy(uncBuf, rawBuf + 1, len - 1);\n    *uncLen = len - 1;\n    return 1;\n}\n\n\n#ifdef HAVE_LIBZ\nstatic int hfs_decompress_zlib_block(char* rawBuf, uint32_t len, char* uncBuf, uint64_t* uncLen)\n{\n    // see if this block is compressed\n    if (len > 0 && (rawBuf[0] & 0x0F) != 0x0F) {\n        // Uncompress the chunk of data\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                        \"%s: Inflating the compression unit\\n\", __func__);\n\n        unsigned long bytesConsumed;\n        int infResult = zlib_inflate(rawBuf, (uint64_t) len,\n            uncBuf, (uint64_t) COMPRESSION_UNIT_SIZE,\n            uncLen, &bytesConsumed);\n        if (infResult != 0) {\n            error_returned\n                  (\" %s: zlib inflation (uncompression) failed\",\n                  __func__, infResult);\n            return 0;\n        }\n\n        if (bytesConsumed != len) {\n            error_detected(TSK_ERR_FS_READ,\n                \" %s, decompressor did not consume the whole compressed data\",\n                __func__);\n            return 0;\n        }\n\n        return 1;\n    }\n    else {\n        // actually an uncompressed block of data; just copy\n        return hfs_decompress_noncompressed_block(rawBuf, len, uncBuf, uncLen);\n    }\n}\n#endif\n\n\nstatic int hfs_decompress_lzvn_block(char* rawBuf, uint32_t len, char* uncBuf, uint64_t* uncLen)\n{\n    // see if this block is compressed\n    if (len > 0 && rawBuf[0] != 0x06) {\n        *uncLen = lzvn_decode_buffer(uncBuf, COMPRESSION_UNIT_SIZE, rawBuf, len);\n        return 1;  // apparently this can't fail\n    }\n    else {\n        // actually an uncompressed block of data; just copy\n        return hfs_decompress_noncompressed_block(rawBuf, len, uncBuf, uncLen);\n    }\n}\n\n\nstatic ssize_t read_and_decompress_block(\n  const TSK_FS_ATTR* rAttr,\n  char* rawBuf,\n  char* uncBuf,\n  const CMP_OFFSET_ENTRY* offsetTable,\n  uint32_t offsetTableSize,\n  uint32_t offsetTableOffset,\n  size_t indx,\n  int (*decompress_block)(char* rawBuf,\n                          uint32_t len,\n                          char* uncBuf,\n                          uint64_t* uncLen)\n)\n{\n    int attrReadResult;\n    uint32_t offset = offsetTableOffset + offsetTable[indx].offset;\n    uint32_t len = offsetTable[indx].length;\n    uint64_t uncLen;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: Reading compression unit %d, length %d\\n\",\n            __func__, indx, len);\n\n    /* Github #383 referenced that if len is 0, then the below code causes\n     * problems. Added this check, but I don't have data to verify this on.\n     * it looks like it should at least not crash, but it isn't clear if it\n     * will also do the right thing and if should actually break here\n     * instead. */\n    if (len == 0) {\n      return 0;\n    }\n\n    if (len > COMPRESSION_UNIT_SIZE + 1) {\n      error_detected(TSK_ERR_FS_READ,\n          \"%s: block size is too large: %u\", __func__, len);\n      return -1;\n    }\n\n    // Read in the block of compressed data\n    attrReadResult = tsk_fs_attr_read(rAttr, offset,\n        rawBuf, len, TSK_FS_FILE_READ_FLAG_NONE);\n    if (attrReadResult != len) {\n        char msg[] =\n            \"%s%s: reading in the compression offset table, \"\n            \"return value %u should have been %u\";\n\n        if (attrReadResult < 0 ) {\n            error_returned(msg, \" \", __func__, attrReadResult, len);\n        }\n        else {\n            error_detected(TSK_ERR_FS_READ, \"\", __func__, attrReadResult, len);\n        }\n        return -1;\n    }\n\n    if (!decompress_block(rawBuf, len, uncBuf, &uncLen)) {\n        return -1;\n    }\n\n    // If size is a multiple of COMPRESSION_UNIT_SIZE,\n    // expected uncompressed length is COMPRESSION_UNIT_SIZE\n    const uint32_t expUncLen = indx == offsetTableSize - 1 ?\n        ((rAttr->fs_file->meta->size - 1) % COMPRESSION_UNIT_SIZE) + 1 :\n        COMPRESSION_UNIT_SIZE;\n\n    if (uncLen != expUncLen) {\n        error_detected(TSK_ERR_FS_READ,\n            \"%s: compressed block decompressed to %u bytes, \"\n            \"should have been %u bytes\", __func__, uncLen, expUncLen);\n        return -1;\n    }\n\n    // There are now uncLen bytes of uncompressed data available from\n    // this comp unit.\n    return (ssize_t)uncLen;\n}\n\n\nstatic uint8_t\nhfs_attr_walk_compressed_rsrc(const TSK_FS_ATTR * fs_attr,\n    int flags, TSK_FS_FILE_WALK_CB a_action, void *ptr,\n    int (*read_block_table)(const TSK_FS_ATTR *rAttr,\n                            CMP_OFFSET_ENTRY** offsetTableOut,\n                            uint32_t* tableSizeOut,\n                            uint32_t* tableOffsetOut),\n    int (*decompress_block)(char* rawBuf,\n                            uint32_t len,\n                            char* uncBuf,\n                            uint64_t* uncLen))\n{\n    TSK_FS_INFO *fs;\n    TSK_FS_FILE *fs_file;\n    const TSK_FS_ATTR *rAttr;   // resource fork attribute\n    char *rawBuf = NULL;               // compressed data\n    char *uncBuf = NULL;               // uncompressed data\n    uint32_t offsetTableOffset;\n    uint32_t offsetTableSize;         // The number of table entries\n    CMP_OFFSET_ENTRY *offsetTable = NULL;\n    size_t indx;                // index for looping over the offset table\n    TSK_OFF_T off = 0;          // the offset in the uncompressed data stream consumed thus far\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s:  Entered, because this is a compressed file with compressed data in the resource fork\\n\", __func__);\n\n    // clean up any error messages that are lying around\n    tsk_error_reset();\n    if ((fs_attr == NULL) || (fs_attr->fs_file == NULL)\n        || (fs_attr->fs_file->meta == NULL)\n        || (fs_attr->fs_file->fs_info == NULL)) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"%s: Null arguments given\\n\", __func__);\n        return 1;\n    }\n\n    // Check that the ATTR being read is the main DATA resource, 128-0,\n    // because this is the only one that can be compressed in HFS+\n    if ((fs_attr->id != HFS_FS_ATTR_ID_DATA) ||\n        (fs_attr->type != TSK_FS_ATTR_TYPE_HFS_DATA)) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: arg specified an attribute %u-%u that is not the data fork, \"\n            \"Only the data fork can be compressed.\", __func__, fs_attr->type,\n            fs_attr->id);\n        return 1;\n    }\n\n    /* This MUST be a compressed attribute     */\n    if (!(fs_attr->flags & TSK_FS_ATTR_COMP)) {\n        error_detected(TSK_ERR_FS_FWALK,\n            \"%s: called with non-special attribute: %x\",\n            __func__, fs_attr->flags);\n        return 1;\n    }\n\n    fs = fs_attr->fs_file->fs_info;\n    fs_file = fs_attr->fs_file;\n\n    /********  Open the Resource Fork ***********/\n\n    // find the attribute for the resource fork\n    rAttr =\n        tsk_fs_file_attr_get_type(fs_file, TSK_FS_ATTR_TYPE_HFS_RSRC,\n        HFS_FS_ATTR_ID_RSRC, TRUE);\n    if (rAttr == NULL) {\n        error_returned\n            (\" %s: could not get the attribute for the resource fork of the file\", __func__);\n        return 1;\n    }\n\n    // read the offset table from the fork header\n    if (!read_block_table(rAttr, &offsetTable, &offsetTableSize, &offsetTableOffset)) {\n      return 1;\n    }\n\n    // Allocate two buffers for the raw and uncompressed data\n    /* Raw data can be COMPRESSION_UNIT_SIZE+1 if the data is not\n     * compressed and there is a 1-byte flag that indicates that\n     * the data is not compressed. */\n    rawBuf = (char *) tsk_malloc(COMPRESSION_UNIT_SIZE + 1);\n    if (rawBuf == NULL) {\n        error_returned\n            (\" %s: buffers for reading and uncompressing\", __func__);\n        goto on_error;\n    }\n\n    uncBuf = (char *) tsk_malloc(COMPRESSION_UNIT_SIZE);\n    if (uncBuf == NULL) {\n        error_returned\n            (\" %s: buffers for reading and uncompressing\", __func__);\n        goto on_error;\n    }\n\n    // FOR entry in the table DO\n    for (indx = 0; indx < offsetTableSize; ++indx) {\n        ssize_t uncLen;        // uncompressed length\n        unsigned int blockSize;\n        uint64_t lumpSize;\n        uint64_t remaining;\n        char *lumpStart;\n\n        switch ((uncLen = read_and_decompress_block(\n                    rAttr, rawBuf, uncBuf,\n                    offsetTable, offsetTableSize, offsetTableOffset, indx,\n                    decompress_block)))\n        {\n        case -1:\n            goto on_error;\n        case  0:\n            continue;\n        default:\n            break;\n        }\n\n        // Call the a_action callback with \"Lumps\"\n        // that are at most the block size.\n        blockSize = fs->block_size;\n        remaining = uncLen;\n        lumpStart = uncBuf;\n\n        while (remaining > 0) {\n            int retval;         // action return value\n            lumpSize = remaining <= blockSize ? remaining : blockSize;\n\n            // Apply the callback function\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"%s: Calling action on lump of size %\"\n                    PRIu64 \" offset %\" PRIu64 \" in the compression unit\\n\",\n                    __func__, lumpSize, uncLen - remaining);\n            if (lumpSize > SIZE_MAX) {\n                error_detected(TSK_ERR_FS_FWALK,\n                    \" %s: lumpSize is too large for the action\", __func__);\n                goto on_error;\n            }\n\n            retval = a_action(fs_attr->fs_file, off, 0, lumpStart,\n                (size_t) lumpSize,   // cast OK because of above test\n                TSK_FS_BLOCK_FLAG_COMP, ptr);\n\n            if (retval == TSK_WALK_ERROR) {\n                error_detected(TSK_ERR_FS | 201,\n                    \"%s: callback returned an error\", __func__);\n                goto on_error;\n            }\n            else if (retval == TSK_WALK_STOP) {\n                break;\n            }\n\n            // Find the next lump\n            off += lumpSize;\n            remaining -= lumpSize;\n            lumpStart += lumpSize;\n        }\n    }\n\n    // Done, so free up the allocated resources.\n    free(offsetTable);\n    free(rawBuf);\n    free(uncBuf);\n    return 0;\n\non_error:\n    free(offsetTable);\n    free(rawBuf);\n    free(uncBuf);\n    return 0;\n}\n\n\n#ifdef HAVE_LIBZ\nstatic uint8_t\nhfs_attr_walk_zlib_rsrc(const TSK_FS_ATTR * fs_attr,\n    int flags, TSK_FS_FILE_WALK_CB a_action, void *ptr)\n{\n    return hfs_attr_walk_compressed_rsrc(\n      fs_attr, flags, a_action, ptr,\n      hfs_read_zlib_block_table,\n      hfs_decompress_zlib_block\n    );\n}\n#endif\n\n\nstatic uint8_t\nhfs_attr_walk_lzvn_rsrc(const TSK_FS_ATTR * fs_attr,\n    int flags, TSK_FS_FILE_WALK_CB a_action, void *ptr)\n{\n    return hfs_attr_walk_compressed_rsrc(\n      fs_attr, flags, a_action, ptr,\n      hfs_read_lzvn_block_table,\n      hfs_decompress_lzvn_block\n    );\n}\n\n\n/** \\internal\n *\n * @returns number of bytes read or -1 on error (incl if offset is past EOF)\n */\nstatic ssize_t\nhfs_file_read_compressed_rsrc(const TSK_FS_ATTR * a_fs_attr,\n    TSK_OFF_T a_offset, char *a_buf, size_t a_len,\n    int (*read_block_table)(const TSK_FS_ATTR *rAttr,\n                            CMP_OFFSET_ENTRY** offsetTableOut,\n                            uint32_t* tableSizeOut,\n                            uint32_t* tableOffsetOut),\n    int (*decompress_block)(char* rawBuf,\n                            uint32_t len,\n                            char* uncBuf,\n                            uint64_t* uncLen))\n{\n    TSK_FS_FILE *fs_file;\n    const TSK_FS_ATTR *rAttr;\n    char *rawBuf = NULL;\n    char *uncBuf = NULL;\n    uint32_t offsetTableOffset;\n    uint32_t offsetTableSize;         // Size of the offset table\n    CMP_OFFSET_ENTRY *offsetTable = NULL;\n    size_t indx;                // index for looping over the offset table\n    uint32_t startUnit = 0;\n    uint32_t startUnitOffset = 0;\n    uint32_t endUnit = 0;\n    uint64_t bytesCopied;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: called because this file is compressed, with data in the resource fork\\n\", __func__);\n\n    // Reading zero bytes?  OK at any offset, I say!\n    if (a_len == 0)\n        return 0;\n\n    if (a_offset < 0) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: reading from file at a negative offset, or negative length\",\n             __func__);\n        return -1;\n    }\n\n    if (a_len > SIZE_MAX / 2) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: trying to read more than SIZE_MAX/2 is not supported.\",\n            __func__);\n        return -1;\n    }\n\n    if ((a_fs_attr == NULL) || (a_fs_attr->fs_file == NULL)\n        || (a_fs_attr->fs_file->meta == NULL)\n        || (a_fs_attr->fs_file->fs_info == NULL)) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: NULL parameters passed\", __func__);\n        return -1;\n    }\n\n    // This should be a compressed file.  If not, that's an error!\n    if (!(a_fs_attr->flags & TSK_FS_ATTR_COMP)) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: called with non-special attribute: %x\",\n            __func__, a_fs_attr->flags);\n        return -1;\n    }\n\n    // Check that the ATTR being read is the main DATA resource, 4352-0,\n    // because this is the only one that can be compressed in HFS+\n    if ((a_fs_attr->id != HFS_FS_ATTR_ID_DATA) ||\n        (a_fs_attr->type != TSK_FS_ATTR_TYPE_HFS_DATA)) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: arg specified an attribute %u-%u that is not the data fork, \"\n            \"Only the data fork can be compressed.\", __func__,\n            a_fs_attr->type, a_fs_attr->id);\n        return -1;\n    }\n\n    /********  Open the Resource Fork ***********/\n    // The file\n    fs_file = a_fs_attr->fs_file;\n\n    // find the attribute for the resource fork\n    rAttr =\n        tsk_fs_file_attr_get_type(fs_file, TSK_FS_ATTR_TYPE_HFS_RSRC,\n        HFS_FS_ATTR_ID_RSRC, TRUE);\n    if (rAttr == NULL) {\n        error_returned\n            (\" %s: could not get the attribute for the resource fork of the file\", __func__);\n        return -1;\n    }\n\n    // read the offset table from the fork header\n    if (!read_block_table(rAttr, &offsetTable, &offsetTableSize, &offsetTableOffset)) {\n      return -1;\n    }\n\n    // Compute the range of compression units needed for the request\n    startUnit = a_offset / COMPRESSION_UNIT_SIZE;\n    startUnitOffset = a_offset % COMPRESSION_UNIT_SIZE;\n    endUnit = (a_offset + a_len - 1) / COMPRESSION_UNIT_SIZE;\n\n    if (startUnit >= offsetTableSize || endUnit >= offsetTableSize) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"%s: range of bytes requested %lld - %lld falls past the \"\n            \"end of the uncompressed stream %llu\\n\",\n            __func__, a_offset, a_offset + a_len,\n            offsetTable[offsetTableSize-1].offset +\n            offsetTable[offsetTableSize-1].length);\n        goto on_error;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: reading compression units: %\" PRIu32\n            \" to %\" PRIu32 \"\\n\", __func__, startUnit, endUnit);\n    bytesCopied = 0;\n\n    // Allocate buffers for the raw and uncompressed data\n    /* Raw data can be COMPRESSION_UNIT_SIZE+1 if the zlib data is not\n     * compressed and there is a 1-byte flag that indicates that\n     * the data is not compressed. */\n    rawBuf = (char *) tsk_malloc(COMPRESSION_UNIT_SIZE + 1);\n    if (rawBuf == NULL) {\n        error_returned\n            (\" %s: buffers for reading and uncompressing\", __func__);\n        goto on_error;\n    }\n\n    uncBuf = (char *) tsk_malloc(COMPRESSION_UNIT_SIZE);\n    if (uncBuf == NULL) {\n        error_returned\n            (\" %s: buffers for reading and uncompressing\", __func__);\n        goto on_error;\n    }\n\n    // Read from the indicated comp units\n    for (indx = startUnit; indx <= endUnit; ++indx) {\n        uint64_t uncLen;\n        char *uncBufPtr = uncBuf;\n        size_t bytesToCopy;\n\n        switch ((uncLen = read_and_decompress_block(\n                    rAttr, rawBuf, uncBuf,\n                    offsetTable, offsetTableSize, offsetTableOffset, indx,\n                    decompress_block)))\n        {\n        case -1:\n            goto on_error;\n        case  0:\n            continue;\n        default:\n            break;\n        }\n\n        // If this is the first comp unit, then we must skip over the\n        // startUnitOffset bytes.\n        if (indx == startUnit) {\n            uncLen -= startUnitOffset;\n            uncBufPtr += startUnitOffset;\n        }\n\n        // How many bytes to copy from this compression unit?\n\n        if (bytesCopied + uncLen < (uint64_t) a_len)    // cast OK because a_len > 0\n            bytesToCopy = (size_t) uncLen;      // uncLen <= size of compression unit, which is small, so cast is OK\n        else\n            bytesToCopy = (size_t) (((uint64_t) a_len) - bytesCopied);  // diff <= compression unit size, so cast is OK\n\n        // Copy into the output buffer, and update bookkeeping.\n        memcpy(a_buf + bytesCopied, uncBufPtr, bytesToCopy);\n        bytesCopied += bytesToCopy;\n    }\n\n    // Well, we don't know (without a lot of work) what the\n    // true uncompressed size of the stream is.  All we know is the \"upper bound\" which\n    // assumes that all of the compression units expand to their full size.  If we did\n    // know the true size, then we could reject requests that go beyond the end of the\n    // stream.  Instead, we treat the stream as if it is padded out to the full size of\n    // the last compression unit with zeros.\n\n    // Have we read and copied all of the bytes requested?\n    if (bytesCopied < a_len) {\n        // set the remaining bytes to zero\n        memset(a_buf + bytesCopied, 0, a_len - (size_t) bytesCopied);   // cast OK because diff must be < compression unit size\n    }\n\n    free(offsetTable);\n    free(rawBuf);\n    free(uncBuf);\n\n    return (ssize_t) bytesCopied;       // cast OK, cannot be greater than a_len which cannot be greater than SIZE_MAX/2 (rounded down).\n\non_error:\n    free(offsetTable);\n    free(rawBuf);\n    free(uncBuf);\n    return -1;\n}\n\n\n#ifdef HAVE_LIBZ\nstatic ssize_t\nhfs_file_read_zlib_rsrc(const TSK_FS_ATTR * a_fs_attr,\n    TSK_OFF_T a_offset, char *a_buf, size_t a_len)\n{\n    return hfs_file_read_compressed_rsrc(\n        a_fs_attr, a_offset, a_buf, a_len,\n        hfs_read_zlib_block_table,\n        hfs_decompress_zlib_block\n    );\n}\n#endif\n\n\nstatic ssize_t\nhfs_file_read_lzvn_rsrc(const TSK_FS_ATTR * a_fs_attr,\n    TSK_OFF_T a_offset, char *a_buf, size_t a_len)\n{\n    return hfs_file_read_compressed_rsrc(\n        a_fs_attr, a_offset, a_buf, a_len,\n        hfs_read_lzvn_block_table,\n        hfs_decompress_lzvn_block\n    );\n}\n\n\nstatic int hfs_decompress_noncompressed_attr(char* rawBuf, uint32_t rawSize, uint64_t uncSize, char** dstBuf, uint64_t* dstSize, int* dstBufFree) {\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: Leading byte, 0x%02x, indicates that the data is not really compressed.\\n\"\n            \"%s:  Loading the default DATA attribute.\", __func__, rawBuf[0], __func__);\n\n    *dstBuf = rawBuf + 1;  // + 1 indicator byte\n    *dstSize = uncSize;\n    *dstBufFree = FALSE;\n    return 1;\n}\n\n\nstatic int hfs_decompress_zlib_attr(char* rawBuf, uint32_t rawSize, uint64_t uncSize, char** dstBuf, uint64_t* dstSize, int* dstBufFree)\n{\n    if ((rawBuf[0] & 0x0F) == 0x0F) {\n        return hfs_decompress_noncompressed_attr(\n            rawBuf, rawSize, uncSize, dstBuf, dstSize, dstBufFree);\n    }\n    else {\n#ifdef HAVE_LIBZ\n        char* uncBuf = NULL;\n        uint64_t uLen;\n        unsigned long bytesConsumed;\n        int infResult;\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                        \"%s: Uncompressing (inflating) data.\", __func__);\n        // Uncompress the remainder of the attribute, and load as 128-0\n        // Note: cast is OK because uncSize will be quite modest, < 4000.\n\n        uncBuf = (char *) tsk_malloc((size_t) uncSize + 100); // add some extra space\n        if (uncBuf == NULL) {\n            error_returned\n                (\" - %s, space for the uncompressed attr\", __func__);\n            return 0;\n        }\n\n        infResult = zlib_inflate(rawBuf, (uint64_t) rawSize,\n                                 uncBuf, (uint64_t) (uncSize + 100),\n                                 &uLen, &bytesConsumed);\n        if (infResult != 0) {\n            error_returned\n                (\" %s, zlib could not uncompress attr\", __func__);\n            free(uncBuf);\n            return 0;\n        }\n\n        if (bytesConsumed != rawSize) {\n            error_detected(TSK_ERR_FS_READ,\n                \" %s, decompressor did not consume the whole compressed data\",\n                __func__);\n            free(uncBuf);\n            return 0;\n        }\n\n        *dstBuf = uncBuf;\n        *dstSize = uncSize;\n        *dstBufFree = TRUE;\n#else\n        // ZLIB compression library is not available, so we will load a\n        // zero-length default DATA attribute. Without this, icat may\n        // misbehave.\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                        \"%s: ZLIB not available, so loading an empty default DATA attribute.\\n\", __func__);\n\n        // Dummy is one byte long, so the ptr is not null, but we set the\n        // length to zero bytes, so it is never read.\n        static uint8_t dummy[1];\n\n        *dstBuf = dummy;\n        *dstSize = 0;\n        *dstBufFree = FALSE;\n#endif\n    }\n\n    return 1;\n}\n\n\nstatic int hfs_decompress_lzvn_attr(char* rawBuf, uint32_t rawSize, uint64_t uncSize, char** dstBuf, uint64_t* dstSize, int* dstBufFree)\n{\n    if (rawBuf[0] == 0x06) {\n        return hfs_decompress_noncompressed_attr(\n            rawBuf, rawSize, uncSize, dstBuf, dstSize, dstBufFree);\n    }\n    \n    char* uncBuf = (char *) tsk_malloc((size_t) uncSize);\n    *dstSize = lzvn_decode_buffer(uncBuf, uncSize, rawBuf, rawSize);\n    *dstBuf = uncBuf;\n    *dstBufFree = TRUE;\n\n    return 1;\n}\n\n\nstatic int\nhfs_file_read_compressed_attr(TSK_FS_FILE* fs_file,\n                              uint8_t cmpType,\n                              char* buffer,\n                              uint32_t attributeLength,\n                              uint64_t uncSize,\n                              int (*decompress_attr)(char* rawBuf,\n                                                     uint32_t rawSize,\n                                                     uint64_t uncSize,\n                                                     char** dstBuf,\n                                                     uint64_t* dstSize,\n                                                     int* dstBufFree))\n{\n    // Data is inline. We will load the uncompressed data as a\n    // resident attribute.\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: Compressed data is inline in the attribute, will load this as the default DATA attribute.\\n\", __func__);\n\n    if (attributeLength <= 16) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"%s: WARNING, Compression Record of type %u is not followed by\"\n                \" compressed data. No data will be loaded into the DATA\"\n                \" attribute.\\n\", __func__, cmpType);\n\n        // oddly, this is not actually considered an error\n        return 1;\n    }\n\n    TSK_FS_ATTR *fs_attr_unc;\n\n    // There is data following the compression record, as there should be.\n    if ((fs_attr_unc = tsk_fs_attrlist_getnew(\n          fs_file->meta->attr, TSK_FS_ATTR_RES)) == NULL)\n    {\n        error_returned(\" - %s, FS_ATTR for uncompressed data\", __func__);\n        return 0;\n    }\n\n    char* dstBuf;\n    uint64_t dstSize;\n    int dstBufFree = FALSE;\n\n    if (!decompress_attr(buffer + 16, attributeLength - 16, uncSize,\n                         &dstBuf, &dstSize, &dstBufFree)) {\n        return 0;\n    }\n\n    if (dstSize != uncSize) {\n        error_detected(TSK_ERR_FS_READ,\n            \" %s, actual uncompressed size not equal to the size in the compression record\", __func__);\n        goto on_error;\n    }\n\n    if (tsk_verbose)\n       tsk_fprintf(stderr,\n                   \"%s: Loading decompressed data as default DATA attribute.\",\n                   __func__);\n\n    // Load the remainder of the attribute as 128-0\n    // set the details in the fs_attr structure.\n    // Note, we are loading this as a RESIDENT attribute.\n    if (tsk_fs_attr_set_str(fs_file,\n                            fs_attr_unc, \"DATA\",\n                            TSK_FS_ATTR_TYPE_HFS_DATA,\n                            HFS_FS_ATTR_ID_DATA, dstBuf,\n                            dstSize))\n    {\n        error_returned(\" - %s\", __func__);\n        goto on_error;\n    }\n\n    if (dstBufFree) {\n        free(dstBuf);\n    }\n    return 1;\n\non_error:\n    if (dstBufFree) {\n        free(dstBuf);\n    }\n    return 0;\n}\n\n\nstatic int hfs_file_read_zlib_attr(TSK_FS_FILE* fs_file,\n                            char* buffer,\n                            uint32_t attributeLength,\n                            uint64_t uncSize)\n{\n    return hfs_file_read_compressed_attr(\n        fs_file, DECMPFS_TYPE_ZLIB_ATTR,\n        buffer, attributeLength, uncSize,\n        hfs_decompress_zlib_attr\n    );\n}\n\n\nstatic int hfs_file_read_lzvn_attr(TSK_FS_FILE* fs_file,\n                            char* buffer,\n                            uint32_t attributeLength,\n                            uint64_t uncSize)\n{\n    return hfs_file_read_compressed_attr(\n        fs_file, DECMPFS_TYPE_LZVN_ATTR,\n        buffer, attributeLength, uncSize,\n        hfs_decompress_lzvn_attr\n    );\n}\n\n\ntypedef struct {\n    TSK_FS_INFO *fs;            // the HFS file system\n    TSK_FS_FILE *file;          // the Attributes file, if open\n    hfs_btree_header_record *header;    // the Attributes btree header record.\n    // For Convenience, unpacked values.\n    TSK_ENDIAN_ENUM endian;\n    uint32_t rootNode;\n    uint16_t nodeSize;\n    uint16_t maxKeyLen;\n} ATTR_FILE_T;\n\n\n/** \\internal\n * Open the Attributes file, and read the btree header record. Fill in the fields of the ATTR_FILE_T struct.\n *\n * @param fs -- the HFS file system\n * @param header -- the header record struct\n *\n * @return 1 on error, 0 on success\n */\nstatic uint8_t\nopen_attr_file(TSK_FS_INFO * fs, ATTR_FILE_T * attr_file)\n{\n\n    int cnt;                    // will hold bytes read\n\n    hfs_btree_header_record *hrec;\n\n    // clean up any error messages that are lying around\n    tsk_error_reset();\n\n    if (fs == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"open_attr_file: fs is NULL\");\n        return 1;\n    }\n\n    if (attr_file == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"open_attr_file: attr_file is NULL\");\n        return 1;\n    }\n\n    // Open the Attributes File\n    attr_file->file =\n        tsk_fs_file_open_meta(fs, NULL, HFS_ATTRIBUTES_FILE_ID);\n\n    if (attr_file->file == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_READ);\n        tsk_error_set_errstr\n            (\"open_attr_file: could not open the Attributes file\");\n        return 1;\n    }\n\n    // Allocate some space for the Attributes btree header record (which\n    //       is passed back to the caller)\n    hrec = (hfs_btree_header_record *)\n        malloc(sizeof(hfs_btree_header_record));\n\n    if (hrec == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS);\n        tsk_error_set_errstr\n            (\"open_attr_file: could not malloc space for Attributes header record\");\n        return 1;\n    }\n\n    // Read the btree header record\n    cnt = tsk_fs_file_read(attr_file->file,\n        14,\n        (char *) hrec,\n        sizeof(hfs_btree_header_record), (TSK_FS_FILE_READ_FLAG_ENUM) 0);\n    if (cnt != sizeof(hfs_btree_header_record)) {\n        tsk_error_set_errno(TSK_ERR_FS_READ);\n        tsk_error_set_errstr\n            (\"open_attr_file: could not open the Attributes file\");\n        tsk_fs_file_close(attr_file->file);\n        free(hrec);\n        return 1;\n    }\n\n    // Fill in the fields of the attr_file struct (which was passed in by the caller)\n    attr_file->fs = fs;\n    attr_file->header = hrec;\n    attr_file->endian = fs->endian;\n    attr_file->nodeSize = tsk_getu16(attr_file->endian, hrec->nodesize);\n    attr_file->rootNode = tsk_getu32(attr_file->endian, hrec->rootNode);\n    attr_file->maxKeyLen = tsk_getu16(attr_file->endian, hrec->maxKeyLen);\n\n    return 0;\n}\n\n\n/** \\internal\n * Closes and frees the data structures associated with ATTR_FILE_T\n */\nstatic uint8_t\nclose_attr_file(ATTR_FILE_T * attr_file)\n{\n    if (attr_file == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_READ);\n        tsk_error_set_errstr(\"close_attr_file: NULL attr_file arg\");\n        return 1;\n    }\n\n    if (attr_file->file != NULL) {\n        tsk_fs_file_close(attr_file->file);\n        attr_file->file = NULL;\n    }\n    if (attr_file->header != NULL) {\n        free(attr_file->header);\n        attr_file->header = NULL;\n    }\n    attr_file->rootNode = 0;\n    attr_file->nodeSize = 0;\n    // Note that we leave the fs component alone.\n    return 0;\n}\n\n\nstatic const char *\nhfs_attrTypeName(uint32_t typeNum)\n{\n    switch (typeNum) {\n    case TSK_FS_ATTR_TYPE_HFS_DEFAULT:\n        return \"DFLT\";\n    case TSK_FS_ATTR_TYPE_HFS_DATA:\n        return \"DATA\";\n    case TSK_FS_ATTR_TYPE_HFS_EXT_ATTR:\n        return \"ExATTR\";\n    case TSK_FS_ATTR_TYPE_HFS_COMP_REC:\n        return \"CMPF\";\n    case TSK_FS_ATTR_TYPE_HFS_RSRC:\n        return \"RSRC\";\n    default:\n        return \"UNKN\";\n    }\n}\n\n\n// TODO: Function description missing here no idea what it is supposed to return\n// in which circumstances.\nstatic uint8_t\nhfs_load_extended_attrs(TSK_FS_FILE * fs_file,\n    unsigned char *isCompressed, unsigned char *cmpType,\n    uint64_t *uncompressedSize)\n{\n    TSK_FS_INFO *fs = fs_file->fs_info;\n    uint64_t fileID;\n    ATTR_FILE_T attrFile;\n    int cnt;                    // count of chars read from file.\n    uint8_t *nodeData;\n    TSK_ENDIAN_ENUM endian;\n    hfs_btree_node *nodeDescriptor;     // The node descriptor\n    uint32_t nodeID;            // The number or ID of the Attributes file node to read.\n    hfs_btree_key_attr *keyB;   // ptr to the key of the Attr file record.\n    unsigned char done;         // Flag to indicate that we are done looping over leaf nodes\n    uint16_t attribute_counter = 2;     // The ID of the next attribute to be loaded.\n    HFS_INFO *hfs;\n    char *buffer = NULL;   // buffer to hold the attribute\n    TSK_LIST *nodeIDs_processed = NULL; // Keep track of node IDs to prevent an infinite loop\n\n    tsk_error_reset();\n\n    // The CNID (or inode number) of the file\n    //  Note that in TSK such numbers are 64 bits, but in HFS+ they are only 32 bits.\n    fileID = fs_file->meta->addr;\n\n    if (fs == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_load_extended_attrs: NULL fs arg\");\n        return 1;\n    }\n\n    hfs = (HFS_INFO *) fs;\n\n    if (!hfs->has_attributes_file) {\n        // No attributes file, and so, no extended attributes\n        return 0;\n    }\n\n    if (tsk_verbose) {\n        tsk_fprintf(stderr,\n            \"hfs_load_extended_attrs:  Processing file %\" PRIuINUM \"\\n\",\n            fileID);\n    }\n\n    // Open the Attributes File\n    if (open_attr_file(fs, &attrFile)) {\n        error_returned\n            (\"hfs_load_extended_attrs: could not open Attributes file\");\n        return 1;\n    }\n\n    // Is the Attributes file empty?\n    if (attrFile.rootNode == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_extended_attrs: Attributes file is empty\\n\");\n        close_attr_file(&attrFile);\n        *isCompressed = FALSE;\n        *cmpType = 0;\n        return 0;\n    }\n\n    // A place to hold one node worth of data\n    nodeData = (uint8_t *) malloc(attrFile.nodeSize);\n    if (nodeData == NULL) {\n        error_detected(TSK_ERR_AUX_MALLOC,\n            \"hfs_load_extended_attrs: Could not malloc space for an Attributes file node\");\n        goto on_error;\n    }\n\n    // Initialize these\n    *isCompressed = FALSE;\n    *cmpType = 0;\n\n    endian = attrFile.fs->endian;\n\n    // Start with the root node\n    nodeID = attrFile.rootNode;\n\n    // While loop, over nodes in path from root node to the correct LEAF node.\n    while (1) {\n        uint16_t numRec;        // Number of records in the node\n        int recIndx;            // index for looping over records\n\n        if (tsk_verbose) {\n            tsk_fprintf(stderr,\n                \"hfs_load_extended_attrs: Reading Attributes File node with ID %\"\n                PRIu32 \"\\n\", nodeID);\n        }\n\n        /* Make sure we do not get into an infinite loop */\n        if (tsk_list_find(nodeIDs_processed, nodeID)) {\n            error_detected(TSK_ERR_FS_READ,\n                \"hfs_load_extended_attrs: Infinite loop detected - trying to read node %\" PRIu32 \" which has already been processed\", nodeID);\n            goto on_error;\n        }\n\n\n        /* Read the node */\n        cnt = tsk_fs_file_read(attrFile.file,\n            (TSK_OFF_T)nodeID * attrFile.nodeSize,\n            (char *) nodeData,\n            attrFile.nodeSize, (TSK_FS_FILE_READ_FLAG_ENUM) 0);\n        if (cnt != attrFile.nodeSize) {\n            error_returned\n                (\"hfs_load_extended_attrs: Could not read in a node from the Attributes File\");\n            goto on_error;\n        }\n\n        /* Save this node ID to the list of processed nodes */\n        if (tsk_list_add(&nodeIDs_processed, nodeID)) {\n            error_detected(TSK_ERR_FS_READ,\n                \"hfs_load_extended_attrs: Could not save nodeID to the list of processed nodes\");\n            goto on_error;\n        }\n\n        /** Node has a:\n         * Descriptor\n         * Set of records\n         * Table at the end with pointers to the records\n         */\n        // Parse the Node header\n        nodeDescriptor = (hfs_btree_node *) nodeData;\n\n        // If we are at a leaf node, then we have found the right node\n        if (nodeDescriptor->type == HFS_ATTR_NODE_LEAF) {\n            break;\n        }\n\n        // This had better be an INDEX node, if not its an error\n        else if (nodeDescriptor->type != HFS_ATTR_NODE_INDEX) {\n            error_detected(TSK_ERR_FS_READ,\n                \"hfs_load_extended_attrs: Reached a non-INDEX and non-LEAF node in searching the Attributes File\");\n            goto on_error;\n        }\n\n        // OK, we are in an INDEX node.  loop over the records to find the last one whose key is\n        // smaller than or equal to the desired key\n\n        numRec = tsk_getu16(endian, nodeDescriptor->num_rec);\n        if (numRec == 0) {\n            // This is wrong, there must always be at least 1 record in an INDEX node.\n            error_detected(TSK_ERR_FS_READ,\n                \"hfs_load_extended_attrs:Attributes File index node %\"\n                PRIu32 \" has zero records\", nodeID);\n            goto on_error;\n        }\n\n        for (recIndx = 0; recIndx < numRec; ++recIndx) {\n            uint16_t keyLength;\n            int comp;           // comparison result\n            char *compStr;      // comparison result, as a string\n            uint8_t *recData;   // pointer to the data part of the record\n            uint32_t keyFileID;\n\n            // The offset to the record is stored in table at end of node\n            uint8_t *recOffsetTblEntry = &nodeData[attrFile.nodeSize - (2 * (recIndx + 1))];  // data describing where this record is\n            uint16_t recOffset = tsk_getu16(endian, recOffsetTblEntry);\n            //uint8_t * nextRecOffsetData = &nodeData[attrFile.nodeSize - 2* (recIndx+2)];\n\n            // make sure the record and first fields are in the buffer\n            if (recOffset + 14 > attrFile.nodeSize) {\n                error_detected(TSK_ERR_FS_READ,\n                    \"hfs_load_extended_attrs: Unable to process attribute (offset too big)\");\n                goto on_error;\n            }\n\n            // Pointer to first byte of record\n            uint8_t *recordBytes = &nodeData[recOffset];\n\n\n            // Cast that to the Attributes file key (n.b., the key is the first thing in the record)\n            keyB = (hfs_btree_key_attr *) recordBytes;\n\n            // Is this key less than what we are seeking?\n            //int comp = comp_attr_key(endian, keyB, fileID, attrName, startBlock);\n\n            keyFileID = tsk_getu32(endian, keyB->file_id);\n            if (keyFileID < fileID) {\n                comp = -1;\n                compStr = \"less than\";\n            }\n            else if (keyFileID > fileID) {\n                comp = 1;\n                compStr = \"greater than\";\n            }\n            else {\n                comp = 0;\n                compStr = \"equal to\";\n            }\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_load_extended_attrs: INDEX record %d, fileID %\"\n                    PRIu32 \" is %s the file ID we are seeking, %\" PRIu32\n                    \".\\n\", recIndx, keyFileID, compStr, fileID);\n            if (comp > 0) {\n                // The key of this record is greater than what we are seeking\n                if (recIndx == 0) {\n                    // This is the first record, so no records are appropriate\n                    // Nothing in this btree will match.  We can stop right here.\n                    goto on_exit;\n                }\n\n                // This is not the first record, so, the previous record's child is the one we want.\n                break;\n            }\n\n            // CASE:  key in this record matches the key we are seeking.  The previous record's child\n            // is the one we want.  However, if this is the first record, then we want THIS record's child.\n            if (comp == 0 && recIndx != 0) {\n                break;\n            }\n\n            // Extract the child node ID from the record data (stored after the key)\n            keyLength = tsk_getu16(endian, keyB->key_len);\n            // make sure the fields we care about are still in the buffer\n            // +2 is because key_len doesn't include its own length\n            // +4 is because of the amount of data we read from the data\n            if (recOffset + keyLength + 2 + 4 > attrFile.nodeSize) {\n                error_detected(TSK_ERR_FS_READ,\n                    \"hfs_load_extended_attrs: Unable to process attribute\");\n                goto on_error;\n            }\n\n            recData = &recordBytes[keyLength + 2];   \n\n            // Data must start on an even offset from the beginning of the record.\n            // So, correct this if needed.\n            if ((recData - recordBytes) % 2) {\n                recData += 1;\n            }\n\n            // The next four bytes should be the Node ID of the child of this node.\n            nodeID = tsk_getu32(endian, recData);\n\n            // At this point, either comp<0 or comp=0 && recIndx=0.  In the latter case we want to\n            // descend to the child of this node, so we break.\n            if (recIndx == 0 && comp == 0) {\n                break;\n            }\n\n            // CASE: key in this record is less than key we seek.  comp < 0\n            // So, continue looping over records in this node.\n        }                       // END loop over records\n\n    }                           // END while loop over Nodes in path from root to LEAF node\n\n    // At this point nodeData holds the contents of a LEAF node with the right range of keys\n    // and nodeDescriptor points to the descriptor of that node.\n\n    // Loop over successive LEAF nodes, starting with this one\n    done = FALSE;\n    while (!done) {\n        uint16_t numRec;        // number of records\n        unsigned int recIndx;            // index for looping over records\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_extended_attrs: Attributes File LEAF Node %\"\n                PRIu32 \".\\n\", nodeID);\n        numRec = tsk_getu16(endian, nodeDescriptor->num_rec);\n        // Note, leaf node could have one (or maybe zero) records\n\n        // Loop over the records in this node\n        for (recIndx = 0; recIndx < numRec; ++recIndx) {\n            \n            // The offset to the record is stored in table at end of node\n            uint8_t *recOffsetTblEntry = &nodeData[attrFile.nodeSize - (2 * (recIndx + 1))];  // data describing where this record is\n            uint16_t recOffset = tsk_getu16(endian, recOffsetTblEntry);\n            \n            int comp;           // comparison result\n            char *compStr;      // comparison result as a string\n            uint32_t keyFileID;\n\n            // make sure the record and first fields are in the buffer\n            if (recOffset + 14 > attrFile.nodeSize) {\n                error_detected(TSK_ERR_FS_READ,\n                    \"hfs_load_extended_attrs: Unable to process attribute (offset too big)\");\n                goto on_error;\n            }\n\n            // Pointer to first byte of record\n            uint8_t *recordBytes = &nodeData[recOffset];\n\n            // Cast that to the Attributes file key\n            keyB = (hfs_btree_key_attr *) recordBytes;\n            \n            // Compare recordBytes key to the key that we are seeking\n            keyFileID = tsk_getu32(endian, keyB->file_id);\n\n            //fprintf(stdout, \" Key file ID = %lu\\n\", keyFileID);\n            if (keyFileID < fileID) {\n                comp = -1;\n                compStr = \"less than\";\n            }\n            else if (keyFileID > fileID) {\n                comp = 1;\n                compStr = \"greater than\";\n            }\n            else {\n                comp = 0;\n                compStr = \"equal to\";\n            }\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_load_extended_attrs: LEAF Record key file ID %\"\n                    PRIu32 \" is %s the desired file ID %\" PRIu32 \"\\n\",\n                    keyFileID, compStr, fileID);\n            // Are they the same?\n            if (comp == 0) {\n                // Yes, so load this attribute\n\n                uint8_t *recData;       // pointer to the data part of the recordBytes\n                hfs_attr_data *attrData;\n                uint32_t attributeLength;\n                uint32_t nameLength;\n                uint32_t recordType;\n                uint16_t keyLength;\n                int conversionResult;\n                char nameBuff[HFS_MAX_ATTR_NAME_LEN_UTF8_B+1];\n                TSK_FS_ATTR_TYPE_ENUM attrType;\n                TSK_FS_ATTR *fs_attr;   // Points to the attribute to be loaded.\n\n                keyLength = tsk_getu16(endian, keyB->key_len);\n                // make sure the fields we care about are still in the buffer\n                // +2 because key_len doesn't include its own length\n                // +16 for the amount of data we'll read from data\n                if (recOffset + keyLength + 2 + 16 > attrFile.nodeSize) {\n                    error_detected(TSK_ERR_FS_READ,\n                        \"hfs_load_extended_attrs: Unable to process attribute\");\n                    goto on_error;\n                }\n\n                recData = &recordBytes[keyLength + 2];\n\n                // Data must start on an even offset from the beginning of the record.\n                // So, correct this if needed.\n                if ((recData - recordBytes) % 2) {\n                    recData += 1;\n                }\n\n                attrData = (hfs_attr_data *) recData;\n\n                // Check we can process the record type before allocating memory\n                recordType = tsk_getu32(endian, attrData->record_type);\n                if (recordType != HFS_ATTR_RECORD_INLINE_DATA) {\n                  error_detected(TSK_ERR_FS_UNSUPTYPE,\n                      \"hfs_load_extended_attrs: Unsupported record type: (%d)\",\n                      recordType);\n                  goto on_error;\n                }\n\n                // This is the length of the useful data, not including the record header\n                attributeLength = tsk_getu32(endian, attrData->attr_size);\n\n                // Check the attribute fits in the node\n                //if (recordType != HFS_ATTR_RECORD_INLINE_DATA) {\n                if (recOffset + keyLength + 2 + attributeLength > attrFile.nodeSize) {\n                    error_detected(TSK_ERR_FS_READ,\n                        \"hfs_load_extended_attrs: Unable to process attribute\");\n                    goto on_error;\n                }\n\n                // attr_name_len is in UTF_16 chars\n                nameLength = tsk_getu16(endian, keyB->attr_name_len);\n                if (2*nameLength > HFS_MAX_ATTR_NAME_LEN_UTF16_B) {\n                    error_detected(TSK_ERR_FS_CORRUPT,\n                        \"hfs_load_extended_attrs: Name length (%d) is too long.\",\n                        nameLength);\n                    goto on_error;\n                }\n\n                buffer = tsk_malloc(attributeLength);\n                if (buffer == NULL) {\n                    error_detected(TSK_ERR_AUX_MALLOC,\n                        \"hfs_load_extended_attrs: Could not malloc space for the attribute.\");\n                    goto on_error;\n                }\n\n                memcpy(buffer, attrData->attr_data, attributeLength);\n\n                // Use the \"attr_name\" part of the key as the attribute name\n                // but must convert to UTF8.  Unfortunately, there does not seem to\n                // be any easy way to determine how long the converted string will\n                // be because UTF8 is a variable length encoding. However, the longest\n                // it will be is 3 * the max number of UTF16 code units.  Add one for null\n                // termination.   (thanks Judson!)\n                \n\n                conversionResult = hfs_UTF16toUTF8(fs, keyB->attr_name,\n                    nameLength, nameBuff, HFS_MAX_ATTR_NAME_LEN_UTF8_B+1, 0);\n                if (conversionResult != 0) {\n                    error_returned\n                        (\"-- hfs_load_extended_attrs could not convert the attr_name in the btree key into a UTF8 attribute name\");\n                    goto on_error;\n                }\n\n                // What is the type of this attribute?  If it is a compression record, then\n                // use TSK_FS_ATTR_TYPE_HFS_COMP_REC.  Else, use TSK_FS_ATTR_TYPE_HFS_EXT_ATTR\n                // Only \"inline data\" kind of record is handled.\n                if (strcmp(nameBuff, \"com.apple.decmpfs\") == 0 &&\n                    tsk_getu32(endian, attrData->record_type) == HFS_ATTR_RECORD_INLINE_DATA) {\n                    // Now, look at the compression record\n                    DECMPFS_DISK_HEADER *cmph = (DECMPFS_DISK_HEADER *) buffer;\n                    *cmpType =\n                        tsk_getu32(TSK_LIT_ENDIAN, cmph->compression_type);\n                    uint64_t uncSize = tsk_getu64(TSK_LIT_ENDIAN,\n                        cmph->uncompressed_size);\n\n                    if (tsk_verbose)\n                        tsk_fprintf(stderr,\n                            \"hfs_load_extended_attrs: This attribute is a compression record.\\n\");\n\n                    attrType = TSK_FS_ATTR_TYPE_HFS_COMP_REC;\n                    *isCompressed = TRUE;       // The data is governed by a compression record (but might not be compressed)\n                    *uncompressedSize = uncSize;\n\n                    switch (*cmpType) {\n                    // Data is inline. We will load the uncompressed\n                    // data as a resident attribute.\n                    case DECMPFS_TYPE_ZLIB_ATTR:\n                        if (!hfs_file_read_zlib_attr(\n                                fs_file, buffer, attributeLength, uncSize))\n                        {\n                            goto on_error;\n                        }\n                        break;\n\n                    case DECMPFS_TYPE_LZVN_ATTR:\n                        if (!hfs_file_read_lzvn_attr(\n                                fs_file, buffer, attributeLength, uncSize))\n                        {\n                            goto on_error;\n                        }\n                        break;\n\n                    // Data is compressed in the resource fork\n                    case DECMPFS_TYPE_ZLIB_RSRC:\n                    case DECMPFS_TYPE_LZVN_RSRC:\n                        if (tsk_verbose)\n                            tsk_fprintf(stderr,\n                                \"%s: Compressed data is in the file Resource Fork.\\n\", __func__);\n                        break;\n                    }\n                }\n                else {          // Attrbute name is NOT com.apple.decmpfs\n                    attrType = TSK_FS_ATTR_TYPE_HFS_EXT_ATTR;\n                }               // END if attribute name is com.apple.decmpfs  ELSE clause\n\n                if ((fs_attr =\n                        tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                            TSK_FS_ATTR_RES)) == NULL) {\n                    error_returned(\" - hfs_load_extended_attrs\");\n                    goto on_error;\n                }\n\n                if (tsk_verbose) {\n                    tsk_fprintf(stderr,\n                        \"hfs_load_extended_attrs: loading attribute %s, type %u (%s)\\n\",\n                        nameBuff, (uint32_t) attrType,\n                        hfs_attrTypeName((uint32_t) attrType));\n                }\n\n                // set the details in the fs_attr structure\n                if (tsk_fs_attr_set_str(fs_file, fs_attr, nameBuff,\n                        attrType, attribute_counter, buffer,\n                        attributeLength)) {\n                    error_returned(\" - hfs_load_extended_attrs\");\n                    goto on_error;\n                }\n\n                free(buffer);\n                buffer = NULL;\n\n                ++attribute_counter;\n            }                   // END if comp == 0\n            if (comp == 1) {\n                // since this record key is greater than our search key, all\n                // subsequent records will also be greater.\n                done = TRUE;\n                break;\n            }\n        }                       // END loop over records in one LEAF node\n\n        /*\n         * We get to this point if either:\n         *\n         * 1. We finish the loop over records and we are still loading attributes\n         *    for the given file.  In this case we are NOT done, and must read in\n         *    the next leaf node, and process its records.  The following code\n         *    loads the next leaf node before we return to the top of the loop.\n         *\n         * 2. We \"broke\" out of the loop over records because we found a key that\n         *    whose file ID is greater than the one we are working on.  In that case\n         *    we are done.  The following code does not run, and we exit the\n         *    while loop over successive leaf nodes.\n         */\n\n        if (!done) {\n            // We did not finish loading the attributes when we got to the end of that node,\n            // so we must get the next node, and continue.\n\n            // First determine the nodeID of the next LEAF node\n            uint32_t newNodeID = tsk_getu32(endian, nodeDescriptor->flink);\n\n            //fprintf(stdout, \"Next Node ID = %u\\n\",  newNodeID);\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_load_extended_attrs: Processed last record of THIS node, still gathering attributes.\\n\");\n\n            // If we are at the very last leaf node in the btree, then\n            // this \"flink\" will be zero.  We break out of this loop over LEAF nodes.\n            if (newNodeID == 0) {\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_load_extended_attrs: But, there are no more leaf nodes, so we are done.\\n\");\n                break;\n            }\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_load_extended_attrs: Reading the next LEAF node %\"\n                    PRIu32 \".\\n\", nodeID);\n\n            nodeID = newNodeID;\n\n            cnt = tsk_fs_file_read(attrFile.file,\n                nodeID * attrFile.nodeSize,\n                (char *) nodeData,\n                attrFile.nodeSize, (TSK_FS_FILE_READ_FLAG_ENUM) 0);\n            if (cnt != attrFile.nodeSize) {\n                error_returned\n                    (\"hfs_load_extended_attrs: Could not read in the next LEAF node from the Attributes File btree\");\n                goto on_error;\n            }\n\n            // Parse the Node header\n            nodeDescriptor = (hfs_btree_node *) nodeData;\n\n            // If we are NOT leaf node, then this is an error\n            if (nodeDescriptor->type != HFS_ATTR_NODE_LEAF) {\n                error_detected(TSK_ERR_FS_CORRUPT,\n                    \"hfs_load_extended_attrs: found a non-LEAF node as a successor to a LEAF node\");\n                goto on_error;\n            }\n        }                       // END if(! done)\n\n\n\n    }                           // END while(! done)  loop over successive LEAF nodes\n\non_exit:\n    free(nodeData);\n    tsk_list_free(nodeIDs_processed);\n    close_attr_file(&attrFile);\n    return 0;\n\non_error:\n    if (buffer != NULL) {\n        free(buffer);\n    }\n\n    if (nodeData != NULL) {\n        free(nodeData);\n    }\n\n    tsk_list_free(nodeIDs_processed);\n    close_attr_file(&attrFile);\n    return 1;\n}\n\ntypedef struct RES_DESCRIPTOR {\n    char type[5];               // type is really 4 chars, but we will null-terminate\n    uint16_t id;\n    uint32_t offset;\n    uint32_t length;\n    char *name;                 // NULL if a name is not defined for this resource\n    struct RES_DESCRIPTOR *next;\n} RES_DESCRIPTOR;\n\nvoid\nfree_res_descriptor(RES_DESCRIPTOR * rd)\n{\n    RES_DESCRIPTOR *nxt;\n\n    if (rd == NULL)\n        return;\n    nxt = rd->next;\n    if (rd->name != NULL)\n        free(rd->name);\n    free(rd);\n    free_res_descriptor(nxt);   // tail recursive\n}\n\n/**\n * The purpose of this function is to parse the resource fork of a file, and to return\n * a data structure that is, in effect, a table of contents for the resource fork.  The\n * data structure is a null-terminated linked list of entries.  Each one describes one\n * resource.  If the resource fork is empty, or if there is not a resource fork at all,\n * or an error occurs, this function returns NULL.\n *\n * A non-NULL answer should be freed by the caller, using free_res_descriptor.\n *\n */\n\nstatic RES_DESCRIPTOR *\nhfs_parse_resource_fork(TSK_FS_FILE * fs_file)\n{\n\n    RES_DESCRIPTOR *result = NULL;\n    RES_DESCRIPTOR *last = NULL;\n    TSK_FS_INFO *fs_info;\n    hfs_fork *fork_info;\n    hfs_fork *resForkInfo;\n    uint64_t resSize;\n    const TSK_FS_ATTR *rAttr;\n    hfs_resource_fork_header rfHeader;\n    hfs_resource_fork_header *resHead;\n    uint32_t dataOffset;\n    uint32_t mapOffset;\n    uint32_t mapLength;\n    char *map;\n    int attrReadResult;\n    int attrReadResult1;\n    int attrReadResult2;\n    hfs_resource_fork_map_header *mapHdr;\n    uint16_t typeListOffset;\n    uint16_t nameListOffset;\n    unsigned char hasNameList;\n    char *nameListBegin = NULL;\n    hfs_resource_type_list *typeList;\n    uint16_t numTypes;\n    hfs_resource_type_list_item *tlItem;\n    int mindx;                  // index for looping over resource types\n\n    if (fs_file == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_parse_resource_fork: null fs_file\");\n        return NULL;\n    }\n\n\n    if (fs_file->meta == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_parse_resource_fork: fs_file has null metadata\");\n        return NULL;\n    }\n\n    if (fs_file->meta->content_ptr == NULL) {\n        if (tsk_verbose)\n            fprintf(stderr,\n                \"hfs_parse_resource_fork: fs_file has null fork data structures, so no resources.\\n\");\n        return NULL;\n    }\n\n    // Extract the fs\n    fs_info = fs_file->fs_info;\n    if (fs_info == NULL) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_parse_resource_fork: null fs within fs_info\");\n        return NULL;\n    }\n\n    // Try to look at the Resource Fork for an HFS+ file\n    // Should be able to cast this to hfs_fork *\n    fork_info = (hfs_fork *) fs_file->meta->content_ptr;        // The data fork\n    // The resource fork is the second one.\n    resForkInfo = &fork_info[1];\n    resSize = tsk_getu64(fs_info->endian, resForkInfo->logic_sz);\n    //uint32_t numBlocks = tsk_getu32(fs_info->endian, resForkInfo->total_blk);\n    //uint32_t clmpSize = tsk_getu32(fs_info->endian, resForkInfo->clmp_sz);\n\n    // Hmm, certainly no resources here!\n    if (resSize == 0) {\n        return NULL;\n    }\n\n    // OK, resource size must be > 0\n\n    // find the attribute for the resource fork\n    rAttr =\n        tsk_fs_file_attr_get_type(fs_file, TSK_FS_ATTR_TYPE_HFS_RSRC,\n        HFS_FS_ATTR_ID_RSRC, TRUE);\n\n\n    if (rAttr == NULL) {\n        error_returned\n            (\"hfs_parse_resource_fork: could not get the resource fork attribute\");\n        return NULL;\n    }\n\n    // JUST read the resource fork header\n\n\n    attrReadResult1 =\n        tsk_fs_attr_read(rAttr, 0, (char *) &rfHeader,\n        sizeof(hfs_resource_fork_header), TSK_FS_FILE_READ_FLAG_NONE);\n\n    if (attrReadResult1 < 0\n        || attrReadResult1 != sizeof(hfs_resource_fork_header)) {\n        error_returned\n            (\" hfs_parse_resource_fork: trying to read the resource fork header\");\n        return NULL;\n    }\n\n    // Begin to parse the resource fork\n    resHead = &rfHeader;\n    dataOffset = tsk_getu32(fs_info->endian, resHead->dataOffset);\n    mapOffset = tsk_getu32(fs_info->endian, resHead->mapOffset);\n    //uint32_t dataLength = tsk_getu32(fs_info->endian, resHead->dataLength);\n    mapLength = tsk_getu32(fs_info->endian, resHead->mapLength);\n\n    // Read in the WHOLE map\n    map = (char *) tsk_malloc(mapLength);\n    if (map == NULL) {\n        error_returned\n            (\"- hfs_parse_resource_fork: could not allocate space for the resource fork map\");\n        return NULL;\n    }\n\n    attrReadResult =\n        tsk_fs_attr_read(rAttr, (uint64_t) mapOffset, map,\n        (size_t) mapLength, TSK_FS_FILE_READ_FLAG_NONE);\n\n    if (attrReadResult < 0 || attrReadResult != mapLength) {\n        error_returned\n            (\"- hfs_parse_resource_fork: could not read the map\");\n        free(map);\n        return NULL;\n    }\n\n    mapHdr = (hfs_resource_fork_map_header *) map;\n\n    typeListOffset = tsk_getu16(fs_info->endian, mapHdr->typeListOffset);\n\n    nameListOffset = tsk_getu16(fs_info->endian, mapHdr->nameListOffset);\n\n    if (nameListOffset >= mapLength || nameListOffset == 0) {\n        hasNameList = FALSE;\n    }\n    else {\n        hasNameList = TRUE;\n        nameListBegin = map + nameListOffset;\n    }\n\n    typeList = (hfs_resource_type_list *) (map + typeListOffset);\n    numTypes = tsk_getu16(fs_info->endian, typeList->typeCount) + 1;\n\n    for (mindx = 0; mindx < numTypes; ++mindx) {\n        uint16_t numRes;\n        uint16_t refOff;\n        int pindx;              // index for looping over resources\n        uint16_t rID;\n        uint32_t rOffset;\n\n        tlItem = &(typeList->type[mindx]);\n        numRes = tsk_getu16(fs_info->endian, tlItem->count) + 1;\n        refOff = tsk_getu16(fs_info->endian, tlItem->offset);\n\n\n        for (pindx = 0; pindx < numRes; ++pindx) {\n            int16_t nameOffset;\n            char *nameBuffer;\n            RES_DESCRIPTOR *rsrc;\n            char lenBuff[4];    // first 4 bytes of a resource encodes its length\n            uint32_t rLen;      // Resource length\n\n            hfs_resource_refListItem *item =\n                ((hfs_resource_refListItem *) (((uint8_t *) typeList) +\n                    refOff)) + pindx;\n            nameOffset = tsk_gets16(fs_info->endian, item->resNameOffset);\n            nameBuffer = NULL;\n\n            if (hasNameList && nameOffset != -1) {\n                char *name = nameListBegin + nameOffset;\n                uint8_t nameLen = (uint8_t) name[0];\n                nameBuffer = tsk_malloc(nameLen + 1);\n                if (nameBuffer == NULL) {\n                    error_returned\n                        (\"hfs_parse_resource_fork: allocating space for the name of a resource\");\n                    free_res_descriptor(result);\n                    return NULL;\n                }\n                memcpy(nameBuffer, name + 1, nameLen);\n                nameBuffer[nameLen] = (char) 0;\n            }\n            else {\n                nameBuffer = tsk_malloc(7);\n                if (nameBuffer == NULL) {\n                    error_returned\n                        (\"hfs_parse_resource_fork: allocating space for the (null) name of a resource\");\n                    free_res_descriptor(result);\n                    return NULL;\n                }\n                memcpy(nameBuffer, \"<none>\", 6);\n                nameBuffer[6] = (char) 0;\n            }\n\n            rsrc = (RES_DESCRIPTOR *) tsk_malloc(sizeof(RES_DESCRIPTOR));\n            if (rsrc == NULL) {\n                error_returned\n                    (\"hfs_parse_resource_fork: space for a resource descriptor\");\n                free_res_descriptor(result);\n                return NULL;\n            }\n\n            // Build the linked list\n            if (result == NULL)\n                result = rsrc;\n            if (last != NULL)\n                last->next = rsrc;\n            last = rsrc;\n            rsrc->next = NULL;\n\n            rID = tsk_getu16(fs_info->endian, item->resID);\n            rOffset =\n                tsk_getu24(fs_info->endian,\n                item->resDataOffset) + dataOffset;\n\n            // Just read the first four bytes of the resource to get its length.  It MUST\n            // be at least 4 bytes long\n            attrReadResult2 = tsk_fs_attr_read(rAttr, (uint64_t) rOffset,\n                lenBuff, (size_t) 4, TSK_FS_FILE_READ_FLAG_NONE);\n\n            if (attrReadResult2 != 4) {\n                error_returned\n                    (\"- hfs_parse_resource_fork: could not read the 4-byte length at beginning of resource\");\n                free_res_descriptor(result);\n                return NULL;\n            }\n            rLen = tsk_getu32(TSK_BIG_ENDIAN, lenBuff); //TODO\n\n            rsrc->id = rID;\n            rsrc->offset = rOffset + 4;\n            memcpy(rsrc->type, tlItem->type, 4);\n            rsrc->type[4] = (char) 0;\n            rsrc->length = rLen;\n            rsrc->name = nameBuffer;\n\n        }                       // END loop over resources of one type\n\n    }                           // END loop over resource types\n\n    return result;\n}\n\n\nstatic uint8_t\nhfs_load_attrs(TSK_FS_FILE * fs_file)\n{\n    TSK_FS_INFO *fs;\n    HFS_INFO *hfs;\n    TSK_FS_ATTR *fs_attr;\n    TSK_FS_ATTR_RUN *attr_run;\n    hfs_fork *forkx;\n    unsigned char resource_fork_has_contents = FALSE;\n    unsigned char compression_flag = FALSE;\n    unsigned char isCompressed = FALSE;\n    unsigned char compDataInRSRCFork = FALSE;\n    unsigned char cmpType = 0;\n    uint64_t uncompressedSize;\n    uint64_t logicalSize;       // of a fork\n\n    // clean up any error messages that are lying around\n    tsk_error_reset();\n\n    if ((fs_file == NULL) || (fs_file->meta == NULL)\n        || (fs_file->fs_info == NULL)) {\n        error_detected(TSK_ERR_FS_ARG,\n            \"hfs_load_attrs: fs_file or meta is NULL\");\n        return 1;\n    }\n\n    fs = (TSK_FS_INFO *) fs_file->fs_info;\n    hfs = (HFS_INFO *) fs;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_load_attrs: Processing file %\" PRIuINUM \"\\n\",\n            fs_file->meta->addr);\n\n\n    // see if we have already loaded the runs\n    if (fs_file->meta->attr_state == TSK_FS_META_ATTR_STUDIED) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_attrs: Attributes already loaded\\n\");\n        return 0;\n    }\n    else if (fs_file->meta->attr_state == TSK_FS_META_ATTR_ERROR) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_attrs: Previous attempt to load attributes resulted in error\\n\");\n        return 1;\n    }\n\n    // Now (re)-initialize the attrlist that will hold the list of attributes\n    if (fs_file->meta->attr != NULL) {\n        tsk_fs_attrlist_markunused(fs_file->meta->attr);\n    }\n    else if (fs_file->meta->attr == NULL) {\n        fs_file->meta->attr = tsk_fs_attrlist_alloc();\n    }\n\n    /****************** EXTENDED ATTRIBUTES *******************************/\n    // We do these first, so that we can detect the mode of compression, if\n    // any.  We need to know that mode in order to handle the forks.\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_load_attrs: loading the HFS+ extended attributes\\n\");\n\n    if (hfs_load_extended_attrs(fs_file, &isCompressed,\n            &cmpType, &uncompressedSize)) {\n        error_returned(\" - hfs_load_attrs A\");\n        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n        return 1;\n    }\n\n// TODO: What about DECMPFS_TYPE_RAW_RSRC?\n    switch (cmpType) {\n    case DECMPFS_TYPE_ZLIB_RSRC:\n    case DECMPFS_TYPE_LZVN_RSRC:\n        compDataInRSRCFork = TRUE;\n        break;\n    default:\n        compDataInRSRCFork = FALSE;\n        break;\n    }\n\n    if (isCompressed) {\n        fs_file->meta->size = uncompressedSize;\n    }\n\n    // This is the flag indicating compression, from the Catalog File record.\n    compression_flag = (fs_file->meta->flags & TSK_FS_META_FLAG_COMP) != 0;\n\n    if (compression_flag && !isCompressed) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_attrs: WARNING, HFS marks this as a\"\n                \" compressed file, but no compression record was found.\\n\");\n    }\n    if (isCompressed && !compression_flag) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_attrs: WARNING, this file has a compression\"\n                \" record, but the HFS compression flag is not set.\\n\");\n    }\n\n    /************* FORKS (both) ************************************/\n\n    // Process the data and resource forks.  We only do this if the\n    // fork data structures are non-null, so test that:\n    if (fs_file->meta->content_ptr != NULL) {\n\n        /**************  DATA FORK STUFF ***************************/\n\n        // Get the data fork data-structure\n        forkx = (hfs_fork *) fs_file->meta->content_ptr;\n\n        // If this is a compressed file, then either this attribute is already loaded\n        // because the data was in the compression record, OR\n        // the compressed data is in the resource fork.  We will load those runs when\n        // we handle the resource fork.\n        if (!isCompressed) {\n            // We only load this attribute if this fork has non-zero length\n            // or if this is a REG or LNK file.  Otherwise, we skip\n            logicalSize = tsk_getu64(fs->endian, forkx->logic_sz);\n\n            if (logicalSize > 0 ||\n                fs_file->meta->type == TSK_FS_META_TYPE_REG ||\n                fs_file->meta->type == TSK_FS_META_TYPE_LNK) {\n\n\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_load_attrs: loading the data fork attribute\\n\");\n\n                // get an attribute structure to store the data in\n                if ((fs_attr = tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                            TSK_FS_ATTR_NONRES)) == NULL) {\n                    error_returned(\" - hfs_load_attrs\");\n                    return 1;\n                }\n                /* NOTE that fs_attr is now tied to fs_file->meta->attr.\n                 * that means that we do not need to free it if we abort in the\n                 * following code (and doing so will cause double free errors). */\n\n                if (logicalSize > 0) {\n\n                    // Convert runs of blocks to the TSK internal form\n                    if (((attr_run =\n                                hfs_extents_to_attr(fs, forkx->extents,\n                                    0)) == NULL)\n                        && (tsk_error_get_errno() != 0)) {\n                        error_returned(\" - hfs_load_attrs\");\n                        return 1;\n                    }\n\n\n\n                    // add the runs to the attribute and the attribute to the file.\n                    if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run,\n                            \"\", TSK_FS_ATTR_TYPE_HFS_DATA,\n                            HFS_FS_ATTR_ID_DATA, logicalSize, logicalSize,\n                            (TSK_OFF_T) tsk_getu32(fs->endian,\n                                forkx->total_blk) * fs->block_size, 0,\n                            0)) {\n                        error_returned(\" - hfs_load_attrs (DATA)\");\n                        tsk_fs_attr_run_free(attr_run);\n                        return 1;\n                    }\n\n                    // see if extents file has additional runs\n                    if (hfs_ext_find_extent_record_attr(hfs,\n                            (uint32_t) fs_file->meta->addr, fs_attr,\n                            TRUE)) {\n                        error_returned(\" - hfs_load_attrs B\");\n                        fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n                        return 1;\n                    }\n\n                }\n                else {\n                    // logicalSize == 0, but this is either a REG or LNK file\n                    // so, it should have a DATA fork attribute of zero length.\n                    if (tsk_fs_attr_set_run(fs_file, fs_attr, NULL, \"\",\n                            TSK_FS_ATTR_TYPE_HFS_DATA, HFS_FS_ATTR_ID_DATA,\n                            0, 0, 0, 0, 0)) {\n                        error_returned(\" - hfs_load_attrs (non-file)\");\n                        return 1;\n                    }\n                }\n\n            }                   // END  logicalSize>0 or REG or LNK file type\n        }                       // END if not Compressed\n\n\n\n        /**************  RESOURCE FORK STUFF ************************************/\n\n        // Get the resource fork.\n        //Note that content_ptr points to an array of two\n        // hfs_fork data structures, the second of which\n        // describes the blocks of the resource fork.\n\n        forkx = &((hfs_fork *) fs_file->meta->content_ptr)[1];\n\n        logicalSize = tsk_getu64(fs->endian, forkx->logic_sz);\n\n        // Skip if the length of the resource fork is zero\n        if (logicalSize > 0) {\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_load_attrs: loading the resource fork\\n\");\n\n            resource_fork_has_contents = TRUE;\n\n            // get an attribute structure to store the resource fork data in.  We will\n            // reuse the fs_attr variable, since we are done with the data fork.\n            if ((fs_attr =\n                    tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                        TSK_FS_ATTR_NONRES)) == NULL) {\n                error_returned(\" - hfs_load_attrs (RSRC)\");\n                return 1;\n            }\n            /* NOTE that fs_attr is now tied to fs_file->meta->attr.\n             * that means that we do not need to free it if we abort in the\n             * following code (and doing so will cause double free errors). */\n\n\n            // convert the resource fork to the TSK format\n            if (((attr_run =\n                        hfs_extents_to_attr(fs, forkx->extents,\n                            0)) == NULL)\n                && (tsk_error_get_errno() != 0)) {\n                error_returned(\" - hfs_load_attrs\");\n                return 1;\n            }\n\n            // add the runs to the attribute and the attribute to the file.\n            if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, \"RSRC\",\n                    TSK_FS_ATTR_TYPE_HFS_RSRC, HFS_FS_ATTR_ID_RSRC,\n                    tsk_getu64(fs->endian, forkx->logic_sz),\n                    tsk_getu64(fs->endian, forkx->logic_sz),\n                    (TSK_OFF_T) tsk_getu32(fs->endian,\n                        forkx->total_blk) * fs->block_size, 0, 0)) {\n                error_returned(\" - hfs_load_attrs (RSRC)\");\n                tsk_fs_attr_run_free(attr_run);\n                return 1;\n            }\n\n            // see if extents file has additional runs for the resource fork.\n            if (hfs_ext_find_extent_record_attr(hfs,\n                    (uint32_t) fs_file->meta->addr, fs_attr, FALSE)) {\n                error_returned(\" - hfs_load_attrs C\");\n                fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n                return 1;\n            }\n\n            if (isCompressed && compDataInRSRCFork) {\n                // OK, we are going to load those same resource fork blocks as the \"DATA\"\n                // attribute, but will mark it as compressed.\n                // get an attribute structure to store the resource fork data in.  We will\n                // reuse the fs_attr variable, since we are done with the data fork.\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"File is compressed with data in the resource fork. \"\n                        \"Loading the default DATA attribute.\\n\");\n                if ((fs_attr =\n                        tsk_fs_attrlist_getnew(fs_file->meta->attr,\n                            TSK_FS_ATTR_NONRES)) == NULL) {\n                    error_returned\n                        (\" - hfs_load_attrs (RSRC loading as DATA)\");\n                    return 1;\n                }\n                /* NOTE that fs_attr is now tied to fs_file->meta->attr.\n                 * that means that we do not need to free it if we abort in the\n                 * following code (and doing so will cause double free errors). */\n\n                switch (cmpType) {\n                case DECMPFS_TYPE_ZLIB_RSRC:\n#ifdef HAVE_LIBZ\n                    fs_attr->w = hfs_attr_walk_zlib_rsrc;\n                    fs_attr->r = hfs_file_read_zlib_rsrc;\n#else\n                    // We don't have zlib, so the uncompressed data is not\n                    // available to us; however, we must have a default DATA\n                    // attribute, or icat will misbehave.\n                    if (tsk_verbose)\n                        tsk_fprintf(stderr,\n                            \"hfs_load_attrs: No zlib compression library, so setting a zero-length default DATA attribute.\\n\");\n\n                    if (tsk_fs_attr_set_run(fs_file, fs_attr, NULL, \"DATA\",\n                            TSK_FS_ATTR_TYPE_HFS_DATA, HFS_FS_ATTR_ID_DATA, 0,\n                            0, 0, 0, 0)) {\n                        error_returned(\" - hfs_load_attrs (non-file)\");\n                        return 1;\n                    }\n#endif\n                    break;\n\n                case DECMPFS_TYPE_LZVN_RSRC:\n\n                    fs_attr->w = hfs_attr_walk_lzvn_rsrc;\n                    fs_attr->r = hfs_file_read_lzvn_rsrc;\n\n                    break;\n                }\n\n                // convert the resource fork to the TSK format\n                if (((attr_run =\n                            hfs_extents_to_attr(fs, forkx->extents,\n                                0)) == NULL)\n                    && (tsk_error_get_errno() != 0)) {\n                    error_returned\n                        (\" - hfs_load_attrs, RSRC fork as DATA fork\");\n                    return 1;\n                }\n\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_load_attrs:  Loading RSRC fork block runs as the default DATA attribute.\\n\");\n\n                // add the runs to the attribute and the attribute to the file.\n                if (tsk_fs_attr_set_run(fs_file, fs_attr, attr_run, \"DECOMP\",\n                        TSK_FS_ATTR_TYPE_HFS_DATA, HFS_FS_ATTR_ID_DATA,\n                        logicalSize,\n                        logicalSize,\n                        (TSK_OFF_T) tsk_getu32(fs->endian,\n                            forkx->total_blk) * fs->block_size,\n                        TSK_FS_ATTR_COMP | TSK_FS_ATTR_NONRES, 0)) {\n                    error_returned\n                        (\" - hfs_load_attrs (RSRC loading as DATA)\");\n                    tsk_fs_attr_run_free(attr_run);\n                    return 1;\n                }\n\n                // see if extents file has additional runs for the resource fork.\n                if (hfs_ext_find_extent_record_attr(hfs,\n                        (uint32_t) fs_file->meta->addr, fs_attr, FALSE)) {\n                    error_returned\n                        (\" - hfs_load_attrs (RSRC loading as DATA\");\n                    fs_file->meta->attr_state = TSK_FS_META_ATTR_ERROR;\n                    return 1;\n                }\n\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_load_attrs: setting the \\\"special\\\" function pointers to inflate compressed data.\\n\");\n            }\n\n        }                       // END resource fork size > 0\n\n    }                           // END the fork data structures are non-NULL\n\n    if (isCompressed && compDataInRSRCFork && !resource_fork_has_contents) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_load_attrs: WARNING, compression record claims that compressed data\"\n                \" is in the Resource Fork, but that fork is empty or non-existent.\\n\");\n    }\n\n    // Finish up.\n    fs_file->meta->attr_state = TSK_FS_META_ATTR_STUDIED;\n\n    return 0;\n}\n\n\n/** \\internal\n* Get allocation status of file system block.\n* adapted from IsAllocationBlockUsed from:\n* http://developer.apple.com/technotes/tn/tn1150.html\n*\n* @param hfs File system being analyzed\n* @param b Block address\n* @returns 1 if allocated, 0 if not, -1 on error\n*/\nstatic int8_t\nhfs_block_is_alloc(HFS_INFO * hfs, TSK_DADDR_T a_addr)\n{\n    TSK_FS_INFO *fs = &(hfs->fs_info);\n    TSK_OFF_T b;\n    size_t b2;\n\n    // lazy loading\n    if (hfs->blockmap_file == NULL) {\n        if ((hfs->blockmap_file =\n                tsk_fs_file_open_meta(fs, NULL,\n                    HFS_ALLOCATION_FILE_ID)) == NULL) {\n            tsk_error_errstr2_concat(\" - Loading blockmap file\");\n            return -1;\n        }\n\n        /* cache the data attribute */\n        hfs->blockmap_attr =\n            tsk_fs_attrlist_get(hfs->blockmap_file->meta->attr,\n            TSK_FS_ATTR_TYPE_DEFAULT);\n        if (!hfs->blockmap_attr) {\n            tsk_error_errstr2_concat\n                (\" - Data Attribute not found in Blockmap File\");\n            return -1;\n        }\n        hfs->blockmap_cache_start = -1;\n        hfs->blockmap_cache_len = 0;\n    }\n\n    // get the byte offset\n    b = (TSK_OFF_T) a_addr / 8;\n    if (b > hfs->blockmap_file->meta->size) {\n        tsk_error_set_errno(TSK_ERR_FS_CORRUPT);\n        tsk_error_set_errstr(\"hfs_block_is_alloc: block %\" PRIuDADDR\n            \" is too large for bitmap (%\" PRIuOFF \")\", a_addr,\n            hfs->blockmap_file->meta->size);\n        return -1;\n    }\n\n    // see if it is in the cache\n    if ((hfs->blockmap_cache_start == -1)\n        || (hfs->blockmap_cache_start > b)\n        || (hfs->blockmap_cache_start + hfs->blockmap_cache_len <= b)) {\n        size_t cnt = tsk_fs_attr_read(hfs->blockmap_attr, b,\n            hfs->blockmap_cache,\n            sizeof(hfs->blockmap_cache), 0);\n        if (cnt < 1) {\n            tsk_error_set_errstr2\n                (\"hfs_block_is_alloc: Error reading block bitmap at offset %\"\n                PRIuOFF, b);\n            return -1;\n        }\n        hfs->blockmap_cache_start = b;\n        hfs->blockmap_cache_len = cnt;\n    }\n    b2 = (size_t) (b - hfs->blockmap_cache_start);\n    return (hfs->blockmap_cache[b2] & (1 << (7 - (a_addr % 8)))) != 0;\n}\n\n\nTSK_FS_BLOCK_FLAG_ENUM\nhfs_block_getflags(TSK_FS_INFO * a_fs, TSK_DADDR_T a_addr)\n{\n    return (hfs_block_is_alloc((HFS_INFO *) a_fs, a_addr) == 1) ?\n        TSK_FS_BLOCK_FLAG_ALLOC : TSK_FS_BLOCK_FLAG_UNALLOC;\n}\n\n\nstatic uint8_t\nhfs_block_walk(TSK_FS_INFO * fs, TSK_DADDR_T start_blk,\n    TSK_DADDR_T end_blk, TSK_FS_BLOCK_WALK_FLAG_ENUM flags,\n    TSK_FS_BLOCK_WALK_CB action, void *ptr)\n{\n    char *myname = \"hfs_block_walk\";\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    TSK_FS_BLOCK *fs_block;\n    TSK_DADDR_T addr;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"%s: start_blk: %\" PRIuDADDR \" end_blk: %\"\n            PRIuDADDR \" flags: %\" PRIu32 \"\\n\", myname, start_blk, end_blk,\n            flags);\n\n    // clean up any error messages that are lying around\n    tsk_error_reset();\n\n    /*\n     * Sanity checks.\n     */\n    if (start_blk < fs->first_block || start_blk > fs->last_block) {\n        tsk_error_set_errno(TSK_ERR_FS_WALK_RNG);\n        tsk_error_set_errstr(\"%s: invalid start block number: %\" PRIuDADDR\n            \"\", myname, start_blk);\n        return 1;\n    }\n    if (end_blk < fs->first_block || end_blk > fs->last_block) {\n        tsk_error_set_errno(TSK_ERR_FS_WALK_RNG);\n        tsk_error_set_errstr(\"%s: invalid last block number: %\" PRIuDADDR\n            \"\", myname, end_blk);\n        return 1;\n    }\n\n    if (start_blk > end_blk)\n        XSWAP(start_blk, end_blk);\n\n    /* Sanity check on flags -- make sure at least one ALLOC is set */\n    if (((flags & TSK_FS_BLOCK_WALK_FLAG_ALLOC) == 0) &&\n        ((flags & TSK_FS_BLOCK_WALK_FLAG_UNALLOC) == 0)) {\n        flags |=\n            (TSK_FS_BLOCK_WALK_FLAG_ALLOC |\n            TSK_FS_BLOCK_WALK_FLAG_UNALLOC);\n    }\n    if (((flags & TSK_FS_BLOCK_WALK_FLAG_META) == 0) &&\n        ((flags & TSK_FS_BLOCK_WALK_FLAG_CONT) == 0)) {\n        flags |=\n            (TSK_FS_BLOCK_WALK_FLAG_CONT | TSK_FS_BLOCK_WALK_FLAG_META);\n    }\n\n    if ((fs_block = tsk_fs_block_alloc(fs)) == NULL) {\n        return 1;\n    }\n\n    /*\n     * Iterate\n     */\n    for (addr = start_blk; addr <= end_blk; ++addr) {\n        int retval;\n        int myflags;\n\n        /* identify if the block is allocated or not */\n        myflags = hfs_block_is_alloc(hfs, addr) ?\n            TSK_FS_BLOCK_FLAG_ALLOC : TSK_FS_BLOCK_FLAG_UNALLOC;\n\n        // test if we should call the callback with this one\n        if ((myflags & TSK_FS_BLOCK_FLAG_ALLOC)\n            && (!(flags & TSK_FS_BLOCK_WALK_FLAG_ALLOC)))\n            continue;\n        else if ((myflags & TSK_FS_BLOCK_FLAG_UNALLOC)\n            && (!(flags & TSK_FS_BLOCK_WALK_FLAG_UNALLOC)))\n            continue;\n\n        if (flags & TSK_FS_BLOCK_WALK_FLAG_AONLY)\n            myflags |= TSK_FS_BLOCK_FLAG_AONLY;\n\n        if (tsk_fs_block_get_flag(fs, fs_block, addr,\n                (TSK_FS_BLOCK_FLAG_ENUM) myflags) == NULL) {\n            tsk_fs_block_free(fs_block);\n            return 1;\n        }\n\n        retval = action(fs_block, ptr);\n        if (TSK_WALK_STOP == retval) {\n            break;\n        }\n        else if (TSK_WALK_ERROR == retval) {\n            tsk_fs_block_free(fs_block);\n            return 1;\n        }\n    }\n\n    tsk_fs_block_free(fs_block);\n    return 0;\n}\n\n\nuint8_t\nhfs_inode_walk(TSK_FS_INFO * fs, TSK_INUM_T start_inum,\n    TSK_INUM_T end_inum, TSK_FS_META_FLAG_ENUM flags,\n    TSK_FS_META_WALK_CB action, void *ptr)\n{\n    TSK_INUM_T inum;\n    TSK_FS_FILE *fs_file;\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_inode_walk: start_inum: %\" PRIuINUM \" end_inum: %\"\n            PRIuINUM \" flags: %\" PRIu32 \"\\n\", start_inum, end_inum, flags);\n\n    /*\n     * Sanity checks.\n     */\n    if (start_inum < fs->first_inum || start_inum > fs->last_inum) {\n        tsk_error_reset();\n        tsk_error_set_errno(TSK_ERR_FS_WALK_RNG);\n        tsk_error_set_errstr(\"inode_walk: Start inode: %\" PRIuINUM \"\",\n            start_inum);\n        return 1;\n    }\n    else if (end_inum < fs->first_inum || end_inum > fs->last_inum\n        || end_inum < start_inum) {\n        tsk_error_reset();\n        tsk_error_set_errno(TSK_ERR_FS_WALK_RNG);\n        tsk_error_set_errstr(\"inode_walk: End inode: %\" PRIuINUM \"\",\n            end_inum);\n        return 1;\n    }\n\n    /* If ORPHAN is wanted, then make sure that the flags are correct */\n    if (flags & TSK_FS_META_FLAG_ORPHAN) {\n        flags |= TSK_FS_META_FLAG_UNALLOC;\n        flags &= ~TSK_FS_META_FLAG_ALLOC;\n        flags |= TSK_FS_META_FLAG_USED;\n        flags &= ~TSK_FS_META_FLAG_UNUSED;\n    }\n\n    else {\n        if (((flags & TSK_FS_META_FLAG_ALLOC) == 0) &&\n            ((flags & TSK_FS_META_FLAG_UNALLOC) == 0)) {\n            flags |= (TSK_FS_META_FLAG_ALLOC | TSK_FS_META_FLAG_UNALLOC);\n        }\n\n        /* If neither of the USED or UNUSED flags are set, then set them\n         * both\n         */\n        if (((flags & TSK_FS_META_FLAG_USED) == 0) &&\n            ((flags & TSK_FS_META_FLAG_UNUSED) == 0)) {\n            flags |= (TSK_FS_META_FLAG_USED | TSK_FS_META_FLAG_UNUSED);\n        }\n    }\n\n    if ((fs_file = tsk_fs_file_alloc(fs)) == NULL)\n        return 1;\n\n    if ((fs_file->meta = tsk_fs_meta_alloc(HFS_FILE_CONTENT_LEN)) == NULL)\n        return 1;\n\n    if (start_inum > end_inum)\n        XSWAP(start_inum, end_inum);\n\n    for (inum = start_inum; inum <= end_inum; ++inum) {\n        int retval;\n\n        if (hfs_inode_lookup(fs, fs_file, inum)) {\n            // deleted files may not exist in the catalog\n            if (tsk_error_get_errno() == TSK_ERR_FS_INODE_NUM) {\n                tsk_error_reset();\n                continue;\n            }\n            else {\n                return 1;\n            }\n        }\n\n        if ((fs_file->meta->flags & flags) != fs_file->meta->flags)\n            continue;\n\n        /* call action */\n        retval = action(fs_file, ptr);\n        if (retval == TSK_WALK_STOP) {\n            tsk_fs_file_close(fs_file);\n            return 0;\n        }\n        else if (retval == TSK_WALK_ERROR) {\n            tsk_fs_file_close(fs_file);\n            return 1;\n        }\n    }\n\n    tsk_fs_file_close(fs_file);\n    return 0;\n}\n\n/* return the name of a file at a given inode\n * in a newly-allocated string, or NULL on error\n */\nchar *\nhfs_get_inode_name(TSK_FS_INFO * fs, TSK_INUM_T inum)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    HFS_ENTRY entry;\n    char *fn = NULL;\n\n    if (hfs_cat_file_lookup(hfs, inum, &entry, FALSE))\n        return NULL;\n\n    fn = malloc(HFS_MAXNAMLEN + 1);\n    if (fn == NULL)\n        return NULL;\n\n    if (hfs_UTF16toUTF8(fs, entry.thread.name.unicode,\n            tsk_getu16(fs->endian, entry.thread.name.length), fn,\n            HFS_MAXNAMLEN + 1, HFS_U16U8_FLAG_REPLACE_SLASH)) {\n        free(fn);\n        return NULL;\n    }\n\n    return fn;\n}\n\n/* print the name of a file at a given inode\n * returns 0 on success, 1 on error */\nstatic uint8_t\nprint_inode_name(FILE * hFile, TSK_FS_INFO * fs, TSK_INUM_T inum)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    char fn[HFS_MAXNAMLEN + 1];\n    HFS_ENTRY entry;\n\n    if (hfs_cat_file_lookup(hfs, inum, &entry, FALSE))\n        return 1;\n\n    if (hfs_UTF16toUTF8(fs, entry.thread.name.unicode,\n            tsk_getu16(fs->endian, entry.thread.name.length), fn,\n            HFS_MAXNAMLEN + 1, HFS_U16U8_FLAG_REPLACE_SLASH))\n        return 1;\n\n    tsk_fprintf(hFile, \"%s\", fn);\n\n    return 0;\n}\n\n/* tail recursive function to print a path... prints the parent path, then\n * appends / and the name of the given inode. prints nothing for root\n * returns 0 on success, 1 on failure\n */\nstatic uint8_t\nprint_parent_path(FILE * hFile, TSK_FS_INFO * fs, TSK_INUM_T inum)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    char fn[HFS_MAXNAMLEN + 1];\n    HFS_ENTRY entry;\n\n    if (inum == HFS_ROOT_INUM)\n        return 0;\n\n    if (inum <= HFS_ROOT_INUM) {\n        tsk_error_set_errno(TSK_ERR_FS_INODE_NUM);\n        tsk_error_set_errstr(\"print_parent_path: out-of-range inode %\"\n            PRIuINUM, inum);\n        return 1;\n    }\n\n    if (hfs_cat_file_lookup(hfs, inum, &entry, FALSE))\n        return 1;\n\n    if (hfs_UTF16toUTF8(fs, entry.thread.name.unicode,\n            tsk_getu16(fs->endian, entry.thread.name.length), fn,\n            HFS_MAXNAMLEN + 1,\n            HFS_U16U8_FLAG_REPLACE_SLASH | HFS_U16U8_FLAG_REPLACE_CONTROL))\n        return 1;\n\n    if (print_parent_path(hFile, fs, (TSK_INUM_T) tsk_getu32(fs->endian,\n                entry.thread.parent_cnid)))\n        return 1;\n\n    tsk_fprintf(hFile, \"/%s\", fn);\n    return 0;\n}\n\n/* print the file name corresponding to an inode, in brackets after a space.\n * uses Unix path conventions, and does not include the volume name.\n * returns 0 on success, 1 on failure\n */\nstatic uint8_t\nprint_inode_file(FILE * hFile, TSK_FS_INFO * fs, TSK_INUM_T inum)\n{\n    tsk_fprintf(hFile, \" [\");\n    if (inum == HFS_ROOT_INUM)\n        tsk_fprintf(hFile, \"/\");\n    else {\n        if (print_parent_path(hFile, fs, inum)) {\n            tsk_fprintf(hFile, \"unknown]\");\n            return 1;\n        }\n    }\n    tsk_fprintf(hFile, \"]\");\n    return 0;\n}\n\nstatic uint8_t\nhfs_fscheck(TSK_FS_INFO * fs, FILE * hFile)\n{\n    tsk_error_reset();\n    tsk_error_set_errno(TSK_ERR_FS_UNSUPFUNC);\n    tsk_error_set_errstr(\"fscheck not implemented for HFS yet\");\n    return 1;\n}\n\n\nstatic uint8_t\nhfs_fsstat(TSK_FS_INFO * fs, FILE * hFile)\n{\n    // char *myname = \"hfs_fsstat\";\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    hfs_plus_vh *sb = hfs->fs;\n    time_t mac_time;\n    TSK_INUM_T inode;\n    char timeBuf[128];\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_fstat: called\\n\");\n\n    tsk_fprintf(hFile, \"FILE SYSTEM INFORMATION\\n\");\n    tsk_fprintf(hFile, \"--------------------------------------------\\n\");\n\n    tsk_fprintf(hFile, \"File System Type: \");\n    if (tsk_getu16(fs->endian, hfs->fs->signature) == HFS_VH_SIG_HFSPLUS)\n        tsk_fprintf(hFile, \"HFS+\\n\");\n    else if (tsk_getu16(fs->endian, hfs->fs->signature) == HFS_VH_SIG_HFSX)\n        tsk_fprintf(hFile, \"HFSX\\n\");\n    else\n        tsk_fprintf(hFile, \"Unknown\\n\");\n\n    // print name and number of version\n    tsk_fprintf(hFile, \"File System Version: \");\n    switch (tsk_getu16(fs->endian, hfs->fs->version)) {\n    case 4:\n        tsk_fprintf(hFile, \"HFS+\\n\");\n        break;\n    case 5:\n        tsk_fprintf(hFile, \"HFSX\\n\");\n        break;\n    default:\n        tsk_fprintf(hFile, \"Unknown (%\" PRIu16 \")\\n\",\n            tsk_getu16(fs->endian, hfs->fs->version));\n        break;\n    }\n\n    if (tsk_getu16(fs->endian, hfs->fs->signature) == HFS_VH_SIG_HFSX) {\n        tsk_fprintf(hFile, \"Case Sensitive: %s\\n\",\n            hfs->is_case_sensitive ? \"yes\" : \"no\");\n    }\n\n    if (hfs->hfs_wrapper_offset > 0) {\n        tsk_fprintf(hFile,\n            \"File system is embedded in an HFS wrapper at offset %\" PRIuOFF\n            \"\\n\", hfs->hfs_wrapper_offset);\n    }\n\n    tsk_fprintf(hFile, \"\\nVolume Name: \");\n    if (print_inode_name(hFile, fs, HFS_ROOT_INUM))\n        return 1;\n    tsk_fprintf(hFile, \"\\n\");\n\n    tsk_fprintf(hFile, \"Volume Identifier: %08\" PRIx32 \"%08\" PRIx32 \"\\n\",\n        tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_ID1]),\n        tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_ID2]));\n\n\n    // print last mounted info\n    tsk_fprintf(hFile, \"\\nLast Mounted By: \");\n    if (tsk_getu32(fs->endian, sb->last_mnt_ver) == HFS_VH_MVER_HFSPLUS)\n        tsk_fprintf(hFile, \"Mac OS X\\n\");\n    else if (tsk_getu32(fs->endian, sb->last_mnt_ver) == HFS_VH_MVER_HFSJ)\n        tsk_fprintf(hFile, \"Mac OS X, Journaled\\n\");\n    else if (tsk_getu32(fs->endian, sb->last_mnt_ver) == HFS_VH_MVER_FSK)\n        tsk_fprintf(hFile, \"failed journal replay\\n\");\n    else if (tsk_getu32(fs->endian, sb->last_mnt_ver) == HFS_VH_MVER_FSCK)\n        tsk_fprintf(hFile, \"fsck_hfs\\n\");\n    else if (tsk_getu32(fs->endian, sb->last_mnt_ver) == HFS_VH_MVER_OS89)\n        tsk_fprintf(hFile, \"Mac OS 8.1 - 9.2.2\\n\");\n    else\n        tsk_fprintf(hFile, \"Unknown (%\" PRIx32 \"\\n\",\n            tsk_getu32(fs->endian, sb->last_mnt_ver));\n\n    /* State of the file system */\n    if ((tsk_getu32(fs->endian, hfs->fs->attr) & HFS_VH_ATTR_UNMOUNTED)\n        && (!(tsk_getu32(fs->endian,\n                    hfs->fs->attr) & HFS_VH_ATTR_INCONSISTENT)))\n        tsk_fprintf(hFile, \"Volume Unmounted Properly\\n\");\n    else\n        tsk_fprintf(hFile, \"Volume Unmounted Improperly\\n\");\n\n    tsk_fprintf(hFile, \"Mount Count: %\" PRIu32 \"\\n\",\n        tsk_getu32(fs->endian, sb->write_cnt));\n\n\n    // Dates\n    // (creation date is in local time zone, not UTC, according to TN 1150)\n    mac_time =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, hfs->fs->cr_date));\n    tsk_fprintf(hFile, \"\\nCreation Date: \\t%s\\n\",\n        tsk_fs_time_to_str(mktime(gmtime(&mac_time)), timeBuf));\n\n    mac_time =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, hfs->fs->m_date));\n    tsk_fprintf(hFile, \"Last Written Date: \\t%s\\n\",\n        tsk_fs_time_to_str(mac_time, timeBuf));\n\n    mac_time =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian,\n            hfs->fs->bkup_date));\n    tsk_fprintf(hFile, \"Last Backup Date: \\t%s\\n\",\n        tsk_fs_time_to_str(mac_time, timeBuf));\n\n    mac_time =\n        hfs_convert_2_unix_time(tsk_getu32(fs->endian, hfs->fs->chk_date));\n    tsk_fprintf(hFile, \"Last Checked Date: \\t%s\\n\",\n        tsk_fs_time_to_str(mac_time, timeBuf));\n\n\n    if (tsk_getu32(fs->endian, hfs->fs->attr) & HFS_VH_ATTR_SOFTWARE_LOCK)\n        tsk_fprintf(hFile, \"Software write protect enabled\\n\");\n\n    /* Print journal information */\n    if (tsk_getu32(fs->endian, sb->attr) & HFS_VH_ATTR_JOURNALED) {\n        tsk_fprintf(hFile, \"\\nJournal Info Block: %\" PRIu32 \"\\n\",\n            tsk_getu32(fs->endian, sb->jinfo_blk));\n    }\n\n    tsk_fprintf(hFile, \"\\nMETADATA INFORMATION\\n\");\n    tsk_fprintf(hFile, \"--------------------------------------------\\n\");\n\n    tsk_fprintf(hFile, \"Range: %\" PRIuINUM \" - %\" PRIuINUM \"\\n\",\n        fs->first_inum, fs->last_inum);\n\n    inode = tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_BOOT]);\n    tsk_fprintf(hFile, \"Bootable Folder ID: %\" PRIuINUM, inode);\n    if (inode > 0)\n        print_inode_file(hFile, fs, inode);\n    tsk_fprintf(hFile, \"\\n\");\n\n    inode = tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_START]);\n    tsk_fprintf(hFile, \"Startup App ID: %\" PRIuINUM, inode);\n    if (inode > 0)\n        print_inode_file(hFile, fs, inode);\n    tsk_fprintf(hFile, \"\\n\");\n\n    inode = tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_OPEN]);\n    tsk_fprintf(hFile, \"Startup Open Folder ID: %\" PRIuINUM, inode);\n    if (inode > 0)\n        print_inode_file(hFile, fs, inode);\n    tsk_fprintf(hFile, \"\\n\");\n\n    inode = tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_BOOT9]);\n    tsk_fprintf(hFile, \"Mac OS 8/9 Blessed System Folder ID: %\" PRIuINUM,\n        inode);\n    if (inode > 0)\n        print_inode_file(hFile, fs, inode);\n    tsk_fprintf(hFile, \"\\n\");\n\n    inode = tsk_getu32(fs->endian, sb->finder_info[HFS_VH_FI_BOOTX]);\n    tsk_fprintf(hFile, \"Mac OS X Blessed System Folder ID: %\" PRIuINUM,\n        inode);\n    if (inode > 0)\n        print_inode_file(hFile, fs, inode);\n    tsk_fprintf(hFile, \"\\n\");\n\n    tsk_fprintf(hFile, \"Number of files: %\" PRIu32 \"\\n\",\n        tsk_getu32(fs->endian, sb->file_cnt));\n    tsk_fprintf(hFile, \"Number of folders: %\" PRIu32 \"\\n\",\n        tsk_getu32(fs->endian, sb->fldr_cnt));\n\n\n    tsk_fprintf(hFile, \"\\nCONTENT INFORMATION\\n\");\n    tsk_fprintf(hFile, \"--------------------------------------------\\n\");\n\n    tsk_fprintf(hFile, \"Block Range: %\" PRIuDADDR \" - %\" PRIuDADDR \"\\n\",\n        fs->first_block, fs->last_block);\n\n    if (fs->last_block != fs->last_block_act)\n        tsk_fprintf(hFile,\n            \"Total Range in Image: %\" PRIuDADDR \" - %\" PRIuDADDR \"\\n\",\n            fs->first_block, fs->last_block_act);\n\n    tsk_fprintf(hFile, \"Allocation Block Size: %u\\n\", fs->block_size);\n\n    tsk_fprintf(hFile, \"Number of Free Blocks: %\" PRIu32 \"\\n\",\n        tsk_getu32(fs->endian, sb->free_blks));\n\n    if (tsk_getu32(fs->endian, hfs->fs->attr) & HFS_VH_ATTR_BADBLOCKS)\n        tsk_fprintf(hFile, \"Volume has bad blocks\\n\");\n\n    return 0;\n}\n\n\n/************************* istat *******************************/\n\n\n/**\n * Text encoding names defined in TN1150, Table 2.\n */\nstatic char *\ntext_encoding_name(uint32_t enc)\n{\n    switch (enc) {\n    case 0:\n        return \"MacRoman\";\n    case 1:\n        return \"MacJapanese\";\n    case 2:\n        return \"MacChineseTrad\";\n    case 4:\n        return \"MacKorean\";\n    case 5:\n        return \"MacArabic\";\n    case 6:\n        return \"MacHebrew\";\n    case 7:\n        return \"MacGreek\";\n    case 8:\n        return \"MacCyrillic\";\n    case 9:\n        return \"MacDevanagari\";\n    case 10:\n        return \"MacGurmukhi\";\n    case 11:\n        return \"MacGujarati\";\n    case 12:\n        return \"MacOriya\";\n    case 13:\n        return \"MacBengali\";\n    case 14:\n        return \"MacTamil\";\n    case 15:\n        return \"Telugu\";\n    case 16:\n        return \"MacKannada\";\n    case 17:\n        return \"MacMalayalam\";\n    case 18:\n        return \"MacSinhalese\";\n    case 19:\n        return \"MacBurmese\";\n    case 20:\n        return \"MacKhmer\";\n    case 21:\n        return \"MacThai\";\n    case 22:\n        return \"MacLaotian\";\n    case 23:\n        return \"MacGeorgian\";\n    case 24:\n        return \"MacArmenian\";\n    case 25:\n        return \"MacChineseSimp\";\n    case 26:\n        return \"MacTibetan\";\n    case 27:\n        return \"MacMongolian\";\n    case 28:\n        return \"MacEthiopic\";\n    case 29:\n        return \"MacCentralEurRoman\";\n    case 30:\n        return \"MacVietnamese\";\n    case 31:\n        return \"MacExtArabic\";\n    case 33:\n        return \"MacSymbol\";\n    case 34:\n        return \"MacDingbats\";\n    case 35:\n        return \"MacTurkish\";\n    case 36:\n        return \"MacCroatian\";\n    case 37:\n        return \"MacIcelandic\";\n    case 38:\n        return \"MacRomanian\";\n    case 49:\n    case 140:\n        return \"MacFarsi\";\n    case 48:\n    case 152:\n        return \"MacUkrainian\";\n    default:\n        return \"Unknown encoding\";\n    }\n}\n\n#define HFS_PRINT_WIDTH 8\ntypedef struct {\n    FILE *hFile;\n    int idx;\n    TSK_DADDR_T startBlock;\n    uint32_t blockCount;\n    unsigned char accumulating;\n} HFS_PRINT_ADDR;\n\nstatic void\noutput_print_addr(HFS_PRINT_ADDR * print)\n{\n    if (!print->accumulating)\n        return;\n    if (print->blockCount == 1) {\n        tsk_fprintf(print->hFile, \"%\" PRIuDADDR \"  \", print->startBlock);\n        print->idx += 1;\n    }\n    else if (print->blockCount > 1) {\n        tsk_fprintf(print->hFile, \"%\" PRIuDADDR \"-%\" PRIuDADDR \"  \",\n            print->startBlock, print->startBlock + print->blockCount - 1);\n        print->idx += 2;\n    }\n    if (print->idx >= HFS_PRINT_WIDTH) {\n        tsk_fprintf(print->hFile, \"\\n\");\n        print->idx = 0;\n    }\n}\n\nstatic TSK_WALK_RET_ENUM\nprint_addr_act(TSK_FS_FILE * fs_file, TSK_OFF_T a_off, TSK_DADDR_T addr,\n    char *buf, size_t size, TSK_FS_BLOCK_FLAG_ENUM flags, void *ptr)\n{\n    HFS_PRINT_ADDR *print = (HFS_PRINT_ADDR *) ptr;\n\n    if (print->accumulating) {\n        if (addr == print->startBlock + print->blockCount) {\n            ++print->blockCount;\n        }\n        else {\n            output_print_addr(print);\n\n            print->startBlock = addr;\n            print->blockCount = 1;\n        }\n    }\n    else {\n        print->startBlock = addr;\n        print->blockCount = 1;\n        print->accumulating = TRUE;\n    }\n\n    return TSK_WALK_CONT;\n}\n\n/**\n * Print details on a specific file to a file handle.\n *\n * @param fs File system file is located in\n * @param hFile File name to print text to\n * @param inum Address of file in file system\n * @param numblock The number of blocks in file to force print (can go beyond file size)\n * @param sec_skew Clock skew in seconds to also print times in\n *\n * @returns 1 on error and 0 on success\n */\nstatic uint8_t\nhfs_istat(TSK_FS_INFO * fs, TSK_FS_ISTAT_FLAG_ENUM istat_flags, FILE * hFile, TSK_INUM_T inum,\n    TSK_DADDR_T numblock, int32_t sec_skew)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    TSK_FS_FILE *fs_file;\n    char hfs_mode[12];\n    HFS_PRINT_ADDR print;\n    HFS_ENTRY entry;\n    char timeBuf[128];\n    // Compression ATTR, if there is one:\n    const TSK_FS_ATTR *compressionAttr = NULL;\n    RES_DESCRIPTOR *rd;         // descriptor of a resource\n\n    tsk_error_reset();\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr,\n            \"hfs_istat: inum: %\" PRIuINUM \" numblock: %\" PRIu32 \"\\n\",\n            inum, numblock);\n\n    if ((fs_file = tsk_fs_file_open_meta(fs, NULL, inum)) == NULL) {\n        error_returned(\"hfs_istat: getting metadata for the file\");\n        return 1;\n    }\n\n    if (inum >= HFS_FIRST_USER_CNID) {\n        int rslt;\n        tsk_fprintf(hFile, \"File Path: \");\n        rslt = print_parent_path(hFile, fs, inum);\n        if (rslt != 0)\n            tsk_fprintf(hFile, \" Error in printing path\\n\");\n        else\n            tsk_fprintf(hFile, \"\\n\");\n    }\n    else {\n        // All of the files in this inum range have names without nulls,\n        // slashes or control characters.  So, it is OK to print this UTF8\n        // string this way.\n        if (fs_file->meta->name2 != NULL)\n            tsk_fprintf(hFile, \"File Name: %s\\n\",\n                fs_file->meta->name2->name);\n    }\n\n    tsk_fprintf(hFile, \"Catalog Record: %\" PRIuINUM \"\\n\", inum);\n    tsk_fprintf(hFile, \"%sAllocated\\n\",\n        (fs_file->meta->flags & TSK_FS_META_FLAG_UNALLOC) ? \"Not \" : \"\");\n\n    tsk_fprintf(hFile, \"Type:\\t\");\n    if (fs_file->meta->type == TSK_FS_META_TYPE_REG)\n        tsk_fprintf(hFile, \"File\\n\");\n    else if (TSK_FS_IS_DIR_META(fs_file->meta->type))\n        tsk_fprintf(hFile, \"Folder\\n\");\n    else\n        tsk_fprintf(hFile, \"\\n\");\n\n    tsk_fs_meta_make_ls(fs_file->meta, hfs_mode, sizeof(hfs_mode));\n    tsk_fprintf(hFile, \"Mode:\\t%s\\n\", hfs_mode);\n    tsk_fprintf(hFile, \"Size:\\t%\" PRIuOFF \"\\n\", fs_file->meta->size);\n\n    if (fs_file->meta->link)\n        tsk_fprintf(hFile, \"Symbolic link to:\\t%s\\n\", fs_file->meta->link);\n\n    tsk_fprintf(hFile, \"uid / gid: %\" PRIuUID \" / %\" PRIuGID \"\\n\",\n        fs_file->meta->uid, fs_file->meta->gid);\n\n    tsk_fprintf(hFile, \"Link count:\\t%d\\n\", fs_file->meta->nlink);\n\n    if (hfs_cat_file_lookup(hfs, inum, &entry, TRUE) == 0) {\n        hfs_uni_str *nm = &entry.thread.name;\n        char name_buf[HFS_MAXNAMLEN + 1];\n        TSK_INUM_T par_cnid;    // parent CNID\n\n        tsk_fprintf(hFile, \"\\n\");\n        hfs_UTF16toUTF8(fs, nm->unicode, (int) tsk_getu16(fs->endian,\n                nm->length), &name_buf[0], HFS_MAXNAMLEN + 1,\n            HFS_U16U8_FLAG_REPLACE_SLASH | HFS_U16U8_FLAG_REPLACE_CONTROL);\n        tsk_fprintf(hFile, \"File Name: %s\\n\", name_buf);\n\n        // Test here to see if this is a hard link.\n        par_cnid = tsk_getu32(fs->endian, &(entry.thread.parent_cnid));\n        if ((hfs->has_meta_dir_crtime && par_cnid == hfs->meta_dir_inum) ||\n            (hfs->has_meta_crtime && par_cnid == hfs->meta_inum)) {\n            int instr = strncmp(name_buf, \"iNode\", 5);\n            int drstr = strncmp(name_buf, \"dir_\", 4);\n\n            if (instr == 0 &&\n                hfs->has_meta_crtime && par_cnid == hfs->meta_inum) {\n                tsk_fprintf(hFile, \"This is a hard link to a file\\n\");\n            }\n            else if (drstr == 0 &&\n                hfs->has_meta_dir_crtime &&\n                par_cnid == hfs->meta_dir_inum) {\n                tsk_fprintf(hFile, \"This is a hard link to a folder.\\n\");\n            }\n        }\n\n        /* The cat.perm union contains file-type specific values.\n         * Print them if they are relevant. */\n        if ((fs_file->meta->type == TSK_FS_META_TYPE_CHR) ||\n            (fs_file->meta->type == TSK_FS_META_TYPE_BLK)) {\n            tsk_fprintf(hFile, \"Device ID:\\t%\" PRIu32 \"\\n\",\n                tsk_getu32(fs->endian, entry.cat.std.perm.special.raw));\n        }\n        else if ((tsk_getu32(fs->endian,\n                    entry.cat.std.u_info.file_type) ==\n                HFS_HARDLINK_FILE_TYPE)\n            && (tsk_getu32(fs->endian,\n                    entry.cat.std.u_info.file_cr) ==\n                HFS_HARDLINK_FILE_CREATOR)) {\n            // technically, the creation date of this item should be the same as either the\n            // creation date of the \"HFS+ Private Data\" folder or the creation date of the root folder\n            tsk_fprintf(hFile, \"Hard link inode number\\t %\" PRIu32 \"\\n\",\n                tsk_getu32(fs->endian, entry.cat.std.perm.special.inum));\n        }\n\n        tsk_fprintf(hFile, \"Admin flags: %\" PRIu8,\n            entry.cat.std.perm.a_flags);\n        if (entry.cat.std.perm.a_flags != 0) {\n            tsk_fprintf(hFile, \" - \");\n            if (entry.cat.std.perm.a_flags & HFS_PERM_AFLAG_ARCHIVED)\n                tsk_fprintf(hFile, \"archived \");\n            if (entry.cat.std.perm.a_flags & HFS_PERM_AFLAG_IMMUTABLE)\n                tsk_fprintf(hFile, \"immutable \");\n            if (entry.cat.std.perm.a_flags & HFS_PERM_AFLAG_APPEND)\n                tsk_fprintf(hFile, \"append-only \");\n        }\n        tsk_fprintf(hFile, \"\\n\");\n\n        tsk_fprintf(hFile, \"Owner flags: %\" PRIu8,\n            entry.cat.std.perm.o_flags);\n        if (entry.cat.std.perm.o_flags != 0) {\n            tsk_fprintf(hFile, \" - \");\n            if (entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_NODUMP)\n                tsk_fprintf(hFile, \"no-dump \");\n            if (entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_IMMUTABLE)\n                tsk_fprintf(hFile, \"immutable \");\n            if (entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_APPEND)\n                tsk_fprintf(hFile, \"append-only \");\n            if (entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_OPAQUE)\n                tsk_fprintf(hFile, \"opaque \");\n            if (entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_COMPRESSED)\n                tsk_fprintf(hFile, \"compressed \");\n        }\n        tsk_fprintf(hFile, \"\\n\");\n\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.flags) & HFS_FILE_FLAG_LOCKED)\n            tsk_fprintf(hFile, \"Locked\\n\");\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.flags) & HFS_FILE_FLAG_ATTR)\n            tsk_fprintf(hFile, \"Has extended attributes\\n\");\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.flags) & HFS_FILE_FLAG_ACL)\n            tsk_fprintf(hFile, \"Has security data (ACLs)\\n\");\n\n        // File_type and file_cr are not relevant for Folders\n        if ( !TSK_FS_IS_DIR_META(fs_file->meta->type)){\n            int windx;          // loop index\n            tsk_fprintf(hFile,\n                \"File type:\\t%04\" PRIx32 \"  \",\n                tsk_getu32(fs->endian, entry.cat.std.u_info.file_type));\n\n            for (windx = 0; windx < 4; ++windx) {\n                uint8_t cu = entry.cat.std.u_info.file_type[windx];\n                if (cu >= 32 && cu <= 126)\n                    tsk_fprintf(hFile, \"%c\", (char) cu);\n                else\n                    tsk_fprintf(hFile, \" \");\n            }\n            tsk_fprintf(hFile, \"\\n\");\n            tsk_fprintf(hFile,\n                \"File creator:\\t%04\" PRIx32 \"  \",\n                tsk_getu32(fs->endian, entry.cat.std.u_info.file_cr));\n            for (windx = 0; windx < 4; ++windx) {\n                uint8_t cu = entry.cat.std.u_info.file_cr[windx];\n                if (cu >= 32 && cu <= 126)\n                    tsk_fprintf(hFile, \"%c\", (char) cu);\n                else\n                    tsk_fprintf(hFile, \" \");\n            }\n            tsk_fprintf(hFile, \"\\n\");\n        }                       // END if(not folder)\n\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.u_info.flags) & HFS_FINDER_FLAG_NAME_LOCKED)\n            tsk_fprintf(hFile, \"Name locked\\n\");\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.u_info.flags) & HFS_FINDER_FLAG_HAS_BUNDLE)\n            tsk_fprintf(hFile, \"Has bundle\\n\");\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.u_info.flags) & HFS_FINDER_FLAG_IS_INVISIBLE)\n            tsk_fprintf(hFile, \"Is invisible\\n\");\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.u_info.flags) & HFS_FINDER_FLAG_IS_ALIAS)\n            tsk_fprintf(hFile, \"Is alias\\n\");\n\n        tsk_fprintf(hFile, \"Text encoding:\\t%\" PRIx32 \" = %s\\n\",\n            tsk_getu32(fs->endian, entry.cat.std.text_enc),\n            text_encoding_name(tsk_getu32(fs->endian,\n                    entry.cat.std.text_enc)));\n\n        if (tsk_getu16(fs->endian,\n                entry.cat.std.rec_type) == HFS_FILE_RECORD) {\n            tsk_fprintf(hFile, \"Resource fork size:\\t%\" PRIu64 \"\\n\",\n                tsk_getu64(fs->endian, entry.cat.resource.logic_sz));\n        }\n    }\n\n    if (sec_skew != 0) {\n        tsk_fprintf(hFile, \"\\nAdjusted times:\\n\");\n        if (fs_file->meta->mtime)\n            fs_file->meta->mtime -= sec_skew;\n        if (fs_file->meta->atime)\n            fs_file->meta->atime -= sec_skew;\n        if (fs_file->meta->ctime)\n            fs_file->meta->ctime -= sec_skew;\n        if (fs_file->meta->crtime)\n            fs_file->meta->crtime -= sec_skew;\n        if (fs_file->meta->time2.hfs.bkup_time)\n            fs_file->meta->time2.hfs.bkup_time -= sec_skew;\n\n        tsk_fprintf(hFile, \"Created:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_file->meta->crtime, timeBuf));\n        tsk_fprintf(hFile, \"Content Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_file->meta->mtime, timeBuf));\n        tsk_fprintf(hFile, \"Attributes Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_file->meta->ctime, timeBuf));\n        tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_file->meta->atime, timeBuf));\n        tsk_fprintf(hFile, \"Backed Up:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_file->meta->time2.hfs.bkup_time,\n                timeBuf));\n\n        if (fs_file->meta->mtime)\n            fs_file->meta->mtime += sec_skew;\n        if (fs_file->meta->atime)\n            fs_file->meta->atime += sec_skew;\n        if (fs_file->meta->ctime)\n            fs_file->meta->ctime += sec_skew;\n        if (fs_file->meta->crtime)\n            fs_file->meta->crtime += sec_skew;\n        if (fs_file->meta->time2.hfs.bkup_time)\n            fs_file->meta->time2.hfs.bkup_time += sec_skew;\n\n        tsk_fprintf(hFile, \"\\nOriginal times:\\n\");\n    }\n    else {\n        tsk_fprintf(hFile, \"\\nTimes:\\n\");\n    }\n\n    tsk_fprintf(hFile, \"Created:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_file->meta->crtime, timeBuf));\n    tsk_fprintf(hFile, \"Content Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_file->meta->mtime, timeBuf));\n    tsk_fprintf(hFile, \"Attributes Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_file->meta->ctime, timeBuf));\n    tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_file->meta->atime, timeBuf));\n    tsk_fprintf(hFile, \"Backed Up:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_file->meta->time2.hfs.bkup_time, timeBuf));\n\n    // IF this is a regular file, then print out the blocks of the DATA and RSRC forks.\n    if (tsk_getu16(fs->endian, entry.cat.std.rec_type) == HFS_FILE_RECORD) {\n        // Only print DATA fork blocks if this file is NOT compressed\n        // N.B., a compressed file has no data fork, and tsk_fs_file_walk() will\n        //   do the wrong thing!\n        if (!(entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_COMPRESSED)) {\n\n            if (!(istat_flags & TSK_FS_ISTAT_RUNLIST)) {\n                tsk_fprintf(hFile, \"\\nData Fork Blocks:\\n\");\n                print.idx = 0;\n                print.hFile = hFile;\n                print.accumulating = FALSE;\n                print.startBlock = 0;\n                print.blockCount = 0;\n\n                if (tsk_fs_file_walk_type(fs_file,\n                    TSK_FS_ATTR_TYPE_HFS_DATA, HFS_FS_ATTR_ID_DATA,\n                    (TSK_FS_FILE_WALK_FLAG_AONLY |\n                        TSK_FS_FILE_WALK_FLAG_SLACK), print_addr_act,\n                        (void *)&print)) {\n                    tsk_fprintf(hFile, \"\\nError reading file data fork\\n\");\n                    tsk_error_print(hFile);\n                    tsk_error_reset();\n                }\n                else {\n                    output_print_addr(&print);\n                    if (print.idx != 0)\n                        tsk_fprintf(hFile, \"\\n\");\n                }\n            }\n        }\n\n        // Only print out the blocks of the Resource fork if it has nonzero size\n        if (tsk_getu64(fs->endian, entry.cat.resource.logic_sz) > 0) {\n\n            if (! (istat_flags & TSK_FS_ISTAT_RUNLIST)) {\n                tsk_fprintf(hFile, \"\\nResource Fork Blocks:\\n\");\n\n                print.idx = 0;\n                print.hFile = hFile;\n                print.accumulating = FALSE;\n                print.startBlock = 0;\n                print.blockCount = 0;\n\n                if (tsk_fs_file_walk_type(fs_file,\n                    TSK_FS_ATTR_TYPE_HFS_RSRC, HFS_FS_ATTR_ID_RSRC,\n                    (TSK_FS_FILE_WALK_FLAG_AONLY |\n                        TSK_FS_FILE_WALK_FLAG_SLACK), print_addr_act,\n                        (void *)&print)) {\n                    tsk_fprintf(hFile, \"\\nError reading file resource fork\\n\");\n                    tsk_error_print(hFile);\n                    tsk_error_reset();\n                }\n                else {\n                    output_print_addr(&print);\n                    if (print.idx != 0)\n                        tsk_fprintf(hFile, \"\\n\");\n                }\n            }\n        }\n    }\n\n    // Force the loading of all attributes.\n    (void) tsk_fs_file_attr_get(fs_file);\n\n    /* Print all of the attributes */\n    tsk_fprintf(hFile, \"\\nAttributes: \\n\");\n    if (fs_file->meta->attr) {\n        int cnt, i;\n\n        // cycle through the attributes\n        cnt = tsk_fs_file_attr_getsize(fs_file);\n        for (i = 0; i < cnt; ++i) {\n            const char *type;   // type of the attribute as a string\n            const TSK_FS_ATTR *fs_attr =\n                tsk_fs_file_attr_get_idx(fs_file, i);\n            if (!fs_attr)\n                continue;\n\n            type = hfs_attrTypeName((uint32_t) fs_attr->type);\n\n            // We will need to do something better than this, in the end.\n            //type = \"Data\";\n\n            /* print the layout if it is non-resident and not \"special\" */\n            if (fs_attr->flags & TSK_FS_ATTR_NONRES) {\n                //NTFS_PRINT_ADDR print_addr;\n\n                tsk_fprintf(hFile,\n                    \"Type: %s (%\" PRIu32 \"-%\" PRIu16\n                    \")   Name: %s   Non-Resident%s%s%s   size: %\"\n                    PRIuOFF \"  init_size: %\" PRIuOFF \"\\n\", type,\n                    fs_attr->type, fs_attr->id,\n                    (fs_attr->name) ? fs_attr->name : \"N/A\",\n                    (fs_attr->flags & TSK_FS_ATTR_ENC) ? \", Encrypted\" :\n                    \"\",\n                    (fs_attr->flags & TSK_FS_ATTR_COMP) ? \", Compressed\" :\n                    \"\",\n                    (fs_attr->flags & TSK_FS_ATTR_SPARSE) ? \", Sparse\" :\n                    \"\", fs_attr->size, fs_attr->nrd.initsize);\n\n                if (istat_flags & TSK_FS_ISTAT_RUNLIST) {\n                    if (tsk_fs_attr_print(fs_attr, hFile)) {\n                        tsk_fprintf(hFile, \"\\nError creating run lists\\n\");\n                        tsk_error_print(hFile);\n                        tsk_error_reset();\n                    }\n                }\n            }                   // END:  non-resident attribute case\n            else {\n                tsk_fprintf(hFile,\n                    \"Type: %s (%\" PRIu32 \"-%\" PRIu16\n                    \")   Name: %s   Resident%s%s%s   size: %\"\n                    PRIuOFF \"\\n\",\n                    type,\n                    fs_attr->type,\n                    fs_attr->id,\n                    (fs_attr->name) ? fs_attr->name : \"N/A\",\n                    (fs_attr->flags & TSK_FS_ATTR_ENC) ? \", Encrypted\" :\n                    \"\",\n                    (fs_attr->flags & TSK_FS_ATTR_COMP) ? \", Compressed\" :\n                    \"\",\n                    (fs_attr->flags & TSK_FS_ATTR_SPARSE) ? \", Sparse\" :\n                    \"\", fs_attr->size);\n                if (fs_attr->type == TSK_FS_ATTR_TYPE_HFS_COMP_REC) {\n                    if (compressionAttr == NULL) {\n                        compressionAttr = fs_attr;\n                    }\n                    else {\n                        // Problem:  there is more than one compression attribute\n                        error_detected(TSK_ERR_FS_CORRUPT,\n                            \"hfs_istat: more than one compression attribute\");\n                        return 1;\n                    }\n                }\n            }                   // END: else (RESIDENT attribute case)\n        }                       // END:  for(;;)  loop over attributes\n    }                           // END:  if(fs_file->meta->attr is non-NULL)\n\n    if ((entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_COMPRESSED)\n        && (compressionAttr == NULL))\n        tsk_fprintf(hFile,\n            \"WARNING: Compression Flag is set, but there\"\n            \" is no compression record for this file.\\n\");\n    if (((entry.cat.std.perm.o_flags & HFS_PERM_OFLAG_COMPRESSED) == 0)\n        && (compressionAttr != NULL))\n        tsk_fprintf(hFile,\n            \"WARNING: Compression Flag is NOT set, but there\"\n            \" is a compression record for this file.\\n\");\n\n    // IF this is a compressed file\n    if (compressionAttr != NULL) {\n        const TSK_FS_ATTR *fs_attr = compressionAttr;\n        int attrReadResult;\n        DECMPFS_DISK_HEADER *cmph;\n        uint32_t cmpType;\n        uint64_t uncSize;\n        uint64_t cmpSize = 0;\n\n        // Read the attribute.  It cannot be too large because it is stored in\n        // a btree node\n        char *aBuf = (char *) tsk_malloc((size_t) fs_attr->size);\n        if (aBuf == NULL) {\n            error_returned(\"hfs_istat: space for a compression attribute\");\n            return 1;\n        }\n        attrReadResult = tsk_fs_attr_read(fs_attr, (TSK_OFF_T) 0,\n            aBuf, (size_t) fs_attr->size,\n            (TSK_FS_FILE_READ_FLAG_ENUM) 0x00);\n        if (attrReadResult == -1) {\n            error_returned(\"hfs_istat: reading the compression attribute\");\n            free(aBuf);\n            return 1;\n        }\n        else if (attrReadResult < fs_attr->size) {\n            error_detected(TSK_ERR_FS_READ,\n                \"hfs_istat: could not read the whole compression attribute\");\n            free(aBuf);\n            return 1;\n        }\n        // Now, cast the attr into a compression header\n        cmph = (DECMPFS_DISK_HEADER *) aBuf;\n        cmpType = tsk_getu32(TSK_LIT_ENDIAN, cmph->compression_type);\n        uncSize = tsk_getu64(TSK_LIT_ENDIAN, cmph->uncompressed_size);\n\n        tsk_fprintf(hFile, \"\\nCompressed File:\\n\");\n        tsk_fprintf(hFile, \"    Uncompressed size: %llu\\n\", uncSize);\n\n        switch (cmpType) {\n        case DECMPFS_TYPE_ZLIB_ATTR:\n            // Data is inline\n            {\n                // size of header, with indicator byte if uncompressed\n                uint32_t off = (cmph->attr_bytes[0] & 0x0F) == 0x0F ? 17 : 16;\n                cmpSize = fs_attr->size - off;\n\n                tsk_fprintf(hFile,\n                    \"    Data follows compression record in the CMPF attribute\\n\"\n                    \"    %\" PRIu64 \" bytes of data at offset %u, %s compressed\\n\",\n                    cmpSize, off, off == 16 ? \"zlib\" : \"not\");\n            }\n            break;\n\n        case DECMPFS_TYPE_LZVN_ATTR:\n            // Data is inline\n            {\n                // size of header, with indicator byte if uncompressed\n                uint32_t off = cmph->attr_bytes[0] == 0x06 ? 17 : 16;\n                cmpSize = fs_attr->size - off;\n\n                tsk_fprintf(hFile,\n                    \"    Data follows compression record in the CMPF attribute\\n\"\n                    \"    %\" PRIu64 \" bytes of data at offset %u, %s compressed\\n\",\n                    cmpSize, off, off == 16 ? \"lzvn\" : \"not\");\n            }\n            break;\n\n        case DECMPFS_TYPE_ZLIB_RSRC:\n            // Data is zlib compressed in the resource fork\n            tsk_fprintf(hFile,\n                \"    Data is zlib compressed in the resource fork\\n\");\n            break;\n\n        case DECMPFS_TYPE_LZVN_RSRC:\n            // Data is lzvn compressed in the resource fork\n            tsk_fprintf(hFile,\n                \"    Data is lzvn compressed in the resource fork\\n\");\n            break;\n\n        default:\n            tsk_fprintf(hFile, \"    Compression type is %u: UNKNOWN\\n\",\n                cmpType);\n        }\n\n        free(aBuf);\n\n        if ((cmpType == DECMPFS_TYPE_ZLIB_RSRC ||\n             cmpType == DECMPFS_TYPE_LZVN_RSRC)\n            && (tsk_getu64(fs->endian, entry.cat.resource.logic_sz) == 0))\n            tsk_fprintf(hFile,\n                \"WARNING: Compression record indicates compressed data\"\n                \" in the RSRC Fork, but that fork is empty.\\n\");\n    }\n\n    // This will return NULL if there is an error, or if there are no resources\n    rd = hfs_parse_resource_fork(fs_file);\n    // TODO: Should check the errnum here to see if there was an error\n\n    if (rd != NULL) {\n        tsk_fprintf(hFile, \"\\nResources:\\n\");\n        while (rd) {\n            tsk_fprintf(hFile,\n                \"  Type: %s \\tID: %-5u \\tOffset: %-5u \\tSize: %-5u \\tName: %s\\n\",\n                rd->type, rd->id, rd->offset, rd->length, rd->name);\n            rd = rd->next;\n        }\n    }\n    // This is OK to call with NULL\n    free_res_descriptor(rd);\n\n    tsk_fs_file_close(fs_file);\n    return 0;\n}\n\n\n\nstatic TSK_FS_ATTR_TYPE_ENUM\nhfs_get_default_attr_type(const TSK_FS_FILE * a_file)\n{\n    // The HFS+ special files have a default attr type of \"Default\"\n    TSK_INUM_T inum = a_file->meta->addr;\n    if (inum == 3 ||            // Extents File\n        inum == 4 ||            // Catalog File\n        inum == 5 ||            // Bad Blocks File\n        inum == 6 ||            // Block Map (Allocation File)\n        inum == 7 ||            // Startup File\n        inum == 8 ||            // Attributes File\n        inum == 14 ||           // Not sure if these two will actually work.  I don't see\n        inum == 15)             // any code to load the attrs of these files, if they exist.\n        return TSK_FS_ATTR_TYPE_DEFAULT;\n    // The \"regular\" files and symbolic links have a DATA fork with type \"DATA\"\n    if (a_file->meta->type == TSK_FS_META_TYPE_REG ||\n        a_file->meta->type == TSK_FS_META_TYPE_LNK)\n        // This should be an HFS-specific type.\n        return TSK_FS_ATTR_TYPE_HFS_DATA;\n\n    // We've got to return *something* for every file, so we return this.\n    return TSK_FS_ATTR_TYPE_DEFAULT;\n}\n\nstatic void\nhfs_close(TSK_FS_INFO * fs)\n{\n    HFS_INFO *hfs = (HFS_INFO *) fs;\n    // We'll grab this lock a bit early.\n    tsk_take_lock(&(hfs->metadata_dir_cache_lock));\n    fs->tag = 0;\n\n    free(hfs->fs);\n\n    if (hfs->catalog_file) {\n        tsk_fs_file_close(hfs->catalog_file);\n        hfs->catalog_attr = NULL;\n    }\n\n    if (hfs->blockmap_file) {\n        tsk_fs_file_close(hfs->blockmap_file);\n        hfs->blockmap_attr = NULL;\n    }\n\n    if (hfs->meta_dir) {\n        tsk_fs_dir_close(hfs->meta_dir);\n        hfs->meta_dir = NULL;\n    }\n\n    if (hfs->dir_meta_dir) {\n        tsk_fs_dir_close(hfs->dir_meta_dir);\n        hfs->dir_meta_dir = NULL;\n    }\n\n    if (hfs->extents_file) {\n        tsk_fs_file_close(hfs->extents_file);\n        hfs->extents_file = NULL;\n    }\n\n    tsk_release_lock(&(hfs->metadata_dir_cache_lock));\n    tsk_deinit_lock(&(hfs->metadata_dir_cache_lock));\n\n    tsk_fs_free((TSK_FS_INFO *)hfs);\n}\n\n/* hfs_open - open an hfs file system\n *\n * Return NULL on error (or not an HFS or HFS+ file system)\n * */\n\nTSK_FS_INFO *\nhfs_open(TSK_IMG_INFO * img_info, TSK_OFF_T offset,\n    TSK_FS_TYPE_ENUM ftype, uint8_t test)\n{\n    HFS_INFO *hfs;\n    unsigned int len;\n    TSK_FS_INFO *fs;\n    ssize_t cnt;\n    TSK_FS_FILE *file;          // The root directory, or the metadata directories\n    TSK_INUM_T inum;            // The inum (or CNID) of the metadata directories\n    int8_t result;              // of tsk_fs_path2inum()\n\n    tsk_error_reset();\n\n    if (TSK_FS_TYPE_ISHFS(ftype) == 0) {\n        tsk_error_set_errno(TSK_ERR_FS_ARG);\n        tsk_error_set_errstr(\"Invalid FS Type in hfs_open\");\n        return NULL;\n    }\n\n    if ((hfs = (HFS_INFO *) tsk_fs_malloc(sizeof(HFS_INFO))) == NULL)\n        return NULL;\n\n    fs = &(hfs->fs_info);\n\n    fs->ftype = TSK_FS_TYPE_HFS;\n    fs->duname = \"Allocation Block\";\n    fs->tag = TSK_FS_INFO_TAG;\n    fs->flags = 0;\n\n    fs->img_info = img_info;\n    fs->offset = offset;\n\n    /*\n     * Read the superblock.\n     */\n    len = sizeof(hfs_plus_vh);\n    if ((hfs->fs = (hfs_plus_vh *) tsk_malloc(len)) == NULL) {\n        fs->tag = 0;\n        tsk_fs_free((TSK_FS_INFO *)hfs);\n        return NULL;\n    }\n\n    if (hfs_checked_read_random(fs, (char *) hfs->fs, len,\n            (TSK_OFF_T) HFS_VH_OFF)) {\n        tsk_error_set_errstr2(\"hfs_open: superblock\");\n        fs->tag = 0;\n        free(hfs->fs);\n        tsk_fs_free((TSK_FS_INFO *)hfs);\n        return NULL;\n    }\n\n    /*\n     * Verify we are looking at an HFS+ image\n     */\n    if (tsk_fs_guessu16(fs, hfs->fs->signature, HFS_VH_SIG_HFSPLUS) &&\n        tsk_fs_guessu16(fs, hfs->fs->signature, HFS_VH_SIG_HFSX) &&\n        tsk_fs_guessu16(fs, hfs->fs->signature, HFS_VH_SIG_HFS)) {\n\n        fs->tag = 0;\n        free(hfs->fs);\n        tsk_fs_free((TSK_FS_INFO *)hfs);\n        tsk_error_set_errno(TSK_ERR_FS_MAGIC);\n        tsk_error_set_errstr(\"not an HFS+ file system (magic)\");\n        return NULL;\n    }\n\n    /*\n     * Handle an HFS-wrapped HFS+ image, which is a HFS volume that contains\n     * the HFS+ volume inside of it.\n     */\n    if (tsk_getu16(fs->endian, hfs->fs->signature) == HFS_VH_SIG_HFS) {\n\n        hfs_mdb *wrapper_sb = (hfs_mdb *) hfs->fs;\n\n        // Verify that we are setting a wrapper and not a normal HFS volume\n        if ((tsk_getu16(fs->endian,\n                    wrapper_sb->drEmbedSigWord) == HFS_VH_SIG_HFSPLUS)\n            || (tsk_getu16(fs->endian,\n                    wrapper_sb->drEmbedSigWord) == HFS_VH_SIG_HFSX)) {\n\n            TSK_FS_INFO *fs_info2;\n            // offset in sectors to start of first HFS block\n            uint16_t drAlBlSt =\n                tsk_getu16(fs->endian, wrapper_sb->drAlBlSt);\n\n            // size of each HFS block\n            uint32_t drAlBlkSiz =\n                tsk_getu32(fs->endian, wrapper_sb->drAlBlkSiz);\n\n            // start of embedded FS\n            uint16_t startBlock = tsk_getu16(fs->endian,\n                wrapper_sb->drEmbedExtent_startBlock);\n\n            // calculate the offset; 512 here is intentional.\n            // TN1150 says \"The drAlBlSt field contains the offset, in\n            // 512-byte blocks, of the wrapper's allocation block 0 relative\n            // to the start of the volume\"\n            TSK_OFF_T hfsplus_offset =\n                (drAlBlSt * (TSK_OFF_T) 512) +\n                (drAlBlkSiz * (TSK_OFF_T) startBlock);\n\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_open: HFS+/HFSX within HFS wrapper at byte offset %\"\n                    PRIuOFF \"\\n\", hfsplus_offset);\n\n            fs->tag = 0;\n            free(hfs->fs);\n            tsk_fs_free((TSK_FS_INFO *)hfs);\n\n            /* just re-open with the new offset, then record the offset */\n            if (hfsplus_offset == 0) {\n                tsk_error_set_errno(TSK_ERR_FS_CORRUPT);\n                tsk_error_set_errstr(\"HFS+ offset is zero\");\n                return NULL;\n            }\n            fs_info2 =\n                hfs_open(img_info, offset + hfsplus_offset, ftype, test);\n\n            if (fs_info2)\n                ((HFS_INFO *) fs_info2)->hfs_wrapper_offset =\n                    hfsplus_offset;\n\n            return fs_info2;\n        }\n        else {\n            fs->tag = 0;\n            free(hfs->fs);\n            tsk_fs_free((TSK_FS_INFO *)hfs);\n            tsk_error_set_errno(TSK_ERR_FS_MAGIC);\n            tsk_error_set_errstr\n                (\"HFS file systems (other than wrappers HFS+/HFSX file systems) are not supported\");\n            return NULL;\n        }\n    }\n\n    fs->block_count = tsk_getu32(fs->endian, hfs->fs->blk_cnt);\n    fs->first_block = 0;\n    fs->last_block = fs->last_block_act = fs->block_count - 1;\n\n    /* this isn't really accurate; fs->block_size reports only the size\n       of the allocation block; the size of the device block has to be\n       found from the device (allocation block size should always be\n       larger than device block size and an even multiple of the device\n       block size) */\n    fs->dev_bsize = fs->block_size =\n        tsk_getu32(fs->endian, hfs->fs->blk_sz);\n\n    // determine the last block we have in this image\n    if (fs->block_size <= 1) {\n        fs->tag = 0;\n        free(hfs->fs);\n        tsk_fs_free((TSK_FS_INFO *)hfs);\n        tsk_error_set_errno(TSK_ERR_FS_CORRUPT);\n        tsk_error_set_errstr(\"HFS+ allocation block size too small\");\n        return NULL;\n    }\n    if ((TSK_DADDR_T) ((img_info->size - offset) / fs->block_size) <\n        fs->block_count)\n        fs->last_block_act =\n            (img_info->size - offset) / fs->block_size - 1;\n\n    // Initialize the lock\n    tsk_init_lock(&(hfs->metadata_dir_cache_lock));\n\n    /*\n     * Set function pointers\n     */\n    fs->inode_walk = hfs_inode_walk;\n    fs->block_walk = hfs_block_walk;\n    fs->block_getflags = hfs_block_getflags;\n    fs->load_attrs = hfs_load_attrs;\n    fs->get_default_attr_type = hfs_get_default_attr_type;\n\n    fs->file_add_meta = hfs_inode_lookup;\n    fs->dir_open_meta = hfs_dir_open_meta;\n    fs->fsstat = hfs_fsstat;\n    fs->fscheck = hfs_fscheck;\n    fs->istat = hfs_istat;\n    fs->close = hfs_close;\n\n    // lazy loading of block map\n    hfs->blockmap_file = NULL;\n    hfs->blockmap_attr = NULL;\n    hfs->blockmap_cache_start = -1;\n    hfs->blockmap_cache_len = 0;\n\n    fs->first_inum = HFS_ROOT_INUM;\n    fs->root_inum = HFS_ROOT_INUM;\n    fs->last_inum = HFS_FIRST_USER_CNID - 1;    // we will later increase this\n    fs->inum_count = fs->last_inum - fs->first_inum + 1;\n\n    /* We will load the extents file data when we need it */\n    hfs->extents_file = NULL;\n    hfs->extents_attr = NULL;\n\n    if (tsk_getu32(fs->endian,\n                hfs->fs->start_file.extents[0].blk_cnt) == 0) {\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_open: Optional Startup File is not present.\\n\");\n            hfs->has_startup_file = FALSE;\n        }\n    else {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_open: Startup File is present.\\n\");\n        hfs->has_startup_file = TRUE;\n    }\n\n    if (tsk_getu32(fs->endian, hfs->fs->ext_file.extents[0].blk_cnt) == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: Optional Extents File (and Badblocks File) is not present.\\n\");\n        hfs->has_extents_file = FALSE;\n    }\n    else {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: Extents File (and BadBlocks File) is present.\\n\");\n        hfs->has_extents_file = TRUE;\n    }\n\n    if (tsk_getu32(fs->endian, hfs->fs->attr_file.extents[0].blk_cnt) == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: Optional Attributes File is not present.\\n\");\n        hfs->has_attributes_file = FALSE;\n    }\n    else {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_open: Attributes File is present.\\n\");\n        hfs->has_attributes_file = TRUE;\n    }\n\n    /* Load the catalog file though */\n    if ((hfs->catalog_file =\n            tsk_fs_file_open_meta(fs, NULL,\n                HFS_CATALOG_FILE_ID)) == NULL) {\n        hfs_close(fs);\n        return NULL;\n    }\n\n    /* cache the data attribute */\n    hfs->catalog_attr =\n        tsk_fs_attrlist_get(hfs->catalog_file->meta->attr,\n        TSK_FS_ATTR_TYPE_DEFAULT);\n    if (!hfs->catalog_attr) {\n        hfs_close(fs);\n        tsk_error_errstr2_concat\n            (\" - Data Attribute not found in Catalog File\");\n        return NULL;\n    }\n\n    // cache the catalog file header\n    cnt = tsk_fs_attr_read(hfs->catalog_attr, 14,\n        (char *) &(hfs->catalog_header),\n        sizeof(hfs_btree_header_record), 0);\n    if (cnt != sizeof(hfs_btree_header_record)) {\n        if (cnt >= 0) {\n            tsk_error_reset();\n            tsk_error_set_errno(TSK_ERR_FS_READ);\n        }\n        hfs_close(fs);\n        tsk_error_set_errstr2(\"hfs_open: Error reading catalog header\");\n        return NULL;\n    }\n\n    if (tsk_getu16(fs->endian, hfs->fs->version) == HFS_VH_VER_HFSPLUS)\n        hfs->is_case_sensitive = 0;\n    else if (tsk_getu16(fs->endian, hfs->fs->version) == HFS_VH_VER_HFSX) {\n        if (hfs->catalog_header.compType == HFS_BT_HEAD_COMP_SENS)\n            hfs->is_case_sensitive = 1;\n        else if (hfs->catalog_header.compType == HFS_BT_HEAD_COMP_INSENS)\n            hfs->is_case_sensitive = 0;\n        else {\n            if (tsk_verbose)\n                tsk_fprintf(stderr,\n                    \"hfs_open: invalid value (0x%02\" PRIx8\n                    \") for key compare type; using case-insensitive\\n\",\n                    hfs->catalog_header.compType);\n            hfs->is_case_sensitive = 0;\n        }\n    }\n    else {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: unknown HFS+/HFSX version (%\" PRIu16 \"\\n\",\n                tsk_getu16(fs->endian, hfs->fs->version));\n        hfs->is_case_sensitive = 0;\n    }\n\n    // update the numbers.\n    fs->last_inum = hfs_find_highest_inum(hfs);\n    fs->inum_count = fs->last_inum + 1;\n\n    snprintf((char *) fs->fs_id, 17, \"%08\" PRIx32 \"%08\" PRIx32,\n        tsk_getu32(fs->endian, hfs->fs->finder_info[HFS_VH_FI_ID1]),\n        tsk_getu32(fs->endian, hfs->fs->finder_info[HFS_VH_FI_ID2]));\n    fs->fs_id_used = 16;\n\n    /* journal */\n    fs->jblk_walk = hfs_jblk_walk;\n    fs->jentry_walk = hfs_jentry_walk;\n    fs->jopen = hfs_jopen;\n    fs->name_cmp = hfs_name_cmp;\n    fs->journ_inum = 0;\n\n    /* Creation Times */\n\n    // First, the root\n    file = tsk_fs_file_open_meta(fs, NULL, 2);\n    if (file != NULL) {\n        hfs->root_crtime = file->meta->crtime;\n        hfs->has_root_crtime = TRUE;\n        tsk_fs_file_close(file);\n    }\n    else {\n        hfs->has_root_crtime = FALSE;\n    }\n    file = NULL;\n\n    // disable hard link traversal while finding the hard\n    // link directories themselves (to prevent problems if\n    // there are hard links in the root directory)\n    hfs->meta_inum = 0;\n    hfs->meta_dir_inum = 0;\n\n    // Now the (file) metadata directory\n\n    // The metadata directory is a sub-directory of the root.  Its name begins with four nulls, followed\n    // by \"HFS+ Private Data\".  The file system parsing code replaces nulls in filenames with UTF8_NULL_REPLACE.\n    // In the released version of TSK, this replacement is the character '^'.\n    // NOTE: There is a standard Unicode replacement which is 0xfffd in UTF16 and 0xEF 0xBF 0xBD in UTF8.\n    // Systems that require the standard definition can redefine UTF8_NULL_REPLACE and UTF16_NULL_REPLACE\n    // in tsk_hfs.h\n    hfs->has_meta_crtime = FALSE;\n    result =\n        tsk_fs_path2inum(fs,\n        \"/\" UTF8_NULL_REPLACE UTF8_NULL_REPLACE UTF8_NULL_REPLACE\n        UTF8_NULL_REPLACE \"HFS+ Private Data\", &inum, NULL);\n    if (result == 0) {\n        TSK_FS_FILE *file_tmp = tsk_fs_file_open_meta(fs, NULL, inum);\n        if (file_tmp != NULL) {\n            hfs->meta_crtime = file_tmp->meta->crtime;\n            hfs->has_meta_crtime = TRUE;\n            hfs->meta_inum = inum;\n            tsk_fs_file_close(file_tmp);\n        }\n    }\n\n    // Now, the directory metadata directory\n\n    // The \"directory\" metadata directory, where hardlinked directories actually live, is a subdirectory\n    // of the root.  The beginning of the name of this directory is \".HFS+ Private Directory Data\" which\n    // is followed by a carriage return (ASCII 13).\n    hfs->has_meta_dir_crtime = FALSE;\n    result =\n        tsk_fs_path2inum(fs, \"/.HFS+ Private Directory Data\\r\", &inum,\n        NULL);\n    if (result == 0) {\n        TSK_FS_FILE *file_tmp = tsk_fs_file_open_meta(fs, NULL, inum);\n        if (file_tmp != NULL) {\n            hfs->metadir_crtime = file_tmp->meta->crtime;\n            hfs->has_meta_dir_crtime = TRUE;\n            hfs->meta_dir_inum = inum;\n            tsk_fs_file_close(file_tmp);\n        }\n    }\n\n    if (hfs->has_root_crtime && hfs->has_meta_crtime\n        && hfs->has_meta_dir_crtime) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: Creation times for key folders have been read and cached.\\n\");\n    }\n    if (!hfs->has_root_crtime) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr,\n                \"hfs_open: Warning: Could not open the root directory.  \"\n                \"Hard link detection and some other functions will be impaired\\n\");\n    }\n    else if (tsk_verbose) {\n        tsk_fprintf(stderr,\n            \"hfs_open: The root directory is accessible.\\n\");\n    }\n\n    if (tsk_verbose) {\n        if (hfs->has_meta_crtime)\n            tsk_fprintf(stderr,\n                \"hfs_open: \\\"/^^^^HFS+ Private Data\\\" metadata folder is accessible.\\n\");\n        else\n            tsk_fprintf(stderr,\n                \"hfs_open: Optional \\\"^^^^HFS+ Private Data\\\" metadata folder is not accessible, or does not exist.\\n\");\n        if (hfs->has_meta_dir_crtime)\n            tsk_fprintf(stderr,\n                \"hfs_open: \\\"/HFS+ Private Directory Data^\\\" metadata folder is accessible.\\n\");\n        else\n            tsk_fprintf(stderr,\n                \"hfs_open: Optional \\\"/HFS+ Private Directory Data^\\\" metadata folder is not accessible, or does not exist.\\n\");\n    }\n\n    // These caches will be set, if they are needed.\n    hfs->meta_dir = NULL;\n    hfs->dir_meta_dir = NULL;\n\n    return fs;\n}\n\n\n/*\n * Error Handling\n */\n\n/**\n * Call this when an error is first detected.  It sets the error code and it also\n * sets the primary error string, describing the lowest level of error.  (Actually,\n * it appends to the error string.)\n *\n * If the error code is already set, then this appends to the primary error\n * string an hex representation of the new error code, plus the new error message.\n *\n * @param errnum  The desired error code\n * @param errstr  The format string for the error message\n */\nvoid\nerror_detected(uint32_t errnum, char *errstr, ...)\n{\n    va_list args;\n\n    va_start(args, errstr);\n\n    {\n        TSK_ERROR_INFO *errInfo = tsk_error_get_info();\n        char *loc_errstr = errInfo->errstr;\n\n        if (errInfo->t_errno == 0)\n            errInfo->t_errno = errnum;\n        else {\n            //This should not happen!  We don't want to wipe out the existing error\n            //code, so we write the new code into the error string, in hex.\n            int sl = strlen(errstr);\n            snprintf(loc_errstr + sl, TSK_ERROR_STRING_MAX_LENGTH - sl,\n                \" Next errnum: 0x%x \", errnum);\n        }\n        if (errstr != NULL) {\n            int sl = strlen(loc_errstr);\n            vsnprintf(loc_errstr + sl, TSK_ERROR_STRING_MAX_LENGTH - sl,\n                errstr, args);\n        }\n    }\n\n    va_end(args);\n\n}\n\n/**\n * Call this when a called TSK function returns an error.  Presumably, that\n * function will have set the error code and the primary error string.  This\n * *appends* to the secondary error string.  It should be called to describe\n * the context of the call.  If no error code has been set, then this sets a\n * default code so that it is not zero.\n *\n * @param errstr  The format string for the error message\n */\nvoid\nerror_returned(char *errstr, ...)\n{\n    va_list args;\n    va_start(args, errstr);\n\n    {\n        TSK_ERROR_INFO *errInfo = tsk_error_get_info();\n        char *loc_errstr2 = errInfo->errstr2;\n\n        if (errInfo->t_errno == 0)\n            errInfo->t_errno = TSK_ERR_AUX_GENERIC;\n        if (errstr != NULL) {\n            int sl = strlen(loc_errstr2);\n            vsnprintf(loc_errstr2 + sl, TSK_ERROR_STRING_MAX_LENGTH - sl,\n                errstr, args);\n        }\n    }\n    va_end(args);\n}\n"], "filenames": ["tsk/fs/hfs.c"], "buggy_code_start_loc": [940], "buggy_code_end_loc": [1046], "fixing_code_start_loc": [940], "fixing_code_end_loc": [1046], "type": "CWE-190", "message": "The Sleuth Kit 4.6.0 and earlier is affected by: Integer Overflow. The impact is: Opening crafted disk image triggers crash in tsk/fs/hfs_dent.c:237. The component is: Overflow in fls tool used on HFS image. Bug is in tsk/fs/hfs.c file in function hfs_cat_traverse() in lines: 952, 1062. The attack vector is: Victim must open a crafted HFS filesystem image.", "other": {"cve": {"id": "CVE-2019-1010065", "sourceIdentifier": "josh@bress.net", "published": "2019-07-18T17:15:11.507", "lastModified": "2022-11-29T18:52:00.217", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The Sleuth Kit 4.6.0 and earlier is affected by: Integer Overflow. The impact is: Opening crafted disk image triggers crash in tsk/fs/hfs_dent.c:237. The component is: Overflow in fls tool used on HFS image. Bug is in tsk/fs/hfs.c file in function hfs_cat_traverse() in lines: 952, 1062. The attack vector is: Victim must open a crafted HFS filesystem image."}, {"lang": "es", "value": "El kit Sleuth 4.6.0 y anteriores se ven afectados por: Desbordamiento de entero. El impacto es: la apertura de los desencadenadores de imagen de disco creados en tsk / fs / hfs_dent.c: 237. El componente es: Desbordamiento en la herramienta fls utilizada en la imagen HFS. El error est\u00e1 en el archivo tsk / fs / hfs.c en la funci\u00f3n hfs_cat_traverse () en las l\u00edneas: 952, 1062. El vector de ataque es: La v\u00edctima debe abrir una imagen del sistema de archivos HFS."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-190"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:sleuthkit:the_sleuth_kit:*:*:*:*:*:*:*:*", "versionEndIncluding": "4.6.0", "matchCriteriaId": "51C5B007-C1DD-4982-9185-AB7DA00CC085"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:29:*:*:*:*:*:*:*", "matchCriteriaId": "D100F7CE-FC64-4CC6-852A-6136D72DA419"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:30:*:*:*:*:*:*:*", "matchCriteriaId": "97A4B8DF-58DA-4AB6-A1F9-331B36409BA3"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}], "references": [{"url": "https://github.com/sleuthkit/sleuthkit/commit/114cd3d0aac8bd1aeaf4b33840feb0163d342d5b", "source": "josh@bress.net", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://issuetracker.google.com/issues/77809383", "source": "josh@bress.net", "tags": ["Permissions Required", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2022/06/msg00015.html", "source": "josh@bress.net", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/6VXDAP6SEO3RCDCZITTFGNZGSVPE5CTY/", "source": "josh@bress.net", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/FGWCQIZKTDCJO4YGL5LGPYFNOVU7SJRX/", "source": "josh@bress.net", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/sleuthkit/sleuthkit/commit/114cd3d0aac8bd1aeaf4b33840feb0163d342d5b"}}
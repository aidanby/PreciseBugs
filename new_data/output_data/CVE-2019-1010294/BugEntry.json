{"buggy_code": ["// SPDX-License-Identifier: BSD-2-Clause\n/*\n * Copyright (c) 2014, STMicroelectronics International N.V.\n * Copyright (c) 2015-2017 Linaro Limited\n */\n\n#include <assert.h>\n#include <compiler.h>\n#include <ctype.h>\n#include <initcall.h>\n#include <keep.h>\n#include <kernel/panic.h>\n#include <kernel/tee_misc.h>\n#include <kernel/tee_ta_manager.h>\n#include <kernel/thread.h>\n#include <kernel/user_ta.h>\n#include <mm/core_memprot.h>\n#include <mm/core_mmu.h>\n#include <mm/mobj.h>\n#include <mm/pgt_cache.h>\n#include <mm/tee_mm.h>\n#include <mm/tee_mmu.h>\n#include <mm/tee_pager.h>\n#include <signed_hdr.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <sys/queue.h>\n#include <ta_pub_key.h>\n#include <tee/tee_cryp_utl.h>\n#include <tee/tee_obj.h>\n#include <tee/tee_svc_cryp.h>\n#include <tee/tee_svc.h>\n#include <tee/tee_svc_storage.h>\n#include <tee/uuid.h>\n#include <trace.h>\n#include <types_ext.h>\n#include <utee_defines.h>\n#include <util.h>\n\n#include \"elf_common.h\"\n#include \"elf_load.h\"\n#include \"elf_load_dyn.h\"\n\n/* ELF file used by a TA (main executable or dynamic library) */\nstruct user_ta_elf {\n\tTEE_UUID uuid;\n\tstruct elf_load_state *elf_state;\n\tstruct mobj *mobj_code;\n\tvaddr_t load_addr;\n\tvaddr_t exidx_start; /* 32-bit ELF only */\n\tsize_t exidx_size;\n\tstruct load_seg *segs;\n\tsize_t num_segs;\n\n\tTAILQ_ENTRY(user_ta_elf) link;\n};\n\nstatic void free_elfs(struct user_ta_elf_head *elfs)\n{\n\tstruct user_ta_elf *elf;\n\tstruct user_ta_elf *next;\n\n\tTAILQ_FOREACH_SAFE(elf, elfs, link, next) {\n\t\tTAILQ_REMOVE(elfs, elf, link);\n\t\tmobj_free(elf->mobj_code);\n\t\tfree(elf->segs);\n\t\tfree(elf);\n\t}\n}\n\nstatic struct user_ta_elf *find_ta_elf(const TEE_UUID *uuid,\n\t\t\t\t       struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *elf;\n\n\tTAILQ_FOREACH(elf, &utc->elfs, link)\n\t\tif (!memcmp(&elf->uuid, uuid, sizeof(*uuid)))\n\t\t\treturn elf;\n\treturn NULL;\n}\n\nstatic struct user_ta_elf *ta_elf(const TEE_UUID *uuid,\n\t\t\t\t  struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *elf;\n\n\telf = find_ta_elf(uuid, utc);\n\tif (elf)\n\t\tgoto out;\n\telf = calloc(1, sizeof(*elf));\n\tif (!elf)\n\t\tgoto out;\n\telf->uuid = *uuid;\n\n\tTAILQ_INSERT_TAIL(&utc->elfs, elf, link);\nout:\n\treturn elf;\n}\n\nstatic uint32_t elf_flags_to_mattr(uint32_t flags)\n{\n\tuint32_t mattr = 0;\n\n\tif (flags & PF_X)\n\t\tmattr |= TEE_MATTR_UX;\n\tif (flags & PF_W)\n\t\tmattr |= TEE_MATTR_UW;\n\tif (flags & PF_R)\n\t\tmattr |= TEE_MATTR_UR;\n\n\treturn mattr;\n}\n\nstruct load_seg {\n\tvaddr_t offs;\n\tuint32_t flags;\n\tvaddr_t oend;\n\tvaddr_t va;\n\tsize_t size;\n};\n\nstatic TEE_Result get_elf_segments(struct user_ta_elf *elf,\n\t\t\t\t   struct load_seg **segs_ret,\n\t\t\t\t   size_t *num_segs_ret)\n{\n\tstruct elf_load_state *elf_state = elf->elf_state;\n\tTEE_Result res;\n\tsize_t idx = 0;\n\tsize_t num_segs = 0;\n\tstruct load_seg *segs = NULL;\n\n\t/*\n\t * Add code segment\n\t */\n\twhile (true) {\n\t\tvaddr_t va;\n\t\tsize_t size;\n\t\tuint32_t flags;\n\t\tuint32_t type;\n\n\t\tres = elf_load_get_next_segment(elf_state, &idx, &va, &size,\n\t\t\t\t\t\t&flags, &type);\n\t\tif (res == TEE_ERROR_ITEM_NOT_FOUND)\n\t\t\tbreak;\n\t\tif (res != TEE_SUCCESS)\n\t\t\treturn res;\n\n\t\tif (type == PT_LOAD) {\n\t\t\tvoid *p = realloc(segs, (num_segs + 1) * sizeof(*segs));\n\n\t\t\tif (!p) {\n\t\t\t\tfree(segs);\n\t\t\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\t\t\t}\n\t\t\tsegs = p;\n\t\t\tsegs[num_segs].offs = ROUNDDOWN(va, SMALL_PAGE_SIZE);\n\t\t\tsegs[num_segs].oend = ROUNDUP(va + size,\n\t\t\t\t\t\t      SMALL_PAGE_SIZE);\n\t\t\tsegs[num_segs].flags = flags;\n\t\t\tnum_segs++;\n\t\t} else if (type == PT_ARM_EXIDX) {\n\t\t\telf->exidx_start = va;\n\t\t\telf->exidx_size = size;\n\t\t}\n\t}\n\n\tidx = 1;\n\twhile (idx < num_segs) {\n\t\tsize_t this_size = segs[idx].oend - segs[idx].offs;\n\t\tsize_t prev_size = segs[idx - 1].oend - segs[idx - 1].offs;\n\n\t\tif (core_is_buffer_intersect(segs[idx].offs, this_size,\n\t\t\t\t\t     segs[idx - 1].offs, prev_size)) {\n\t\t\t/* Merge the segments and their attributes */\n\t\t\tsegs[idx - 1].oend = MAX(segs[idx - 1].oend,\n\t\t\t\t\t\t segs[idx].oend);\n\t\t\tsegs[idx - 1].flags |= segs[idx].flags;\n\n\t\t\t/* Remove this index */\n\t\t\tmemcpy(segs + idx, segs + idx + 1,\n\t\t\t       (num_segs - idx - 1) * sizeof(*segs));\n\t\t\tnum_segs--;\n\t\t} else {\n\t\t\tidx++;\n\t\t}\n\t}\n\n\t*segs_ret = segs;\n\t*num_segs_ret = num_segs;\n\treturn TEE_SUCCESS;\n}\n\nstatic struct mobj *alloc_ta_mem(size_t size)\n{\n#ifdef CFG_PAGED_USER_TA\n\treturn mobj_paged_alloc(size);\n#else\n\tstruct mobj *mobj = mobj_mm_alloc(mobj_sec_ddr, size, &tee_mm_sec_ddr);\n\n\tif (mobj)\n\t\tmemset(mobj_get_va(mobj, 0), 0, size);\n\treturn mobj;\n#endif\n}\n\nstatic void init_utee_param(struct utee_params *up,\n\t\t\tconst struct tee_ta_param *p, void *va[TEE_NUM_PARAMS])\n{\n\tsize_t n;\n\n\tup->types = p->types;\n\tfor (n = 0; n < TEE_NUM_PARAMS; n++) {\n\t\tuintptr_t a;\n\t\tuintptr_t b;\n\n\t\tswitch (TEE_PARAM_TYPE_GET(p->types, n)) {\n\t\tcase TEE_PARAM_TYPE_MEMREF_INPUT:\n\t\tcase TEE_PARAM_TYPE_MEMREF_OUTPUT:\n\t\tcase TEE_PARAM_TYPE_MEMREF_INOUT:\n\t\t\ta = (uintptr_t)va[n];\n\t\t\tb = p->u[n].mem.size;\n\t\t\tbreak;\n\t\tcase TEE_PARAM_TYPE_VALUE_INPUT:\n\t\tcase TEE_PARAM_TYPE_VALUE_INOUT:\n\t\t\ta = p->u[n].val.a;\n\t\t\tb = p->u[n].val.b;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\ta = 0;\n\t\t\tb = 0;\n\t\t\tbreak;\n\t\t}\n\t\t/* See comment for struct utee_params in utee_types.h */\n\t\tup->vals[n * 2] = a;\n\t\tup->vals[n * 2 + 1] = b;\n\t}\n}\n\nstatic void update_from_utee_param(struct tee_ta_param *p,\n\t\t\tconst struct utee_params *up)\n{\n\tsize_t n;\n\n\tfor (n = 0; n < TEE_NUM_PARAMS; n++) {\n\t\tswitch (TEE_PARAM_TYPE_GET(p->types, n)) {\n\t\tcase TEE_PARAM_TYPE_MEMREF_OUTPUT:\n\t\tcase TEE_PARAM_TYPE_MEMREF_INOUT:\n\t\t\t/* See comment for struct utee_params in utee_types.h */\n\t\t\tp->u[n].mem.size = up->vals[n * 2 + 1];\n\t\t\tbreak;\n\t\tcase TEE_PARAM_TYPE_VALUE_OUTPUT:\n\t\tcase TEE_PARAM_TYPE_VALUE_INOUT:\n\t\t\t/* See comment for struct utee_params in utee_types.h */\n\t\t\tp->u[n].val.a = up->vals[n * 2];\n\t\t\tp->u[n].val.b = up->vals[n * 2 + 1];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void clear_vfp_state(struct user_ta_ctx *utc __unused)\n{\n#ifdef CFG_WITH_VFP\n\tthread_user_clear_vfp(&utc->vfp);\n#endif\n}\n\nstatic TEE_Result user_ta_enter(TEE_ErrorOrigin *err,\n\t\t\tstruct tee_ta_session *session,\n\t\t\tenum utee_entry_func func, uint32_t cmd,\n\t\t\tstruct tee_ta_param *param)\n{\n\tTEE_Result res;\n\tstruct utee_params *usr_params;\n\tuaddr_t usr_stack;\n\tstruct user_ta_ctx *utc = to_user_ta_ctx(session->ctx);\n\tTEE_ErrorOrigin serr = TEE_ORIGIN_TEE;\n\tstruct tee_ta_session *s __maybe_unused;\n\tvoid *param_va[TEE_NUM_PARAMS] = { NULL };\n\n\t/* Map user space memory */\n\tres = tee_mmu_map_param(utc, param, param_va);\n\tif (res != TEE_SUCCESS)\n\t\tgoto cleanup_return;\n\n\t/* Switch to user ctx */\n\ttee_ta_push_current_session(session);\n\n\t/* Make room for usr_params at top of stack */\n\tusr_stack = utc->stack_addr + utc->mobj_stack->size;\n\tusr_stack -= ROUNDUP(sizeof(struct utee_params), STACK_ALIGNMENT);\n\tusr_params = (struct utee_params *)usr_stack;\n\tinit_utee_param(usr_params, param, param_va);\n\n\tres = thread_enter_user_mode(func, tee_svc_kaddr_to_uref(session),\n\t\t\t\t     (vaddr_t)usr_params, cmd, usr_stack,\n\t\t\t\t     utc->entry_func, utc->is_32bit,\n\t\t\t\t     &utc->ctx.panicked, &utc->ctx.panic_code);\n\n\tclear_vfp_state(utc);\n\t/*\n\t * According to GP spec the origin should allways be set to the\n\t * TA after TA execution\n\t */\n\tserr = TEE_ORIGIN_TRUSTED_APP;\n\n\tif (utc->ctx.panicked) {\n\t\tDMSG(\"tee_user_ta_enter: TA panicked with code 0x%x\\n\",\n\t\t     utc->ctx.panic_code);\n\t\tserr = TEE_ORIGIN_TEE;\n\t\tres = TEE_ERROR_TARGET_DEAD;\n\t}\n\n\t/* Copy out value results */\n\tupdate_from_utee_param(param, usr_params);\n\n\ts = tee_ta_pop_current_session();\n\tassert(s == session);\ncleanup_return:\n\n\t/*\n\t * Clear the cancel state now that the user TA has returned. The next\n\t * time the TA will be invoked will be with a new operation and should\n\t * not have an old cancellation pending.\n\t */\n\tsession->cancel = false;\n\n\t/*\n\t * Can't update *err until now since it may point to an address\n\t * mapped for the user mode TA.\n\t */\n\t*err = serr;\n\n\treturn res;\n}\n\nstatic TEE_Result user_ta_enter_open_session(struct tee_ta_session *s,\n\t\t\tstruct tee_ta_param *param, TEE_ErrorOrigin *eo)\n{\n\treturn user_ta_enter(eo, s, UTEE_ENTRY_FUNC_OPEN_SESSION, 0, param);\n}\n\nstatic TEE_Result user_ta_enter_invoke_cmd(struct tee_ta_session *s,\n\t\t\tuint32_t cmd, struct tee_ta_param *param,\n\t\t\tTEE_ErrorOrigin *eo)\n{\n\treturn user_ta_enter(eo, s, UTEE_ENTRY_FUNC_INVOKE_COMMAND, cmd, param);\n}\n\nstatic void user_ta_enter_close_session(struct tee_ta_session *s)\n{\n\tTEE_ErrorOrigin eo;\n\tstruct tee_ta_param param = { 0 };\n\n\tuser_ta_enter(&eo, s, UTEE_ENTRY_FUNC_CLOSE_SESSION, 0, &param);\n}\n\nstatic int elf_idx(struct user_ta_ctx *utc, vaddr_t r_va, size_t r_size)\n{\n\tstruct user_ta_elf *elf;\n\tint idx = 0;\n\n\tTAILQ_FOREACH(elf, &utc->elfs, link) {\n\t\tsize_t n;\n\n\t\tfor (n = 0; n < elf->num_segs; n++)\n\t\t\tif (elf->segs[n].va == r_va &&\n\t\t\t    elf->segs[n].size == r_size)\n\t\t\t\treturn idx;\n\t\tidx++;\n\t}\n\treturn -1;\n}\n\nstatic void describe_region(struct user_ta_ctx *utc, vaddr_t va, size_t size,\n\t\t\t    char *desc, size_t desc_size)\n{\n\tint idx;\n\n\tif (!desc_size)\n\t\treturn;\n\tidx = elf_idx(utc, va, size);\n\tif (idx != -1)\n\t\tsnprintf(desc, desc_size, \"[%d]\", idx);\n\telse\n\t\tdesc[0] = '\\0';\n\tdesc[desc_size - 1] = '\\0';\n}\n\nstatic void show_elfs(struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *elf;\n\tsize_t __maybe_unused idx = 0;\n\n\tTAILQ_FOREACH(elf, &utc->elfs, link)\n\t\tEMSG_RAW(\" [%zu] %pUl @ %#\" PRIxVA, idx++,\n\t\t\t (void *)&elf->uuid, elf->load_addr);\n}\n\nstatic void user_ta_dump_state(struct tee_ta_ctx *ctx)\n{\n\tstruct user_ta_ctx *utc = to_user_ta_ctx(ctx);\n\tstruct vm_region *r;\n\tchar flags[7] = { '\\0', };\n\tchar desc[13];\n\tsize_t n = 0;\n\n\tEMSG_RAW(\" arch: %s  load address: %#\" PRIxVA \" ctx-idr: %d\",\n\t\t utc->is_32bit ? \"arm\" : \"aarch64\", utc->load_addr,\n\t\t utc->vm_info->asid);\n\tEMSG_RAW(\" stack: 0x%\" PRIxVA \" %zu\",\n\t\t utc->stack_addr, utc->mobj_stack->size);\n\tTAILQ_FOREACH(r, &utc->vm_info->regions, link) {\n\t\tpaddr_t pa = 0;\n\n\t\tif (r->mobj)\n\t\t\tmobj_get_pa(r->mobj, r->offset, 0, &pa);\n\n\t\tmattr_perm_to_str(flags, sizeof(flags), r->attr);\n\t\tdescribe_region(utc, r->va, r->size, desc, sizeof(desc));\n\t\tEMSG_RAW(\" region %zu: va %#\" PRIxVA \" pa %#\" PRIxPA\n\t\t\t \" size %#zx flags %s %s\",\n\t\t\t n, r->va, pa, r->size, flags, desc);\n\t\tn++;\n\t}\n\tshow_elfs(utc);\n}\nKEEP_PAGER(user_ta_dump_state);\n\nstatic void release_ta_memory_by_mobj(struct mobj *mobj)\n{\n\tvoid *va;\n\n\tif (!mobj)\n\t\treturn;\n\n\tva = mobj_get_va(mobj, 0);\n\tif (!va)\n\t\treturn;\n\n\tmemset(va, 0, mobj->size);\n\tcache_op_inner(DCACHE_AREA_CLEAN, va, mobj->size);\n}\n\nstatic void free_utc(struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *elf;\n\n\ttee_pager_rem_uta_areas(utc);\n\tTAILQ_FOREACH(elf, &utc->elfs, link)\n\t\trelease_ta_memory_by_mobj(elf->mobj_code);\n\trelease_ta_memory_by_mobj(utc->mobj_stack);\n\trelease_ta_memory_by_mobj(utc->mobj_exidx);\n\n\t/*\n\t * Close sessions opened by this TA\n\t * Note that tee_ta_close_session() removes the item\n\t * from the utc->open_sessions list.\n\t */\n\twhile (!TAILQ_EMPTY(&utc->open_sessions)) {\n\t\ttee_ta_close_session(TAILQ_FIRST(&utc->open_sessions),\n\t\t\t\t     &utc->open_sessions, KERN_IDENTITY);\n\t}\n\n\tvm_info_final(utc);\n\tmobj_free(utc->mobj_stack);\n\tmobj_free(utc->mobj_exidx);\n\tfree_elfs(&utc->elfs);\n\n\t/* Free cryp states created by this TA */\n\ttee_svc_cryp_free_states(utc);\n\t/* Close cryp objects opened by this TA */\n\ttee_obj_close_all(utc);\n\t/* Free emums created by this TA */\n\ttee_svc_storage_close_all_enum(utc);\n\tfree(utc);\n}\n\nstatic void user_ta_ctx_destroy(struct tee_ta_ctx *ctx)\n{\n\tfree_utc(to_user_ta_ctx(ctx));\n}\n\nstatic uint32_t user_ta_get_instance_id(struct tee_ta_ctx *ctx)\n{\n\treturn to_user_ta_ctx(ctx)->vm_info->asid;\n}\n\nstatic const struct tee_ta_ops user_ta_ops __rodata_unpaged = {\n\t.enter_open_session = user_ta_enter_open_session,\n\t.enter_invoke_cmd = user_ta_enter_invoke_cmd,\n\t.enter_close_session = user_ta_enter_close_session,\n\t.dump_state = user_ta_dump_state,\n\t.destroy = user_ta_ctx_destroy,\n\t.get_instance_id = user_ta_get_instance_id,\n};\n\n/*\n * Break unpaged attribute dependency propagation to user_ta_ops structure\n * content thanks to a runtime initialization of the ops reference.\n */\nstatic struct tee_ta_ops const *_user_ta_ops;\n\nstatic TEE_Result init_user_ta(void)\n{\n\t_user_ta_ops = &user_ta_ops;\n\n\treturn TEE_SUCCESS;\n}\nservice_init(init_user_ta);\n\nstatic void set_ta_ctx_ops(struct tee_ta_ctx *ctx)\n{\n\tctx->ops = _user_ta_ops;\n}\n\nbool is_user_ta_ctx(struct tee_ta_ctx *ctx)\n{\n\treturn ctx->ops == _user_ta_ops;\n}\n\nstatic TEE_Result check_ta_store(void)\n{\n\tconst struct user_ta_store_ops *op = NULL;\n\n\tSCATTERED_ARRAY_FOREACH(op, ta_stores, struct user_ta_store_ops)\n\t\tDMSG(\"TA store: \\\"%s\\\"\", op->description);\n\n\treturn TEE_SUCCESS;\n}\nservice_init(check_ta_store);\n\n#ifdef CFG_TA_DYNLINK\n\nstatic int hex(char c)\n{\n\tchar lc = tolower(c);\n\n\tif (isdigit(lc))\n\t\treturn lc - '0';\n\tif (isxdigit(lc))\n\t\treturn lc - 'a' + 10;\n\treturn -1;\n}\n\nstatic uint32_t parse_hex(const char *s, size_t nchars, uint32_t *res)\n{\n\tuint32_t v = 0;\n\tsize_t n;\n\tint c;\n\n\tfor (n = 0; n < nchars; n++) {\n\t\tc = hex(s[n]);\n\t\tif (c == (char)-1) {\n\t\t\t*res = TEE_ERROR_BAD_FORMAT;\n\t\t\tgoto out;\n\t\t}\n\t\tv = (v << 4) + c;\n\t}\n\t*res = TEE_SUCCESS;\nout:\n\treturn v;\n}\n\n/*\n * Convert a UUID string @s into a TEE_UUID @uuid\n * Expected format for @s is: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n * 'x' being any hexadecimal digit (0-9a-fA-F)\n */\nstatic TEE_Result parse_uuid(const char *s, TEE_UUID *uuid)\n{\n\tTEE_Result res = TEE_SUCCESS;\n\tTEE_UUID u = { 0 };\n\tconst char *p = s;\n\tsize_t i;\n\n\tif (strlen(p) != 36)\n\t\treturn TEE_ERROR_BAD_FORMAT;\n\tif (p[8] != '-' || p[13] != '-' || p[18] != '-' || p[23] != '-')\n\t\treturn TEE_ERROR_BAD_FORMAT;\n\n\tu.timeLow = parse_hex(p, 8, &res);\n\tif (res)\n\t\tgoto out;\n\tp += 9;\n\tu.timeMid = parse_hex(p, 4, &res);\n\tif (res)\n\t\tgoto out;\n\tp += 5;\n\tu.timeHiAndVersion = parse_hex(p, 4, &res);\n\tif (res)\n\t\tgoto out;\n\tp += 5;\n\tfor (i = 0; i < 8; i++) {\n\t\tu.clockSeqAndNode[i] = parse_hex(p, 2, &res);\n\t\tif (res)\n\t\t\tgoto out;\n\t\tif (i == 1)\n\t\t\tp += 3;\n\t\telse\n\t\t\tp += 2;\n\t}\n\t*uuid = u;\nout:\n\treturn res;\n}\n\nstatic TEE_Result add_elf_deps(struct user_ta_ctx *utc, char **deps,\n\t\t\t       size_t num_deps)\n{\n\tstruct user_ta_elf *libelf;\n\tTEE_Result res = TEE_SUCCESS;\n\tTEE_UUID u;\n\tsize_t n;\n\n\tfor (n = 0; n < num_deps; n++) {\n\t\tres = parse_uuid(deps[n], &u);\n\t\tif (res) {\n\t\t\tEMSG(\"Invalid dependency (not a UUID): %s\", deps[n]);\n\t\t\tgoto out;\n\t\t}\n\t\tDMSG(\"Library needed: %pUl\", (void *)&u);\n\t\tlibelf = ta_elf(&u, utc);\n\t\tif (!libelf) {\n\t\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\t\tgoto out;\n\t\t}\n\t}\nout:\n\treturn res;\n}\n\nstatic TEE_Result resolve_symbol(struct user_ta_elf_head *elfs,\n\t\t\t\t const char *name, uintptr_t *val)\n{\n\tstruct user_ta_elf *elf;\n\tTEE_Result res;\n\n\t/*\n\t * The loop naturally implements a breadth first search due to the\n\t * order in which the libraries were added.\n\t */\n\tTAILQ_FOREACH(elf, elfs, link) {\n\t\tres = elf_resolve_symbol(elf->elf_state, name, val);\n\t\tif (res == TEE_ERROR_ITEM_NOT_FOUND)\n\t\t\tcontinue;\n\t\tif (res)\n\t\t\treturn res;\n\t\t*val += elf->load_addr;\n\t\tFMSG(\"%pUl/0x%\" PRIxPTR \" %s\", (void *)&elf->uuid, *val, name);\n\t\treturn TEE_SUCCESS;\n\t}\n\n\treturn TEE_ERROR_ITEM_NOT_FOUND;\n}\n\nstatic TEE_Result add_deps(struct user_ta_ctx *utc,\n\t\t\t   struct elf_load_state *state, vaddr_t load_addr)\n{\n\tchar **deps = NULL;\n\tsize_t num_deps = 0;\n\tTEE_Result res;\n\n\tres = elf_get_needed(state, load_addr, &deps, &num_deps);\n\tif (res)\n\t\treturn res;\n\n\tres = add_elf_deps(utc, deps, num_deps);\n\tfree(deps);\n\n\treturn res;\n}\n\n#else\n\nstatic TEE_Result (*resolve_symbol)(struct user_ta_elf_head *, const char *,\n\t\t\t\t    uintptr_t *);\n\nstatic TEE_Result add_deps(struct user_ta_ctx *utc __unused,\n\t\t\t   struct elf_load_state *state __unused,\n\t\t\t   vaddr_t load_addr __unused)\n{\n\treturn TEE_SUCCESS;\n}\n\n#endif\n\nstatic TEE_Result load_elf_from_store(const TEE_UUID *uuid,\n\t\t\t\t      const struct user_ta_store_ops *ta_store,\n\t\t\t\t      struct user_ta_ctx *utc)\n{\n\tstruct user_ta_store_handle *handle = NULL;\n\tstruct elf_load_state *elf_state = NULL;\n\tstruct ta_head *ta_head;\n\tstruct user_ta_elf *exe;\n\tstruct user_ta_elf *elf;\n\tstruct user_ta_elf *prev;\n\tTEE_Result res;\n\tsize_t vasize;\n\tvoid *p;\n\tsize_t n;\n\tsize_t num_segs = 0;\n\tstruct load_seg *segs = NULL;\n\n\tres = ta_store->open(uuid, &handle);\n\tif (res)\n\t\treturn res;\n\n\telf = ta_elf(uuid, utc);\n\tif (!elf) {\n\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\tgoto out;\n\t}\n\n\texe = TAILQ_FIRST(&utc->elfs);\n\tprev = TAILQ_PREV(elf, user_ta_elf_head, link);\n\n\tres = elf_load_init(ta_store, handle, elf == exe, &utc->elfs,\n\t\t\t    resolve_symbol, &elf_state);\n\tif (res)\n\t\tgoto out;\n\telf->elf_state = elf_state;\n\n\tres = elf_load_head(elf_state,\n\t\t\t    elf == exe ? sizeof(struct ta_head) : 0,\n\t\t\t    &p, &vasize, &utc->is_32bit);\n\tif (res)\n\t\tgoto out;\n\tta_head = p;\n\n\n\telf->mobj_code = alloc_ta_mem(vasize);\n\tif (!elf->mobj_code) {\n\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\tgoto out;\n\t}\n\n\tif (elf == exe) {\n\t\t/* Ensure proper alignment of stack */\n\t\tsize_t stack_sz = ROUNDUP(ta_head->stack_size,\n\t\t\t\t\t  STACK_ALIGNMENT);\n\t\tutc->mobj_stack = alloc_ta_mem(stack_sz);\n\t\tif (!utc->mobj_stack) {\n\t\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * Map physical memory into TA virtual memory\n\t */\n\tif (elf == exe) {\n\n\t\tres = vm_info_init(utc);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\n\t\t/* Add stack segment */\n\t\tutc->stack_addr = 0;\n\t\tres = vm_map(utc, &utc->stack_addr, utc->mobj_stack->size,\n\t\t\t     TEE_MATTR_URW | TEE_MATTR_PRW, utc->mobj_stack,\n\t\t\t     0);\n\t\tif (res)\n\t\t\tgoto out;\n\t}\n\n\tres = get_elf_segments(elf, &segs, &num_segs);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\tif (prev) {\n\t\telf->load_addr = prev->load_addr + prev->mobj_code->size;\n\t\telf->load_addr = ROUNDUP(elf->load_addr,\n\t\t\t\t\t CORE_MMU_USER_CODE_SIZE);\n\t}\n\n\tfor (n = 0; n < num_segs; n++) {\n\t\tuint32_t prot = elf_flags_to_mattr(segs[n].flags) |\n\t\t\t\tTEE_MATTR_PRW;\n\n\t\tsegs[n].va = elf->load_addr - segs[0].offs + segs[n].offs;\n\t\tsegs[n].size = segs[n].oend - segs[n].offs;\n\t\tres = vm_map(utc, &segs[n].va, segs[n].size, prot,\n\t\t\t     elf->mobj_code, segs[n].offs);\n\t\tif (res)\n\t\t\tgoto out;\n\t\tif (!n) {\n\t\t\telf->load_addr = segs[0].va;\n\t\t\tDMSG(\"ELF load address %#\" PRIxVA, elf->load_addr);\n\t\t}\n\t}\n\n\ttee_mmu_set_ctx(&utc->ctx);\n\n\tres = elf_load_body(elf_state, elf->load_addr);\n\tif (res)\n\t\tgoto out;\n\n\t/* Find any external dependency (dynamically linked libraries) */\n\tres = add_deps(utc, elf_state, elf->load_addr);\nout:\n\tif (res) {\n\t\tfree(segs);\n\t} else {\n\t\telf->segs = segs;\n\t\telf->num_segs = num_segs;\n\t}\n\tta_store->close(handle);\n\t/* utc is cleaned by caller on error */\n\treturn res;\n}\n\n/* Loads a single ELF file (main executable or library) */\nstatic TEE_Result load_elf(const TEE_UUID *uuid, struct user_ta_ctx *utc)\n{\n\tTEE_Result res;\n\tconst struct user_ta_store_ops *op = NULL;\n\n\tSCATTERED_ARRAY_FOREACH(op, ta_stores, struct user_ta_store_ops) {\n\t\tDMSG(\"Lookup user TA ELF %pUl (%s)\", (void *)uuid,\n\t\t     op->description);\n\n\t\tres = load_elf_from_store(uuid, op, utc);\n\t\tif (res == TEE_ERROR_ITEM_NOT_FOUND)\n\t\t\tcontinue;\n\t\tif (res) {\n\t\t\tDMSG(\"res=0x%x\", res);\n\t\t\tcontinue;\n\t\t}\n\n\t\treturn res;\n\t}\n\n\treturn TEE_ERROR_ITEM_NOT_FOUND;\n}\n\nstatic void free_elf_states(struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *elf;\n\n\tTAILQ_FOREACH(elf, &utc->elfs, link)\n\t\t\telf_load_final(elf->elf_state);\n}\n\nstatic TEE_Result set_seg_prot(struct user_ta_ctx *utc,\n\t\t\t       struct user_ta_elf *elf)\n{\n\tTEE_Result res;\n\tsize_t n;\n\n\tfor (n = 0; n < elf->num_segs; n++) {\n\t\tstruct load_seg *seg = &elf->segs[n];\n\n\t\tres = vm_set_prot(utc, seg->va, seg->size,\n\t\t\t\t  elf_flags_to_mattr(seg->flags));\n\t\tif (res)\n\t\t\tbreak;\n\t}\n\treturn res;\n}\n\n#ifdef CFG_UNWIND\n\n/*\n * 32-bit TAs: set the address and size of the exception index table (EXIDX).\n * If the TA contains only one ELF, we point to its table. Otherwise, a\n * consolidated table is made by concatenating the tables found in each ELF and\n * adjusting their content to account for the offset relative to the original\n * location.\n */\nstatic TEE_Result set_exidx(struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *exe;\n\tstruct user_ta_elf *elf;\n\tstruct user_ta_elf *last_elf;\n\tvaddr_t exidx;\n\tsize_t exidx_sz = 0;\n\tTEE_Result res;\n\tuint8_t *p;\n\n\tif (!utc->is_32bit)\n\t\treturn TEE_SUCCESS;\n\n\texe = TAILQ_FIRST(&utc->elfs);\n\tif (!TAILQ_NEXT(exe, link)) {\n\t\t/* We have a single ELF: simply reference its table */\n\t\tutc->exidx_start = exe->exidx_start;\n\t\tutc->exidx_size = exe->exidx_size;\n\t\treturn TEE_SUCCESS;\n\t}\n\tlast_elf = TAILQ_LAST(&utc->elfs, user_ta_elf_head);\n\n\tTAILQ_FOREACH(elf, &utc->elfs, link)\n\t\texidx_sz += elf->exidx_size;\n\n\tif (!exidx_sz) {\n\t\t/* The empty table from first segment will fit */\n\t\tutc->exidx_start = exe->exidx_start;\n\t\tutc->exidx_size = exe->exidx_size;\n\t\treturn TEE_SUCCESS;\n\t}\n\n\tutc->mobj_exidx = alloc_ta_mem(exidx_sz);\n\tif (!utc->mobj_exidx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\texidx = ROUNDUP(last_elf->load_addr + last_elf->mobj_code->size,\n\t\t\tCORE_MMU_USER_CODE_SIZE);\n\tres = vm_map(utc, &exidx, exidx_sz, TEE_MATTR_UR | TEE_MATTR_PRW,\n\t\t     utc->mobj_exidx, 0);\n\tif (res)\n\t\tgoto err;\n\tDMSG(\"New EXIDX table mapped at 0x%\" PRIxVA \" size %zu\",\n\t     exidx, exidx_sz);\n\n\tp = (void *)exidx;\n\tTAILQ_FOREACH(elf, &utc->elfs, link) {\n\t\tvoid *e_exidx = (void *)(elf->exidx_start + elf->load_addr);\n\t\tsize_t e_exidx_sz = elf->exidx_size;\n\t\tint32_t offs = (int32_t)((vaddr_t)e_exidx - (vaddr_t)p);\n\n\t\tmemcpy(p, e_exidx, e_exidx_sz);\n\t\tres = relocate_exidx(p, e_exidx_sz, offs);\n\t\tif (res)\n\t\t\tgoto err;\n\t\tp += e_exidx_sz;\n\t}\n\n\t/*\n\t * Drop privileged mode permissions. Normally we should keep\n\t * TEE_MATTR_PR because the code that accesses this table runs in\n\t * privileged mode. However, privileged read is always enabled if\n\t * unprivileged read is enabled, so it doesn't matter. For consistency\n\t * with other ELF section mappings, let's clear all the privileged\n\t * permission bits.\n\t */\n\tres = vm_set_prot(utc, exidx,\n\t\t\t  ROUNDUP(exidx_sz, SMALL_PAGE_SIZE),\n\t\t\t  TEE_MATTR_UR);\n\tif (res)\n\t\tgoto err;\n\n\tutc->exidx_start = exidx - utc->load_addr;\n\tutc->exidx_size = exidx_sz;\n\n\treturn TEE_SUCCESS;\nerr:\n\tmobj_free(utc->mobj_exidx);\n\tutc->mobj_exidx = NULL;\n\treturn res;\n}\n\n#else /* CFG_UNWIND */\n\nstatic TEE_Result set_exidx(struct user_ta_ctx *utc __unused)\n{\n\treturn TEE_SUCCESS;\n}\n\n#endif /* CFG_UNWIND */\n\nTEE_Result tee_ta_init_user_ta_session(const TEE_UUID *uuid,\n\t\t\t\t       struct tee_ta_session *s)\n{\n\tTEE_Result res;\n\tstruct user_ta_ctx *utc = NULL;\n\tstruct ta_head *ta_head;\n\tstruct user_ta_elf *exe;\n\tstruct user_ta_elf *elf;\n\n\t/* Register context */\n\tutc = calloc(1, sizeof(struct user_ta_ctx));\n\tif (!utc)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\tTAILQ_INIT(&utc->open_sessions);\n\tTAILQ_INIT(&utc->cryp_states);\n\tTAILQ_INIT(&utc->objects);\n\tTAILQ_INIT(&utc->storage_enums);\n\tTAILQ_INIT(&utc->elfs);\n\n\t/*\n\t * Set context TA operation structure. It is required by generic\n\t * implementation to identify userland TA versus pseudo TA contexts.\n\t */\n\tset_ta_ctx_ops(&utc->ctx);\n\n\t/*\n\t * Create entry for the main executable\n\t */\n\texe = ta_elf(uuid, utc);\n\tif (!exe) {\n\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\tgoto err;\n\t}\n\n\t/*\n\t * Load binaries and map them into the TA virtual memory. load_elf()\n\t * may add external libraries to the list, so the loop will end when\n\t * all the dependencies are satisfied or an error occurs.\n\t */\n\tTAILQ_FOREACH(elf, &utc->elfs, link) {\n\t\tres = load_elf(&elf->uuid, utc);\n\t\tif (res)\n\t\t\tgoto err;\n\t}\n\n\t/*\n\t * Perform relocations and apply final memory attributes\n\t */\n\tTAILQ_FOREACH(elf, &utc->elfs, link) {\n\t\tDMSG(\"Processing relocations in %pUl\", (void *)&elf->uuid);\n\t\tres = elf_process_rel(elf->elf_state, elf->load_addr);\n\t\tif (res)\n\t\t\tgoto err;\n\t\tres = set_seg_prot(utc, elf);\n\t\tif (res)\n\t\t\tgoto err;\n\t}\n\n\tutc->load_addr = exe->load_addr;\n\tres = set_exidx(utc);\n\tif (res)\n\t\tgoto err;\n\n\tta_head = (struct ta_head *)(vaddr_t)utc->load_addr;\n\n\tif (memcmp(&ta_head->uuid, uuid, sizeof(TEE_UUID)) != 0) {\n\t\tres = TEE_ERROR_SECURITY;\n\t\tgoto err;\n\t}\n\n\tif (ta_head->flags & ~TA_FLAGS_MASK) {\n\t\tEMSG(\"Invalid TA flag(s) 0x%\" PRIx32,\n\t\t\tta_head->flags & ~TA_FLAGS_MASK);\n\t\tres = TEE_ERROR_BAD_FORMAT;\n\t\tgoto err;\n\t}\n\n\tutc->ctx.flags = ta_head->flags;\n\tutc->ctx.uuid = ta_head->uuid;\n\tutc->entry_func = ta_head->entry.ptr64;\n\tutc->ctx.ref_count = 1;\n\tcondvar_init(&utc->ctx.busy_cv);\n\tTAILQ_INSERT_TAIL(&tee_ctxes, &utc->ctx, link);\n\ts->ctx = &utc->ctx;\n\n\tfree_elf_states(utc);\n\ttee_mmu_set_ctx(NULL);\n\treturn TEE_SUCCESS;\n\nerr:\n\tfree_elf_states(utc);\n\ttee_mmu_set_ctx(NULL);\n\tfree_utc(utc);\n\treturn res;\n}\n"], "fixing_code": ["// SPDX-License-Identifier: BSD-2-Clause\n/*\n * Copyright (c) 2014, STMicroelectronics International N.V.\n * Copyright (c) 2015-2017 Linaro Limited\n */\n\n#include <assert.h>\n#include <compiler.h>\n#include <ctype.h>\n#include <initcall.h>\n#include <keep.h>\n#include <kernel/panic.h>\n#include <kernel/tee_misc.h>\n#include <kernel/tee_ta_manager.h>\n#include <kernel/thread.h>\n#include <kernel/user_ta.h>\n#include <mm/core_memprot.h>\n#include <mm/core_mmu.h>\n#include <mm/mobj.h>\n#include <mm/pgt_cache.h>\n#include <mm/tee_mm.h>\n#include <mm/tee_mmu.h>\n#include <mm/tee_pager.h>\n#include <signed_hdr.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <sys/queue.h>\n#include <ta_pub_key.h>\n#include <tee/tee_cryp_utl.h>\n#include <tee/tee_obj.h>\n#include <tee/tee_svc_cryp.h>\n#include <tee/tee_svc.h>\n#include <tee/tee_svc_storage.h>\n#include <tee/uuid.h>\n#include <trace.h>\n#include <types_ext.h>\n#include <utee_defines.h>\n#include <util.h>\n\n#include \"elf_common.h\"\n#include \"elf_load.h\"\n#include \"elf_load_dyn.h\"\n\n/* ELF file used by a TA (main executable or dynamic library) */\nstruct user_ta_elf {\n\tTEE_UUID uuid;\n\tstruct elf_load_state *elf_state;\n\tstruct mobj *mobj_code;\n\tvaddr_t load_addr;\n\tvaddr_t exidx_start; /* 32-bit ELF only */\n\tsize_t exidx_size;\n\tstruct load_seg *segs;\n\tsize_t num_segs;\n\n\tTAILQ_ENTRY(user_ta_elf) link;\n};\n\nstatic void free_elfs(struct user_ta_elf_head *elfs)\n{\n\tstruct user_ta_elf *elf;\n\tstruct user_ta_elf *next;\n\n\tTAILQ_FOREACH_SAFE(elf, elfs, link, next) {\n\t\tTAILQ_REMOVE(elfs, elf, link);\n\t\tmobj_free(elf->mobj_code);\n\t\tfree(elf->segs);\n\t\tfree(elf);\n\t}\n}\n\nstatic struct user_ta_elf *find_ta_elf(const TEE_UUID *uuid,\n\t\t\t\t       struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *elf;\n\n\tTAILQ_FOREACH(elf, &utc->elfs, link)\n\t\tif (!memcmp(&elf->uuid, uuid, sizeof(*uuid)))\n\t\t\treturn elf;\n\treturn NULL;\n}\n\nstatic struct user_ta_elf *ta_elf(const TEE_UUID *uuid,\n\t\t\t\t  struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *elf;\n\n\telf = find_ta_elf(uuid, utc);\n\tif (elf)\n\t\tgoto out;\n\telf = calloc(1, sizeof(*elf));\n\tif (!elf)\n\t\tgoto out;\n\telf->uuid = *uuid;\n\n\tTAILQ_INSERT_TAIL(&utc->elfs, elf, link);\nout:\n\treturn elf;\n}\n\nstatic uint32_t elf_flags_to_mattr(uint32_t flags)\n{\n\tuint32_t mattr = 0;\n\n\tif (flags & PF_X)\n\t\tmattr |= TEE_MATTR_UX;\n\tif (flags & PF_W)\n\t\tmattr |= TEE_MATTR_UW;\n\tif (flags & PF_R)\n\t\tmattr |= TEE_MATTR_UR;\n\n\treturn mattr;\n}\n\nstruct load_seg {\n\tvaddr_t offs;\n\tuint32_t flags;\n\tvaddr_t oend;\n\tvaddr_t va;\n\tsize_t size;\n};\n\nstatic TEE_Result get_elf_segments(struct user_ta_elf *elf,\n\t\t\t\t   struct load_seg **segs_ret,\n\t\t\t\t   size_t *num_segs_ret)\n{\n\tstruct elf_load_state *elf_state = elf->elf_state;\n\tTEE_Result res;\n\tsize_t idx = 0;\n\tsize_t num_segs = 0;\n\tstruct load_seg *segs = NULL;\n\n\t/*\n\t * Add code segment\n\t */\n\twhile (true) {\n\t\tvaddr_t va;\n\t\tsize_t size;\n\t\tuint32_t flags;\n\t\tuint32_t type;\n\n\t\tres = elf_load_get_next_segment(elf_state, &idx, &va, &size,\n\t\t\t\t\t\t&flags, &type);\n\t\tif (res == TEE_ERROR_ITEM_NOT_FOUND)\n\t\t\tbreak;\n\t\tif (res != TEE_SUCCESS)\n\t\t\treturn res;\n\n\t\tif (type == PT_LOAD) {\n\t\t\tvoid *p = realloc(segs, (num_segs + 1) * sizeof(*segs));\n\n\t\t\tif (!p) {\n\t\t\t\tfree(segs);\n\t\t\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\t\t\t}\n\t\t\tsegs = p;\n\t\t\tsegs[num_segs].offs = ROUNDDOWN(va, SMALL_PAGE_SIZE);\n\t\t\tsegs[num_segs].oend = ROUNDUP(va + size,\n\t\t\t\t\t\t      SMALL_PAGE_SIZE);\n\t\t\tsegs[num_segs].flags = flags;\n\t\t\tnum_segs++;\n\t\t} else if (type == PT_ARM_EXIDX) {\n\t\t\telf->exidx_start = va;\n\t\t\telf->exidx_size = size;\n\t\t}\n\t}\n\n\tidx = 1;\n\twhile (idx < num_segs) {\n\t\tsize_t this_size = segs[idx].oend - segs[idx].offs;\n\t\tsize_t prev_size = segs[idx - 1].oend - segs[idx - 1].offs;\n\n\t\tif (core_is_buffer_intersect(segs[idx].offs, this_size,\n\t\t\t\t\t     segs[idx - 1].offs, prev_size)) {\n\t\t\t/* Merge the segments and their attributes */\n\t\t\tsegs[idx - 1].oend = MAX(segs[idx - 1].oend,\n\t\t\t\t\t\t segs[idx].oend);\n\t\t\tsegs[idx - 1].flags |= segs[idx].flags;\n\n\t\t\t/* Remove this index */\n\t\t\tmemcpy(segs + idx, segs + idx + 1,\n\t\t\t       (num_segs - idx - 1) * sizeof(*segs));\n\t\t\tnum_segs--;\n\t\t} else {\n\t\t\tidx++;\n\t\t}\n\t}\n\n\t*segs_ret = segs;\n\t*num_segs_ret = num_segs;\n\treturn TEE_SUCCESS;\n}\n\nstatic struct mobj *alloc_ta_mem(size_t size)\n{\n#ifdef CFG_PAGED_USER_TA\n\treturn mobj_paged_alloc(size);\n#else\n\tstruct mobj *mobj = mobj_mm_alloc(mobj_sec_ddr, size, &tee_mm_sec_ddr);\n\n\tif (mobj) {\n\t\tsize_t granularity = BIT(tee_mm_sec_ddr.shift);\n\n\t\t/* Round up to allocation granularity size */\n\t\tmemset(mobj_get_va(mobj, 0), 0, ROUNDUP(size, granularity));\n\t}\n\treturn mobj;\n#endif\n}\n\nstatic void init_utee_param(struct utee_params *up,\n\t\t\tconst struct tee_ta_param *p, void *va[TEE_NUM_PARAMS])\n{\n\tsize_t n;\n\n\tup->types = p->types;\n\tfor (n = 0; n < TEE_NUM_PARAMS; n++) {\n\t\tuintptr_t a;\n\t\tuintptr_t b;\n\n\t\tswitch (TEE_PARAM_TYPE_GET(p->types, n)) {\n\t\tcase TEE_PARAM_TYPE_MEMREF_INPUT:\n\t\tcase TEE_PARAM_TYPE_MEMREF_OUTPUT:\n\t\tcase TEE_PARAM_TYPE_MEMREF_INOUT:\n\t\t\ta = (uintptr_t)va[n];\n\t\t\tb = p->u[n].mem.size;\n\t\t\tbreak;\n\t\tcase TEE_PARAM_TYPE_VALUE_INPUT:\n\t\tcase TEE_PARAM_TYPE_VALUE_INOUT:\n\t\t\ta = p->u[n].val.a;\n\t\t\tb = p->u[n].val.b;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\ta = 0;\n\t\t\tb = 0;\n\t\t\tbreak;\n\t\t}\n\t\t/* See comment for struct utee_params in utee_types.h */\n\t\tup->vals[n * 2] = a;\n\t\tup->vals[n * 2 + 1] = b;\n\t}\n}\n\nstatic void update_from_utee_param(struct tee_ta_param *p,\n\t\t\tconst struct utee_params *up)\n{\n\tsize_t n;\n\n\tfor (n = 0; n < TEE_NUM_PARAMS; n++) {\n\t\tswitch (TEE_PARAM_TYPE_GET(p->types, n)) {\n\t\tcase TEE_PARAM_TYPE_MEMREF_OUTPUT:\n\t\tcase TEE_PARAM_TYPE_MEMREF_INOUT:\n\t\t\t/* See comment for struct utee_params in utee_types.h */\n\t\t\tp->u[n].mem.size = up->vals[n * 2 + 1];\n\t\t\tbreak;\n\t\tcase TEE_PARAM_TYPE_VALUE_OUTPUT:\n\t\tcase TEE_PARAM_TYPE_VALUE_INOUT:\n\t\t\t/* See comment for struct utee_params in utee_types.h */\n\t\t\tp->u[n].val.a = up->vals[n * 2];\n\t\t\tp->u[n].val.b = up->vals[n * 2 + 1];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void clear_vfp_state(struct user_ta_ctx *utc __unused)\n{\n#ifdef CFG_WITH_VFP\n\tthread_user_clear_vfp(&utc->vfp);\n#endif\n}\n\nstatic TEE_Result user_ta_enter(TEE_ErrorOrigin *err,\n\t\t\tstruct tee_ta_session *session,\n\t\t\tenum utee_entry_func func, uint32_t cmd,\n\t\t\tstruct tee_ta_param *param)\n{\n\tTEE_Result res;\n\tstruct utee_params *usr_params;\n\tuaddr_t usr_stack;\n\tstruct user_ta_ctx *utc = to_user_ta_ctx(session->ctx);\n\tTEE_ErrorOrigin serr = TEE_ORIGIN_TEE;\n\tstruct tee_ta_session *s __maybe_unused;\n\tvoid *param_va[TEE_NUM_PARAMS] = { NULL };\n\n\t/* Map user space memory */\n\tres = tee_mmu_map_param(utc, param, param_va);\n\tif (res != TEE_SUCCESS)\n\t\tgoto cleanup_return;\n\n\t/* Switch to user ctx */\n\ttee_ta_push_current_session(session);\n\n\t/* Make room for usr_params at top of stack */\n\tusr_stack = utc->stack_addr + utc->mobj_stack->size;\n\tusr_stack -= ROUNDUP(sizeof(struct utee_params), STACK_ALIGNMENT);\n\tusr_params = (struct utee_params *)usr_stack;\n\tinit_utee_param(usr_params, param, param_va);\n\n\tres = thread_enter_user_mode(func, tee_svc_kaddr_to_uref(session),\n\t\t\t\t     (vaddr_t)usr_params, cmd, usr_stack,\n\t\t\t\t     utc->entry_func, utc->is_32bit,\n\t\t\t\t     &utc->ctx.panicked, &utc->ctx.panic_code);\n\n\tclear_vfp_state(utc);\n\t/*\n\t * According to GP spec the origin should allways be set to the\n\t * TA after TA execution\n\t */\n\tserr = TEE_ORIGIN_TRUSTED_APP;\n\n\tif (utc->ctx.panicked) {\n\t\tDMSG(\"tee_user_ta_enter: TA panicked with code 0x%x\\n\",\n\t\t     utc->ctx.panic_code);\n\t\tserr = TEE_ORIGIN_TEE;\n\t\tres = TEE_ERROR_TARGET_DEAD;\n\t}\n\n\t/* Copy out value results */\n\tupdate_from_utee_param(param, usr_params);\n\n\ts = tee_ta_pop_current_session();\n\tassert(s == session);\ncleanup_return:\n\n\t/*\n\t * Clear the cancel state now that the user TA has returned. The next\n\t * time the TA will be invoked will be with a new operation and should\n\t * not have an old cancellation pending.\n\t */\n\tsession->cancel = false;\n\n\t/*\n\t * Can't update *err until now since it may point to an address\n\t * mapped for the user mode TA.\n\t */\n\t*err = serr;\n\n\treturn res;\n}\n\nstatic TEE_Result user_ta_enter_open_session(struct tee_ta_session *s,\n\t\t\tstruct tee_ta_param *param, TEE_ErrorOrigin *eo)\n{\n\treturn user_ta_enter(eo, s, UTEE_ENTRY_FUNC_OPEN_SESSION, 0, param);\n}\n\nstatic TEE_Result user_ta_enter_invoke_cmd(struct tee_ta_session *s,\n\t\t\tuint32_t cmd, struct tee_ta_param *param,\n\t\t\tTEE_ErrorOrigin *eo)\n{\n\treturn user_ta_enter(eo, s, UTEE_ENTRY_FUNC_INVOKE_COMMAND, cmd, param);\n}\n\nstatic void user_ta_enter_close_session(struct tee_ta_session *s)\n{\n\tTEE_ErrorOrigin eo;\n\tstruct tee_ta_param param = { 0 };\n\n\tuser_ta_enter(&eo, s, UTEE_ENTRY_FUNC_CLOSE_SESSION, 0, &param);\n}\n\nstatic int elf_idx(struct user_ta_ctx *utc, vaddr_t r_va, size_t r_size)\n{\n\tstruct user_ta_elf *elf;\n\tint idx = 0;\n\n\tTAILQ_FOREACH(elf, &utc->elfs, link) {\n\t\tsize_t n;\n\n\t\tfor (n = 0; n < elf->num_segs; n++)\n\t\t\tif (elf->segs[n].va == r_va &&\n\t\t\t    elf->segs[n].size == r_size)\n\t\t\t\treturn idx;\n\t\tidx++;\n\t}\n\treturn -1;\n}\n\nstatic void describe_region(struct user_ta_ctx *utc, vaddr_t va, size_t size,\n\t\t\t    char *desc, size_t desc_size)\n{\n\tint idx;\n\n\tif (!desc_size)\n\t\treturn;\n\tidx = elf_idx(utc, va, size);\n\tif (idx != -1)\n\t\tsnprintf(desc, desc_size, \"[%d]\", idx);\n\telse\n\t\tdesc[0] = '\\0';\n\tdesc[desc_size - 1] = '\\0';\n}\n\nstatic void show_elfs(struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *elf;\n\tsize_t __maybe_unused idx = 0;\n\n\tTAILQ_FOREACH(elf, &utc->elfs, link)\n\t\tEMSG_RAW(\" [%zu] %pUl @ %#\" PRIxVA, idx++,\n\t\t\t (void *)&elf->uuid, elf->load_addr);\n}\n\nstatic void user_ta_dump_state(struct tee_ta_ctx *ctx)\n{\n\tstruct user_ta_ctx *utc = to_user_ta_ctx(ctx);\n\tstruct vm_region *r;\n\tchar flags[7] = { '\\0', };\n\tchar desc[13];\n\tsize_t n = 0;\n\n\tEMSG_RAW(\" arch: %s  load address: %#\" PRIxVA \" ctx-idr: %d\",\n\t\t utc->is_32bit ? \"arm\" : \"aarch64\", utc->load_addr,\n\t\t utc->vm_info->asid);\n\tEMSG_RAW(\" stack: 0x%\" PRIxVA \" %zu\",\n\t\t utc->stack_addr, utc->mobj_stack->size);\n\tTAILQ_FOREACH(r, &utc->vm_info->regions, link) {\n\t\tpaddr_t pa = 0;\n\n\t\tif (r->mobj)\n\t\t\tmobj_get_pa(r->mobj, r->offset, 0, &pa);\n\n\t\tmattr_perm_to_str(flags, sizeof(flags), r->attr);\n\t\tdescribe_region(utc, r->va, r->size, desc, sizeof(desc));\n\t\tEMSG_RAW(\" region %zu: va %#\" PRIxVA \" pa %#\" PRIxPA\n\t\t\t \" size %#zx flags %s %s\",\n\t\t\t n, r->va, pa, r->size, flags, desc);\n\t\tn++;\n\t}\n\tshow_elfs(utc);\n}\nKEEP_PAGER(user_ta_dump_state);\n\nstatic void release_ta_memory_by_mobj(struct mobj *mobj)\n{\n\tvoid *va;\n\n\tif (!mobj)\n\t\treturn;\n\n\tva = mobj_get_va(mobj, 0);\n\tif (!va)\n\t\treturn;\n\n\tmemset(va, 0, mobj->size);\n\tcache_op_inner(DCACHE_AREA_CLEAN, va, mobj->size);\n}\n\nstatic void free_utc(struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *elf;\n\n\ttee_pager_rem_uta_areas(utc);\n\tTAILQ_FOREACH(elf, &utc->elfs, link)\n\t\trelease_ta_memory_by_mobj(elf->mobj_code);\n\trelease_ta_memory_by_mobj(utc->mobj_stack);\n\trelease_ta_memory_by_mobj(utc->mobj_exidx);\n\n\t/*\n\t * Close sessions opened by this TA\n\t * Note that tee_ta_close_session() removes the item\n\t * from the utc->open_sessions list.\n\t */\n\twhile (!TAILQ_EMPTY(&utc->open_sessions)) {\n\t\ttee_ta_close_session(TAILQ_FIRST(&utc->open_sessions),\n\t\t\t\t     &utc->open_sessions, KERN_IDENTITY);\n\t}\n\n\tvm_info_final(utc);\n\tmobj_free(utc->mobj_stack);\n\tmobj_free(utc->mobj_exidx);\n\tfree_elfs(&utc->elfs);\n\n\t/* Free cryp states created by this TA */\n\ttee_svc_cryp_free_states(utc);\n\t/* Close cryp objects opened by this TA */\n\ttee_obj_close_all(utc);\n\t/* Free emums created by this TA */\n\ttee_svc_storage_close_all_enum(utc);\n\tfree(utc);\n}\n\nstatic void user_ta_ctx_destroy(struct tee_ta_ctx *ctx)\n{\n\tfree_utc(to_user_ta_ctx(ctx));\n}\n\nstatic uint32_t user_ta_get_instance_id(struct tee_ta_ctx *ctx)\n{\n\treturn to_user_ta_ctx(ctx)->vm_info->asid;\n}\n\nstatic const struct tee_ta_ops user_ta_ops __rodata_unpaged = {\n\t.enter_open_session = user_ta_enter_open_session,\n\t.enter_invoke_cmd = user_ta_enter_invoke_cmd,\n\t.enter_close_session = user_ta_enter_close_session,\n\t.dump_state = user_ta_dump_state,\n\t.destroy = user_ta_ctx_destroy,\n\t.get_instance_id = user_ta_get_instance_id,\n};\n\n/*\n * Break unpaged attribute dependency propagation to user_ta_ops structure\n * content thanks to a runtime initialization of the ops reference.\n */\nstatic struct tee_ta_ops const *_user_ta_ops;\n\nstatic TEE_Result init_user_ta(void)\n{\n\t_user_ta_ops = &user_ta_ops;\n\n\treturn TEE_SUCCESS;\n}\nservice_init(init_user_ta);\n\nstatic void set_ta_ctx_ops(struct tee_ta_ctx *ctx)\n{\n\tctx->ops = _user_ta_ops;\n}\n\nbool is_user_ta_ctx(struct tee_ta_ctx *ctx)\n{\n\treturn ctx->ops == _user_ta_ops;\n}\n\nstatic TEE_Result check_ta_store(void)\n{\n\tconst struct user_ta_store_ops *op = NULL;\n\n\tSCATTERED_ARRAY_FOREACH(op, ta_stores, struct user_ta_store_ops)\n\t\tDMSG(\"TA store: \\\"%s\\\"\", op->description);\n\n\treturn TEE_SUCCESS;\n}\nservice_init(check_ta_store);\n\n#ifdef CFG_TA_DYNLINK\n\nstatic int hex(char c)\n{\n\tchar lc = tolower(c);\n\n\tif (isdigit(lc))\n\t\treturn lc - '0';\n\tif (isxdigit(lc))\n\t\treturn lc - 'a' + 10;\n\treturn -1;\n}\n\nstatic uint32_t parse_hex(const char *s, size_t nchars, uint32_t *res)\n{\n\tuint32_t v = 0;\n\tsize_t n;\n\tint c;\n\n\tfor (n = 0; n < nchars; n++) {\n\t\tc = hex(s[n]);\n\t\tif (c == (char)-1) {\n\t\t\t*res = TEE_ERROR_BAD_FORMAT;\n\t\t\tgoto out;\n\t\t}\n\t\tv = (v << 4) + c;\n\t}\n\t*res = TEE_SUCCESS;\nout:\n\treturn v;\n}\n\n/*\n * Convert a UUID string @s into a TEE_UUID @uuid\n * Expected format for @s is: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n * 'x' being any hexadecimal digit (0-9a-fA-F)\n */\nstatic TEE_Result parse_uuid(const char *s, TEE_UUID *uuid)\n{\n\tTEE_Result res = TEE_SUCCESS;\n\tTEE_UUID u = { 0 };\n\tconst char *p = s;\n\tsize_t i;\n\n\tif (strlen(p) != 36)\n\t\treturn TEE_ERROR_BAD_FORMAT;\n\tif (p[8] != '-' || p[13] != '-' || p[18] != '-' || p[23] != '-')\n\t\treturn TEE_ERROR_BAD_FORMAT;\n\n\tu.timeLow = parse_hex(p, 8, &res);\n\tif (res)\n\t\tgoto out;\n\tp += 9;\n\tu.timeMid = parse_hex(p, 4, &res);\n\tif (res)\n\t\tgoto out;\n\tp += 5;\n\tu.timeHiAndVersion = parse_hex(p, 4, &res);\n\tif (res)\n\t\tgoto out;\n\tp += 5;\n\tfor (i = 0; i < 8; i++) {\n\t\tu.clockSeqAndNode[i] = parse_hex(p, 2, &res);\n\t\tif (res)\n\t\t\tgoto out;\n\t\tif (i == 1)\n\t\t\tp += 3;\n\t\telse\n\t\t\tp += 2;\n\t}\n\t*uuid = u;\nout:\n\treturn res;\n}\n\nstatic TEE_Result add_elf_deps(struct user_ta_ctx *utc, char **deps,\n\t\t\t       size_t num_deps)\n{\n\tstruct user_ta_elf *libelf;\n\tTEE_Result res = TEE_SUCCESS;\n\tTEE_UUID u;\n\tsize_t n;\n\n\tfor (n = 0; n < num_deps; n++) {\n\t\tres = parse_uuid(deps[n], &u);\n\t\tif (res) {\n\t\t\tEMSG(\"Invalid dependency (not a UUID): %s\", deps[n]);\n\t\t\tgoto out;\n\t\t}\n\t\tDMSG(\"Library needed: %pUl\", (void *)&u);\n\t\tlibelf = ta_elf(&u, utc);\n\t\tif (!libelf) {\n\t\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\t\tgoto out;\n\t\t}\n\t}\nout:\n\treturn res;\n}\n\nstatic TEE_Result resolve_symbol(struct user_ta_elf_head *elfs,\n\t\t\t\t const char *name, uintptr_t *val)\n{\n\tstruct user_ta_elf *elf;\n\tTEE_Result res;\n\n\t/*\n\t * The loop naturally implements a breadth first search due to the\n\t * order in which the libraries were added.\n\t */\n\tTAILQ_FOREACH(elf, elfs, link) {\n\t\tres = elf_resolve_symbol(elf->elf_state, name, val);\n\t\tif (res == TEE_ERROR_ITEM_NOT_FOUND)\n\t\t\tcontinue;\n\t\tif (res)\n\t\t\treturn res;\n\t\t*val += elf->load_addr;\n\t\tFMSG(\"%pUl/0x%\" PRIxPTR \" %s\", (void *)&elf->uuid, *val, name);\n\t\treturn TEE_SUCCESS;\n\t}\n\n\treturn TEE_ERROR_ITEM_NOT_FOUND;\n}\n\nstatic TEE_Result add_deps(struct user_ta_ctx *utc,\n\t\t\t   struct elf_load_state *state, vaddr_t load_addr)\n{\n\tchar **deps = NULL;\n\tsize_t num_deps = 0;\n\tTEE_Result res;\n\n\tres = elf_get_needed(state, load_addr, &deps, &num_deps);\n\tif (res)\n\t\treturn res;\n\n\tres = add_elf_deps(utc, deps, num_deps);\n\tfree(deps);\n\n\treturn res;\n}\n\n#else\n\nstatic TEE_Result (*resolve_symbol)(struct user_ta_elf_head *, const char *,\n\t\t\t\t    uintptr_t *);\n\nstatic TEE_Result add_deps(struct user_ta_ctx *utc __unused,\n\t\t\t   struct elf_load_state *state __unused,\n\t\t\t   vaddr_t load_addr __unused)\n{\n\treturn TEE_SUCCESS;\n}\n\n#endif\n\nstatic TEE_Result load_elf_from_store(const TEE_UUID *uuid,\n\t\t\t\t      const struct user_ta_store_ops *ta_store,\n\t\t\t\t      struct user_ta_ctx *utc)\n{\n\tstruct user_ta_store_handle *handle = NULL;\n\tstruct elf_load_state *elf_state = NULL;\n\tstruct ta_head *ta_head;\n\tstruct user_ta_elf *exe;\n\tstruct user_ta_elf *elf;\n\tstruct user_ta_elf *prev;\n\tTEE_Result res;\n\tsize_t vasize;\n\tvoid *p;\n\tsize_t n;\n\tsize_t num_segs = 0;\n\tstruct load_seg *segs = NULL;\n\n\tres = ta_store->open(uuid, &handle);\n\tif (res)\n\t\treturn res;\n\n\telf = ta_elf(uuid, utc);\n\tif (!elf) {\n\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\tgoto out;\n\t}\n\n\texe = TAILQ_FIRST(&utc->elfs);\n\tprev = TAILQ_PREV(elf, user_ta_elf_head, link);\n\n\tres = elf_load_init(ta_store, handle, elf == exe, &utc->elfs,\n\t\t\t    resolve_symbol, &elf_state);\n\tif (res)\n\t\tgoto out;\n\telf->elf_state = elf_state;\n\n\tres = elf_load_head(elf_state,\n\t\t\t    elf == exe ? sizeof(struct ta_head) : 0,\n\t\t\t    &p, &vasize, &utc->is_32bit);\n\tif (res)\n\t\tgoto out;\n\tta_head = p;\n\n\n\telf->mobj_code = alloc_ta_mem(vasize);\n\tif (!elf->mobj_code) {\n\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\tgoto out;\n\t}\n\n\tif (elf == exe) {\n\t\t/* Ensure proper alignment of stack */\n\t\tsize_t stack_sz = ROUNDUP(ta_head->stack_size,\n\t\t\t\t\t  STACK_ALIGNMENT);\n\t\tutc->mobj_stack = alloc_ta_mem(stack_sz);\n\t\tif (!utc->mobj_stack) {\n\t\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * Map physical memory into TA virtual memory\n\t */\n\tif (elf == exe) {\n\n\t\tres = vm_info_init(utc);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\n\t\t/* Add stack segment */\n\t\tutc->stack_addr = 0;\n\t\tres = vm_map(utc, &utc->stack_addr, utc->mobj_stack->size,\n\t\t\t     TEE_MATTR_URW | TEE_MATTR_PRW, utc->mobj_stack,\n\t\t\t     0);\n\t\tif (res)\n\t\t\tgoto out;\n\t}\n\n\tres = get_elf_segments(elf, &segs, &num_segs);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\tif (prev) {\n\t\telf->load_addr = prev->load_addr + prev->mobj_code->size;\n\t\telf->load_addr = ROUNDUP(elf->load_addr,\n\t\t\t\t\t CORE_MMU_USER_CODE_SIZE);\n\t}\n\n\tfor (n = 0; n < num_segs; n++) {\n\t\tuint32_t prot = elf_flags_to_mattr(segs[n].flags) |\n\t\t\t\tTEE_MATTR_PRW;\n\n\t\tsegs[n].va = elf->load_addr - segs[0].offs + segs[n].offs;\n\t\tsegs[n].size = segs[n].oend - segs[n].offs;\n\t\tres = vm_map(utc, &segs[n].va, segs[n].size, prot,\n\t\t\t     elf->mobj_code, segs[n].offs);\n\t\tif (res)\n\t\t\tgoto out;\n\t\tif (!n) {\n\t\t\telf->load_addr = segs[0].va;\n\t\t\tDMSG(\"ELF load address %#\" PRIxVA, elf->load_addr);\n\t\t}\n\t}\n\n\ttee_mmu_set_ctx(&utc->ctx);\n\n\tres = elf_load_body(elf_state, elf->load_addr);\n\tif (res)\n\t\tgoto out;\n\n\t/* Find any external dependency (dynamically linked libraries) */\n\tres = add_deps(utc, elf_state, elf->load_addr);\nout:\n\tif (res) {\n\t\tfree(segs);\n\t} else {\n\t\telf->segs = segs;\n\t\telf->num_segs = num_segs;\n\t}\n\tta_store->close(handle);\n\t/* utc is cleaned by caller on error */\n\treturn res;\n}\n\n/* Loads a single ELF file (main executable or library) */\nstatic TEE_Result load_elf(const TEE_UUID *uuid, struct user_ta_ctx *utc)\n{\n\tTEE_Result res;\n\tconst struct user_ta_store_ops *op = NULL;\n\n\tSCATTERED_ARRAY_FOREACH(op, ta_stores, struct user_ta_store_ops) {\n\t\tDMSG(\"Lookup user TA ELF %pUl (%s)\", (void *)uuid,\n\t\t     op->description);\n\n\t\tres = load_elf_from_store(uuid, op, utc);\n\t\tif (res == TEE_ERROR_ITEM_NOT_FOUND)\n\t\t\tcontinue;\n\t\tif (res) {\n\t\t\tDMSG(\"res=0x%x\", res);\n\t\t\tcontinue;\n\t\t}\n\n\t\treturn res;\n\t}\n\n\treturn TEE_ERROR_ITEM_NOT_FOUND;\n}\n\nstatic void free_elf_states(struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *elf;\n\n\tTAILQ_FOREACH(elf, &utc->elfs, link)\n\t\t\telf_load_final(elf->elf_state);\n}\n\nstatic TEE_Result set_seg_prot(struct user_ta_ctx *utc,\n\t\t\t       struct user_ta_elf *elf)\n{\n\tTEE_Result res;\n\tsize_t n;\n\n\tfor (n = 0; n < elf->num_segs; n++) {\n\t\tstruct load_seg *seg = &elf->segs[n];\n\n\t\tres = vm_set_prot(utc, seg->va, seg->size,\n\t\t\t\t  elf_flags_to_mattr(seg->flags));\n\t\tif (res)\n\t\t\tbreak;\n\t}\n\treturn res;\n}\n\n#ifdef CFG_UNWIND\n\n/*\n * 32-bit TAs: set the address and size of the exception index table (EXIDX).\n * If the TA contains only one ELF, we point to its table. Otherwise, a\n * consolidated table is made by concatenating the tables found in each ELF and\n * adjusting their content to account for the offset relative to the original\n * location.\n */\nstatic TEE_Result set_exidx(struct user_ta_ctx *utc)\n{\n\tstruct user_ta_elf *exe;\n\tstruct user_ta_elf *elf;\n\tstruct user_ta_elf *last_elf;\n\tvaddr_t exidx;\n\tsize_t exidx_sz = 0;\n\tTEE_Result res;\n\tuint8_t *p;\n\n\tif (!utc->is_32bit)\n\t\treturn TEE_SUCCESS;\n\n\texe = TAILQ_FIRST(&utc->elfs);\n\tif (!TAILQ_NEXT(exe, link)) {\n\t\t/* We have a single ELF: simply reference its table */\n\t\tutc->exidx_start = exe->exidx_start;\n\t\tutc->exidx_size = exe->exidx_size;\n\t\treturn TEE_SUCCESS;\n\t}\n\tlast_elf = TAILQ_LAST(&utc->elfs, user_ta_elf_head);\n\n\tTAILQ_FOREACH(elf, &utc->elfs, link)\n\t\texidx_sz += elf->exidx_size;\n\n\tif (!exidx_sz) {\n\t\t/* The empty table from first segment will fit */\n\t\tutc->exidx_start = exe->exidx_start;\n\t\tutc->exidx_size = exe->exidx_size;\n\t\treturn TEE_SUCCESS;\n\t}\n\n\tutc->mobj_exidx = alloc_ta_mem(exidx_sz);\n\tif (!utc->mobj_exidx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\texidx = ROUNDUP(last_elf->load_addr + last_elf->mobj_code->size,\n\t\t\tCORE_MMU_USER_CODE_SIZE);\n\tres = vm_map(utc, &exidx, exidx_sz, TEE_MATTR_UR | TEE_MATTR_PRW,\n\t\t     utc->mobj_exidx, 0);\n\tif (res)\n\t\tgoto err;\n\tDMSG(\"New EXIDX table mapped at 0x%\" PRIxVA \" size %zu\",\n\t     exidx, exidx_sz);\n\n\tp = (void *)exidx;\n\tTAILQ_FOREACH(elf, &utc->elfs, link) {\n\t\tvoid *e_exidx = (void *)(elf->exidx_start + elf->load_addr);\n\t\tsize_t e_exidx_sz = elf->exidx_size;\n\t\tint32_t offs = (int32_t)((vaddr_t)e_exidx - (vaddr_t)p);\n\n\t\tmemcpy(p, e_exidx, e_exidx_sz);\n\t\tres = relocate_exidx(p, e_exidx_sz, offs);\n\t\tif (res)\n\t\t\tgoto err;\n\t\tp += e_exidx_sz;\n\t}\n\n\t/*\n\t * Drop privileged mode permissions. Normally we should keep\n\t * TEE_MATTR_PR because the code that accesses this table runs in\n\t * privileged mode. However, privileged read is always enabled if\n\t * unprivileged read is enabled, so it doesn't matter. For consistency\n\t * with other ELF section mappings, let's clear all the privileged\n\t * permission bits.\n\t */\n\tres = vm_set_prot(utc, exidx,\n\t\t\t  ROUNDUP(exidx_sz, SMALL_PAGE_SIZE),\n\t\t\t  TEE_MATTR_UR);\n\tif (res)\n\t\tgoto err;\n\n\tutc->exidx_start = exidx - utc->load_addr;\n\tutc->exidx_size = exidx_sz;\n\n\treturn TEE_SUCCESS;\nerr:\n\tmobj_free(utc->mobj_exidx);\n\tutc->mobj_exidx = NULL;\n\treturn res;\n}\n\n#else /* CFG_UNWIND */\n\nstatic TEE_Result set_exidx(struct user_ta_ctx *utc __unused)\n{\n\treturn TEE_SUCCESS;\n}\n\n#endif /* CFG_UNWIND */\n\nTEE_Result tee_ta_init_user_ta_session(const TEE_UUID *uuid,\n\t\t\t\t       struct tee_ta_session *s)\n{\n\tTEE_Result res;\n\tstruct user_ta_ctx *utc = NULL;\n\tstruct ta_head *ta_head;\n\tstruct user_ta_elf *exe;\n\tstruct user_ta_elf *elf;\n\n\t/* Register context */\n\tutc = calloc(1, sizeof(struct user_ta_ctx));\n\tif (!utc)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\tTAILQ_INIT(&utc->open_sessions);\n\tTAILQ_INIT(&utc->cryp_states);\n\tTAILQ_INIT(&utc->objects);\n\tTAILQ_INIT(&utc->storage_enums);\n\tTAILQ_INIT(&utc->elfs);\n\n\t/*\n\t * Set context TA operation structure. It is required by generic\n\t * implementation to identify userland TA versus pseudo TA contexts.\n\t */\n\tset_ta_ctx_ops(&utc->ctx);\n\n\t/*\n\t * Create entry for the main executable\n\t */\n\texe = ta_elf(uuid, utc);\n\tif (!exe) {\n\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\tgoto err;\n\t}\n\n\t/*\n\t * Load binaries and map them into the TA virtual memory. load_elf()\n\t * may add external libraries to the list, so the loop will end when\n\t * all the dependencies are satisfied or an error occurs.\n\t */\n\tTAILQ_FOREACH(elf, &utc->elfs, link) {\n\t\tres = load_elf(&elf->uuid, utc);\n\t\tif (res)\n\t\t\tgoto err;\n\t}\n\n\t/*\n\t * Perform relocations and apply final memory attributes\n\t */\n\tTAILQ_FOREACH(elf, &utc->elfs, link) {\n\t\tDMSG(\"Processing relocations in %pUl\", (void *)&elf->uuid);\n\t\tres = elf_process_rel(elf->elf_state, elf->load_addr);\n\t\tif (res)\n\t\t\tgoto err;\n\t\tres = set_seg_prot(utc, elf);\n\t\tif (res)\n\t\t\tgoto err;\n\t}\n\n\tutc->load_addr = exe->load_addr;\n\tres = set_exidx(utc);\n\tif (res)\n\t\tgoto err;\n\n\tta_head = (struct ta_head *)(vaddr_t)utc->load_addr;\n\n\tif (memcmp(&ta_head->uuid, uuid, sizeof(TEE_UUID)) != 0) {\n\t\tres = TEE_ERROR_SECURITY;\n\t\tgoto err;\n\t}\n\n\tif (ta_head->flags & ~TA_FLAGS_MASK) {\n\t\tEMSG(\"Invalid TA flag(s) 0x%\" PRIx32,\n\t\t\tta_head->flags & ~TA_FLAGS_MASK);\n\t\tres = TEE_ERROR_BAD_FORMAT;\n\t\tgoto err;\n\t}\n\n\tutc->ctx.flags = ta_head->flags;\n\tutc->ctx.uuid = ta_head->uuid;\n\tutc->entry_func = ta_head->entry.ptr64;\n\tutc->ctx.ref_count = 1;\n\tcondvar_init(&utc->ctx.busy_cv);\n\tTAILQ_INSERT_TAIL(&tee_ctxes, &utc->ctx, link);\n\ts->ctx = &utc->ctx;\n\n\tfree_elf_states(utc);\n\ttee_mmu_set_ctx(NULL);\n\treturn TEE_SUCCESS;\n\nerr:\n\tfree_elf_states(utc);\n\ttee_mmu_set_ctx(NULL);\n\tfree_utc(utc);\n\treturn res;\n}\n"], "filenames": ["core/arch/arm/kernel/user_ta.c"], "buggy_code_start_loc": [200], "buggy_code_end_loc": [202], "fixing_code_start_loc": [200], "fixing_code_end_loc": [206], "type": "CWE-189", "message": "Linaro/OP-TEE OP-TEE 3.3.0 and earlier is affected by: Rounding error. The impact is: Potentially leaking code and/or data from previous Trusted Application. The component is: optee_os. The fixed version is: 3.4.0 and later.", "other": {"cve": {"id": "CVE-2019-1010294", "sourceIdentifier": "josh@bress.net", "published": "2019-07-15T18:15:11.383", "lastModified": "2019-07-16T16:13:05.490", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Linaro/OP-TEE OP-TEE 3.3.0 and earlier is affected by: Rounding error. The impact is: Potentially leaking code and/or data from previous Trusted Application. The component is: optee_os. The fixed version is: 3.4.0 and later."}, {"lang": "es", "value": "OP-TEE versi\u00f3n 3.3.0 y anteriores de Linaro/OP-TEE, est\u00e1 afectado por: Error de redondeo. El impacto es: Potencialmente filtrado de c\u00f3digo y/o datos de Aplicaciones de Confianza previas. El componente es: optee_os. La versi\u00f3n corregida es: 3.4.0 y posteriores."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-189"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linaro:op-tee:*:*:*:*:*:*:*:*", "versionEndIncluding": "3.3.0", "matchCriteriaId": "BE2AA919-55C6-4AE4-B611-EBEB412B2370"}]}]}], "references": [{"url": "https://github.com/OP-TEE/optee_os/commit/7e768f8a473409215fe3fff8f6e31f8a3a0103c6", "source": "josh@bress.net", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/OP-TEE/optee_os/commit/7e768f8a473409215fe3fff8f6e31f8a3a0103c6"}}